import{_ as r}from"./plugin-vue_export-helper-c27b6911.js";import{r as u,o as k,c as d,d as b,a as n,e as t,w as a,b as s,f as c}from"./app-2a2d189a.js";const m="/assets/figure3-1-9218b91c.png",v="/assets/figure3-2-8c08aa0c.png",g="/assets/figure3-3-0140f96a.png",h="/assets/figure3-4-ea5e2a4f.png",f="/assets/figure3-5-ed1c0bdd.png",_="/assets/figure3-6-73079cbe.png",y="/assets/figure3-7-ab448955.png",x="/assets/figure3-8-b82a8adb.png",w="/assets/figure3-9-db480d38.png",D="/assets/figure3-10-5616dfce.png",M="/assets/figure3-11-2cb3d3ab.png",U="/assets/figure3-12-2b2cf734.png",S="/assets/figure3-13-62e8576e.png",P="/assets/figure3-14-e8fe7d97.png",C="/assets/figure3-15-1fd6f152.png",G="/assets/figure3-16-425962dd.png",I="/assets/figure3-18-0ad5299a.png",A="/assets/figure3-19-9f330035.png",z="/assets/figure3-20-5dc74f6b.png",R="/assets/figure3-21-fd952a49.png",W="/assets/figure3-22-33854cf3.png",H="/assets/figure3-23-12fd0872.png",K="/assets/figure3-24-e807e169.png",T="/assets/figure3-25-ee507c4b.png",E="/assets/figure3-26-f2f5974c.png",N="/assets/figure3-27-577fb85a.png",O="/assets/figure3-28-d53830b8.png",$="/assets/figure3-29-a83ab2a2.png",B="/assets/figure3-30-e8f7eb16.png",F={},L=n("h1",{id:"c-第三章节",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#c-第三章节","aria-hidden":"true"},"#"),s(" C-第三章节")],-1),q=n("p",null,"C-第三章节",-1),X={class:"table-of-contents"},V=c('<h2 id="简单介绍主要是基础" tabindex="-1"><a class="header-anchor" href="#简单介绍主要是基础" aria-hidden="true">#</a> 简单介绍主要是基础</h2><div class="hint-container info"><p class="hint-container-title">说明</p><p>主要是各种搜索找的学习；</p><p>主题：CUDA核心GPU编程</p><p>前置条件：</p><ul><li>应具备C++编程知识</li><li>需理解内存管理，如malloc和free</li><li>理解STL及其模板机制</li><li>需配置NVIDIA显卡，型号需为900系列或更高</li><li>所用扩展要求版本为11或更新</li><li>编译器版本不低于11</li><li>CMake版本需在3.18以上</li></ul></div><div class="hint-container info"><p class="hint-container-title">问题</p><ul><li><p>第二章是grid and block的理论限制数量大小：</p></li><li><p>在本章会重点介绍指令吞吐量</p></li><li><p><mark>每个SM上可以常驻的线程数量？</mark></p></li><li><p>每个Kepler SM包括4个线程束调度器和8个指令调度器，以确保在单一的SM上同时发送和执行4个线程束。</p></li><li><p>Kepler K20X架构（计算能力3.5）可以同时在每个SM上调度64个线程束，即在一个SM上可同时常驻2048个线程。</p></li><li><p>所以？因为架构不一样吗？</p></li><li></li><li><p><mark>GPU构成</mark></p></li><li><p>每个SM是一个硬件，多个SM构成一个GPU；</p></li><li><p>所以就是说，自己设计线程块，然后线程块挪移到SM上进行执行?</p></li><li><p>内核函数的执行 grid 对应：GPU</p></li><li><p>block 对应：SM(所以每个SM都是一个小管家？)</p></li><li><p>thread 对应: cuda core</p></li><li><p><mark>核函数启动</mark></p></li><li><p>1-线程块被分配到可用的SM上执行并且线程块一旦被调度到一个SM上，其中的线程只会在那个指定的SM上并发执行</p><ul><li>1.1-这个是因为 一个block 可能 SM不能一下子执行全部threads</li><li>1.2- 这个分配是按照随机性or看到可用性，就是说不同的block可能被分配到同一个SM在同一时间，一个SM可以容纳多个线程块</li></ul></li><li><p>2-然后给block分配共享内存和寄存器；CUDA将这些资源分配到SM中的所有常驻线程里；</p><ul><li>2.1-因此，这些有限的资源限制了在SM上活跃的线程束数量，活跃的线程束数量对应于SM上的并行量。</li><li>2.2-这个是说的真正上的 时间上的并行 不是并发了；</li></ul></li><li><p>3-每个SM都将分配给它的线程块划分到包含32个线程的线程束中，然后在可用的硬件资源上调度执行。</p></li><li><p>4-因为先分配了资源，然后划分了warp，但是可能SM硬件一下子执行的warp数量有限，所以先执行一些warp，然后如果此warp进行执行读数据之类的，那么立刻切换已经分配了资源的warp进行调度(warp调度器)；</p></li><li><p><mark>对于SM</mark></p></li><li><p>寄存器和共享内存是SM中的稀缺资源</p></li><li><p>共享内存被分配在SM上的常驻线程块中(这个的意思是说一个SM上会被分配很多的block来执行，但是由于资源限制，会先执行一些or一个block，然后这样的block被称为常驻线程块？然后分配给其共享内存和寄存器资源？)</p></li><li><p>当有一个block来调度这进行执行的时候，会分配给其 上面的两个资源；</p></li><li><p>也就是说如果一个block很大那么其一个SM也完不成一个block的话就不能运行的；嗯就是这样</p></li><li><p>这样的话：线程块中的线程通过这些资源可以进行相互的合作和通信。 就是一个block内的线程就是这样交互的；</p></li><li><p>但是由于硬件原因：一个block内的threads并不是并行的，而是看资源限制；</p></li><li><p><mark>对于warp</mark></p></li><li><p>32线程为一个warp</p></li><li><p>线程束中的所有线程同时执行相同的指令。</p></li><li><p>尽管线程块里的线程束可以任意顺序调度，但活跃的线程束的数量还是会由SM的资<br> 源所限制。当线程束由于任何理由闲置的时候（如等待从设备内存中读取数值），SM可<br> 以从同一SM上的常驻线程块中调度其他可用的线程束。在并发的线程束间切换并没有开<br> 销，因为硬件资源已经被分配到了SM上的所有线程和块中，所以最新被调度的线程束的<br> 状态已经存储在SM上。</p></li><li><p><mark>对于thread</mark></p></li><li><p>每个线程都有自己的指令地址计数器和寄存器状态，利用自身的数据执行当前的指令</p></li><li><p>每个线程可以有一个独立的执行路径</p></li><li><p>上面三个都是消耗的寄存器资源吗？</p></li></ul></div><h2 id="第3章-cuda执行模型" tabindex="-1"><a class="header-anchor" href="#第3章-cuda执行模型" aria-hidden="true">#</a> 第3章 CUDA执行模型</h2><p>CUDA Execution Model</p><ul><li><p><mark>WHAT’S IN THIS CHAPTER?</mark></p></li><li><p>Developing kernels with a profi le-driven approach 使用配置文件驱动方法开发内核</p></li><li><p>Understanding the nature of warp execution 理解线程束执行的本质</p></li><li><p>Exposing more parallelism to the GPU增大GPU的并行性</p></li><li><p>Mastering grid and block confi guration heuristics掌握网格和线程块的启发式配置</p></li><li><p>Learning various CUDA performance metrics and events学习多种CUDA的性能指标和事件</p></li><li><p>Probing dynamic parallelism and nested execution了解动态并行与嵌套执行</p></li><li><p>通过上一章的练习，你已经学会了如何在网格和线程块中组织线程以获得最佳的性<br> 能。尽管可以通过反复试验找到最佳的执行配置，但你可能仍然会感到疑惑，为什么选择<br> 这样的执行配置会更好。你可能想知道是否有一些选择网格和块配置的准则。本章将会回<br> 答这些问题，并从硬件方面深入介绍内核启动配置和性能分析的信息。(在上一章节，虽然<br> 可能是一个线程负责一个数据，且是基本是按照数据的规模进行在一定的线程数量限制内进行<br> 的线程组织规划模式，所以？)</p></li></ul><h2 id="_3-1-cuda执行模型概述" tabindex="-1"><a class="header-anchor" href="#_3-1-cuda执行模型概述" aria-hidden="true">#</a> 3.1 CUDA执行模型概述</h2><p>INTRODUCING THE CUDA EXECUTION MODEL</p><ul><li>一般来说，执行模型会提供一个操作视图，说明如何在特定的计算架构上执行指令。<br> CUDA执行模型揭示了GPU并行架构的抽象视图，使我们能够据此分析线程的并发。在第<br> 2章里，已经介绍了CUDA编程模型中两个主要的抽象概念：内存层次结构和线程层次结<br> 构。它们能够控制大规模并行GPU。因此，CUDA执行模型能够提供有助于在指令吞吐量<br> 和内存访问方面编写高效代码的见解。</li><li>在本章会重点介绍指令吞吐量，在第4章和第5章里会介绍更多的关于高效内存访问的内容。</li><li>在这章，指令吞吐量？</li></ul><h3 id="_3-1-1-gpu架构概述" tabindex="-1"><a class="header-anchor" href="#_3-1-1-gpu架构概述" aria-hidden="true">#</a> 3.1.1 GPU架构概述</h3><p>GPU Architecture Overview</p><ul><li><p>GPU架构是围绕一个流式多处理器（SM）的可扩展阵列搭建的。可以通过复制这种<br> 架构的构建块来实现GPU的硬件并行。图3-1说明了Fermi SM的关键组件：<br> CUDA核心<br> 共享内存/一级缓存<br> 寄存器文件<br> 加载/存储单元<br> 特殊功能单元<br> 线程束调度器</p></li><li><p>GPU中的每一个SM都能支持数百个线程并发执行，每个GPU通常有多个SM，所以在<br> 一个GPU上并发执行数千个线程是有可能的。当启动一个内核网格时，它的线程块被分布<br> 在了可用的SM上来执行。线程块一旦被调度到一个SM上，其中的线程只会在那个指定的<br> SM上并发执行。多个线程块可能会被分配到同一个SM上，而且是根据SM资源的可用性<br> 进行调度的。同一线程中的指令利用指令级并行性进行流水线化，另外，在CUDA中已经<br> 介绍了线程级并行。</p></li><li><p>CUDA采用单指令多线程（SIMT）架构来管理和执行线程，每32个线程为一组，被称<br> 为线程束（warp）。线程束中的所有线程同时执行相同的指令。每个线程都有自己的指<br> 令地址计数器和寄存器状态，利用自身的数据执行当前的指令。每个SM都将分配给它的<br> 线程块划分到包含32个线程的线程束中，然后在可用的硬件资源上调度执行。</p></li><li><p>SIMT架构与SIMD（单指令多数据）架构相似。两者都是将相同的指令广播给多个执<br> 行单元来实现并行。一个关键的区别是SIMD要求同一个向量中的所有元素要在一个统一<br> 的同步组中一起执行，而SIMT允许属于同一线程束的多个线程独立执行。尽管一个线程<br> 束中的所有线程在相同的程序地址上同时开始执行，但是单独的线程仍有可能有不同的行<br> 为。SIMT确保可以编写独立的线程级并行代码、标量线程以及用于协调线程的数据并行<br> 代码。</p></li><li><p>SIMT模型包含3个SIMD所不具备的关键特征。<br> 每个线程都有自己的指令地址计数器<br> 每个线程都有自己的寄存器状态<br> ·每个线程可以有一个独立的执行路径</p></li></ul><figure><img src="'+m+'" alt="figure3-1" tabindex="0" loading="lazy"><figcaption>figure3-1</figcaption></figure><ul><li><mark>一个神奇的数字：32</mark></li><li>32在CUDA程序里是一个神奇的数字。它来自于硬件系统，也对软件的性能有着重要<br> 的影响。</li><li>从概念上讲，它是SM用SIMD方式所同时处理的工作粒度。优化工作负载以适应线程<br> 束（一组有32个线程）的边界，一般这样会更有效地利用GPU计算资源。在后面的章节中<br> 将会介绍更多这方面的内容。</li></ul><br><ul><li>一个线程块只能在一个SM上被调度。一旦线程块在一个SM上被调度，就会保存在该<br> SM上直到执行完成。在同一时间，一个SM可以容纳多个线程块。图3-2从逻辑视图和硬件视图的角度描述了CUDA编程对应的组件。</li></ul><figure><img src="'+v+'" alt="figure3-2" tabindex="0" loading="lazy"><figcaption>figure3-2</figcaption></figure><ul><li><p>在SM中，共享内存和寄存器是非常重要的资源。共享内存被分配在SM上的常驻线程<br> 块中(这个的意思是说一个SM上会被分配很多的block来执行，但是由于资源限制，会先执行<br> 一些or一个block，然后这样的block被称为常驻线程块？然后分配给其共享内存和寄存器资源？)<br> 寄存器在线程中被分配。线程块中的线程通过这些资源可以进行相互的合作和通<br> 信。尽管线程块里的所有线程都可以逻辑地并行运行，但是并不是所有线程都可以同时在<br> 物理层面执行。因此，线程块里的不同线程可能会以不同的速度前进。(所以同步是为了<br> 等待同一block内的不同warp的线程进行同步？是这样吧，因为硬件资源限制，一个block<br> 内有多个warp，然后有的warp执行好了，但是有的还没有被warp调度器调度，所以同步)</p></li><li><p>在并行线程中共享数据可能会引起竞争：多个线程使用未定义的顺序访问同一个数<br> 据，从而导致不可预测的程序行为。CUDA提供了一种用来同步线程块里的线程的方法，<br> 从而保证所有线程在进一步动作之前都达到执行过程中的一个特定点。然而，没有提供块<br> 间同步的原语。</p></li><li><p>尽管线程块里的线程束可以任意顺序调度，但活跃的线程束的数量还是会由SM的资<br> 源所限制。当线程束由于任何理由闲置的时候（如等待从设备内存中读取数值），SM可<br> 以从同一SM上的常驻线程块中调度其他可用的线程束。在并发的线程束间切换并没有开<br> 销，因为硬件资源已经被分配到了SM上的所有线程和块中，所以最新被调度的线程束的<br> 状态已经存储在SM上。</p></li><li><p><mark>SM：GPU架构的核心</mark></p></li><li><p>流式多处理器（SM）SM是GPU架构的核心。寄存器和共享内存是SM中的稀缺资源。CUDA将这些资源分配到SM中的所有常驻线程里。因此，这些有限的资源限制了在SM上活跃的线程束数量，活跃的线程束数量对应于SM上的并行量。了解一些SM硬件组成的基本知识，有助于组织线程和配置内核执行以获得最佳的性能。</p></li><li><p>在下一节，将会介绍NVIDIA中的两个GPU架构：Fermi架构和Kepler架构，重点介绍<br> 它们的<mark>硬件资源</mark>。你将会通过示例和练习来学习它们的硬件特征，这有助于提高对内核性<br> 能的理解</p></li></ul><h3 id="_3-1-2-fermi架构" tabindex="-1"><a class="header-anchor" href="#_3-1-2-fermi架构" aria-hidden="true">#</a> 3.1.2 Fermi架构</h3><p>The Fermi Architecture</p><ul><li>Fermi架构是第一个完整的GPU计算架构，能够为大多数高性能计算应用提供所需要<br> 的功能。Fermi已经被广泛应用于加速生产工作负载中。</li><li>图3-3所示为Fermi架构的逻辑框图，其重点是GPU计算，它在很大程度上忽略了图形<br> 具体组成部分。Fermi的特征是多达512个加速器核心，这被称为CUDA核心。每个CUDA<br> 核心都有一个全流水线的整数算术逻辑单元（ALU）和一个浮点运算单元（FPU），在这<br> 里每个时钟周期执行一个整数或是浮点数指令。CUDA核心被组织到16个SM中，每一个<br> SM含有32个CUDA核心。Fermi架构有6个384位的GDDR5 DRAM存储器接口，支持多达<br> 6GB的全局机载内存，这是许多应用程序关键的计算资源。主机接口通过PCIe总线将GPU<br> 与CPU相连。GigaThread引擎（图示左侧第三部分）是一个全局调度器，用来分配线程块<br> 到SM线程束调度器上。(这样看的话其实真正并行的某时刻仅仅有512threads)</li></ul><figure><img src="'+g+'" alt="figure3-3" tabindex="0" loading="lazy"><figcaption>figure3-3</figcaption></figure><ul><li><p>Fermi架构包含一个耦合的768 KB的二级缓存，被16个SM所共享。在图3-3中，一个<br> 垂直矩形条表示一个SM，包含了以下内容：</p><ul><li>执行单元（CUDA核心）</li><li>调度线程束的调度器和调度单元</li><li>共享内存、寄存器文件和一级缓存(只有共享内存是可编程吗？)</li></ul></li><li><p>每一个多处理器有16个加载/存储单元（如图3-1所示），允许每个时钟周期内有16个<br> 线程（线程束的一半）计算源地址和目的地址。特殊功能单元（SFU）执行固有指令，如正弦、余弦、平方根和插值。每个SFU在每个时钟周期内的每个线程上执行一个固有指令。</p></li><li><p>每个SM有两个线程束调度器和两个指令调度单元。当一个线程块被指定给一个SM<br> 时，线程块中的所有线程被分成了线程束。两个线程束调度器选择两个线程束，再把一个<br> 指令从线程束中发送到一个组上，组里有16个CUDA核心、16个加载/存储单元或4个特殊<br> 功能单元（如图3-4所示）。Fermi架构，计算性能2.x，可以在每个SM上同时处理48个线<br> 程束，即可在一个SM上同时常驻1536个线程。（？？在这个到底什么意思？？）</p></li><li><p><mark>？？在这个到底什么意思？？</mark></p></li><li><p>如果一个流多处理器（SM）可以同时处理 48 个线程束，由于每个线程束有 32 个线程，那么总共可以同时处理的线程数量就是 48×32 = 1536 个线程。</p></li><li><p>“常驻” 意味着这些线程可以在这个 SM 上同时处于活跃状态，等待被调度执行。这种设计使得 GPU 能够并行处理大量的线程，提高计算性能。</p></li><li><p>这是因为资源限制，可用分配给48个warp资源，然后因为warp调度没有消耗，所以这样说；可用常驻1536个线程；</p></li><li><p>其实如果 共享 内存 一个 block分配 比较不合理的话，好像也没影响；也不是，如果一个512个线程的block分配了SM全部的共享内存，那么可能常驻线程数量就是512个了；</p></li><li><p>好像也不是，上面这个解释是对应：早期的架构的；</p></li><li><p><mark>Fermi架构，计算性能2.x</mark></p></li><li><p>可能对于这个架构，就是每个SM有 1536 个 核心？？？？</p></li></ul><figure><img src="'+h+'" alt="figure3-4" tabindex="0" loading="lazy"><figcaption>figure3-4</figcaption></figure><ul><li>Fermi架构的一个关键特征是有一个64KB的片内可配置存储器，它在共享内存与一级<br> 缓存之间进行分配。对于许多高性能的应用程序，共享内存是影响性能的一个关键因素。<br> 共享内存允许一个块上的线程相互合作，这有利于芯片内数据的广泛重用，并大大降低了<br> 片外的通信量。CUDA提供了一个运行时API，它可以用来调整共享内存和一级缓存的数<br> 量。根据给定的内核中共享内存或缓存的使用修改片内存储器的配置，可以提高性能。这<br> 一部分内容将会在第4章和第5章详细介绍。</li><li>Fermi架构也支持并发内核执行：在相同的GPU上执行相同应用程序的上下文中，同<br> 时启动多个内核。并发内核执行允许执行一些小的内核程序来充分利用GPU，如图3-5所<br> 示。Fermi架构允许多达16个内核同时在设备上运行。从程序员的角度看，并发内核执行<br> 使GPU表现得更像MIMD架构。</li></ul><h3 id="_3-1-3-kepler架构" tabindex="-1"><a class="header-anchor" href="#_3-1-3-kepler架构" aria-hidden="true">#</a> 3.1.3 Kepler架构</h3><p>The Kepler Architecture</p><ul><li>发布于2012年秋季的Kepler GPU架构是一种快速、高效、高性能的计算架构。Kepler<br> 的特点使得混合计算更容易理解。图3-6表示了Kepler K20X芯片框图，它包含了15个SM<br> 和6个64位的内存控制器。以下是Kepler架构的3个重要的创新。 <ul><li>Enhanced SMs</li><li>Dynamic Parallelism</li><li>Hyper-Q</li></ul></li></ul><figure><img src="'+f+'" alt="figure3-5" tabindex="0" loading="lazy"><figcaption>figure3-5</figcaption></figure><figure><img src="'+_+'" alt="figure3-6" tabindex="0" loading="lazy"><figcaption>figure3-6</figcaption></figure><ul><li>Kepler K20X的关键部分是有一个新的SM单元，其包括一些结构的创新，以提高编程<br> 效率和功率效率。每个Kepler SM单元包含192个单精度CUDA核心，64个双精度单元，32<br> 个特殊功能单元（SFU）以及32个加载/存储单元（LD/ST）（如图3-7所示）。</li></ul><figure><img src="'+y+'" alt="figure3-7" tabindex="0" loading="lazy"><figcaption>figure3-7</figcaption></figure><ul><li><p>每个Kepler SM包括4个线程束调度器和8个指令调度器，以确保在单一的SM上同时发<br> 送和执行4个线程束。Kepler K20X架构（计算能力3.5）可以同时在每个SM上调度64个线程束，即在一个SM上可同时常驻2048个线程。K20X架构中寄存器文件容量达到64KB，<br> Fermi架构中只有32KB。同时，K20X还允许片内存储器在共享内存和一级缓存间有更多<br> 的分区。K20X能够提供超过1TFlop的峰值双精度计算能力，相较于Fermi的设计，功率效<br> 率提高了80%，每瓦的性能也提升了三倍。</p></li><li><p>动态并行是Kepler GPU的一个新特性，它允许GPU动态启动新的网格。有了这个特<br> 点，任一内核都能启动其他的内核，并且管理任何核间需要的依赖关系来正确地执行附加<br> 的工作。这一特点也让你更容易创建和优化递归及与数据相关的执行模式。如图3-8所<br> 示，它展示了没有动态并行时主机在GPU上启动每一个内核时的情况；有了动态并行，<br> GPU能够启动嵌套内核，消除了与CPU通信的需求。动态并行拓宽了GPU在各种学科上的<br> 适用性。动态地启动小型和中型的并行工作负载，这在以前是需要很高代价的。</p></li></ul><figure><img src="'+x+'" alt="figure3-8" tabindex="0" loading="lazy"><figcaption>figure3-8</figcaption></figure><ul><li>Hyper-Q技术增加了更多的CPU和GPU之间的同步硬件连接，以确保CPU核心能够在<br> GPU上同时运行更多的任务。因此，当使用Kepler GPU时，既可以增加GPU的利用率，也<br> 可以减少CPU的闲置时间。Fermi GPU依赖一个单一的硬件工作队列来从CPU到GPU间传<br> 送任务，这可能会导致一个单独的任务阻塞队列中在该任务之后的所有其他任务。Kepler<br> Hyper-Q消除了这个限制。如图3-9所示，Kepler GPU在主机与GPU之间提供了32个硬件工<br> 作队列。Hyper-Q保证了在GPU上有更多的并发执行，最大限度地提高了GPU的利用并提<br> 高了整体的性能。</li></ul><figure><img src="'+w+'" alt="figure3-9" tabindex="0" loading="lazy"><figcaption>figure3-9</figcaption></figure><ul><li><mark>The major architectural features for different compute capabilities are briefl y summarized in Table 3-1.</mark></li></ul><h3 id="_3-1-4-配置文件驱动优化" tabindex="-1"><a class="header-anchor" href="#_3-1-4-配置文件驱动优化" aria-hidden="true">#</a> 3.1.4 配置文件驱动优化</h3><p>Profile-Driven Optimization</p><ul><li><p>性能分析是通过检测来分析程序性能的行为：</p></li><li><p>The space (memory) or time complexity of application code 应用代码的空间（内存）或时间复杂性</p></li><li><p>The use of particular instructions特定指令的使用</p></li><li><p>The frequency and duration of function calls函数调用的频率和持续时间</p></li><li><p>性能分析是程序开发中的关键一步，特别是对于优化HPC应用程序代码。性能分析往<br> 往需要对平台的执行模型有一个基本的理解以制定应用程序的优化方法。开发一个HPC应<br> 用程序通常包括两个主要步骤：</p><ul><li>提高代码的正确性。</li><li>提高代码的性能。</li></ul></li><li><p>对于第二步，使用配置文件驱动的方法是很自然的。配置文件驱动的发展对于CUDA<br> 编程尤为重要，原因主要有以下几个方面。</p><ul><li>一个单纯的内核应用一般不会产生最佳的性能。性能分析工具能帮助你找到代码中影响性能的关键部分，也就是性能瓶颈。</li><li>CUDA将SM中的计算资源在该SM中的多个常驻线程块之间进行分配。这种分配形式导致一些资源成为了性能限制者。性能分析工具能帮助我们理解计算资源是如何被利用的。</li><li>CUDA提供了一个硬件架构的抽象，它能够让用户控制线程并发。性能分析工具可以检测和优化，并将优化可视化。</li></ul></li><li><p>性能分析工具深入洞察内核的性能，检测核函数中影响性能的瓶颈。CUDA提供了两<br> 个主要的性能分析工具：nvvp，独立的可视化分析器；nvprof，命令行分析器。</p></li><li><p>nvvp是可视化分析器，它可以可视化并优化CUDA程序的性能。这个工具会显示CPU<br> 与GPU上的程序活动的时间表，从而找到可以改善性能的机会。此外，nvvp可以分析应用<br> 程序潜在的性能瓶颈，并给出建议以消除或减少这些瓶颈。该工具既可作为一个独立的应<br> 用程序，也可作为Nsight Eclipse Edition（nsight）的一部分。</p></li><li><p>nvprof在命令行上收集和显示分析数据。nvprof是和CUDA 5一起发布的，它是从一个<br> 旧的命令行CUDA分析工具进化而来的。跟nvvp一样，它可以获得CPU与GPU上CUDA关<br> 联活动的时间表，其中包括内核执行、内存传输和CUDA的API调用。它也可以获得硬件<br> 计数器和CUDA内核的性能指标。</p></li><li><p>除了预定义的指标，还可以利用基于分析器获得的硬件计数器来自定义指标。</p></li></ul><br><ul><li><p><mark>事件和指标</mark></p></li><li><p>在CUDA性能分析中，事件是可计算的活动，它对应一个在内核执行期间被收集的硬<br> 件计数器。指标是内核的特征，它由一个或多个事件计算得到。请记住以下概念事件和指<br> 标：</p><ul><li>大多数计数器是按流式多处理器报告的，而不是按整个 GPU 报告的。</li><li>一个单一的运行只能获得几个计数器。有些计数器的获得是相互排斥的。多个性能<br> 分析运行往往需要获取所有相关的计数器。</li><li>由于GPU执行中的变化（如线程块和线程束调度指令），经重复运行，计数器值可<br> 能不是完全相同的。</li></ul></li><li><p>选择合适的性能指标以及将检测性能与理论峰值性能进行对比对于寻找内核的性能瓶<br> 颈是很重要的。在本书的示例和练习中，你将了解用命令行分析器分析内核的适当指标，以及掌握使用配置文件驱动的方法来编写高效的核函数的技巧</p></li><li><p>在本书中主要使用nvprof来提高内核性能。本书还介绍了如何选择合适的计数器和指<br> 标，并使用命令行中的nvprof来收集分析数据，以便用于设计优化策略。你还将会学习如<br> 何使用不同的计数器和指标，从多个角度分析内核。</p></li><li><p>您可能会遇到三种常见的限制内核性能的因素：</p></li><li><p>Memory bandwidth 内存带宽</p></li><li><p>Compute resources 计算资源</p></li><li><p>Instruction and memory latency 指令和内存延迟</p></li><li><p>本章主要介绍指令延迟的问题，其次会介绍一些计算资源限制的问题。后续章节将讨<br> 论其余的性能限制因素。</p></li><li><p><mark>了解硬件资源的详细信息</mark></p></li><li><p>作为一个C程序员，如果编写代码只追求正确性，那么可以忽略缓存行的大小。然<br> 而，当调整代码以获得最佳性能时，必须考虑代码结构中高速缓存的特性。</p></li><li><p>这对于CUDA C编程来说也一样。作为CUDA C程序员，如果想改善内核的性能，必<br> 须对硬件资源有一定的了解。</p></li><li><p>即使不懂硬件架构，CUDA编译器仍然能很好地优化内核，但它能做的只有这么多。<br> 即使仅掌握最基本的GPU体系架构的知识，你也能够编写出更好的代码，并且能够充分开<br> 发设备的性能.</p></li><li><p>在本章的后续部分，你将看到硬件的概念是如何与性能指标联系起来的，以及性能指<br> 标是如何被用于指导性能的</p></li></ul><h2 id="_3-2-理解线程束执行的本质" tabindex="-1"><a class="header-anchor" href="#_3-2-理解线程束执行的本质" aria-hidden="true">#</a> 3.2 理解线程束执行的本质</h2><p>UNDERSTANDING THE NATURE OF WARP EXECUTION</p><ul><li>启动内核时，从软件的角度你看到了什么？对于你来说，在内核中似乎所有的线程都<br> 是并行地运行的。在逻辑上这是正确的，但从硬件的角度来看，不是所有线程在物理上都<br> 可以同时并行地执行。本章已经提到了把32个线程划分到一个执行单元中的概念：线程<br> 束。现在从硬件的角度来介绍线程束执行，并能够获得指导内核设计的方法。</li></ul><h3 id="_3-2-1-线程束和线程块" tabindex="-1"><a class="header-anchor" href="#_3-2-1-线程束和线程块" aria-hidden="true">#</a> 3.2.1 线程束和线程块</h3><p>Warps and Thread Blocks</p><ul><li>线程束是SM中基本的执行单元。当一个线程块的网格被启动后，网格中的线程块分<br> 布在SM中。一旦线程块被调度到一个SM上，线程块中的线程会被进一步划分为线程束。<br> 一个线程束由32个连续的线程组成，在一个线程束中，所有的线程按照单指令多线程<br> （SIMT）方式执行；也就是说，所有线程都执行相同的指令，每个线程在私有数据上进<br> 行操作。图3-10展示了线程块的逻辑视图和硬件视图之间的关系。</li></ul><figure><img src="'+D+'" alt="figure3-10" tabindex="0" loading="lazy"><figcaption>figure3-10</figcaption></figure><ul><li><p>然而，从硬件的角度来看，所有的线程都被组织成了一维的，线程块可以被配置为一<br> 维、二维或三维的。在一个块中，每个线程都有一个唯一的ID。对于一维的线程块，唯一<br> 的线程ID被存储在CUDA的内置变量threadIdx.x中，并且，threadIdx.x中拥有连续值的线程被分组到线程束中。例如，一个有128个线程的一维线程块被组织到4个线程束里，如下所示：<br> Warp 0: thread 0, thread 1, thread 2, ... thread 31<br> Warp 1: thread 32, thread 33, thread 34, ... thread 63<br> Warp 3: thread 64, thread 65, thread 66, ... thread 95<br> Warp 4: thread 96, thread 97, thread 98, ... thread 127</p></li><li><p>用x维度作为最内层的维度，y维度作为第二个维度，z作为最外层的维度，则二维或<br> 三维线程块的逻辑布局可以转化为一维物理布局。例如，对于一个给定的二维线程块，在<br> 一个块中每个线程的独特标识符都可以用内置变量threadIdx和blockDim来计算：<br> threadIdx.y * blockDim.x + threadIdx.x.</p></li><li><p>对于一个三维线程块，计算如下：<br> threadIdx.z * blockDim.y * blockDim.x + threadIdx.y * blockDim.x + threadIdx.x</p></li><li><p>一个线程块的线程束的数量可以根据下式确定：<br> WarpsPerBlock = ceil(ThreadsPerBlock / WarpSize)</p></li><li><p>因此，硬件总是给一个线程块分配一定数量的线程束。线程束不会在不同的线程块之<br> 间分离。如果线程块的大小不是线程束大小的偶数倍，那么在最后的线程束里有些线程就<br> 不会活跃。图3-11是一个在x轴中有40个线程、在y轴中有2个线程的二维线程块。从应用<br> 程序的角度来看，在一个二维网格中共有80个线程。</p></li><li><p>硬件为这个线程块配置了3个线程束，使总共96个硬件线程去支持80个软件线程。注<br> 意，最后半个线程束是不活跃的。即使这些线程未被使用，它们仍然消耗SM的资源，如<br> 寄存器。</p></li></ul><figure><img src="'+M+`" alt="figure3-11" tabindex="0" loading="lazy"><figcaption>figure3-11</figcaption></figure><ul><li><mark>线程块：逻辑角度与硬件角度</mark></li><li>从逻辑角度来看，线程块是线程的集合，它们可以被组织为一维、二维或三维布局。</li><li>从硬件角度来看，线程块是一维线程束的集合。在线程块中线程被组织成一维布局，<br> 每32个连续线程组成一个线程束。</li></ul><h3 id="_3-2-2-线程束分化" tabindex="-1"><a class="header-anchor" href="#_3-2-2-线程束分化" aria-hidden="true">#</a> 3.2.2 线程束分化</h3><p>Warp Divergence</p><ul><li>控制流是高级编程语言的基本构造中的一种。GPU支持传统的、C风格的、显式的控<br> 制流结构，例如，if…then…else、for和while。</li><li>CPU拥有复杂的硬件以执行分支预测，也就是在每个条件检查中预测应用程序的控制<br> 流会使用哪个分支。如果预测正确，CPU中的分支只需付出很小的性能代价。如果预测不<br> 正确，CPU可能会停止运行很多个周期，因为指令流水线被清空了。我们不必完全理解为<br> 什么CPU擅长处理复杂的控制流。这个解释只是作为对比的背景。</li><li>GPU是相对简单的设备，它没有复杂的分支预测机制。一个线程束中的所有线程在同<br> 一周期中必须执行相同的指令，如果一个线程执行一条指令，那么线程束中的所有线程都<br> 必须执行该指令。如果在同一线程束中的线程使用不同的路径通过同一个应用程序，这可<br> 能会产生问题。例如，思考下面的语句：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code> <span class="token keyword">if</span> <span class="token punctuation">(</span>cond<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
 <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
 <span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>假设在一个线程束中有16个线程执行这段代码，cond为true，但对于其他16个来说<br> cond为false。一半的线程束需要执行if语句块中的指令，而另一半需要执行else语句块中的指令。在同一线程束中的线程执行不同的指令，被称为线程束分化。我们已经知道，在一<br> 个线程束中所有线程在每个周期中必须执行相同的指令，所以线程束分化似乎会产生一个悖论。</p></li><li><p>如果一个线程束中的线程产生分化，线程束将连续执行每一个分支路径，而禁用不执<br> 行这一路径的线程。线程束分化会导致性能明显地下降。在前面的例子中可以看到，线程<br> 束中并行线程的数量减少了一半：只有16个线程同时活跃地执行，而其他16个被禁用了。<br> 条件分支越多，并行性削弱越严重。</p></li><li><p>注意，线程束分化只发生在同一个线程束中。在不同的线程束中，不同的条件值不会<br> 引起线程束分化。</p></li><li><p>图3-12显示了线程束分化。在一个线程束中所有的线程必须采用if…then两个分支来<br> 表述。如果线程的条件为true，它将执行if子句；否则，当等待执行完成时，线程停止。</p></li></ul><figure><img src="`+U+`" alt="figure3-12" tabindex="0" loading="lazy"><figcaption>figure3-12</figcaption></figure><ul><li><p>为了获得最佳的性能，应该避免在同一线程束中有不同的执行路径。请记住，在一个<br> 线程块中，线程的线程束分配是确定的。因此，以这样的方式对数据进行分区是可行的<br> （尽管不是微不足道的，但取决于算法），以确保同一个线程束中的所有线程在一个应用<br> 程序中使用同一个控制路径。</p></li><li><p>例如，假设有两个分支，下面展示了简单的算术内核示例。我们可以用一个偶数和奇<br> 数线程方法来模拟一个简单的数据分区，目的是导致线程束分化。该条件（tid%2==0）使<br> 偶数编号的线程执行if子句，奇数编号的线程执行else子句。</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code> __global__ <span class="token keyword">void</span> <span class="token function">mathKernel1</span><span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span>c<span class="token punctuation">)</span> <span class="token punctuation">{</span>
   <span class="token keyword">int</span> tid <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
   <span class="token keyword">float</span> a<span class="token punctuation">,</span> b<span class="token punctuation">;</span>
   a <span class="token operator">=</span> b <span class="token operator">=</span> <span class="token number">0.0f</span><span class="token punctuation">;</span>
   <span class="token keyword">if</span> <span class="token punctuation">(</span>tid <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
      a <span class="token operator">=</span> <span class="token number">100.0f</span><span class="token punctuation">;</span>
  <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>
      b <span class="token operator">=</span> <span class="token number">200.0f</span><span class="token punctuation">;</span>
   <span class="token punctuation">}</span>
   c<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">=</span> a <span class="token operator">+</span> b<span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>如果使用线程束方法（而不是线程方法）来交叉存取数据，可以避免线程束分化，并<br> 且设备的利用率可达到100%。条件（tid/warpSize）%2==0使分支粒度是线程束大小的倍<br> 数；偶数编号的线程执行if子句，奇数编号的线程执行else子句。这个核函数产生相同的<br> 输出，但是顺序不同。</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code> __global__ <span class="token keyword">void</span> <span class="token function">mathKernel2</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
   <span class="token keyword">int</span> tid <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
   <span class="token keyword">float</span> a<span class="token punctuation">,</span> b<span class="token punctuation">;</span>
   a <span class="token operator">=</span> b <span class="token operator">=</span> <span class="token number">0.0f</span><span class="token punctuation">;</span>
   <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>tid <span class="token operator">/</span> warpSize<span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
      a <span class="token operator">=</span> <span class="token number">100.0f</span><span class="token punctuation">;</span>
   <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>
      b <span class="token operator">=</span> <span class="token number">200.0f</span><span class="token punctuation">;</span>
   <span class="token punctuation">}</span>
   c<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">=</span> a <span class="token operator">+</span> b<span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,62),Q={href:"http://xn--Wrox-4m5f2w6et62b.com",target:"_blank",rel:"noopener noreferrer"},j=n("br",null,null,-1),Y={class:"hint-container details"},J=n("summary",null,"Click me to view the code!",-1),Z=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token function"},"main"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" argc"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"char"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),s("argv"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
   `),n("span",{class:"token comment"},"// set up device"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" dev "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(`
   cudaDeviceProp deviceProp`),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaGetDeviceProperties"),n("span",{class:"token punctuation"},"("),n("span",{class:"token operator"},"&"),s("deviceProp"),n("span",{class:"token punctuation"},","),s(" dev"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"%s using Device %d: %s\\n"'),n("span",{class:"token punctuation"},","),s(" argv"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},","),s("dev"),n("span",{class:"token punctuation"},","),s(" deviceProp"),n("span",{class:"token punctuation"},"."),s("name"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// set up data size"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" size "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"64"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" blocksize "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"64"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"if"),n("span",{class:"token punctuation"},"("),s("argc "),n("span",{class:"token operator"},">"),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),s(" blocksize "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"atoi"),n("span",{class:"token punctuation"},"("),s("argv"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"if"),n("span",{class:"token punctuation"},"("),s("argc "),n("span",{class:"token operator"},">"),s(),n("span",{class:"token number"},"2"),n("span",{class:"token punctuation"},")"),s(" size      "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"atoi"),n("span",{class:"token punctuation"},"("),s("argv"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"2"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"Data size %d "'),n("span",{class:"token punctuation"},","),s(" size"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// set up execution configuration"),s(`
   dim3 `),n("span",{class:"token function"},"block"),s(),n("span",{class:"token punctuation"},"("),s("blocksize"),n("span",{class:"token punctuation"},","),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   dim3 `),n("span",{class:"token function"},"grid"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),s("size"),n("span",{class:"token operator"},"+"),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"-"),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"/"),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"Execution Configure (block %d grid %d)\\n"'),n("span",{class:"token punctuation"},","),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s(" grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// allocate gpu memory"),s(`
   `),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),s("d_C"),n("span",{class:"token punctuation"},";"),s(`
   size_t nBytes `),n("span",{class:"token operator"},"="),s(" size "),n("span",{class:"token operator"},"*"),s(),n("span",{class:"token keyword"},"sizeof"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"cudaMalloc"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"&"),s("d_C"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// run a warmup kernel to remove overhead "),s(`
   size_t iStart`),n("span",{class:"token punctuation"},","),s("iElaps"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaDeviceSynchronize"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   iStart `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"seconds"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   warmingup`),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s(),n("span",{class:"token punctuation"},"("),s("d_C"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaDeviceSynchronize"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   iElaps `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"seconds"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"-"),s(" iStart"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"warmup      <<< %4d %4d >>> elapsed %d sec \\n"'),n("span",{class:"token punctuation"},","),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s(" iElaps "),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// run kernel 1"),s(`
   iStart `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"seconds"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   mathKernel1`),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),n("span",{class:"token punctuation"},"("),s("d_C"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaDeviceSynchronize"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   iElaps `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"seconds"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"-"),s(" iStart"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"mathKernel1 <<< %4d %4d >>> elapsed %d sec \\n"'),n("span",{class:"token punctuation"},","),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s("iElaps "),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// run kernel 3"),s(`
   iStart `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"seconds"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   mathKernel2`),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),n("span",{class:"token punctuation"},"("),s("d_C"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaDeviceSynchronize"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   iElaps `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"seconds"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"-"),s(" iStart"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"mathKernel2 <<< %4d %4d >>> elapsed %d sec \\n"'),n("span",{class:"token punctuation"},","),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s("iElaps "),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// run kernel 3"),s(`
   iStart `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"seconds"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   mathKernel3`),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),n("span",{class:"token punctuation"},"("),s("d_C"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaDeviceSynchronize"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   iElaps `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"seconds"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"-"),s(" iStart"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"mathKernel3 <<< %4d %4d >>> elapsed %d sec \\n"'),n("span",{class:"token punctuation"},","),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s("iElaps"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// run kernel 4"),s(`
   iStart `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"seconds"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   mathKernel4`),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),n("span",{class:"token punctuation"},"("),s("d_C"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaDeviceSynchronize"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   iElaps `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"seconds"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"-"),s(" iStart"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"mathKernel4 <<< %4d %4d >>> elapsed %d sec \\n"'),n("span",{class:"token punctuation"},","),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s("iElaps"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// free gpu memory and reset divece"),s(`
   `),n("span",{class:"token function"},"cudaFree"),n("span",{class:"token punctuation"},"("),s("d_C"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaDeviceReset"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"return"),s(" EXIT_SUCCESS"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),nn=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s(`使用下面的命令编译这段代码：
 $ nvcc `),n("span",{class:"token operator"},"-"),s("O3 "),n("span",{class:"token operator"},"-"),s("arch"),n("span",{class:"token operator"},"="),s("sm_20 simpleDivergence"),n("span",{class:"token punctuation"},"."),s("cu "),n("span",{class:"token operator"},"-"),s(`o simpleDivergence



在Fermi M2070 GPU上运行simpleDivergence，输出报告如下。两个内核的运行时间很相近。
 $ `),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s("simpleDivergence "),n("span",{class:"token keyword"},"using"),s(" Device "),n("span",{class:"token number"},"0"),n("span",{class:"token operator"},":"),s(` Tesla M2070 
Data size `),n("span",{class:"token number"},"64"),s(" Execution "),n("span",{class:"token function"},"Configuration"),s(),n("span",{class:"token punctuation"},"("),s("block "),n("span",{class:"token number"},"64"),s(" grid "),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),s(`
 Warmingup   elapsed `),n("span",{class:"token number"},"0.000040"),s(` sec
 mathKernel1 elapsed `),n("span",{class:"token number"},"0.000016"),s(` sec
 mathKernel2 elapsed `),n("span",{class:"token number"},"0.000014"),s(` sec


通过使用nvprof分析器，可以从GPU中获得指标，从而可以直接观察到线程束分化。
在这里，nvprof的branch_efficiency指标是用来计算simpleDivergence的样本执行的：
 $ nvprof `),n("span",{class:"token operator"},"--"),s("metrics branch_efficiency "),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s(`simpleDivergence

下面的结果是由nvprof报告的。
 Kernel`),n("span",{class:"token operator"},":"),s(),n("span",{class:"token function"},"mathKernel1"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"void"),n("span",{class:"token punctuation"},")"),s(`
 `),n("span",{class:"token number"},"1"),s("   branch_efficiency   Branch Efficiency     "),n("span",{class:"token number"},"100.00"),n("span",{class:"token operator"},"%"),s("     "),n("span",{class:"token number"},"100.00"),n("span",{class:"token operator"},"%"),s("     "),n("span",{class:"token number"},"100.00"),n("span",{class:"token operator"},"%"),s(`
 Kernel`),n("span",{class:"token operator"},":"),s(),n("span",{class:"token function"},"mathKernel2"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"void"),n("span",{class:"token punctuation"},")"),s(`
 `),n("span",{class:"token number"},"1"),s("   branch_efficiency   Branch Efficiency     "),n("span",{class:"token number"},"100.00"),n("span",{class:"token operator"},"%"),s("     "),n("span",{class:"token number"},"100.00"),n("span",{class:"token operator"},"%"),s("     "),n("span",{class:"token number"},"100.00"),n("span",{class:"token operator"},"%"),s(`


分支效率被定义为未分化的分支与全部分支之比，可以使用以下公式来计算：
BranchEfficiency `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"100"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},"("),s("#Branches "),n("span",{class:"token operator"},"-"),s(" #DivergentBranches"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"/"),s(),n("span",{class:"token punctuation"},"("),s("#Branches"),n("span",{class:"token punctuation"},")"),s(`


`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),sn=c(`<ul><li><p>奇怪的是，没有报告显示出有分支分化（即分支效率是100%）。这个奇怪的现象是<br> CUDA编译器优化导致的结果，它将短的、有条件的代码段的断定指令取代了分支指令<br> （导致分化的实际控制流指令）。</p></li><li><p>在分支预测中，根据条件，把每个线程中的一个断定变量设置为1或0。这两种条件流<br> 路径被完全执行，但只有断定为1的指令被执行。断定为0的指令不被执行，但相应的线程<br> 也不会停止。这和实际的分支指令之间的区别是微妙的，但理解它很重要。只有在条件语<br> 句的指令数小于某个阈值时，编译器才用断定指令替换分支指令。因此，一段很长的代码<br> 路径肯定会导致线程束分化。</p></li><li><p>如下所示，重写mathKernel1核函数，使内核代码的分支预测直接显示：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code> __global__ <span class="token keyword">void</span> <span class="token function">mathKernel3</span><span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span>c<span class="token punctuation">)</span> <span class="token punctuation">{</span> 
   <span class="token keyword">int</span> tid <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
   <span class="token keyword">float</span> ia<span class="token punctuation">,</span> ib<span class="token punctuation">;</span>
   ia <span class="token operator">=</span> ib <span class="token operator">=</span> <span class="token number">0.0f</span><span class="token punctuation">;</span>
   <span class="token keyword">bool</span> ipred <span class="token operator">=</span> <span class="token punctuation">(</span>tid <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
   <span class="token keyword">if</span> <span class="token punctuation">(</span>ipred<span class="token punctuation">)</span> <span class="token punctuation">{</span>
      ia <span class="token operator">=</span> <span class="token number">100.0f</span><span class="token punctuation">;</span>
   <span class="token punctuation">}</span>
   <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>ipred<span class="token punctuation">)</span> <span class="token punctuation">{</span>
      ib <span class="token operator">=</span> <span class="token number">200.0f</span><span class="token punctuation">;</span>
   <span class="token punctuation">}</span>
   c<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">=</span> ia <span class="token operator">+</span> ib<span class="token punctuation">;</span>
 <span class="token punctuation">}</span> 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,2),an={href:"http://xn--simpleDivergence-c02z745anko9x6fmuyank1hujzb1wr00w.cu",target:"_blank",rel:"noopener noreferrer"},tn=n("br",null,null,-1),en=n("br",null,null,-1),on=n("br",null,null,-1),pn=n("br",null,null,-1),cn=n("br",null,null,-1),ln={href:"http://simpleDivergence.cu",target:"_blank",rel:"noopener noreferrer"},un=c("<li><p>如下所示，可以用nvprof再次检查没有被优化的内核分化：<br> $ nvprof --metrics branch_efficiency ./simpleDivergence</p></li><li><p>结果总结如下：<br> mathKernel1: Branch Efficiency 83.33%<br> mathKernel2: Branch Efficiency 100.00%<br> mathKernel3: Branch Efficiency 71.43%</p></li><li><p>另外，可以用nvprof获得分支和分化分支的事件计数器，如下所示：<br> $ nvprof --events branch,divergent_branch ./simpleDivergence</p></li><li><p>结果如下：<br> mathKernel1: branch 12 divergent_branch 2<br> mathKernel2: branch 12 divergent_branch 0<br> mathKernel3: branch 14 divergent_branch 4</p></li><li><p>CUDA的nvcc编译器仍然是在mathKernel1和mathKernel3上执行有限的优化，以保持分<br> 支效率在50%以上。注意，mathKernel2不报告分支分化的唯一原因是它的分支粒度是线程<br> 束大小的倍数。此外，把mathKernel1中的if...else语句分离为mathKernel3的多个if语句，可以使分化分支的数量翻倍。</p></li><li><p><mark>重要提示：</mark></p></li><li><p>当一个分化的线程采取不同的代码路径时，会产生线程束分化</p></li><li><p>不同的if-then-else分支会连续执行</p></li><li><p>尝试调整分支粒度以适应线程束大小的倍数，避免线程束分化</p></li><li><p>不同的分化可以执行不同的代码且无须以牺牲性能为代价</p></li>",10),rn=c('<h3 id="_3-2-3-资源分配" tabindex="-1"><a class="header-anchor" href="#_3-2-3-资源分配" aria-hidden="true">#</a> 3.2.3 资源分配</h3><p>Resource Partitioning</p><ul><li>warp 的本地执行环境主要由以下资源组成：</li><li>Program counters程序计数器</li><li>Registers寄存器</li><li>Shared memory共享内存</li><li>由SM处理的每个线程束的执行上下文，在整个线程束的生存期中是保存在芯片内<br> 的。因此，从一个执行上下文切换到另一个执行上下文没有损失。<br> (因为分配资源是按照block进行分配的？所以同block的warp切换没有损失？)</li><li>每个SM都有32位的寄存器组，它存储在寄存器文件中，并且可以在线程中进行分<br> 配，同时固定数量的共享内存用来在线程块中进行分配。对于一个给定的内核，同时存在<br> 于同一个SM中的线程块和线程束的数量取决于在SM中可用的且内核所需的寄存器和共享<br> 内存的数量。</li><li>图3-13显示了若每个线程消耗的寄存器越多，则可以放在一个SM中的线程束就越<br> 少。如果可以减少内核消耗寄存器的数量，那么就可以同时处理更多的线程束。如图3-14<br> 所示，若一个线程块消耗的共享内存越多，则在一个SM中可以被同时处理的线程块就会<br> 变少。如果每个线程块使用的共享内存数量变少，那么可以同时处理更多的线程块。</li><li>确实是这样理解的目前；</li></ul><figure><img src="'+S+'" alt="figure3-13" tabindex="0" loading="lazy"><figcaption>figure3-13</figcaption></figure><figure><img src="'+P+'" alt="figure3-14" tabindex="0" loading="lazy"><figcaption>figure3-14</figcaption></figure><ul><li><p>资源可用性通常会限制SM中常驻线程块的数量。每个SM中寄存器和共享内存的数量<br> 因设备拥有不同的计算能力而不同。如果每个SM没有足够的寄存器或共享内存去处理至<br> 少一个块，那么内核将无法启动。一些关键的限度如表3-2所示。(所以资源分配是按照block进行分配的？)</p></li><li><p>当计算资源（如寄存器和共享内存）已分配给线程块时，线程块被称为活跃的块。它<br> 所包含的线程束被称为活跃的线程束。活跃的线程束可以进一步被分为以下3种类型：</p><ul><li>选定的线程束（正在cuda core 上进行执行的）</li><li>阻塞的线程束 （缺少条件的 还不能进行执行的）</li><li>符合条件的线程束 （就等warp调度器 调度到cuda core上了）</li></ul></li><li><p>一个SM上的线程束调度器在每个周期都选择活跃的线程束，然后把它们调度到执行<br> 单元。活跃执行的线程束被称为选定的线程束。如果一个活跃的线程束准备执行但尚未执<br> 行，它是一个符合条件的线程束。如果一个线程束没有做好执行的准备，它是一个阻塞的<br> 线程束。如果同时满足以下两个条件则线程束符合执行条件。<br> ·32个CUDA核心可用于执行<br> ·当前指令中所有的参数都已就绪</p></li><li><p>例如，Kepler SM上活跃的线程束数量，从启动到完成在任何时候都必须小于或等于<br> 64个并发线程束的架构限度。在任何周期中，选定的线程束数量都小于或等于4。如果线<br> 程束阻塞，线程束调度器会令一个符合条件的线程束代替它去执行。由于计算资源是在线<br> 程束之间进行分配的，而且在线程束的整个生存期中都保持在芯片内，因此线程束上下文的切换是非常快的。在下面几节中，你将会认识到为了隐藏由线程束阻塞造成的延迟，需<br> 要让大量的线程束保持活跃。</p></li><li><p>在CUDA编程中需要特别关注计算资源分配：计算资源限制了活跃的线程束的数量。<br> 因此必须了解由硬件产生的限制和内核用到的资源。为了最大程度地利用GPU，需要最大<br> 化活跃的线程束数量。</p></li></ul><h3 id="_3-2-4-延迟隐藏" tabindex="-1"><a class="header-anchor" href="#_3-2-4-延迟隐藏" aria-hidden="true">#</a> 3.2.4 延迟隐藏</h3><p>Latency Hiding</p><ul><li><p>SM依赖线程级并行，以最大化功能单元的利用率，因此，利用率与常驻线程束的数<br> 量直接相关。在指令发出和完成之间的时钟周期被定义为指令延迟。当每个时钟周期中所<br> 有的线程调度器都有一个符合条件的线程束时，可以达到计算资源的完全利用。这就可以<br> 保证，通过在其他常驻线程束中发布其他指令，可以隐藏每个指令的延迟。</p></li><li><p>与在CPU上用C语言编程相比，延迟隐藏在CUDA编程中尤为重要。CPU核心是为同<br> 时最小化延迟一个或两个线程而设计的，而GPU则是为处理大量并发和轻量级线程以最大<br> 化吞吐量而设计的。GPU的指令延迟被其他线程束的计算隐藏。</p></li><li><p>当考虑指令延迟时，指令可以分为两种基本类型：<br> Arithmetic instructions 算术指令<br> Memory instructions 内存指令</p></li><li><p>算术指令延迟是一个算术操作从开始到它产生输出之间的时间。内存指令延迟是指发<br> 送出的加载或存储操作和数据到达目的地之间的时间。对于每种情况，相应的延迟大约<br> 为：<br> 10-20 cycles for arithmetic operations算术运算需要10-20个周期<br> 400-800 cycles for global memory accesses全局内存访问需要400-800个周期</p></li><li><p>图3-15表示线程束0阻塞执行流水线的一个示例。线程束调度器选取其他线程束执<br> 行，当线程束0符合条件时再执行它。</p></li></ul><figure><img src="'+C+'" alt="figure3-15" tabindex="0" loading="lazy"><figcaption>figure3-15</figcaption></figure><ul><li><p>你可能想知道如何估算隐藏延迟所需要的活跃线程束的数量。利特尔法则（Little’s<br> Law）可以提供一个合理的近似值。它起源于队列理论中的一个定理，它也可以应用于<br> GPU中：<br> 所需线程束数量＝延迟×吞吐量</p></li><li><p>图3-16形象地说明了利特尔法则。假设在内核里一条指令的平均延迟是5个周期。为<br> 了保持在每个周期内执行6个线程束的吞吐量，则至少需要30个未完成的线程束。</p></li></ul><figure><img src="'+G+'" alt="figure3-16" tabindex="0" loading="lazy"><figcaption>figure3-16</figcaption></figure><ul><li><p><mark>吞吐量和带宽</mark></p></li><li><p>带宽和吞吐量经常被混淆，根据实际情况它们可以被交换使用。吞吐量和带宽都是用<br> 来度量性能的速度指标。</p></li><li><p>带宽通常是指理论峰值，而吞吐量是指已达到的值。</p></li><li><p>带宽通常是用来描述单位时间内最大可能的数据传输量，而吞吐量是用来描述单位时<br> 间内任何形式的信息或操作的执行速度，例如，每个周期完成多少个指令。</p></li><li><p>对于算术运算来说，其所需的并行可以表示成隐藏算术延迟所需要的操作数量。表3-<br> 3列出了Fermi和Kepler设备所需的操作数量。示例中的算术运算是一个32位的浮点数乘加<br> 运算（a＋b×c），表示在每个SM中每个时钟周期内的操作数量。吞吐量因不同的算术指<br> 令而不同。</p></li><li><p>吞吐量由SM中每个周期内的操作数量确定，而执行一条指令的一个线程束对应32个<br> 操作。因此，为保持计算资源的充分利用，对于Fermi GPU而言，每个SM中所需的线程束<br> 数量通过计算为640÷32＝20个线程束。因此，算术运算所需的并行可以用操作的数量或<br> 线程束的数量来表示。这个简单的单位转换表明，有两种方法可以提高并行：<br> ·指令级并行（ILP）：一个线程中有很多独立的指令<br> ·线程级并行（TLP）：很多并发地符合条件的线程</p></li><li><p>对内存操作来说，其所需的并行可以表示为在每个周期内隐藏内存延迟所需的字节<br> 数。表3-4列出了Fermi和Kepler架构的指标。</p></li><li><p>因为内存吞吐量通常表示为每秒千兆字节数，所以首先需要用对应的内存频率将吞吐<br> 量转换为每周期千兆字节数。可以使用下面的命令检测设备的内存频率：<br> $ nvidia-smi -a -q -d CLOCK | fgrep -A 3 &quot;Max Clocks&quot; | fgrep &quot;Memory&quot;</p></li><li><p>例如，Fermi的内存频率（在Tesla C2070上测量得到）是1.566 GHz。Kepler的内存频<br> 率（在Tesla K20上测量得到）是2.6 GHz。因为1 Hz被定义为每秒一个周期，所以可以把<br> 带宽从每秒千兆字节数转换为每周期千兆字节数，公式如下所示：</p></li><li><p>用内存延迟乘以每周期字节数，可以得到Fermi内存操作所需的并行，接近74KB的内<br> 存I/O运行，用以实现充分的利用。这个值是对于整个设备，而不是对于每个SM来说的，<br> 因为内存带宽是对于整个设备而言的。</p></li><li><p>利用应用程序，把这些值与线程束或线程数量关联起来。假设每个线程都把一浮点数<br> 据（4个字节）从全局内存移动到SM中用于计算，则在Fermi GPU上，总共需要18500个线<br> 程或579个线程束来隐藏所有内存延迟，具体运算如下所示：</p></li><li><p>Fermi架构有16个SM。因此，需要579个线程束÷16个SM＝36个线程束/SM，以隐藏所<br> 有的内存延迟。如果每个线程执行多个独立的4字节加载，隐藏内存延迟需要的线程就可<br> 以更少</p></li><li><p>与指令延迟很像，通过在每个线程/线程束中创建更多独立的内存操作，或创建更多<br> 并发地活跃的线程/线程束，可以增加可用的并行。</p></li><li><p>延迟隐藏取决于每个SM中活跃线程束的数量，这一数量由执行配置和资源约束隐式<br> 决定（一个内核中寄存器和共享内存的使用情况）。选择一个最优执行配置的关键是在延<br> 迟隐藏和资源利用之间找到一种平衡。下一节将会更加详细地研究这个问题。</p></li><li><p><mark>显示充足的并行</mark></p></li><li><p>因为GPU在线程间分配计算资源并在并发线程束之间切换的消耗（在一个或两个周期<br> 命令上）很小，所以所需的状态可以在芯片内获得。如果有足够的并发活跃线程，那么可<br> 以让GPU在每个周期内的每一个流水线阶段中忙碌。在这种情况下，一个线程束的延迟可<br> 以被其他线程束的执行隐藏。因此，向SM显示足够的并行对性能是有利的。</p></li><li><p>计算所需并行的一个简单的公式是，用每个SM核心的数量乘以在该SM上一条算术指<br> 令的延迟。例如，Fermi有32个单精度浮点流水线线路，一个算术指令的延迟是20个周<br> 期，所以，每个SM至少需要有32×20＝640个线程使设备处于忙碌状态。然而，这只是一<br> 个下边界.</p></li></ul><h3 id="_3-2-5-占用率" tabindex="-1"><a class="header-anchor" href="#_3-2-5-占用率" aria-hidden="true">#</a> 3.2.5 占用率</h3>',14),kn=c("<li><p>在每个CUDA核心里指令是顺序执行的。当一个线程束阻塞时，SM切换执行其他符<br> 合条件的线程束。理想情况下，我们想要有足够的线程束占用设备的核心。占用率是每个<br> SM中活跃的线程束占最大线程束数量的比值。</p></li><li><p>占用率 = 活跃线程束数量 / 最大线程束数量</p></li><li><p>使用下述函数，可以检测设备中每个SM的最大线程束数量：<br> cudaBrror_t cudaGetDeviceProperties(struct cudaDeviceProp *prop，int device);</p></li><li><p>来自设备的各种统计数据在cudaDeviceProp结构中被返回。每个SM中线程数量的最大<br> 值在以下变量中返回：maxThreadsPerMultiProcessor</p></li><li><p>用maxThreadsPerMultiProcessor除以32，可以得到最大线程束数量。代码清单3-2展示了如何使用cudaGetDeviceProperties获得GPU的配置信息。</p></li>",5),dn={href:"http://simpleDeviceQuery.cu",target:"_blank",rel:"noopener noreferrer"},bn={class:"hint-container details"},mn=n("summary",null,"Click me to view the code!",-1),vn=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s("pnpm add "),n("span",{class:"token operator"},"-"),s("D vuepress"),n("span",{class:"token operator"},"-"),s("theme"),n("span",{class:"token operator"},"-"),s(`hope
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"})])],-1),gn=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s("从Wrox"),n("span",{class:"token punctuation"},"."),s("com中可以下载simpleDeviceQuery"),n("span",{class:"token punctuation"},"."),s(`cu文件。使用以下命令编译并运行这个示
例

Tesla M2070的输出结果显示如下。每个SM中线程数量的最大值是`),n("span",{class:"token number"},"1536"),s(`。因此，每个
SM中线程束数量的最大值是`),n("span",{class:"token number"},"48"),s(`。



`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),hn=c(`<ul><li><p>CUDA工具包包含了一个电子表格，它被称为CUDA占用率计算器，有助于选择网格<br> 和块的维数以使一个内核的占用率最大化。图3-17展示了占用率计算器的一个截图</p></li><li><p>占用率计算器包含几个部分。首先，必须提供GPU的计算能力和内核的资源使用情况<br> 的信息。</p></li><li><p>在确定GPU的计算能力后，物理限制部分的数据是自动填充的。接下来，需要输入以<br> 下内核资源信息：<br> ·每个块的线程（执行配置）<br> ·每个线程的寄存器（资源使用情况）<br> ·每个块的共享内存（资源使用情况）</p></li><li><p>每个线程的寄存器和每个块的共享内存资源的使用情况可以从nvcc中用以下编译器标<br> 志获得：<br> --ptxas-options=-v</p></li><li><p>一旦进入这个数据，内核占用率便会显示在GPU占用率数据段。其他部分提供必要的<br> 信息，来调整执行配置和资源使用情况，以获得更好的设备占用率。</p></li><li><p>内核使用的寄存器数量会对常驻线程束数量产生显著的影响。寄存器的使用可以用下<br> 面的nvcc标志手动控制。<br> -maxrregcount=NUM</p></li><li><p>-maxrregcount选项告诉编译器每个线程使用的寄存器数量不能超过NUM个。使用这个<br> 编译器标志，可以得到占用率计算器推荐的寄存器数量，同时使用这个数值可以改善应用<br> 程序的性能。</p></li><li><p>为了提高占用率，还需要调整线程块配置或重新调整资源的使用情况，以允许更多的<br> 线程束同时处于活跃状态和提高计算资源的利用率。极端地操纵线程块会限制资源的利<br> 用：<br> 小线程块：每个块中线程太少，会在所有资源被充分利用之前导致硬件达到每个SM<br> 的线程束数量的限制。<br> 大线程块：每个块中有太多的线程，会导致在每个SM中每个线程可用的硬件资源较<br> 少。</p></li><li><p><mark>网格和线程块大小的准则</mark></p></li><li><p>使用这些准则可以使应用程序适用于当前和将来的设备：<br> 保持每个块中线程数量是线程束大小（32）的倍数<br> 避免块太小：每个块至少要有128或256个线程<br> 根据内核资源的需求调整块大小<br> 块的数量要远远多于SM的数量，从而在设备中可以显示有足够的并行<br> 通过实验得到最佳执行配置和资源使用情况</p></li><li><p>尽管在每种情况下会遇到不同的硬件限制，但它们都会导致计算资源未被充分利用，<br> 阻碍隐藏指令和内存延迟的并行的建立。占用率唯一注重的是在每个SM中并发线程或线<br> 程束的数量。然而，充分的占用率不是性能优化的唯一目标。内核一旦达到一定级别的占<br> 用率，进一步增加占用率可能不会改进性能。为了提高性能，可以调整很多其他因素。在<br> 后续章节中将详细介绍这些内容。</p></li></ul><h3 id="_3-2-6-同步" tabindex="-1"><a class="header-anchor" href="#_3-2-6-同步" aria-hidden="true">#</a> 3.2.6 同步</h3><p>Synchronization</p><ul><li><p>栅栏同步是一个原语，它在许多并行编程语言中都很常见。在CUDA中，同步可以在<br> 两个级别执行：</p><ul><li>系统级：等待主机和设备完成所有的工作</li><li>·块级：在设备执行过程中等待一个线程块中所有线程到达同一点</li></ul></li><li><p>对于主机来说，由于许多CUDA API调用和所有的内核启动不是同步的，<br> cudaDeviceSyn-chronize函数可以用来阻塞主机应用程序，直到所有的CUDA操作（复制、核函数等）完成：</p><ul><li>cudaError_t cudaDeviceSynchronize(void);</li></ul></li><li><p>这个函数可能会从先前的异步CUDA操作返回错误。</p></li><li><p>因为在一个线程块中线程束以一个未定义的顺序被执行，CUDA提供了一个使用块局<br> 部栅栏来同步它们的执行的功能。使用下述函数在内核中标记同步点：</p></li><li><p><strong>device</strong> void __syncthreads(void);</p></li><li><p>当__syncthreads被调用时，在同一个线程块中每个线程都必须等待直至该线程块中所<br> 有其他线程都已经达到这个同步点。在栅栏之前所有线程产生的所有全局内存和共享内存<br> 访问，将会在栅栏后对线程块中所有其他的线程可见。该函数可以协调同一个块中线程之<br> 间的通信，但它强制线程束空闲，从而可能对性能产生负面影响。</p></li><li><p>线程块中的线程可以通过共享内存和寄存器来共享数据。当线程之间共享数据时，要<br> 避免竞争条件。竞争条件或危险，是指多个线程无序地访问相同的内存位置。例如，当一<br> 个位置的无序读发生在写操作之后时，写后读竞争条件发生。因为读和写之间没有顺序，所以读应该在写前还是在写后加载值是未定义的。其他竞争条件的例子有读后写或写后<br> 写。当线程块中的线程在逻辑上并行运行时，在物理上并不是所有的线程都可以在同一时<br> 间执行。如果线程A试图读取由线程B在不同的线程束中写的数据，若使用了适当的同<br> 步，只需确定线程B已经写完就可以了。否则，会出现竞争条件。第4章会更深入地研究<br> 同步问题。</p></li><li><p>在不同的块之间没有线程同步。块间同步，唯一安全的方法是在每个内核执行结束端<br> 使用全局同步点；也就是说，在全局同步之后，终止当前的核函数，开始执行新的核函<br> 数。</p></li><li><p>不同块中的线程不允许相互同步，因此GPU可以以任意顺序执行块。这使得CUDA程<br> 序在大规模并行GPU上是可扩展的。</p></li></ul><h3 id="_3-2-7-可扩展性" tabindex="-1"><a class="header-anchor" href="#_3-2-7-可扩展性" aria-hidden="true">#</a> 3.2.7 可扩展性</h3><p>Scalability</p><ul><li>对于任何并行应用程序而言，可扩展性是一个理想的特性。可扩展性意味着为并行应<br> 用程序提供了额外的硬件资源，相对于增加的资源，并行应用程序会产生加速。例如，若<br> 一个CUDA程序在两个SM中是可扩展的，则与在一个SM中运行相比，在两个SM中运行会<br> 使运行时间减半。一个可扩展的并行程序可以高效地使用所有的计算资源以提高性能。可<br> 扩展性意味着增加的计算核心可以提高性能。串行代码本身是不可扩展的，因为在成千上<br> 万的内核上运行一个串行单线程应用程序，对性能是没有影响的。并行代码有可扩展的潜<br> 能，但真正的可扩展性取决于算法设计和硬件特性。</li><li>能够在可变数量的计算核心上执行相同的应用程序代码的能力被称为透明可扩展性。<br> 一个透明的可扩展平台拓宽了现有应用程序的应用范围，并减少了开发人员的负担，因为<br> 它们可以避免新的或不同的硬件产生的变化。可扩展性比效率更重要。一个可扩展但效率<br> 很低的系统可以通过简单添加硬件核心来处理更大的工作负载。一个效率很高但不可扩展<br> 的系统可能很快会达到可实现性能的上限。</li><li>CUDA内核启动时，线程块分布在多个SM中。网格中的线程块以并行或连续或任意<br> 的顺序被执行。这种独立性使得CUDA程序在任意数量的计算核心间可以扩展。</li><li>图3-18展示了CUDA架构可扩展性的一个例子。左侧的GPU有两个SM，可以同时执行<br> 两个块；右侧的GPU有4个SM，可以同时执行4个块。不修改任何代码，一个应用程序可<br> 以在不同的GPU配置上运行，并且所需的执行时间根据可用的资源而改变。</li></ul><h2 id="_3-3-并行性的表现" tabindex="-1"><a class="header-anchor" href="#_3-3-并行性的表现" aria-hidden="true">#</a> 3.3 并行性的表现</h2><p>EXPOSING PARALLELISM</p><ul><li>为更好地理解线程束执行的本质，将使用不同的执行配置分析下述的sumMatrixOn-GPU2D核函数。使用nvprof配置指标，可以有助于理解为什么有些网格/块的维数组合比其他的组合更好。这些练习会提供网格和块的启发式算法，这是CUDA编程人员必备的技能</li><li>The 2D matrix summation kernel is as follows:</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code> __global__ <span class="token keyword">void</span> <span class="token function">sumMatrixOnGPU2D</span><span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span>A<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>B<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>C<span class="token punctuation">,</span> <span class="token keyword">int</span> NX<span class="token punctuation">,</span> <span class="token keyword">int</span> NY<span class="token punctuation">)</span> <span class="token punctuation">{</span>
   <span class="token keyword">unsigned</span> <span class="token keyword">int</span> ix <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
   <span class="token keyword">unsigned</span> <span class="token keyword">int</span> iy <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>y <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>y <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">;</span>
   <span class="token keyword">unsigned</span> <span class="token keyword">int</span> idx <span class="token operator">=</span> iy <span class="token operator">*</span> NX <span class="token operator">+</span> ix<span class="token punctuation">;</span>
   <span class="token keyword">if</span> <span class="token punctuation">(</span>ix <span class="token operator">&lt;</span> NX <span class="token operator">&amp;&amp;</span> iy <span class="token operator">&lt;</span> NY<span class="token punctuation">)</span> <span class="token punctuation">{</span>
      C<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> A<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">+</span> B<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">;</span>
  <span class="token punctuation">}</span>
 <span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><figure><img src="`+I+`" alt="figure3-18" tabindex="0" loading="lazy"><figcaption>figure3-18</figcaption></figure><ul><li>Specify a large matrix with 16,384 elements in each dimension:<br> int nx = 1&lt;&lt;14;<br> int ny = 1&lt;&lt;14;</li><li>以下代码片段允许从命令行配置程序块尺寸：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code> <span class="token keyword">if</span> <span class="token punctuation">(</span>argc <span class="token operator">&gt;</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
   dimx <span class="token operator">=</span> <span class="token function">atoi</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
   dimy <span class="token operator">=</span> <span class="token function">atoi</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 dim3 <span class="token function">block</span><span class="token punctuation">(</span>dimx<span class="token punctuation">,</span> dimy<span class="token punctuation">)</span><span class="token punctuation">;</span>
 dim3 <span class="token function">grid</span><span class="token punctuation">(</span><span class="token punctuation">(</span>nx <span class="token operator">+</span> block<span class="token punctuation">.</span>x <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> block<span class="token punctuation">.</span>x<span class="token punctuation">,</span> <span class="token punctuation">(</span>ny <span class="token operator">+</span> block<span class="token punctuation">.</span>y <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> block<span class="token punctuation">.</span>y<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,14),fn={href:"http://sumMatrix.cu",target:"_blank",rel:"noopener noreferrer"},_n={href:"http://Wrox.com",target:"_blank",rel:"noopener noreferrer"},yn=n("br",null,null,-1),xn={href:"http://sumMatrix.cu",target:"_blank",rel:"noopener noreferrer"},wn=n("li",null,"在接下来的章节中，您将使用生成的 sumMatrix 可执行文件尝试块和网格配置。",-1),Dn=c('<h3 id="_3-3-1-用nvprof检测活跃的线程束" tabindex="-1"><a class="header-anchor" href="#_3-3-1-用nvprof检测活跃的线程束" aria-hidden="true">#</a> 3.3.1 用nvprof检测活跃的线程束</h3><p>Checking Active Warps with nvprof</p><ul><li><p>首先，您需要创建一个参考结果作为性能基准。为此，首先要测试一组基本的线程块配置，特别是大小为 (32,32)、(32,16)、(16,32) 和 (16,16) 的线程块。回想一下，sumMatrix 的第一个参数是线程块配置的 x 维度，第二个参数是线程块配置的 y 维度。通过调用带有相应命令行参数的 sumMatrix，可以测试各种线程块配置。</p></li><li><p>The following results are output on a Tesla M2070:<br> $ ./sumMatrix 32 32<br> sumMatrixOnGPU2D &lt;&lt;&lt; (512,512), (32,32) &gt;&gt;&gt; elapsed 60 ms<br> $ ./sumMatrix 32 16<br> sumMatrixOnGPU2D &lt;&lt;&lt; (512,1024), (32,16) &gt;&gt;&gt; elapsed 38 ms<br> $ ./sumMatrix 16 32<br> sumMatrixOnGPU2D &lt;&lt;&lt; (1024,512), (16,32) &gt;&gt;&gt; elapsed 51 ms<br> $ ./sumMatrix 16 16<br> sumMatrixOnGPU2D &lt;&lt;&lt; (1024,1024),(16,16) &gt;&gt;&gt; elapsed 46 ms</p></li><li><p>比较这些结果，性能最慢的是第一个区块配置（32，32）。速度最快的是第二个线程块配置（32，16）。你可能会认为，第二种情况比第一种情况有更多的线程块，因此，它暴露了更多的并行性。可以使用 nvprof 和 achieved_occupancy 指标来验证这一理论。内核的占用率定义为每个周期的平均活动翘曲数与 SM 上支持的最大翘曲数之比。结果总结如下（注：如果系统有多个 GPU，可以使用 --devices 命令行选项引导 nvprof 从特定设备收集配置信息）：<br> $ nvprof --metrics achieved_occupancy ./sumMatrix 32 32<br> sumMatrixOnGPU2D &lt;&lt;&lt;(512,512), (32,32)&gt;&gt;&gt; Achieved Occupancy 0.501071<br> $ nvprof --metrics achieved_occupancy ./sumMatrix 32 16<br> sumMatrixOnGPU2D &lt;&lt;&lt;(512,1024), (32,16)&gt;&gt;&gt; Achieved Occupancy 0.736900<br> $ nvprof --metrics achieved_occupancy ./sumMatrix 16 32<br> sumMatrixOnGPU2D &lt;&lt;&lt;(1024,512), (16,32)&gt;&gt;&gt; Achieved Occupancy 0.766037<br> $ nvprof --metrics achieved_occupancy ./sumMatrix 16 16<br> sumMatrixOnGPU2D &lt;&lt;&lt;(1024,1024),(16,16)&gt;&gt;&gt; Achieved Occupancy 0.810691</p></li><li><p>From the results you can observe two things:</p></li><li><p>由于第二种情况比第一种情况有更多的区块，因此它向设备暴露了更多的活动翘曲。这可能就是第二个案例比第一个案例获得更高的占用率和更好的性能的原因。</p></li><li><p>第四种情况的占用率最高，但速度并不是最快的；因此，占用率越高并不总是等同于性能越高。一定还有其他因素限制了性能</p></li></ul><h3 id="_3-3-2-用nvprof检测内存操作" tabindex="-1"><a class="header-anchor" href="#_3-3-2-用nvprof检测内存操作" aria-hidden="true">#</a> 3.3.2 用nvprof检测内存操作</h3><p>Checking Memory Operations with nvprof</p><ul><li><p>在sumMatrix内核（C[idx]＝A[idx]＋B[idx]）中有3个内存操作：两个内存加载和一个内存存储。可以使用nvprof检测这些内存操作的效率。首先，用gld_throughput指标检查内核的内存读取效率，从而得到每个执行配置的差异：<br> $ nvprof --metrics gld_throughput./sumMatrix 32 32<br> sumMatrixOnGPU2D &lt;&lt;&lt;(512,512), (32,32)&gt;&gt;&gt; Global Load Throughput 35.908GB/s<br> $ nvprof --metrics gld_throughput./sumMatrix 32 16<br> sumMatrixOnGPU2D &lt;&lt;&lt;(512,1024), (32,16)&gt;&gt;&gt; Global Load Throughput 56.478GB/s<br> $ nvprof --metrics gld_throughput./sumMatrix 16 32<br> sumMatrixOnGPU2D &lt;&lt;&lt;(1024,512), (16,32)&gt;&gt;&gt; Global Load Throughput 85.195GB/s<br> $ nvprof --metrics gld_throughput./sumMatrix 16 16<br> sumMatrixOnGPU2D &lt;&lt;&lt;(1024,1024),(16,16)&gt;&gt;&gt; Global Load Throughput 94.708GB/s</p></li><li><p>第四种情况中的加载吞吐量最高，第二种情况中的加载吞吐量大约是第四种情况的一<br> 半，但第四种情况却比第二种情况慢。所以，更高的加载吞吐量并不一定意味着更高的性<br> 能。第4章介绍内存事务在GPU设备上的工作原理时将会具体分析产生这种现象的原因。</p></li><li><p>接下来，用gld_efficiency指标检测全局加载效率，即被请求的全局加载吞吐量占所需<br> 的全局加载吞吐量的比值。它衡量了应用程序的加载操作利用设备内存带宽的程度。结果<br> 总结如下：<br> $ nvprof --metrics gld_efficiency ./sumMatrix 32 32<br> sumMatrixOnGPU2D &lt;&lt;&lt;(512,512), (32,32)&gt;&gt;&gt; Global Memory Load Efficiency 100.00%<br> $ nvprof --metrics gld_efficiency ./sumMatrix 32 16<br> sumMatrixOnGPU2D &lt;&lt;&lt;(512,1024), (32,16)&gt;&gt;&gt; Global Memory Load Efficiency 100.00%<br> $ nvprof --metrics gld_efficiency ./sumMatrix 16 32<br> sumMatrixOnGPU2D &lt;&lt;&lt;(1024,512), (16,32)&gt;&gt;&gt; Global Memory Load Efficiency 49.96%<br> $ nvprof --metrics gld_efficiency ./sumMatrix 16 16<br> sumMatrixOnGPU2D &lt;&lt;&lt;(1024,1024),(16,16)&gt;&gt;&gt; Global Memory Load Efficiency 49.80%</p></li><li><p>从上述结果可知，最后两种情况下的加载效率是最前面两种情况的一半。这可以解释<br> 为什么最后两种情况下更高的加载吞吐量和可实现占用率没有产生较好的性能。尽管在最<br> 后两种情况下正在执行的加载数量（即吞吐量）很多，但是那些加载的有效性（即效率）<br> 是较低的。</p></li><li><p>注意，最后两种情况的共同特征是它们在最内层维数中块的大小是线程束的一半。如<br> 前所述，对网格和块启发式算法来说，最内层的维数应该总是线程束大小的倍数。第4章<br> 将讨论半个线程束大小的线程块是如何影响性能的。</p></li></ul><h3 id="_3-3-3-增大并行性" tabindex="-1"><a class="header-anchor" href="#_3-3-3-增大并行性" aria-hidden="true">#</a> 3.3.3 增大并行性</h3><p>Exposing More Parallelism</p>',8),Mn=n("li",null,[n("p",null,[s("从前一节可以总结出，一个块的最内层维数（block.x）应该是线程束大小的倍数。这"),n("br"),s(" 样能极大地提高了加载效率。你可能对以下问题仍然很好奇：")]),n("ul",null,[n("li",null,"是否有可能通过调整 block.x 进一步提高负载吞吐量(the load throughput)？"),n("li",null,"有其他方法可以增大并行性吗")])],-1),Un=n("br",null,null,-1),Sn=n("br",null,null,-1),Pn=n("br",null,null,-1),Cn=n("br",null,null,-1),Gn=n("br",null,null,-1),In=n("br",null,null,-1),An=n("br",null,null,-1),zn=n("br",null,null,-1),Rn=n("br",null,null,-1),Wn=n("br",null,null,-1),Hn=n("br",null,null,-1),Kn=n("br",null,null,-1),Tn=n("br",null,null,-1),En=n("br",null,null,-1),Nn=n("br",null,null,-1),On=n("br",null,null,-1),$n=n("br",null,null,-1),Bn=n("br",null,null,-1),Fn=n("br",null,null,-1),Ln=n("br",null,null,-1),qn={href:"http://sumMatrix.cu:163",target:"_blank",rel:"noopener noreferrer"},Xn=c("<li><p>以下是从这些结果中得出的一些看法和结论：</p></li><li><p>·最后一次的执行配置块的大小为（256，8），这是无效的。一个块中线程总数超过<br> 了1024个（这是GPU的硬件限制）。</p></li><li><p>最好的结果是第四种情况，块大小为（128，2）</p></li><li><p>第一种情况中块大小为（64，2），尽管在这种情况下启动的线程块最多，但不是最<br> 快的配置。</p></li><li><p>因为第二种情况中块的配置为（64，4），与最好的情况有相同数量的线程块，这两<br> 种情况应该在设备上显示出相同的并行性。因为这种情况相比（128，2）仍然表现较差，<br> 所以你可以得出这样的结论：线程块最内层维度的大小对性能起着的关键的作用。这正重<br> 复了前一节中总结的结论。</p></li><li><p>在所有其他情况下，线程块的数量都比最好的情况少。因此，增大并行性仍然是性<br> 能优化的一个重要因素。</p></li><li><p>你可能会想，线程块最少的那些示例应该显示出较低的可实现占用率，线程块最多的<br> 那些例子应该显示出较高的可实现占用率。这个理论可以用nvprof检测achieved_occu-pancy指标来验证一下：<br> $ nvprof --metrics achieved_occupancy ./sumMatrix 64 2<br> sumMatrixOnGPU2D &lt;&lt;&lt;(256,8192), (64,2) &gt;&gt;&gt; Achieved Occupancy 0.554556<br> $ nvprof --metrics achieved_occupancy ./sumMatrix 64 4<br> sumMatrixOnGPU2D &lt;&lt;&lt;(256,4096), (64,4) &gt;&gt;&gt; Achieved Occupancy 0.798622<br> $ nvprof --metrics achieved_occupancy ./sumMatrix 64 8<br> sumMatrixOnGPU2D &lt;&lt;&lt;(256,2048), (64,8) &gt;&gt;&gt; Achieved Occupancy 0.753532<br> $ nvprof --metrics achieved_occupancy ./sumMatrix 128 2<br> sumMatrixOnGPU2D &lt;&lt;&lt;(128,8192), (128,2)&gt;&gt;&gt; Achieved Occupancy 0.802598<br> $ nvprof --metrics achieved_occupancy ./sumMatrix 128 4<br> sumMatrixOnGPU2D &lt;&lt;&lt;(128,4096), (128,4)&gt;&gt;&gt; Achieved Occupancy 0.746367<br> $ nvprof --metrics achieved_occupancy ./sumMatrix 128 8<br> sumMatrixOnGPU2D &lt;&lt;&lt;(128,2048), (128,8)&gt;&gt;&gt; Achieved Occupancy 0.573449<br> $ nvprof --metrics achieved_occupancy ./sumMatrix 256 2<br> sumMatrixOnGPU2D &lt;&lt;&lt;(64,8192), (256,2) &gt;&gt;&gt; Achieved Occupancy 0.760901<br> $ nvprof --metrics achieved_occupancy ./sumMatrix 256 4<br> sumMatrixOnGPU2D &lt;&lt;&lt;(64,4096), (256,4) &gt;&gt;&gt; Achieved Occupancy 0.595197</p></li><li><p>从上面的结果可以得到，第一种情况（64，2）在所有例子中可实现占用率最低，但<br> 它的线程块是最多的。这种情况在线程块的最大数量上遇到了硬件限制。</p></li><li><p>第四种情况（128，2）和第七种情况（256，2），拥有最高的性能配置，有几乎相同<br> 的可实现占用率。在这两种情况下，通过将block.y设置为1来增大块间并行性，观察性能<br> 将如何变化。这使得每个线程块大小减少了，引起了更多的线程块被启动来处理相同数量的数据。这样做会产生以下结果：<br> $ ./sumMatrix 128 1<br> sumMatrixOnGPU2D &lt;&lt;&lt;(128,16384),(128,1)&gt;&gt;&gt; elapsed 0.032602 sec<br> $ ./sumMatrix 256 1<br> sumMatrixOnGPU2D &lt;&lt;&lt;(64,16384), (256,1)&gt;&gt;&gt; elapsed 0.030959 sec</p></li><li><p>到目前为止，这些配置能产生最佳的性能。特别是（256，1）的块配置优于（128，<br> 1）。可以使用以下的指令查看可实现占用率、加载吞吐量和加载效率：</p></li>",10),Vn=c(`<p>$ nvprof --metrics achieved_occupancy ./sumMatrix 256 1<br> $ nvprof --metrics gld_throughput ./sumMatrix 256 1<br> $ nvprof --metrics gld_efficiency ./sumMatrix 256 1</p><ul><li><p>报告结果如下<br> Achieved Occupancy 0.808622<br> Global Load Throughput 69.762GB/s<br> Global Memory Load Efficiency 100.00%</p></li><li><p>值得注意的是，最好的执行配置既不具有最高的可实现占用率，也不具有最高的加载<br> 吞吐量。从这些实验中可以推断出，没有一个单独的指标能直接优化性能。我们需要在几<br> 个相关的指标间寻找一个恰当的平衡来达到最佳的总体性能。</p></li><li><p><mark>指标与性能</mark></p></li><li><p>在大部分情况下，一个单独的指标不能产生最佳的性能</p></li><li><p>Which metric or event most directly relates to overall performance depends on the nature of the kernel code.与总体性能最直接相关的指标或事件取决于内核代码的本质</p></li><li><p>Seek a good balance among related metrics and events在相关的指标与事件之间寻求一个好的平衡</p></li><li><p>Check the kernel from different angles to fi nd a balance among the related metrics.从不同角度查看内核以寻找相关指标间的平衡</p></li><li><p>Grid/block heuristics provide a good starting point for performance tuning.网格/块启发式算法为性能调节提供了一个很好的起点</p></li></ul><h2 id="_3-4-避免分支分化" tabindex="-1"><a class="header-anchor" href="#_3-4-避免分支分化" aria-hidden="true">#</a> 3.4 避免分支分化</h2><p>AVOIDING BRANCH DIVERGENCE</p><ul><li>有时，控制流依赖于线程索引。线程束中的条件执行可能引起线程束分化，这会导致<br> 内核性能变差。通过重新组织数据的获取模式，可以减少或避免线程束分化。在本节里，<br> 将会以并行归约为例，介绍避免分支分化的基本技术。</li></ul><h3 id="_3-4-1-并行归约问题" tabindex="-1"><a class="header-anchor" href="#_3-4-1-并行归约问题" aria-hidden="true">#</a> 3.4.1 并行归约问题</h3><p>The Parallel Reduction Problem</p><ul><li>假设要对一个有N个元素的整数数组求和。使用如下的串行代码很容易实现算法：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">int</span> sum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span>
   sum <span class="token operator">+=</span> array<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>如果有大量的数据元素会怎么样呢？如何通过并行计算快速求和呢？鉴于加法的结合<br> 律和交换律，数组元素可以以任何顺序求和。所以可以用以下的方法执行并行加法运算：</p></li><li><p>1、Partition the input vector into smaller chunks将输入向量划分到更小的数据块中</p></li><li><p>2、Have a thread calculate the partial sum for each chunk.用一个线程计算一个数据块的部分和</p></li><li><p>3、Add the partial results from each chunk into a fi nal sum.对每个数据块的部分和再求和得出最终结果。</p></li><li><p>并行加法的一个常用方法是使用迭代成对实现。一个数据块只包含一对元素，并且一<br> 个线程对这两个元素求和产生一个局部结果。然后，这些局部结果在最初的输入向量中就<br> 地保存。这些新值被作为下一次迭代求和的输入值。因为输入值的数量在每一次迭代后会<br> 减半，当输出向量的长度达到1时，最终的和就已经被计算出来了。</p></li><li><p>根据每次迭代后输出元素就地存储的位置，成对的并行求和实现可以被进一步分为以<br> 下两种类型：</p></li><li><p>Neighbored pair: Elements are paired with their immediate neighbor.相邻配对：元素与它们直接相邻的元素配对</p></li><li><p>Interleaved pair: Paired elements are separated by a given stride.交错配对：根据给定的跨度配对元素</p></li><li><p>图3-19所示为相邻配对的实现。在每一步实现中，一个线程对两个相邻元素进行操<br> 作，产生部分和。对于有N个元素的数组，这种实现方式需要N―1次求和，进行log2 N<br> 步</p></li><li><p>图3-20所示为交错配对的实现。值得注意的是，在这种实现方法的每一步中，一个线<br> 程的输入是输入数组长度的一半。</p></li></ul><p><img src="`+A+'" alt="figure3-19" loading="lazy"><br><img src="'+z+`" alt="figure3-20" loading="lazy"></p><ul><li>下列的C语言函数是一个交错配对方法的递归实现：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">int</span> <span class="token function">recursiveReduce</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token operator">*</span>data<span class="token punctuation">,</span> <span class="token keyword">int</span> <span class="token keyword">const</span> size<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token comment">// terminate check</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>size <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">return</span> data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token comment">// renew the stride</span>
 <span class="token keyword">int</span> <span class="token keyword">const</span> stride <span class="token operator">=</span> size <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">;</span>
 <span class="token comment">// in-place reduction</span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> stride<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 data<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+=</span> data<span class="token punctuation">[</span>i <span class="token operator">+</span> stride<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 <span class="token comment">// call recursively</span>
 <span class="token keyword">return</span> <span class="token function">recursiveReduce</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> stride<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>尽管以上代码实现的是加法，但任何满足交换律和结合律的运算都可以代替加法。例<br> 如，通过调用max代替求和运算，就可以计算输入向量中的最大值。其他有效运算的例子<br> 有最小值、平均值和乘积。</li><li>在向量中执行满足交换律和结合律的运算，被称为归约问题。并行归约问题是这种运<br> 算的并行执行。并行归约是一种最常见的并行模式，并且是许多并行算法中的一个关键运<br> 算。</li><li>在本节里，会实现多个不同的并行归约核函数，并且将测试不同的实现是如何影响内<br> 核性能的.</li></ul><h3 id="_3-4-2-并行归约中的分化" tabindex="-1"><a class="header-anchor" href="#_3-4-2-并行归约中的分化" aria-hidden="true">#</a> 3.4.2 并行归约中的分化</h3><ul><li>图3-21所示的是相邻配对方法的内核实现流程。每个线程将相邻的两个元素相加产生<br> 部分和。</li><li>在这个内核里，有两个全局内存数组：一个大数组用来存放整个数组，进行归约；另<br> 一个小数组用来存放每个线程块的部分和。每个线程块在数组的一部分上独立地执行操<br> 作。循环中迭代一次执行一个归约步骤。归约是在就地完成的，这意味着在每一步，全局<br> 内存里的值都被部分和替代。__syncthreads语句可以保证，线程块中的任一线程在进入下一次迭代之前，在当前迭代里每个线程的所有部分和都被保存在了全局内存中。进入下一次迭代的所有线程都使用上一步产生的数值。在最后一个循环以后，整个线程块的和被保存进全局内存中。</li></ul><figure><img src="`+R+`" alt="figure3-21" tabindex="0" loading="lazy"><figcaption>figure3-21</figcaption></figure><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">reduceNeighbored</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token operator">*</span>g_idata<span class="token punctuation">,</span> <span class="token keyword">int</span> <span class="token operator">*</span>g_odata<span class="token punctuation">,</span> <span class="token keyword">unsigned</span> <span class="token keyword">int</span> n<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token comment">// set thread ID</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> tid <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 <span class="token comment">// convert global data pointer to the local pointer of this block</span>
 <span class="token keyword">int</span> <span class="token operator">*</span>idata <span class="token operator">=</span> g_idata <span class="token operator">+</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 <span class="token comment">// boundary check</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>idx <span class="token operator">&gt;=</span> n<span class="token punctuation">)</span> <span class="token keyword">return</span><span class="token punctuation">;</span>
 <span class="token comment">// in-place reduction in global memory</span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> stride <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span> stride <span class="token operator">&lt;</span> blockDim<span class="token punctuation">.</span>x<span class="token punctuation">;</span> stride <span class="token operator">*=</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>tid <span class="token operator">%</span> <span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> stride<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 idata<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> idata<span class="token punctuation">[</span>tid <span class="token operator">+</span> stride<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 <span class="token comment">// synchronize within block</span>
 <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 <span class="token comment">// write result for this block to global mem</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>tid <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> g_odata<span class="token punctuation">[</span>blockIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span> <span class="token operator">=</span> idata<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>两个相邻元素间的距离被称为跨度，初始化均为1。在每一次归约循环结束后，这个<br> 间隔就被乘以2。在第一次循环结束后，idata（全局数据指针）的偶数元素将会被部分和<br> 替代。在第二次循环结束后，idata的每四个元素将会被新产生的部分和替代。因为线程块间无法同步，所以每个线程块产生的部分和被复制回了主机，并且在那儿进行串行求和，如图3-22所示。</li></ul><figure><img src="`+W+'" alt="figure3-22" tabindex="0" loading="lazy"><figcaption>figure3-22</figcaption></figure>',20),Qn={class:"hint-container details"},jn=n("summary",null,"Click me to view the code!",-1),Yn=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token function"},"main"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" argc"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"char"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),s("argv"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token comment"},"// set up device"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" dev "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(`
 cudaDeviceProp deviceProp`),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"cudaGetDeviceProperties"),n("span",{class:"token punctuation"},"("),n("span",{class:"token operator"},"&"),s("deviceProp"),n("span",{class:"token punctuation"},","),s(" dev"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"%s starting reduction at "'),n("span",{class:"token punctuation"},","),s(" argv"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"device %d: %s "'),n("span",{class:"token punctuation"},","),s(" dev"),n("span",{class:"token punctuation"},","),s(" deviceProp"),n("span",{class:"token punctuation"},"."),s("name"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"cudaSetDevice"),n("span",{class:"token punctuation"},"("),s("dev"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"bool"),s(" bResult "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token boolean"},"false"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// initialization"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" size "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"1"),n("span",{class:"token operator"},"<<"),n("span",{class:"token number"},"24"),n("span",{class:"token punctuation"},";"),s(),n("span",{class:"token comment"},"// total number of elements to reduce"),s(`
 `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'" with array size %d "'),n("span",{class:"token punctuation"},","),s(" size"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// execution configuration"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" blocksize "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"512"),n("span",{class:"token punctuation"},";"),s(),n("span",{class:"token comment"},"// initial block size"),s(`
 `),n("span",{class:"token keyword"},"if"),n("span",{class:"token punctuation"},"("),s("argc "),n("span",{class:"token operator"},">"),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 blocksize `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"atoi"),n("span",{class:"token punctuation"},"("),s("argv"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(),n("span",{class:"token comment"},"// block size from command line argument"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 dim3 `),n("span",{class:"token function"},"block"),s(),n("span",{class:"token punctuation"},"("),s("blocksize"),n("span",{class:"token punctuation"},","),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 dim3 `),n("span",{class:"token function"},"grid"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),s("size"),n("span",{class:"token operator"},"+"),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"-"),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"/"),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"grid %d block %d\\n"'),n("span",{class:"token punctuation"},","),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// allocate host memory"),s(`
 size_t bytes `),n("span",{class:"token operator"},"="),s(" size "),n("span",{class:"token operator"},"*"),s(),n("span",{class:"token keyword"},"sizeof"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("h_idata "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token function"},"malloc"),n("span",{class:"token punctuation"},"("),s("bytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("h_odata "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token function"},"malloc"),n("span",{class:"token punctuation"},"("),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"*"),n("span",{class:"token keyword"},"sizeof"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("tmp "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token function"},"malloc"),n("span",{class:"token punctuation"},"("),s("bytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// initialize the array"),s(`
 `),n("span",{class:"token keyword"},"for"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" i "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(" i "),n("span",{class:"token operator"},"<"),s(" size"),n("span",{class:"token punctuation"},";"),s(" i"),n("span",{class:"token operator"},"++"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token comment"},"// mask off high 2 bytes to force max number to 255"),s(`
 h_idata`),n("span",{class:"token punctuation"},"["),s("i"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},"("),n("span",{class:"token function"},"rand"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"&"),s(),n("span",{class:"token number"},"0xFF"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token function"},"memcpy"),s(),n("span",{class:"token punctuation"},"("),s("tmp"),n("span",{class:"token punctuation"},","),s(" h_idata"),n("span",{class:"token punctuation"},","),s(" bytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 size_t iStart`),n("span",{class:"token punctuation"},","),s("iElaps"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" gpu_sum "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// allocate device memory"),s(`
 `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("d_idata "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token constant"},"NULL"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("d_odata "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token constant"},"NULL"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"cudaMalloc"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"&"),s("d_idata"),n("span",{class:"token punctuation"},","),s(" bytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"cudaMalloc"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"&"),s("d_odata"),n("span",{class:"token punctuation"},","),s(" grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"*"),n("span",{class:"token keyword"},"sizeof"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// cpu reduction"),s(`
 iStart `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"seconds"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" cpu_sum "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"recursiveReduce"),n("span",{class:"token punctuation"},"("),s("tmp"),n("span",{class:"token punctuation"},","),s(" size"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 iElaps `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"seconds"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"-"),s(" iStart"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"cpu reduce elapsed %d ms cpu_sum: %d\\n"'),n("span",{class:"token punctuation"},","),s("iElaps"),n("span",{class:"token punctuation"},","),s("cpu_sum"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// kernel 1: reduceNeighbored"),s(`
 `),n("span",{class:"token function"},"cudaMemcpy"),n("span",{class:"token punctuation"},"("),s("d_idata"),n("span",{class:"token punctuation"},","),s(" h_idata"),n("span",{class:"token punctuation"},","),s(" bytes"),n("span",{class:"token punctuation"},","),s(" cudaMemcpyHostToDevice"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
`),n("span",{class:"token function"},"cudaDeviceSynchronize"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 iStart `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"seconds"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 warmup`),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),n("span",{class:"token punctuation"},"("),s("d_idata"),n("span",{class:"token punctuation"},","),s(" d_odata"),n("span",{class:"token punctuation"},","),s(" size"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"cudaDeviceSynchronize"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 iElaps `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"seconds"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"-"),s(" iStart"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"cudaMemcpy"),n("span",{class:"token punctuation"},"("),s("h_odata"),n("span",{class:"token punctuation"},","),s(" d_odata"),n("span",{class:"token punctuation"},","),s(" grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"*"),n("span",{class:"token keyword"},"sizeof"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},","),s(" cudaMemcpyDeviceToHost"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 gpu_sum `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"for"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" i"),n("span",{class:"token operator"},"="),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(" i"),n("span",{class:"token operator"},"<"),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(" i"),n("span",{class:"token operator"},"++"),n("span",{class:"token punctuation"},")"),s(" gpu_sum "),n("span",{class:"token operator"},"+="),s(" h_odata"),n("span",{class:"token punctuation"},"["),s("i"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"gpu Warmup elapsed %d ms gpu_sum: %d <<<grid %d block %d>>>\\n"'),n("span",{class:"token punctuation"},","),s(`
 iElaps`),n("span",{class:"token punctuation"},","),s("gpu_sum"),n("span",{class:"token punctuation"},","),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// kernel 1: reduceNeighbored"),s(`
 `),n("span",{class:"token function"},"cudaMemcpy"),n("span",{class:"token punctuation"},"("),s("d_idata"),n("span",{class:"token punctuation"},","),s(" h_idata"),n("span",{class:"token punctuation"},","),s(" bytes"),n("span",{class:"token punctuation"},","),s(" cudaMemcpyHostToDevice"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"cudaDeviceSynchronize"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 iStart `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"seconds"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 reduceNeighbored`),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),n("span",{class:"token punctuation"},"("),s("d_idata"),n("span",{class:"token punctuation"},","),s(" d_odata"),n("span",{class:"token punctuation"},","),s(" size"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"cudaDeviceSynchronize"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 iElaps `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"seconds"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"-"),s(" iStart"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"cudaMemcpy"),n("span",{class:"token punctuation"},"("),s("h_odata"),n("span",{class:"token punctuation"},","),s(" d_odata"),n("span",{class:"token punctuation"},","),s(" grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"*"),n("span",{class:"token keyword"},"sizeof"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},","),s(" cudaMemcpyDeviceToHost"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 gpu_sum `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"for"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" i"),n("span",{class:"token operator"},"="),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(" i"),n("span",{class:"token operator"},"<"),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(" i"),n("span",{class:"token operator"},"++"),n("span",{class:"token punctuation"},")"),s(" gpu_sum "),n("span",{class:"token operator"},"+="),s(" h_odata"),n("span",{class:"token punctuation"},"["),s("i"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"gpu Neighbored elapsed %d ms gpu_sum: %d <<<grid %d block %d>>>\\n"'),n("span",{class:"token punctuation"},","),s(`
 iElaps`),n("span",{class:"token punctuation"},","),s("gpu_sum"),n("span",{class:"token punctuation"},","),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"cudaDeviceSynchronize"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 iElaps `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"seconds"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"-"),s(" iStart"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"cudaMemcpy"),n("span",{class:"token punctuation"},"("),s("h_odata"),n("span",{class:"token punctuation"},","),s(" d_odata"),n("span",{class:"token punctuation"},","),s(" grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"/"),n("span",{class:"token number"},"8"),n("span",{class:"token operator"},"*"),n("span",{class:"token keyword"},"sizeof"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},","),s(" cudaMemcpyDeviceToHost"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 gpu_sum `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"for"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" i "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(" i "),n("span",{class:"token operator"},"<"),s(" grid"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"/"),s(),n("span",{class:"token number"},"8"),n("span",{class:"token punctuation"},";"),s(" i"),n("span",{class:"token operator"},"++"),n("span",{class:"token punctuation"},")"),s(" gpu_sum "),n("span",{class:"token operator"},"+="),s(" h_odata"),n("span",{class:"token punctuation"},"["),s("i"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"gpu Cmptnroll elapsed %d ms gpu_sum: %d <<<grid %d block %d>>>\\n"'),n("span",{class:"token punctuation"},","),s(`
 iElaps`),n("span",{class:"token punctuation"},","),s("gpu_sum"),n("span",{class:"token punctuation"},","),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"/"),n("span",{class:"token number"},"8"),n("span",{class:"token punctuation"},","),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"/// free host memory"),s(`
 `),n("span",{class:"token function"},"free"),n("span",{class:"token punctuation"},"("),s("h_idata"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"free"),n("span",{class:"token punctuation"},"("),s("h_odata"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// free device memory"),s(`
 `),n("span",{class:"token function"},"cudaFree"),n("span",{class:"token punctuation"},"("),s("d_idata"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"cudaFree"),n("span",{class:"token punctuation"},"("),s("d_odata"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// reset device"),s(`
 `),n("span",{class:"token function"},"cudaDeviceReset"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// check the results"),s(`
 bResult `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),s("gpu_sum "),n("span",{class:"token operator"},"=="),s(" cpu_sum"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"if"),n("span",{class:"token punctuation"},"("),n("span",{class:"token operator"},"!"),s("bResult"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"Test failed!\\n"'),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"return"),s(" EXIT_SUCCESS"),n("span",{class:"token punctuation"},";"),s(`
`),n("span",{class:"token punctuation"},"}"),s(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),Jn=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s("The input array is initialized to contain "),n("span",{class:"token number"},"16"),s("M elements"),n("span",{class:"token operator"},":"),s(`
`),n("span",{class:"token keyword"},"int"),s(" size "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"1"),n("span",{class:"token operator"},"<<"),n("span",{class:"token number"},"24"),n("span",{class:"token punctuation"},";"),s(`

然后，内核被配置为一维网格和一维块：
dim3 `),n("span",{class:"token function"},"block"),s(),n("span",{class:"token punctuation"},"("),s("blocksize"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
dim3 `),n("span",{class:"token function"},"grid"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),s("size "),n("span",{class:"token operator"},"+"),s(" block"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"-"),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"/"),s(" block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`

用以下的命令编译文件：
$ nvcc `),n("span",{class:"token operator"},"-"),s("O3 "),n("span",{class:"token operator"},"-"),s("arch"),n("span",{class:"token operator"},"="),s("sm_20 reduceInteger"),n("span",{class:"token punctuation"},"."),s("cu "),n("span",{class:"token operator"},"-"),s(`o reduceInteger


运行可执行文件，以下是运行结果。
$ `),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s("reduceInteger starting reduction at device "),n("span",{class:"token number"},"0"),n("span",{class:"token operator"},":"),s(` Tesla M2070 
 with array size `),n("span",{class:"token number"},"16777216"),s(" grid "),n("span",{class:"token number"},"32768"),s(" block "),n("span",{class:"token number"},"512"),s(`
cpu reduce elapsed `),n("span",{class:"token number"},"29"),s(" ms cpu_sum"),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"2139353471"),s(`
gpu Neighbored elapsed `),n("span",{class:"token number"},"11"),s(" ms gpu_sum"),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"2139353471"),s(),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid "),n("span",{class:"token number"},"32768"),s(" block "),n("span",{class:"token number"},"512"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s(`

在接下来的一节中，这些结果将会被作为性能调节的基准
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),Zn=c('<h3 id="_3-4-3-改善并行归约的分化" tabindex="-1"><a class="header-anchor" href="#_3-4-3-改善并行归约的分化" aria-hidden="true">#</a> 3.4.3 改善并行归约的分化</h3><ul><li>测试核函数reduceNeighbored，并注意以下条件表达式：<br> if ((tid % (2 * stride)) == 0)</li><li>因为上述语句只对偶数ID的线程为true，所以这会导致很高的线程束分化。在并行归<br> 约的第一次迭代中，只有ID为偶数的线程执行这个条件语句的主体，但是所有的线程都必<br> 须被调度。在第二次迭代中，只有四分之一的线程是活跃的，但是所有的线程仍然都必须<br> 被调度。通过重新组织每个线程的数组索引来强制ID相邻的线程执行求和操作，线程束分<br> 化就能被归约了。图3-23展示了这种实现。和图3-21相比，部分和的存储位置并没有改<br> 变，但是工作线程已经更新了。</li></ul><figure><img src="'+H+'" alt="figure3-23" tabindex="0" loading="lazy"><figcaption>figure3-23</figcaption></figure>',3),ns={class:"hint-container details"},ss=n("summary",null,"Click me to view the code!",-1),as=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s("The kernel code "),n("span",{class:"token keyword"},"for"),s(),n("span",{class:"token keyword"},"this"),s(" change is listed here"),n("span",{class:"token operator"},":"),s(`
__global__ `),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"reduceNeighboredLess"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("g_idata"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("g_odata"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" n"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token comment"},"// set thread ID"),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" tid "),n("span",{class:"token operator"},"="),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" idx "),n("span",{class:"token operator"},"="),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"+"),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// convert global data pointer to the local pointer of this block"),s(`
 `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("idata "),n("span",{class:"token operator"},"="),s(" g_idata "),n("span",{class:"token operator"},"+"),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"*"),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// boundary check"),s(`
 `),n("span",{class:"token keyword"},"if"),n("span",{class:"token punctuation"},"("),s("idx "),n("span",{class:"token operator"},">="),s(" n"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token keyword"},"return"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// in-place reduction in global memory"),s(`
 `),n("span",{class:"token keyword"},"for"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" stride "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},";"),s(" stride "),n("span",{class:"token operator"},"<"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(" stride "),n("span",{class:"token operator"},"*="),s(),n("span",{class:"token number"},"2"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token comment"},"// convert tid into local array index"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" index "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"2"),s(),n("span",{class:"token operator"},"*"),s(" stride "),n("span",{class:"token operator"},"*"),s(" tid"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("index "),n("span",{class:"token operator"},"<"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 idata`),n("span",{class:"token punctuation"},"["),s("index"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" idata"),n("span",{class:"token punctuation"},"["),s("index "),n("span",{class:"token operator"},"+"),s(" stride"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token comment"},"// synchronize within threadblock"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token comment"},"// write result for this block to global mem"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("tid "),n("span",{class:"token operator"},"=="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s(" g_odata"),n("span",{class:"token punctuation"},"["),s("blockIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" idata"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
`),n("span",{class:"token punctuation"},"}"),s(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),ts=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s(`注意内核中的下述语句，它为每个线程设置数组访问索引：
`),n("span",{class:"token keyword"},"int"),s(" index "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"2"),s(),n("span",{class:"token operator"},"*"),s(" stride "),n("span",{class:"token operator"},"*"),s(" tid"),n("span",{class:"token punctuation"},";"),s(`

因为跨度乘以了`),n("span",{class:"token number"},"2"),s(`，所以下面的语句使用线程块的前半部分来执行求和操作：
`),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("index "),n("span",{class:"token operator"},"<"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},")"),s(`

对于一个有`),n("span",{class:"token number"},"512"),s("个线程的块来说，前"),n("span",{class:"token number"},"8"),s("个线程束执行第一轮归约，剩下"),n("span",{class:"token number"},"8"),s(`个线程束什么
也不做。在第二轮里，前`),n("span",{class:"token number"},"4"),s("个线程束执行归约，剩下"),n("span",{class:"token number"},"12"),s(`个线程束什么也不做。因此，这样
就彻底不存在分化了。在最后五轮中，当每一轮的线程总数小于线程束的大小时，分化就
会出现。在下一节将会介绍如何处理这一问题

在主函数里调用基准内核之后，通过以下代码段可以调用这个新内核。
`),n("span",{class:"token comment"},"// kernel 2: reduceNeighbored with less divergence"),s(`
 `),n("span",{class:"token function"},"cudaMemcpy"),n("span",{class:"token punctuation"},"("),s("d_idata"),n("span",{class:"token punctuation"},","),s(" h_idata"),n("span",{class:"token punctuation"},","),s(" bytes"),n("span",{class:"token punctuation"},","),s(" cudaMemcpyHostToDevice"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"cudaDeviceSynchronize"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 iStart `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"seconds"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 reduceNeighboredLess`),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),n("span",{class:"token punctuation"},"("),s("d_idata"),n("span",{class:"token punctuation"},","),s(" d_odata"),n("span",{class:"token punctuation"},","),s(" size"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"cudaDeviceSynchronize"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 iElaps `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"seconds"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"-"),s(" iStart"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"cudaMemcpy"),n("span",{class:"token punctuation"},"("),s("h_odata"),n("span",{class:"token punctuation"},","),s(" d_odata"),n("span",{class:"token punctuation"},","),s(" grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"*"),n("span",{class:"token keyword"},"sizeof"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},","),s(" cudaMemcpyDeviceToHost"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 gpu_sum `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"for"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" i"),n("span",{class:"token operator"},"="),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(" i"),n("span",{class:"token operator"},"<"),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(" i"),n("span",{class:"token operator"},"++"),n("span",{class:"token punctuation"},")"),s(" gpu_sum "),n("span",{class:"token operator"},"+="),s(" h_odata"),n("span",{class:"token punctuation"},"["),s("i"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"gpu Neighbored2 elapsed %d ms gpu_sum: %d <<<grid %d block %d>>>\\n"'),n("span",{class:"token punctuation"},","),s(`
 iElaps`),n("span",{class:"token punctuation"},","),s("gpu_sum"),n("span",{class:"token punctuation"},","),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`

用reduceNeighboredLess函数测试，较早的核函数将产生如下报告：
$ `),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s("reduceInteger Starting reduction at device "),n("span",{class:"token number"},"0"),n("span",{class:"token operator"},":"),s(` Tesla M2070 
 vector size `),n("span",{class:"token number"},"16777216"),s(" grid "),n("span",{class:"token number"},"32768"),s(" block "),n("span",{class:"token number"},"512"),s(`
cpu reduce elapsed `),n("span",{class:"token number"},"0.029138"),s(" sec cpu_sum"),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"2139353471"),s(`
gpu Neighbored elapsed `),n("span",{class:"token number"},"0.011722"),s(" sec gpu_sum"),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"2139353471"),s(),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid "),n("span",{class:"token number"},"32768"),s(" block "),n("span",{class:"token number"},"512"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s(`
gpu NeighboredL elapsed `),n("span",{class:"token number"},"0.009321"),s(" sec gpu_sum"),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"2139353471"),s(),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid "),n("span",{class:"token number"},"32768"),s(" block "),n("span",{class:"token number"},"512"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s(`

新的实现比原来的快了`),n("span",{class:"token number"},"1.26"),s(`倍。
可以通过测试不同的指标来解释这两个内核之间的不同行为。用inst_per_warp指标来
查看每个线程束上执行指令数量的平均值。
$ nvprof `),n("span",{class:"token operator"},"--"),s("metrics inst_per_warp "),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s(`reduceInteger

结果总结如下，原来的内核在每个线程束里执行的指令数是新内核的两倍多，它是原
来实现高分化的一个指示器：
Neighbored Instructions per warp `),n("span",{class:"token number"},"295.562500"),s(`
NeighboredLess Instructions per warp `),n("span",{class:"token number"},"115.312500"),s(`

用gld_throughput指标来查看内存加载吞吐量：
$ nvprof `),n("span",{class:"token operator"},"--"),s("metrics gld_throughput "),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s(`reduceInteger

结果总结如下，新的实现拥有更高的加载吞吐量，因为虽然I`),n("span",{class:"token operator"},"/"),s(`O操作数量相同，但是
其耗时更短：
Neighbored Global Load Throughput `),n("span",{class:"token number"},"67.663"),s("GB"),n("span",{class:"token operator"},"/"),s(`s 
NeighboredL Global Load Throughput `),n("span",{class:"token number"},"80.144"),s("GB"),n("span",{class:"token operator"},"/"),s(`s
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),es=c('<h3 id="_3-4-4-交错配对的归约" tabindex="-1"><a class="header-anchor" href="#_3-4-4-交错配对的归约" aria-hidden="true">#</a> 3.4.4 交错配对的归约</h3><ul><li>与相邻配对方法相比，交错配对方法颠倒了元素的跨度。初始跨度是线程块大小的一<br> 半，然后在每次迭代中减少一半（如图3-24所示）。在每次循环中，每个线程对两个被当<br> 前跨度隔开的元素进行求和，以产生一个部分和。与图3-23相比，交错归约的工作线程没<br> 有变化。但是，每个线程在全局内存中的加载/存储位置是不同的。</li></ul><figure><img src="'+K+'" alt="figure3-24" tabindex="0" loading="lazy"><figcaption>figure3-24</figcaption></figure><ul><li>交错归约的内核代码如下所示：</li></ul>',4),os={class:"hint-container details"},ps=n("summary",null,"Click me to view the code!",-1),cs=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s(),n("span",{class:"token comment"},"/// Interleaved Pair Implementation with less divergence"),s(`
 __global__ `),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"reduceInterleaved"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("g_idata"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("g_odata"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" n"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(` 
   `),n("span",{class:"token comment"},"// set thread ID"),s(`
   `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" tid "),n("span",{class:"token operator"},"="),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" idx "),n("span",{class:"token operator"},"="),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"+"),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// convert global data pointer to the local pointer of this block"),s(`
   `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("idata "),n("span",{class:"token operator"},"="),s(" g_idata "),n("span",{class:"token operator"},"+"),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// boundary check"),s(`
   `),n("span",{class:"token keyword"},"if"),n("span",{class:"token punctuation"},"("),s("idx "),n("span",{class:"token operator"},">="),s(" n"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token keyword"},"return"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// in-place reduction in global memory"),s(`
   `),n("span",{class:"token keyword"},"for"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" stride "),n("span",{class:"token operator"},"="),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"/"),s(),n("span",{class:"token number"},"2"),n("span",{class:"token punctuation"},";"),s(" stride "),n("span",{class:"token operator"},">"),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(" stride "),n("span",{class:"token operator"},">>="),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
      `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("tid "),n("span",{class:"token operator"},"<"),s(" stride"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
         idata`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(" stride"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
      `),n("span",{class:"token punctuation"},"}"),s(`
      `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token punctuation"},"}"),s(`
   `),n("span",{class:"token comment"},"// write result for this block to global mem"),s(`
   `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("tid "),n("span",{class:"token operator"},"=="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s(" g_odata"),n("span",{class:"token punctuation"},"["),s("blockIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" idata"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),ls=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s(`注意核函数中的下述语句，两个元素间的跨度被初始化为线程块大小的一半，然后在
每次循环中减少一半：
`),n("span",{class:"token keyword"},"for"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" stride "),n("span",{class:"token operator"},"="),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"/"),s(),n("span",{class:"token number"},"2"),n("span",{class:"token punctuation"},";"),s(" stride "),n("span",{class:"token operator"},">"),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(" stride "),n("span",{class:"token operator"},">>="),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),s(` 


下面的语句在第一次迭代时强制线程块中的前半部分线程执行求和操作，第二次迭代
时是线程块的前四分之一，以此类推：
`),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("tid "),n("span",{class:"token operator"},"<"),s(" stride"),n("span",{class:"token punctuation"},")"),s(`


下面的代码增加到主函数中，执行交错归约的代码：
`),n("span",{class:"token function"},"cudaMemcpy"),n("span",{class:"token punctuation"},"("),s("d_idata"),n("span",{class:"token punctuation"},","),s(" h_idata"),n("span",{class:"token punctuation"},","),s(" bytes"),n("span",{class:"token punctuation"},","),s(" cudaMemcpyHostToDevice"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
`),n("span",{class:"token function"},"cudaDeviceSynchronize"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
iStart `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"seconds"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 reduceInterleaved  `),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s(" grid"),n("span",{class:"token punctuation"},","),s(" block "),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s(),n("span",{class:"token punctuation"},"("),s("d_idata"),n("span",{class:"token punctuation"},","),s(" d_odata"),n("span",{class:"token punctuation"},","),s(" size"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"cudaDeviceSynchronize"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 iElaps `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"seconds"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"-"),s(" iStart"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"cudaMemcpy"),n("span",{class:"token punctuation"},"("),s("h_odata"),n("span",{class:"token punctuation"},","),s(" d_odata"),n("span",{class:"token punctuation"},","),s(" grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"*"),n("span",{class:"token keyword"},"sizeof"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},","),s(" cudaMemcpyDeviceToHost"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 gpu_sum `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"for"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" i "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(" i "),n("span",{class:"token operator"},"<"),s(" grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(" i"),n("span",{class:"token operator"},"++"),n("span",{class:"token punctuation"},")"),s(" gpu_sum "),n("span",{class:"token operator"},"+="),s(" h_odata"),n("span",{class:"token punctuation"},"["),s("i"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"gpu Interleaved elapsed %f sec gpu_sum: %d <<<grid %d block %d>>>\\n"'),n("span",{class:"token punctuation"},","),s("iElaps"),n("span",{class:"token punctuation"},","),s("gpu_sum"),n("span",{class:"token punctuation"},","),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`

用reduceInterleaved函数进行测试，较早的内核函数将产生如下报告：

 $ `),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s("reduce starting reduction at device "),n("span",{class:"token number"},"0"),n("span",{class:"token operator"},":"),s(` Tesla M2070
     with array size `),n("span",{class:"token number"},"16777216"),s("  grid "),n("span",{class:"token number"},"32768"),s(" block "),n("span",{class:"token number"},"512"),s(`
 cpu reduce      elapsed `),n("span",{class:"token number"},"0.029138"),s(" sec cpu_sum"),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"2139353471"),s(`
 gpu Warmup      elapsed `),n("span",{class:"token number"},"0.011745"),s(" sec gpu_sum"),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"2139353471"),s(),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid "),n("span",{class:"token number"},"32768"),s(" block "),n("span",{class:"token number"},"512"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s(`
 gpu Neighbored  elapsed `),n("span",{class:"token number"},"0.011722"),s(" sec gpu_sum"),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"2139353471"),s(),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid "),n("span",{class:"token number"},"32768"),s(" block "),n("span",{class:"token number"},"512"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s(`
 gpu NeighboredL elapsed `),n("span",{class:"token number"},"0.009321"),s(" sec gpu_sum"),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"2139353471"),s(),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid "),n("span",{class:"token number"},"32768"),s(" block "),n("span",{class:"token number"},"512"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s(`
 gpu Interleaved elapsed `),n("span",{class:"token number"},"0.006967"),s(" sec gpu_sum"),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"2139353471"),s(),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid "),n("span",{class:"token number"},"32768"),s(" block "),n("span",{class:"token number"},"512"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s(`


交错实现比第一个实现快了`),n("span",{class:"token number"},"1.69"),s("倍，比第二个实现快了"),n("span",{class:"token number"},"1.34"),s(`倍。这种性能的提升主要
是由reduceInterleaved函数里的全局内存加载`),n("span",{class:"token operator"},"/"),s("存储模式导致的。在第"),n("span",{class:"token number"},"4"),s("章里会介绍更多有关于全局内存加载"),n("span",{class:"token operator"},"/"),s("存储模式对内核性能的影响。reduceInterleaved函数和reduceNeigh"),n("span",{class:"token operator"},"-"),s(`boredLess函数维持相同的线程束分化。

`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),is=c(`<h2 id="_3-5-展开循环" tabindex="-1"><a class="header-anchor" href="#_3-5-展开循环" aria-hidden="true">#</a> 3.5 展开循环</h2><ul><li>循环展开是一个尝试通过减少分支出现的频率和循环维护指令来优化循环的技术。在<br> 循环展开中，循环主体在代码中要多次被编写，而不是只编写一次循环主体再使用另一个<br> 循环来反复执行的。任何的封闭循环可将它的迭代次数减少或完全删除。循环体的复制数<br> 量被称为循环展开因子，迭代次数就变为了原始循环迭代次数除以循环展开因子。在顺序<br> 数组中，当循环的迭代次数在循环执行之前就已经知道时，循环展开是最有效提升性能的<br> 方法。考虑下面的代码：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">100</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 a<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> b<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> c<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>如果重复操作一次循环体，迭代次数能减少到原始循环的一半：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">100</span><span class="token punctuation">;</span> i <span class="token operator">+=</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 a<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> b<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> c<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>
 a<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> b<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> c<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>从高级语言层面上来看，循环展开使性能提高的原因可能不是显而易见的。这种提升<br> 来自于编译器执行循环展开时低级指令的改进和优化。例如，在前面循环展开的例子中，<br> 条件i&lt;100只检查了50次，而在原来的循环中则检查了100次。另外，因为在每个循环中每<br> 个语句的读和写都是独立的，所以CPU可以同时发出内存操作。</p></li><li><p>在CUDA中，循环展开的意义非常重大。我们的目标仍然是相同的：通过减少指令消<br> 耗和增加更多的独立调度指令来提高性能。因此，更多的并发操作被添加到流水线上，以<br> 产生更高的指令和内存带宽。这为线程束调度器提供更多符合条件的线程束，它们可以帮<br> 助隐藏指令或内存延迟。</p></li></ul><h3 id="_3-5-1-展开的归约" tabindex="-1"><a class="header-anchor" href="#_3-5-1-展开的归约" aria-hidden="true">#</a> 3.5.1 展开的归约</h3><ul><li>你可能会注意到，在reduceInterleaved核函数中每个线程块只处理一部分数据，这些<br> 数据可以被认为是一个数据块。如果用一个线程块手动展开两个数据块的处理，会怎么<br> 样？以下的核函数是reduceInterleaved核函数的修正版：每个线程块汇总了来自两个数据块的数据。这是一个循环分区（在第1章中已介绍）的例子，每个线程作用于多个数据<br> 块，并处理每个数据块的一个元素：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">reduceUnrolling2</span> <span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token operator">*</span>g_idata<span class="token punctuation">,</span> <span class="token keyword">int</span> <span class="token operator">*</span>g_odata<span class="token punctuation">,</span> <span class="token keyword">unsigned</span> <span class="token keyword">int</span> n<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token comment">// set thread ID</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> tid <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> idx <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">*</span> <span class="token number">2</span> <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 <span class="token comment">// convert global data pointer to the local pointer of this block</span>
 <span class="token keyword">int</span> <span class="token operator">*</span>idata <span class="token operator">=</span> g_idata <span class="token operator">+</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">;</span>
 <span class="token comment">// unrolling 2 data blocks</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>idx <span class="token operator">+</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">&lt;</span> n<span class="token punctuation">)</span> g_idata<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">+=</span> g_idata<span class="token punctuation">[</span>idx <span class="token operator">+</span> blockDim<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// in-place reduction in global memory</span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> stride <span class="token operator">=</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">;</span> stride <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">;</span> stride <span class="token operator">&gt;&gt;=</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>tid <span class="token operator">&lt;</span> stride<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 idata<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> idata<span class="token punctuation">[</span>tid <span class="token operator">+</span> stride<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span> 
 <span class="token comment">// synchronize within threadblock</span>
 <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 <span class="token comment">// write result for this block to global mem</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>tid <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> g_odata<span class="token punctuation">[</span>blockIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span> <span class="token operator">=</span> idata<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>注意要在核函数的开头添加的下述语句。在这里，每个线程都添加一个来自于相邻数<br> 据块的元素。从概念上来讲，可以把它作为归约循环的一个迭代，此循环可在数据块间归<br> 约：<br> if (idx + blockDim.x &lt; n) g_idata[idx] += g_idata[idx+blockDim.x];</p></li><li><p>如下所示，全局数组索引被相应地调整，因为只需要一半的线程块来处理相同的数据<br> 集。请注意，这也意味着对于相同大小的数据集，向设备显示的线程束和线程块级别的并<br> 行性更低。图3-25所示为每个线程的数据访问。<br> unsigned int idx = blockIdx.x * blockDim.x * 2 + threadIdx.x;<br> int *idata = g_idata + blockIdx.x * blockDim.x * 2;</p></li></ul><figure><img src="`+T+`" alt="figure3-25" tabindex="0" loading="lazy"><figcaption>figure3-25</figcaption></figure><ul><li>向主函数添加下面的代码，调用新的核函数：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>d_idata<span class="token punctuation">,</span> h_idata<span class="token punctuation">,</span> bytes<span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaDeviceSynchronize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
iStart <span class="token operator">=</span> <span class="token function">seconds</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
reduceUnrolling2 <span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span> grid<span class="token punctuation">.</span>x<span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">,</span> block <span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token punctuation">(</span>d_idata<span class="token punctuation">,</span> d_odata<span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaDeviceSynchronize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
iElaps <span class="token operator">=</span> <span class="token function">seconds</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> iStart<span class="token punctuation">;</span>
<span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>h_odata<span class="token punctuation">,</span> d_odata<span class="token punctuation">,</span> grid<span class="token punctuation">.</span>x<span class="token operator">/</span><span class="token number">2</span><span class="token operator">*</span><span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cudaMemcpyDeviceToHost<span class="token punctuation">)</span><span class="token punctuation">;</span>
gpu_sum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> grid<span class="token punctuation">.</span>x <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> gpu_sum <span class="token operator">+=</span> h_odata<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">&quot;gpu Unrolling2 elapsed %f sec gpu_sum: %d &lt;&lt;&lt;grid %d block %d&gt;&gt;&gt;\\n&quot;</span><span class="token punctuation">,</span>iElaps<span class="token punctuation">,</span>gpu_sum<span class="token punctuation">,</span>grid<span class="token punctuation">.</span>x<span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">,</span>block<span class="token punctuation">.</span>x<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>因为现在每个线程块处理两个数据块，我们需要调整内核的执行配置，将网格大小减<br> 小至一半：<br><code>reduceUnrolling2&lt;&lt;&lt;grid.x / 2, block&gt;&gt;&gt;(d_idata, d_odata, size);</code></p></li><li><p>现在编译和运行这些代码，出现以下结果：<br> gpu Unrolling2 elapsed 0.003430 sec gpu_sum: 2139353471 &lt;&lt;&lt;grid 16384 block 512&gt;&gt;&gt;</p></li><li><p>即使只进行简单的更改，现在核函数的执行速度比原来快3.42倍。可以进一步展开以<br> 产生更好的性能吗？reduceInteger.cu文件包含着展开的核函数中其他的两个实现，如下所示：<br> reduceUnrolling4 : each threadblock handles 4 data blocks<br> reduceUnrolling8 : each threadblock handles 8 data blocks</p></li><li><p>相应的结果概括如下：<br> gpu Unrolling2 elapsed 0.003430 sec gpu_sum: 2139353471 &lt;&lt;&lt;grid 16384 block 512&gt;&gt;&gt;<br> gpu Unrolling4 elapsed 0.001829 sec gpu_sum: 2139353471 &lt;&lt;&lt;grid 8192 block 512&gt;&gt;&gt;<br> gpu Unrolling8 elapsed 0.001422 sec gpu_sum: 2139353471 &lt;&lt;&lt;grid 4096 block 512&gt;&gt;&gt;</p></li><li><p>正如预想的一样，在一个线程中有更多的独立内存加载/存储操作会产生更好的性<br> 能，因为内存延迟可以更好地被隐藏起来。可以使用设备内存读取吞吐量指标，以确定这<br> 就是性能提高的原因：<br> $ nvprof --metrics dram_read_throughput ./reduceInteger</p></li><li><p>结果总结如下，归约的展开测试用例和设备读吞吐量之间是成正比的：<br> Unrolling2 Device Memory Read Throughput 26.295GB/s<br> Unrolling4 Device Memory Read Throughput 49.546GB/s<br> Unrolling8 Device Memory Read Throughput 62.764GB/s</p></li></ul><h3 id="_3-5-2-展开线程的归约" tabindex="-1"><a class="header-anchor" href="#_3-5-2-展开线程的归约" aria-hidden="true">#</a> 3.5.2 展开线程的归约</h3><ul><li>__syncthreads是用于块内同步的。在归约核函数中，它用来确保在线程进入下一轮之<br> 前，每一轮中所有线程已经将局部结果写入全局内存中了。</li><li>然而，要细想一下只剩下32个或更少线程（即一个线程束）的情况。因为线程束的执<br> 行是SIMT（单指令多线程）的，每条指令之后有隐式的线程束内同步过程。因此，归约<br> 循环的最后6个迭代可以用下述语句来展开：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">if</span> <span class="token punctuation">(</span>tid <span class="token operator">&lt;</span> <span class="token number">32</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token keyword">volatile</span> <span class="token keyword">int</span> <span class="token operator">*</span>vmem <span class="token operator">=</span> idata<span class="token punctuation">;</span>
 vmem<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> vmem<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
 vmem<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> vmem<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">16</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
 vmem<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> vmem<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
 vmem<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> vmem<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
 vmem<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> vmem<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
 vmem<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> vmem<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>这个线程束的展开避免了执行循环控制和线程同步逻辑。</p></li><li><p>注意变量vmem是和volatile修饰符一起被声明的，它告诉编译器每次赋值时必须将<br> vmem[tid]的值存回全局内存中。如果省略了volatile修饰符，这段代码将不能正常工作，因为编译器或缓存可能对全局或共享内存优化读写。如果位于全局或共享内存中的变量有volatile修饰符，编译器会假定其值可以被其他线程在任何时间修改或使用。因此，任何参考volatile修饰符的变量强制直接读或写内存，而不是简单地读写缓存或寄存器。</p></li><li><p>基于reduceUnrolling8，线程束的展开可以添加到归约核函数中，如下所示：</p></li></ul>`,18),us={class:"hint-container details"},rs=n("summary",null,"Click me to view the code!",-1),ks=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s("__global__ "),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"reduceUnrollWarps8"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("g_idata"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("g_odata"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" n"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token comment"},"// set thread ID"),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" tid "),n("span",{class:"token operator"},"="),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" idx "),n("span",{class:"token operator"},"="),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"*"),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"*"),n("span",{class:"token number"},"8"),s(),n("span",{class:"token operator"},"+"),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// convert global data pointer to the local pointer of this block"),s(`
 `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("idata "),n("span",{class:"token operator"},"="),s(" g_idata "),n("span",{class:"token operator"},"+"),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"*"),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"*"),n("span",{class:"token number"},"8"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// unrolling 8"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("idx "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"7"),n("span",{class:"token operator"},"*"),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"<"),s(" n"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" a1 "),n("span",{class:"token operator"},"="),s(" g_idata"),n("span",{class:"token punctuation"},"["),s("idx"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" a2 "),n("span",{class:"token operator"},"="),s(" g_idata"),n("span",{class:"token punctuation"},"["),s("idx"),n("span",{class:"token operator"},"+"),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" a3 "),n("span",{class:"token operator"},"="),s(" g_idata"),n("span",{class:"token punctuation"},"["),s("idx"),n("span",{class:"token operator"},"+"),n("span",{class:"token number"},"2"),n("span",{class:"token operator"},"*"),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" a4 "),n("span",{class:"token operator"},"="),s(" g_idata"),n("span",{class:"token punctuation"},"["),s("idx"),n("span",{class:"token operator"},"+"),n("span",{class:"token number"},"3"),n("span",{class:"token operator"},"*"),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" b1 "),n("span",{class:"token operator"},"="),s(" g_idata"),n("span",{class:"token punctuation"},"["),s("idx"),n("span",{class:"token operator"},"+"),n("span",{class:"token number"},"4"),n("span",{class:"token operator"},"*"),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" b2 "),n("span",{class:"token operator"},"="),s(" g_idata"),n("span",{class:"token punctuation"},"["),s("idx"),n("span",{class:"token operator"},"+"),n("span",{class:"token number"},"5"),n("span",{class:"token operator"},"*"),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" b3 "),n("span",{class:"token operator"},"="),s(" g_idata"),n("span",{class:"token punctuation"},"["),s("idx"),n("span",{class:"token operator"},"+"),n("span",{class:"token number"},"6"),n("span",{class:"token operator"},"*"),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" b4 "),n("span",{class:"token operator"},"="),s(" g_idata"),n("span",{class:"token punctuation"},"["),s("idx"),n("span",{class:"token operator"},"+"),n("span",{class:"token number"},"7"),n("span",{class:"token operator"},"*"),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 g_idata`),n("span",{class:"token punctuation"},"["),s("idx"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" a1"),n("span",{class:"token operator"},"+"),s("a2"),n("span",{class:"token operator"},"+"),s("a3"),n("span",{class:"token operator"},"+"),s("a4"),n("span",{class:"token operator"},"+"),s("b1"),n("span",{class:"token operator"},"+"),s("b2"),n("span",{class:"token operator"},"+"),s("b3"),n("span",{class:"token operator"},"+"),s("b4"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// in-place reduction in global memory"),s(`
 `),n("span",{class:"token keyword"},"for"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" stride "),n("span",{class:"token operator"},"="),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"/"),s(),n("span",{class:"token number"},"2"),n("span",{class:"token punctuation"},";"),s(" stride "),n("span",{class:"token operator"},">"),s(),n("span",{class:"token number"},"32"),n("span",{class:"token punctuation"},";"),s(" stride "),n("span",{class:"token operator"},">>="),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("tid "),n("span",{class:"token operator"},"<"),s(" stride"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 idata`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(" stride"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token comment"},"// synchronize within threadblock"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token comment"},"// unrolling warp"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("tid "),n("span",{class:"token operator"},"<"),s(),n("span",{class:"token number"},"32"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token keyword"},"volatile"),s(),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("vmem "),n("span",{class:"token operator"},"="),s(" idata"),n("span",{class:"token punctuation"},";"),s(`
 vmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"32"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 vmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"16"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 vmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"8"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 vmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"4"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 vmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"2"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 vmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token comment"},"// write result for this block to global mem"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("tid "),n("span",{class:"token operator"},"=="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s(" g_odata"),n("span",{class:"token punctuation"},"["),s("blockIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" idata"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
`),n("span",{class:"token punctuation"},"}"),s(`

`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),ds=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s("因为在这个实现中，每个线程处理"),n("span",{class:"token number"},"8"),s(`个数据块，调用这个内核的同时它的网格尺寸减
小到`),n("span",{class:"token number"},"1"),n("span",{class:"token operator"},"/"),n("span",{class:"token number"},"8"),s(`：
reduceUnrollWarps8`),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"/"),s(),n("span",{class:"token number"},"8"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s(),n("span",{class:"token punctuation"},"("),s("d_idata"),n("span",{class:"token punctuation"},","),s(" d_odata"),n("span",{class:"token punctuation"},","),s(" size"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`


这个核函数的执行时间比reduceUnrolling8快`),n("span",{class:"token number"},"1.05"),s("倍，比原来的核函数reduceNeigh"),n("span",{class:"token operator"},"-"),s("bored快"),n("span",{class:"token number"},"8.65"),s(`倍：
gpu UnrollWarp8 elapsed `),n("span",{class:"token number"},"0.001355"),s(" sec gpu_sum"),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"2139353471"),s(),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid "),n("span",{class:"token number"},"4096"),s(" block "),n("span",{class:"token number"},"512"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s(`


使用下面的命令，stall_sync指标可以用来证实，由于__syncthreads的同步，更少的线
程束发生阻塞：
$ nvprof `),n("span",{class:"token operator"},"--"),s("metrics stall_sync "),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s(`reduce

结果总结如下。通过展开最后的线程束，百分比几乎减半了，这表明__syncthreads能
减少新的核函数中的阻塞。
Unrolling8 Issue Stall Reasons `),n("span",{class:"token number"},"58.37"),n("span",{class:"token operator"},"%"),s(`
UnrollWarps8 Issue Stall Reasons `),n("span",{class:"token number"},"30.60"),n("span",{class:"token operator"},"%"),s(`


`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),bs=n("h3",{id:"_3-5-3-完全展开的归约",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#_3-5-3-完全展开的归约","aria-hidden":"true"},"#"),s(" 3.5.3 完全展开的归约")],-1),ms=n("ul",null,[n("li",null,[s("如果编译时已知一个循环中的迭代次数，就可以把循环完全展开。因为在Fermi或"),n("br"),s(" Kepler架构中，每个块的最大线程数都是1024（参见表3-2），并且在这些归约核函数中"),n("br"),s(" 循环迭代次数是基于一个线程块维度的，所以完全展开归约循环是可能的：")])],-1),vs={class:"hint-container details"},gs=n("summary",null,"Click me to view the code!",-1),hs=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s("k dimension"),n("span",{class:"token punctuation"},","),s(" it is possible to completely unroll the reduction loop"),n("span",{class:"token operator"},":"),s(`
__global__ `),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"reduceCompleteUnrollWarps8"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("g_idata"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("g_odata"),n("span",{class:"token punctuation"},","),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" n"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token comment"},"// set thread ID"),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" tid "),n("span",{class:"token operator"},"="),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" idx "),n("span",{class:"token operator"},"="),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"*"),s(),n("span",{class:"token number"},"8"),s(),n("span",{class:"token operator"},"+"),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// convert global data pointer to the local pointer of this block"),s(`
 `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("idata "),n("span",{class:"token operator"},"="),s(" g_idata "),n("span",{class:"token operator"},"+"),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"*"),s(),n("span",{class:"token number"},"8"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// unrolling 8"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("idx "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"7"),n("span",{class:"token operator"},"*"),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"<"),s(" n"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" a1 "),n("span",{class:"token operator"},"="),s(" g_idata"),n("span",{class:"token punctuation"},"["),s("idx"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" a2 "),n("span",{class:"token operator"},"="),s(" g_idata"),n("span",{class:"token punctuation"},"["),s("idx "),n("span",{class:"token operator"},"+"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" a3 "),n("span",{class:"token operator"},"="),s(" g_idata"),n("span",{class:"token punctuation"},"["),s("idx "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"2"),s(),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" a4 "),n("span",{class:"token operator"},"="),s(" g_idata"),n("span",{class:"token punctuation"},"["),s("idx "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"3"),s(),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" b1 "),n("span",{class:"token operator"},"="),s(" g_idata"),n("span",{class:"token punctuation"},"["),s("idx "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"4"),s(),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" b2 "),n("span",{class:"token operator"},"="),s(" g_idata"),n("span",{class:"token punctuation"},"["),s("idx "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"5"),s(),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" b3 "),n("span",{class:"token operator"},"="),s(" g_idata"),n("span",{class:"token punctuation"},"["),s("idx "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"6"),s(),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" b4 "),n("span",{class:"token operator"},"="),s(" g_idata"),n("span",{class:"token punctuation"},"["),s("idx "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"7"),s(),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 g_idata`),n("span",{class:"token punctuation"},"["),s("idx"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" a1 "),n("span",{class:"token operator"},"+"),s(" a2 "),n("span",{class:"token operator"},"+"),s(" a3 "),n("span",{class:"token operator"},"+"),s(" a4 "),n("span",{class:"token operator"},"+"),s(" b1 "),n("span",{class:"token operator"},"+"),s(" b2 "),n("span",{class:"token operator"},"+"),s(" b3 "),n("span",{class:"token operator"},"+"),s(" b4"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// in-place reduction and complete unroll"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},">="),n("span",{class:"token number"},"1024"),s(),n("span",{class:"token operator"},"&&"),s(" tid "),n("span",{class:"token operator"},"<"),s(),n("span",{class:"token number"},"512"),n("span",{class:"token punctuation"},")"),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"512"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},">="),n("span",{class:"token number"},"512"),s(),n("span",{class:"token operator"},"&&"),s(" tid "),n("span",{class:"token operator"},"<"),s(),n("span",{class:"token number"},"256"),n("span",{class:"token punctuation"},")"),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"256"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},">="),n("span",{class:"token number"},"256"),s(),n("span",{class:"token operator"},"&&"),s(" tid "),n("span",{class:"token operator"},"<"),s(),n("span",{class:"token number"},"128"),n("span",{class:"token punctuation"},")"),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"128"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},">="),n("span",{class:"token number"},"128"),s(),n("span",{class:"token operator"},"&&"),s(" tid "),n("span",{class:"token operator"},"<"),s(),n("span",{class:"token number"},"64"),n("span",{class:"token punctuation"},")"),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"64"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// unrolling warp"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("tid "),n("span",{class:"token operator"},"<"),s(),n("span",{class:"token number"},"32"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token keyword"},"volatile"),s(),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("vsmem "),n("span",{class:"token operator"},"="),s(" idata"),n("span",{class:"token punctuation"},";"),s(`
 vsmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vsmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"32"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 vsmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vsmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"16"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 vsmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vsmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"8"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 vsmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vsmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"4"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 vsmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vsmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"2"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 vsmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vsmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token comment"},"// write result for this block to global mem"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("tid "),n("span",{class:"token operator"},"=="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s(" g_odata"),n("span",{class:"token punctuation"},"["),s("blockIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" idata"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
`),n("span",{class:"token punctuation"},"}"),s(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),fs=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s(`用以下执行配置调用这个核函数：
reduceCompleteUnrollWarps8`),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"/"),s(),n("span",{class:"token number"},"8"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),n("span",{class:"token punctuation"},"("),s("d_idata"),n("span",{class:"token punctuation"},","),s(" d_odata"),n("span",{class:"token punctuation"},","),s(" size"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`


内核时间再次有了小小的改善，它的执行比reduceUnrollWarps8快`),n("span",{class:"token number"},"1.06"),s(`倍，比原来的实
现快`),n("span",{class:"token number"},"9.16"),s(`倍：
gpu CmptUnroll8 elapsed `),n("span",{class:"token number"},"0.001280"),s(" sec gpu_sum"),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"2139353471"),s(),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid "),n("span",{class:"token number"},"4096"),s(" block "),n("span",{class:"token number"},"512"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s(`

`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),_s=n("h3",{id:"_3-5-4-模板函数的归约",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#_3-5-4-模板函数的归约","aria-hidden":"true"},"#"),s(" 3.5.4 模板函数的归约")],-1),ys=n("ul",null,[n("li",null,[s("虽然可以手动展开循环，但是使用模板函数有助于进一步减少分支消耗。在设备函数"),n("br"),s(" 上CUDA支持模板参数。如下所示，可以指定块的大小作为模板函数的参数：")])],-1),xs={class:"hint-container details"},ws=n("summary",null,"Click me to view the code!",-1),Ds=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[n("span",{class:"token keyword"},"template"),s(),n("span",{class:"token operator"},"<"),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" iBlockSize"),n("span",{class:"token operator"},">"),s(`
__global__ `),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"reduceCompleteUnroll"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("g_idata"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("g_odata"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" n"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token comment"},"// set thread ID"),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" tid "),n("span",{class:"token operator"},"="),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" idx "),n("span",{class:"token operator"},"="),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"*"),s(),n("span",{class:"token number"},"8"),s(),n("span",{class:"token operator"},"+"),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// convert global data pointer to the local pointer of this block"),s(`
 `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("idata "),n("span",{class:"token operator"},"="),s(" g_idata "),n("span",{class:"token operator"},"+"),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"*"),s(),n("span",{class:"token number"},"8"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// unrolling 8"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("idx "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"7"),n("span",{class:"token operator"},"*"),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"<"),s(" n"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" a1 "),n("span",{class:"token operator"},"="),s(" g_idata"),n("span",{class:"token punctuation"},"["),s("idx"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" a2 "),n("span",{class:"token operator"},"="),s(" g_idata"),n("span",{class:"token punctuation"},"["),s("idx "),n("span",{class:"token operator"},"+"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" a3 "),n("span",{class:"token operator"},"="),s(" g_idata"),n("span",{class:"token punctuation"},"["),s("idx "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"2"),s(),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" a4 "),n("span",{class:"token operator"},"="),s(" g_idata"),n("span",{class:"token punctuation"},"["),s("idx "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"3"),s(),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" b1 "),n("span",{class:"token operator"},"="),s(" g_idata"),n("span",{class:"token punctuation"},"["),s("idx "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"4"),s(),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" b2 "),n("span",{class:"token operator"},"="),s(" g_idata"),n("span",{class:"token punctuation"},"["),s("idx "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"5"),s(),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" b3 "),n("span",{class:"token operator"},"="),s(" g_idata"),n("span",{class:"token punctuation"},"["),s("idx "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"6"),s(),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" b4 "),n("span",{class:"token operator"},"="),s(" g_idata"),n("span",{class:"token punctuation"},"["),s("idx "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"7"),s(),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 g_idata`),n("span",{class:"token punctuation"},"["),s("idx"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" a1"),n("span",{class:"token operator"},"+"),s("a2"),n("span",{class:"token operator"},"+"),s("a3"),n("span",{class:"token operator"},"+"),s("a4"),n("span",{class:"token operator"},"+"),s("b1"),n("span",{class:"token operator"},"+"),s("b2"),n("span",{class:"token operator"},"+"),s("b3"),n("span",{class:"token operator"},"+"),s("b4"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// in-place reduction and complete unroll"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("iBlockSize"),n("span",{class:"token operator"},">="),n("span",{class:"token number"},"1024"),s(),n("span",{class:"token operator"},"&&"),s(" tid "),n("span",{class:"token operator"},"<"),s(),n("span",{class:"token number"},"512"),n("span",{class:"token punctuation"},")"),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"512"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("iBlockSize"),n("span",{class:"token operator"},">="),n("span",{class:"token number"},"512"),s(),n("span",{class:"token operator"},"&&"),s(" tid "),n("span",{class:"token operator"},"<"),s(),n("span",{class:"token number"},"256"),n("span",{class:"token punctuation"},")"),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"256"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
`),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("iBlockSize"),n("span",{class:"token operator"},">="),n("span",{class:"token number"},"256"),s(),n("span",{class:"token operator"},"&&"),s(" tid "),n("span",{class:"token operator"},"<"),s(),n("span",{class:"token number"},"128"),n("span",{class:"token punctuation"},")"),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"128"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("iBlockSize"),n("span",{class:"token operator"},">="),n("span",{class:"token number"},"128"),s(),n("span",{class:"token operator"},"&&"),s(" tid "),n("span",{class:"token operator"},"<"),s(),n("span",{class:"token number"},"64"),n("span",{class:"token punctuation"},")"),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"64"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// unrolling warp"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("tid "),n("span",{class:"token operator"},"<"),s(),n("span",{class:"token number"},"32"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token keyword"},"volatile"),s(),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("vsmem "),n("span",{class:"token operator"},"="),s(" idata"),n("span",{class:"token punctuation"},";"),s(`
 vsmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vsmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"32"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 vsmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vsmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"16"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 vsmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vsmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"8"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 vsmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vsmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"4"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 vsmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vsmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"2"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 vsmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vsmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token comment"},"// write result for this block to global mem"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("tid "),n("span",{class:"token operator"},"=="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s(" g_odata"),n("span",{class:"token punctuation"},"["),s("blockIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" idata"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
`),n("span",{class:"token punctuation"},"}"),s(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),Ms=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s(`相比reduceCompleteUnrollWarps8，唯一的区别是使用了模板参数替换了块大小。检查
块大小的`),n("span",{class:"token keyword"},"if"),s("语句将在编译时被评估，如果这一条件为"),n("span",{class:"token boolean"},"false"),s("，那么编译时它将会被删除，使得内循环更有效率。例如，在线程块大小为"),n("span",{class:"token number"},"256"),s("的情况下调用这个核函数，下述语句将永远是"),n("span",{class:"token boolean"},"false"),s(`：
iBlockSize`),n("span",{class:"token operator"},">="),n("span",{class:"token number"},"1024"),s(),n("span",{class:"token operator"},"&&"),s(" tid "),n("span",{class:"token operator"},"<"),s(),n("span",{class:"token number"},"512"),s(`


编译器会自动从执行内核中移除它。
该核函数一定要在`),n("span",{class:"token keyword"},"switch"),n("span",{class:"token operator"},"-"),n("span",{class:"token keyword"},"case"),s(`结构中被调用。这允许编译器为特定的线程块大小自动
优化代码，但这也意味着它只对在特定块大小下启动reduceCompleteUnroll有效：
`),n("span",{class:"token keyword"},"switch"),s(),n("span",{class:"token punctuation"},"("),s("blocksize"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token keyword"},"case"),s(),n("span",{class:"token number"},"1024"),n("span",{class:"token operator"},":"),s(`
 reduceCompleteUnroll`),n("span",{class:"token operator"},"<"),n("span",{class:"token number"},"1024"),n("span",{class:"token operator"},">"),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"/"),n("span",{class:"token number"},"8"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),n("span",{class:"token punctuation"},"("),s("d_idata"),n("span",{class:"token punctuation"},","),s(" d_odata"),n("span",{class:"token punctuation"},","),s(" size"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"break"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"case"),s(),n("span",{class:"token number"},"512"),n("span",{class:"token operator"},":"),s(`
 reduceCompleteUnroll`),n("span",{class:"token operator"},"<"),n("span",{class:"token number"},"512"),n("span",{class:"token operator"},">"),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"/"),n("span",{class:"token number"},"8"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),n("span",{class:"token punctuation"},"("),s("d_idata"),n("span",{class:"token punctuation"},","),s(" d_odata"),n("span",{class:"token punctuation"},","),s(" size"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"break"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"case"),s(),n("span",{class:"token number"},"256"),n("span",{class:"token operator"},":"),s(`
 reduceCompleteUnroll`),n("span",{class:"token operator"},"<"),n("span",{class:"token number"},"256"),n("span",{class:"token operator"},">"),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"/"),n("span",{class:"token number"},"8"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),n("span",{class:"token punctuation"},"("),s("d_idata"),n("span",{class:"token punctuation"},","),s(" d_odata"),n("span",{class:"token punctuation"},","),s(" size"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"break"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"case"),s(),n("span",{class:"token number"},"128"),n("span",{class:"token operator"},":"),s(`
 reduceCompleteUnroll`),n("span",{class:"token operator"},"<"),n("span",{class:"token number"},"128"),n("span",{class:"token operator"},">"),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"/"),n("span",{class:"token number"},"8"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),n("span",{class:"token punctuation"},"("),s("d_idata"),n("span",{class:"token punctuation"},","),s(" d_odata"),n("span",{class:"token punctuation"},","),s(" size"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"break"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"case"),s(),n("span",{class:"token number"},"64"),n("span",{class:"token operator"},":"),s(`
 reduceCompleteUnroll`),n("span",{class:"token operator"},"<"),n("span",{class:"token number"},"64"),n("span",{class:"token operator"},">"),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"/"),n("span",{class:"token number"},"8"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),n("span",{class:"token punctuation"},"("),s("d_idata"),n("span",{class:"token punctuation"},","),s(" d_odata"),n("span",{class:"token punctuation"},","),s(" size"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(` 
 `),n("span",{class:"token keyword"},"break"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`


`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),Us=c('<ul><li>表3-5概括了本节提到的所有并行归约实现的结果。</li><li>注意，最大的相对性能增益是通过reduceUnrolling8核函数获得的，在这个函数之中每个线程在归约前处理8个数据块。有了8个独立的内存访问，可以更好地让内存带宽饱和及隐藏加载/存储延迟。可以使用以下命令检测内存加载/存储效率指标：<br> $nvprof --metrics gld_efficiency,gst_efficiency ./reduceInteger</li><li>表3-6总结了所有核函数的结果。在第4章，将会更加详细地介绍全局内存访问，并且<br> 会对内存访问如何影响内核性能有更深的了解。</li></ul><h2 id="_3-6-动态并行" tabindex="-1"><a class="header-anchor" href="#_3-6-动态并行" aria-hidden="true">#</a> 3.6 动态并行</h2><ul><li><p>在本书中，到目前为止，所有核函数都是从主机线程中被调用的。GPU的工作负载完<br> 全在CPU的控制下。CUDA的动态并行允许在GPU端直接创建和同步新的GPU内核。在一<br> 个核函数中在任意点动态增加GPU应用程序的并行性，是一个令人兴奋的新功能。</p></li><li><p>到目前为止，我们需要把算法设计为单独的、大规模数据并行的内核启动。动态并行<br> 提供了一个更有层次结构的方法，在这个方法中，并发性可以在一个GPU内核的多个级别<br> 中表现出来。使用动态并行可以让递归算法更加清晰易懂，也更容易理解。</p></li><li><p>有了动态并行，可以推迟到运行时决定需要在GPU上创建多少个块和网格，可以动态<br> 地利用GPU硬件调度器和加载平衡器，并进行调整以适应数据驱动或工作负载。</p></li><li><p>在GPU端直接创建工作的能力可以减少在主机和设备之间传输执行控制和数据的需<br> 求，因为在设备上执行的线程可以在运行时决定启动配置。</p></li><li><p>在本节中，将通过使用动态并行实现递归归约核函数的例子，对如何利用动态并行有<br> 一个基本的了解。</p></li></ul><h3 id="_3-6-1-嵌套执行" tabindex="-1"><a class="header-anchor" href="#_3-6-1-嵌套执行" aria-hidden="true">#</a> 3.6.1 嵌套执行</h3><ul><li><p>通过动态并行，我们已经熟悉了内核执行的概念（网格、块、启动配置等），也可以<br> 直接在GPU上进行内核调用。相同的内核调用语法被用在一个内核内启动一个新的核函<br> 数。</p></li><li><p>在动态并行中，内核执行分为两种类型：父母和孩子。父线程、父线程块或父网格启<br> 动一个新的网格，即子网格。子线程、子线程块或子网格被父母启动。子网格必须在父线<br> 程、父线程块或父网格完成之前完成。只有在所有的子网格都完成之后，父母才会完成。</p></li><li><p>图3-26说明了父网格和子网格的适用范围。主机线程配置和启动父网格，父网格配置<br> 和启动子网格。子网格的调用和完成必须进行适当地嵌套，这意味着在线程创建的所有子<br> 网格都完成之后，父网格才会完成。如果调用的线程没有显式地同步启动子网格，那么运<br> 行时保证父母和孩子之间的隐式同步。在图3-26中，在父线程中设置了栅栏，从而可以与<br> 其子网格显式地同步。</p></li></ul><figure><img src="'+E+`" alt="figure3-26" tabindex="0" loading="lazy"><figcaption>figure3-26</figcaption></figure><ul><li><p>设备线程中的网格启动，在线程块间是可见的。这意味着，线程可能与由该线程启动<br> 的或由相同线程块中其他线程启动的子网格同步。在线程块中，只有当所有线程创建的所<br> 有子网格完成之后，线程块的执行才会完成。如果块中所有线程在所有的子网格完成之前<br> 退出，那么在那些子网格上隐式同步会被触发。</p></li><li><p>当父母启动一个子网格，父线程块与孩子显式同步之后，孩子才能开始执行。</p></li><li><p>父网格和子网格共享相同的全局和常量内存存储，但它们有不同的局部内存和共享内<br> 存。有了孩子和父母之间的弱一致性作为保证，父网格和子网格可以对全局内存并发存<br> 取。有两个时刻，子网格和它的父线程见到的内存完全相同：子网格开始时和子网格完成<br> 时。当父线程优于子网格调用时，所有的全局内存操作要保证对子网格是可见的。当父母<br> 在子网格完成时进行同步操作后，子网格所有的内存操作应保证对父母是可见的。</p></li><li><p>共享内存和局部内存分别对于线程块或线程来说是私有的，同时，在父母和孩子之间<br> 不是可见或一致的。局部内存对线程来说是私有存储，并且对该线程外部不可见。当启动<br> 一个子网格时，向局部内存传递一个指针作为参数是无效的。</p></li></ul><h3 id="_3-6-2-在gpu上嵌套hello-world" tabindex="-1"><a class="header-anchor" href="#_3-6-2-在gpu上嵌套hello-world" aria-hidden="true">#</a> 3.6.2 在GPU上嵌套Hello World</h3><ul><li><p>为了初步理解动态并行，可以创建一个核函数，使其用动态并行来输出“Hello<br> World”。图3-27说明了用动态并行由这个核函数构造的嵌套、递归执行。主机应用程序调<br> 用父网格，该父网格在一个线程块中有8个线程。然后，该父网格中的线程0调用一个子网<br> 格，该子网格中有一半线程，即4个线程。之后，第一个子网格中的线程0再调用一个新的<br> 子网格，这个新的子网格中也只有一半线程，即2个线程，以此类推，直到最后的嵌套中<br> 只剩下一个线程。</p></li><li><p>实现这个逻辑的内核代码如下所示。每个线程的核函数执行，会先输出“Hello<br> World”。接着，每个线程检查自己是否该停止。如果在这个嵌套层里线程数大于1，线程0<br> 就递归地调用一个带有线程数一半的子网格。</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">nestedHelloWorld</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token keyword">const</span> iSize<span class="token punctuation">,</span><span class="token keyword">int</span> iDepth<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token keyword">int</span> tid <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">&quot;Recursion=%d: Hello World from thread %d&quot;</span> 
 <span class="token string">&quot;block %d\\n&quot;</span><span class="token punctuation">,</span>iDepth<span class="token punctuation">,</span>tid<span class="token punctuation">,</span>blockIdx<span class="token punctuation">.</span>x<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// condition to stop recursive execution</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>iSize <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">return</span><span class="token punctuation">;</span>
 <span class="token comment">// reduce block size to half</span>
 <span class="token keyword">int</span> nthreads <span class="token operator">=</span> iSize<span class="token operator">&gt;&gt;</span><span class="token number">1</span><span class="token punctuation">;</span>
 <span class="token comment">// thread 0 launches child grid recursively</span>
 <span class="token keyword">if</span><span class="token punctuation">(</span>tid <span class="token operator">==</span> <span class="token number">0</span> <span class="token operator">&amp;&amp;</span> nthreads <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 nestedHelloWorld<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token number">1</span><span class="token punctuation">,</span> nthreads<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>nthreads<span class="token punctuation">,</span><span class="token operator">++</span>iDepth<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">&quot;-------&gt; nested execution depth: %d\\n&quot;</span><span class="token punctuation">,</span>iDepth<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><figure><img src="`+N+'" alt="figure3-27" tabindex="0" loading="lazy"><figcaption>figure3-27</figcaption></figure>',11),Ss={href:"http://nestedHelloWorld.cu",target:"_blank",rel:"noopener noreferrer"},Ps=c("<li><p>因为动态并行是由设备运行时库所支持的，所以nestedHelloWorld函数必须在命令行<br> 使用-lcudadevrt进行明确链接。</p></li><li><p>当-rdc标志为true时，它强制生成可重定位的设备代码，这是动态并行的一个要求。<br> 在本书的第10章将会介绍到更多可重定位设备代码的内容。</p></li><li><p>嵌套核函数的输出如下<br> ./nestedHelloWorld Execution Configuration: grid 1 block 8<br> Recursion=0: Hello World from thread 0 block 0<br> Recursion=0: Hello World from thread 1 block 0<br> Recursion=0: Hello World from thread 2 block 0<br> Recursion=0: Hello World from thread 3 block 0<br> Recursion=0: Hello World from thread 4 block 0<br> Recursion=0: Hello World from thread 5 block 0<br> Recursion=0: Hello World from thread 6 block 0<br> Recursion=0: Hello World from thread 7 block 0<br> -------&gt; nested execution depth: 1<br> Recursion=1: Hello World from thread 0 block 0<br> Recursion=1: Hello World from thread 1 block 0<br> Recursion=1: Hello World from thread 2 block 0<br> Recursion=1: Hello World from thread 3 block 0<br> -------&gt; nested execution depth: 2<br> Recursion=2: Hello World from thread 0 block 0<br> Recursion=2: Hello World from thread 1 block 0<br> -------&gt; nested execution depth: 3<br> Recursion=3: Hello World from thread 0 block 0</p></li><li><p>从输出信息中可见，由主机调用的父网格有1个线程块和8个线程。nestedHelloWorld<br> 核函数递归地调用三次，每次调用的线程数是上一次的一半。可以用nvvp工具通过以下的<br> 命令证明这一点：<br> $ nvvp ./nestedHelloWorld</p></li><li><p>图3-28所示为由nvvp显示的嵌套执行。子网格被适当地嵌套，并且每个父网格会等待<br> 直到它的子网格执行结束，空白处说明内核在等待子网格执行结束。</p></li>",5),Cs=c('<figure><img src="'+O+'" alt="figure3-28" tabindex="0" loading="lazy"><figcaption>figure3-28</figcaption></figure><ul><li><p>现在，试着使用两个线程块调用父网格，而不是使用一个。<br> $ ./nestedHelloWorld 2</p></li><li><p>嵌套内核程序的输出如下：<br> ./nestedHelloWorld 2Execution Configuration: grid 2 block 8<br> Recursion=0: Hello World from thread 0 block 1<br> Recursion=0: Hello World from thread 1 block 1<br> Recursion=0: Hello World from thread 2 block 1<br> Recursion=0: Hello World from thread 3 block 1<br> Recursion=0: Hello World from thread 4 block 1<br> Recursion=0: Hello World from thread 5 block 1<br> Recursion=0: Hello World from thread 6 block 1<br> Recursion=0: Hello World from thread 7 block 1<br> Recursion=0: Hello World from thread 0 block 0<br> Recursion=0: Hello World from thread 1 block 0<br> Recursion=0: Hello World from thread 2 block 0<br> Recursion=0: Hello World from thread 3 block 0<br> Recursion=0: Hello World from thread 4 block 0<br> Recursion=0: Hello World from thread 5 block 0<br> Recursion=0: Hello World from thread 6 block 0<br> Recursion=0: Hello World from thread 7 block 0<br> -------&gt; nested execution depth: 1<br> -------&gt; nested execution depth: 1<br> Recursion=1: Hello World from thread 0 block 0<br> Recursion=1: Hello World from thread 1 block 0<br> Recursion=1: Hello World from thread 2 block 0<br> Recursion=1: Hello World from thread 3 block 0<br> Recursion=1: Hello World from thread 0 block 0<br> Recursion=1: Hello World from thread 1 block 0<br> Recursion=1: Hello World from thread 2 block 0<br> Recursion=1: Hello World from thread 3 block 0<br> -------&gt; nested execution depth: 2<br> -------&gt; nested execution depth: 2<br> Recursion=2: Hello World from thread 0 block 0<br> Recursion=2: Hello World from thread 1 block 0<br> Recursion=2: Hello World from thread 0 block 0<br> Recursion=2: Hello World from thread 1 block 0<br> -------&gt; nested execution depth: 3<br> -------&gt; nested execution depth: 3<br> Recursion=3: Hello World from thread 0 block 0<br> Recursion=3: Hello World from thread 0 block 0</p></li><li><p>为什么在输出信息里所有子网格线程块的ID都是0？图3-29说明了子网格是如何被两<br> 个初始线程块递归调用的。父网格包含两个线程块，所有嵌套的子网格仍然只包含一个线<br> 程块，这是由于线程配置核函数在nestedHelloWorld函数里启动：<br> nestedHelloWorld&lt;&lt;&lt;1, nthreads&gt;&gt;&gt;(nthreads, ++iDepth);</p></li><li><p>可以尝试使用不同的启动策略。图3-30所示为另一种生成相同数量并行性的方法，这<br> 一部分留给读者作为练习。</p></li></ul><figure><img src="'+$+'" alt="figure3-29" tabindex="0" loading="lazy"><figcaption>figure3-29</figcaption></figure><figure><img src="'+B+'" alt="figure3-30" tabindex="0" loading="lazy"><figcaption>figure3-30</figcaption></figure><ul><li><mark>动态并行的限制条件</mark></li><li>动态并行只有在计算能力为3.5或更高的设备上才能被支持。</li><li>通过动态并行调用的内核不能在物理方面独立的设备上启动。然而，在系统中允许查<br> 询任一个带CUDA功能的设备性能。</li><li>动态并行的最大嵌套深度限制为24，但是实际上，在每一个新的级别中大多数内核受<br> 限于设备运行时系统需要的内存数量。因为为了对每个嵌套层中的父网格和子网格之间进<br> 行同步管理，设备运行时要保留额外的内存。</li></ul><h3 id="_3-6-3-嵌套归约" tabindex="-1"><a class="header-anchor" href="#_3-6-3-嵌套归约" aria-hidden="true">#</a> 3.6.3 嵌套归约</h3><ul><li>归约可以被表示为一个递归函数。本章中的3.4节已经用C语言演示了递归归约。在<br> CUDA里使用动态并行，可以确保CUDA里的递归归约核函数的实现像在C语言中一样简<br> 单。</li><li>下面列出了带有动态并行的递归归约的内核代码。这个核函数采取图3-29所示的方<br> 法，原始的网格包含许多线程块，但所有嵌套的子网格中只有一个由其父网格的线程0调<br> 用的线程块。核函数的第一步是将全局内存地址g_idata转换为每个线程块的本地地址。接着，如果满足停止条件（这是指如果该条件是嵌套执行树上的叶子），结果就被拷贝回全局内存，并且控制立刻返回到父内核中。如果它不是一片叶子内核，就需要计算本地归约的大小，一半的线程执行就地归约。在就地归约完成后，同步线程块以保证所有部分和的计算。紧接着，线程0产生一个只有一个线程块和一个当前线程块一半线程数量的子网<br> 格。在子网格被调用后，所有子网格会设置一个障碍点。因为在每个线程块里，一个线程<br> 只产生一个子网格，所以这个障碍点只会同步一个子网格。</li></ul>',7),Gs={class:"hint-container details"},Is=n("summary",null,"Click me to view the code!",-1),As=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s("__global__ "),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"gpuRecursiveReduce"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("g_idata"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("g_odata"),n("span",{class:"token punctuation"},","),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" isize"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token comment"},"// set thread ID"),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" tid "),n("span",{class:"token operator"},"="),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// convert global data pointer to the local pointer of this block"),s(`
 `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("idata "),n("span",{class:"token operator"},"="),s(" g_idata "),n("span",{class:"token operator"},"+"),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"*"),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("odata "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token operator"},"&"),s("g_odata"),n("span",{class:"token punctuation"},"["),s("blockIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// stop condition"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("isize "),n("span",{class:"token operator"},"=="),s(),n("span",{class:"token number"},"2"),s(),n("span",{class:"token operator"},"&&"),s(" tid "),n("span",{class:"token operator"},"=="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 g_odata`),n("span",{class:"token punctuation"},"["),s("blockIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" idata"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token operator"},"+"),s("idata"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"return"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token comment"},"// nested invocation"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" istride "),n("span",{class:"token operator"},"="),s(" isize"),n("span",{class:"token operator"},">>"),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"if"),n("span",{class:"token punctuation"},"("),s("istride "),n("span",{class:"token operator"},">"),s(),n("span",{class:"token number"},"1"),s(),n("span",{class:"token operator"},"&&"),s(" tid "),n("span",{class:"token operator"},"<"),s(" istride"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token comment"},"// in place reduction"),s(`
 idata`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(" istride"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token comment"},"// sync at block level"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// nested invocation to generate child grids "),s(`
 `),n("span",{class:"token keyword"},"if"),n("span",{class:"token punctuation"},"("),s("tid"),n("span",{class:"token operator"},"=="),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 gpuRecursiveReduce `),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},","),s(" istride"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),n("span",{class:"token punctuation"},"("),s("idata"),n("span",{class:"token punctuation"},","),s("odata"),n("span",{class:"token punctuation"},","),s("istride"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// sync all child grids launched in this block"),s(`
 `),n("span",{class:"token function"},"cudaDeviceSynchronize"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token comment"},"// sync at block level again"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
`),n("span",{class:"token punctuation"},"}"),s(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),zs=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s("在Wrox"),n("span",{class:"token punctuation"},"."),s("com上可以下载nestedReduce"),n("span",{class:"token punctuation"},"."),s(`cu文件，里面有本例的所有代码。可以用以下命
令编译代码：
$ nvcc `),n("span",{class:"token operator"},"-"),s("arch"),n("span",{class:"token operator"},"="),s("sm_35 "),n("span",{class:"token operator"},"-"),s("rdc"),n("span",{class:"token operator"},"="),n("span",{class:"token boolean"},"true"),s(" nestedReduce"),n("span",{class:"token punctuation"},"."),s("cu "),n("span",{class:"token operator"},"-"),s("o nestedReduce "),n("span",{class:"token operator"},"-"),s(`lcudadevrt


用Kepler K40设备的输出结果展示如下，相较于使用相邻配对方法的内核实现，嵌套
内核慢到无法接受：
`),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s("nestedReduce starting reduction at device "),n("span",{class:"token number"},"0"),n("span",{class:"token operator"},":"),s(` Tesla K40c
 array `),n("span",{class:"token number"},"1048576"),s(" grid "),n("span",{class:"token number"},"2048"),s(" block "),n("span",{class:"token number"},"512"),s(`
cpu reduce elapsed `),n("span",{class:"token number"},"0.000689"),s(" sec cpu_sum"),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"1048576"),s(`
gpu Neighbored elapsed `),n("span",{class:"token number"},"0.000532"),s(" sec gpu_sum"),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"1048576"),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid "),n("span",{class:"token number"},"2048"),s(" block "),n("span",{class:"token number"},"512"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s(`
gpu nested elapsed `),n("span",{class:"token number"},"0.172036"),s(" sec gpu_sum"),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"1048576"),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid "),n("span",{class:"token number"},"2048"),s(" block "),n("span",{class:"token number"},"512"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s(`

正如输出结果显示，最初有`),n("span",{class:"token number"},"2048"),s("个线程块。因为每个线程块执行"),n("span",{class:"token number"},"8"),s(`次递归，所以总共
创建了`),n("span",{class:"token number"},"16384"),s("个子线程块，用于同步线程块内部的__syncthreads函数也被调用了"),n("span",{class:"token number"},"16384"),s(`次。如此大量的内核调用与同步很可能是造成内核效率很低的主要原因。


当一个子网格被调用后，它看到的内存与父线程是完全一样的。因为每一个子线程只
需要父线程的数值来指导部分归约，所以在每个子网格启动前执行线程块内部的同步是没
有必要的。去除所有同步操作会产生如下的核函数：
__global__ `),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"gpuRecursiveReduceNosync"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("g_idata"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("g_odata"),n("span",{class:"token punctuation"},","),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" isize"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(` 
 `),n("span",{class:"token comment"},"// set thread ID"),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" tid "),n("span",{class:"token operator"},"="),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// convert global data pointer to the local pointer of this block"),s(`
 `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("idata "),n("span",{class:"token operator"},"="),s(" g_idata "),n("span",{class:"token operator"},"+"),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("odata "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token operator"},"&"),s("g_odata"),n("span",{class:"token punctuation"},"["),s("blockIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// stop condition"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("isize "),n("span",{class:"token operator"},"=="),s(),n("span",{class:"token number"},"2"),s(),n("span",{class:"token operator"},"&&"),s(" tid "),n("span",{class:"token operator"},"=="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 g_odata`),n("span",{class:"token punctuation"},"["),s("blockIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" idata"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+"),s(" idata"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"return"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token comment"},"// nested invoke"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" istride "),n("span",{class:"token operator"},"="),s(" isize"),n("span",{class:"token operator"},">>"),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"if"),n("span",{class:"token punctuation"},"("),s("istride "),n("span",{class:"token operator"},">"),s(),n("span",{class:"token number"},"1"),s(),n("span",{class:"token operator"},"&&"),s(" tid "),n("span",{class:"token operator"},"<"),s(" istride"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 idata`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(" istride"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"if"),n("span",{class:"token punctuation"},"("),s("tid"),n("span",{class:"token operator"},"=="),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 gpuRecursiveReduceNosync`),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},","),s(" istride"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),n("span",{class:"token punctuation"},"("),s("idata"),n("span",{class:"token punctuation"},","),s("odata"),n("span",{class:"token punctuation"},","),s("istride"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(` 
 `),n("span",{class:"token punctuation"},"}"),s(` 
 `),n("span",{class:"token punctuation"},"}"),s(` 
`),n("span",{class:"token punctuation"},"}"),s(`


在Wrox`),n("span",{class:"token punctuation"},"."),s("com上可以下载nestedReduceNosync"),n("span",{class:"token punctuation"},"."),s(`cu文件，里面有本例的完整代码。编译运
行它。下面列出了在Kepler K40设备上的输出结果。所需时间减少到了第一次动态并行实
现的`),n("span",{class:"token number"},"1"),n("span",{class:"token operator"},"/"),n("span",{class:"token number"},"3"),s(`：
`),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s("nestedReduceNoSync starting reduction at device "),n("span",{class:"token number"},"0"),n("span",{class:"token operator"},":"),s(` Tesla K40c
array `),n("span",{class:"token number"},"1048576"),s(" grid "),n("span",{class:"token number"},"2048"),s(" block "),n("span",{class:"token number"},"512"),s(`
cpu reduce elapsed `),n("span",{class:"token number"},"0.000689"),s(" sec cpu_sum"),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"1048576"),s(`
gpu Neighbored elapsed `),n("span",{class:"token number"},"0.000532"),s(" sec gpu_sum"),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"1048576"),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid "),n("span",{class:"token number"},"2048"),s(" block "),n("span",{class:"token number"},"512"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s(`
gpu nested elapsed `),n("span",{class:"token number"},"0.172036"),s(" sec gpu_sum"),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"1048576"),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid "),n("span",{class:"token number"},"2048"),s(" block "),n("span",{class:"token number"},"512"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s(`
gpu nestedNosyn elapsed `),n("span",{class:"token number"},"0.059125"),s(" sec gpu_sum"),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"1048576"),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid "),n("span",{class:"token number"},"2048"),s(" block "),n("span",{class:"token number"},"512"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s(`

然而，相较于相邻配对内核，它的性能仍然很差。需要考虑如何减少由大量的子网格
启动引起的消耗。在当前的实现中，每个线程块产生一个子网格，并且引起了大量的调
用。如果使用了图`),n("span",{class:"token number"},"3"),n("span",{class:"token operator"},"-"),n("span",{class:"token number"},"30"),s(`展示的方法，当创建的子网格数量减少时，那么每个子网格中线程
块的数量将会增加，以保持相同数量的并行性。

以下的核函数实现了这种方法：网格中第一个线程块中的第一个线程在每一步嵌套时
都调用子网格。比较这两个核函数的特征码，会发现多了一个参数。因为每次嵌套调用
时，子线程块大小会减到其父线程块大小的一半，父线程块的维度也必须传递给嵌套的子
网格。这使得每个线程都能为它的工作负载部分正确计算出消耗部分的全局内存偏移地
址。值得注意的是，在这个实现中，所有空闲的线程都是在每次内核启动时被移除的，而
对于第一次实现而言，在每个嵌套层的内核执行过程中都会有一半的线程空闲下来。这样
的改变将会释放一半的被第一个核函数消耗的计算资源，这样可以让更多的线程块活跃起
来。
__global__ `),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"gpuRecursiveReduce2"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("g_idata"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("g_odata"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"int"),s(" iStride"),n("span",{class:"token punctuation"},","),s(` 
 `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token keyword"},"const"),s(" iDim"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(` 
 `),n("span",{class:"token comment"},"// convert global data pointer to the local pointer of this block"),s(`
 `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("idata "),n("span",{class:"token operator"},"="),s(" g_idata "),n("span",{class:"token operator"},"+"),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"*"),s("iDim"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// stop condition"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("iStride "),n("span",{class:"token operator"},"=="),s(),n("span",{class:"token number"},"1"),s(),n("span",{class:"token operator"},"&&"),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"=="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 g_odata`),n("span",{class:"token punctuation"},"["),s("blockIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" idata"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token operator"},"+"),s("idata"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"return"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token comment"},"// in place reduction"),s(`
 idata`),n("span",{class:"token punctuation"},"["),s("threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" idata"),n("span",{class:"token punctuation"},"["),s("threadIdx"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"+"),s(" iStride"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// nested invocation to generate child grids"),s(`
 `),n("span",{class:"token keyword"},"if"),n("span",{class:"token punctuation"},"("),s("threadIdx"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"=="),s(),n("span",{class:"token number"},"0"),s(),n("span",{class:"token operator"},"&&"),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"=="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 gpuRecursiveReduce2 `),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("gridDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s("iStride"),n("span",{class:"token operator"},"/"),n("span",{class:"token number"},"2"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),n("span",{class:"token punctuation"},"("),s(`
 g_idata`),n("span",{class:"token punctuation"},","),s("g_odata"),n("span",{class:"token punctuation"},","),s("iStride"),n("span",{class:"token operator"},"/"),n("span",{class:"token number"},"2"),n("span",{class:"token punctuation"},","),s("iDim"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
`),n("span",{class:"token punctuation"},"}"),s(`


在Wrox`),n("span",{class:"token punctuation"},"."),s("com上可以下载nestedReduce2"),n("span",{class:"token punctuation"},"."),s(`cu文件，里面有本例的完整代码。K40 GPU设备
输出结果如下：
`),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s("nestedReduce2 starting reduction at device "),n("span",{class:"token number"},"0"),n("span",{class:"token operator"},":"),s(` Tesla K40c
array `),n("span",{class:"token number"},"1048576"),s(" grid "),n("span",{class:"token number"},"2048"),s(" block "),n("span",{class:"token number"},"512"),s(`
cpu reduce elapsed `),n("span",{class:"token number"},"0.000689"),s(" sec cpu_sum"),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"1048576"),s(`
gpu Neighbored elapsed `),n("span",{class:"token number"},"0.000532"),s(" sec gpu_sum"),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"1048576"),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid "),n("span",{class:"token number"},"2048"),s(" block "),n("span",{class:"token number"},"512"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s(`
gpu nested elapsed `),n("span",{class:"token number"},"0.172036"),s(" sec gpu_sum"),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"1048576"),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid "),n("span",{class:"token number"},"2048"),s(" block "),n("span",{class:"token number"},"512"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s(`
gpu nestedNosyn elapsed `),n("span",{class:"token number"},"0.059125"),s(" sec gpu_sum"),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"1048576"),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid "),n("span",{class:"token number"},"2048"),s(" block "),n("span",{class:"token number"},"512"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s(`
gpu nested2 elapsed `),n("span",{class:"token number"},"0.000797"),s(" sec gpu_sum"),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"1048576"),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid "),n("span",{class:"token number"},"2048"),s(" block "),n("span",{class:"token number"},"512"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s(`

从这个结果可以看到，递归归约核函数的第三种实现比前两种实现更快了，大概是由
于调用了较少的子网格。可以使用nvprof来验证性能提高的原因：
$ nvprof `),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s(`nestedReduce2


部分输出结果概括如下。第二列显示了设备内核的调用次数。第一个和第二个内核在
设备上共创建了`),n("span",{class:"token number"},"16384"),s("个子网格。gpuRecursiveReduce2内核中的"),n("span",{class:"token number"},"8"),s("层嵌套并行只创建了"),n("span",{class:"token number"},"8"),s(`个子网格。
`),n("span",{class:"token function"},"Calls"),s(),n("span",{class:"token punctuation"},"("),s("host"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token function"},"Calls"),s(),n("span",{class:"token punctuation"},"("),s("device"),n("span",{class:"token punctuation"},")"),s(` Avg Min Max Name
 `),n("span",{class:"token number"},"1"),s(),n("span",{class:"token number"},"16384"),s(),n("span",{class:"token number"},"441.48u"),s("s "),n("span",{class:"token number"},"2.3360u"),s("s "),n("span",{class:"token number"},"171.34"),s(`ms gpuRecursiveReduce
 `),n("span",{class:"token number"},"1"),s(),n("span",{class:"token number"},"16384"),s(),n("span",{class:"token number"},"51.140u"),s("s "),n("span",{class:"token number"},"2.2080u"),s("s "),n("span",{class:"token number"},"57.906"),s(`ms gpuRecursiveReduceNosync
 `),n("span",{class:"token number"},"1"),s(),n("span",{class:"token number"},"8"),s(),n("span",{class:"token number"},"56.195u"),s("s "),n("span",{class:"token number"},"22.048u"),s("s "),n("span",{class:"token number"},"100.74u"),s(`s gpuRecursiveReduce2
 `),n("span",{class:"token number"},"1"),s(),n("span",{class:"token number"},"0"),s(),n("span",{class:"token number"},"352.67u"),s("s "),n("span",{class:"token number"},"352.67u"),s("s "),n("span",{class:"token number"},"352.67u"),s(`s reduceNeighbored


 该递归归约的例子说明了动态并行。对于一个给定的算法，通过使用不同的动态并行
技术，可以有多种可能的实现方式。避免大量嵌套调用有助于减少消耗并提升性能。同步
对性能与正确性都至关重要，但减少线程块内部的同步次数可能会使嵌套内核效率更高。
因为在每一个嵌套层上设备运行时系统都要保留额外的内存，所以内核嵌套的最大数量可
能是受限制的。这种限制的程度依赖于内核，也可能会限制任何使用动态并行应用程序的
扩展、性能以及其他的性能。
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),Rs=c(`<h2 id="_3-7-总结" tabindex="-1"><a class="header-anchor" href="#_3-7-总结" aria-hidden="true">#</a> 3.7 总结</h2><ul><li><p>本章从硬件的角度分析了内核执行。在GPU设备上，CUDA执行模型有两个最显著的<br> 特性：<br> 使用SIMT方式在线程束中执行线程<br> 在线程块与线程中分配了硬件资源</p></li><li><p>这些执行模型的特征使得我们在提高并行性和性能时，能控制应用程序是如何让指令<br> 和内存带宽饱和的。不同计算能力的GPU设备有不同的硬件限制，因此，网格和线程块的<br> 启发式算法在为不同平台优化内核性能方面发挥了非常重要的作用。</p></li><li><p>动态并行使设备能够直接创建新的工作。它确保我们可以用一种更自然和更易于理解<br> 的方式来表达递归或依赖数据并行的算法。为实现一个有效的嵌套内核，必须注意设备运<br> 行时的使用，其包括子网格启动策略、父子同步和嵌套层的深度。</p></li><li><p>本章也介绍了使用命令行分析工具nvprof详细分析内核性能的方法。因为一个单纯的<br> 内核实现可能不会产生很好的性能，所以配置文件驱动的方法在CUDA编程中尤其重要。<br> 性能分析对内核行为提供了详细的分析，并能找到产生最佳性能的主要因素。</p></li><li><p>在第4章和第5章，将会从CUDA内存模型的角度介绍内核执行的内容。</p></li></ul><h2 id="_3-8-习题" tabindex="-1"><a class="header-anchor" href="#_3-8-习题" aria-hidden="true">#</a> 3.8 习题</h2><ul><li><p>1.当在CUDA中展开循环、数据块或线程束时，可以提高性能的两个主要原因是什<br> 么？解释每种展开是如何提升指令吞吐量的。</p></li><li><p>2.参考核函数reduceUnrolling8和实现核函数reduceUnrolling16，在这个函数中每个线程处理16个数据块。<br> 将该函数的性能与reduceUnrolling8内核性能进行比较，通过nvprof使用合适的指标与事件来解释性能差异。</p></li><li><p>3.参考核函数reduceUnrolling8，替换以下的代码段：<br> 比较每次的性能并解释使用nvprof指标的差异。</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code> <span class="token keyword">int</span> a1 <span class="token operator">=</span> g_idata<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token keyword">int</span> a2 <span class="token operator">=</span> g_idata<span class="token punctuation">[</span>idx<span class="token operator">+</span>blockDim<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token keyword">int</span> a3 <span class="token operator">=</span> g_idata<span class="token punctuation">[</span>idx<span class="token operator">+</span><span class="token number">2</span><span class="token operator">*</span>blockDim<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token keyword">int</span> a4 <span class="token operator">=</span> g_idata<span class="token punctuation">[</span>idx<span class="token operator">+</span><span class="token number">3</span><span class="token operator">*</span>blockDim<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token keyword">int</span> b1 <span class="token operator">=</span> g_idata<span class="token punctuation">[</span>idx<span class="token operator">+</span><span class="token number">4</span><span class="token operator">*</span>blockDim<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token keyword">int</span> b2 <span class="token operator">=</span> g_idata<span class="token punctuation">[</span>idx<span class="token operator">+</span><span class="token number">5</span><span class="token operator">*</span>blockDim<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token keyword">int</span> b3 <span class="token operator">=</span> g_idata<span class="token punctuation">[</span>idx<span class="token operator">+</span><span class="token number">6</span><span class="token operator">*</span>blockDim<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token keyword">int</span> b4 <span class="token operator">=</span> g_idata<span class="token punctuation">[</span>idx<span class="token operator">+</span><span class="token number">7</span><span class="token operator">*</span>blockDim<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">;</span>
 g_idata<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> a1<span class="token operator">+</span>a2<span class="token operator">+</span>a3<span class="token operator">+</span>a4<span class="token operator">+</span>b1<span class="token operator">+</span>b2<span class="token operator">+</span>b3<span class="token operator">+</span>b4<span class="token punctuation">;</span>
  使用下面在功能上等价的代码：
 <span class="token keyword">int</span> <span class="token operator">*</span>ptr <span class="token operator">=</span> g_idata <span class="token operator">+</span> idx<span class="token punctuation">;</span>
 <span class="token keyword">int</span> tmp <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
 <span class="token comment">// Increment tmp 8 times with values strided by blockDim.x</span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">8</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 tmp <span class="token operator">+=</span> <span class="token operator">*</span>ptr<span class="token punctuation">;</span> ptr <span class="token operator">+=</span> blockDim<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 g_idata<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> tmp<span class="token punctuation">;</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,5),Ws=n("li",null,[n("p",null,"4.参考核函数reduceCompleteUnrollWarps8。不要将vmem声明为volatile修饰符，而是使用__syncthreads。注意__syncthreads必须被线程块里的所有线程调用。比较两个核函数的性能并使用nvprof来解释所有的差异。")],-1),Hs=n("li",null,[n("p",null,"5.用C语言实现浮点数s的求和归约。")],-1),Ks=n("li",null,[n("p",null,"6.参考核函数reduceInterleaved和reduceCompleteUnrollWarps8，实现每个浮点数s的版本。比较它们的性能，选择合适的指标与/或事件来解释所有差异。它们相比于操作整数数据类型有什么不同吗？")],-1),Ts=n("li",null,[n("p",null,"7.被动态地产生孩子的全局数据进行更改，这种改变什么时候能保证对其父亲可见？")],-1),Es={href:"http://8.xn--nestedHelloWorld-c02zs54dqf1fjyzf.cu",target:"_blank",rel:"noopener noreferrer"},Ns={href:"http://9.xn--nestedHelloWorld-c02zs54dqf1fjyzf.cu",target:"_blank",rel:"noopener noreferrer"},Os=n("br",null,null,-1);function $s(Bs,Fs){const e=u("router-link"),l=u("ExternalLinkIcon"),i=u("CodeTabs");return k(),d("div",null,[L,q,b(" more "),n("nav",X,[n("ul",null,[n("li",null,[t(e,{to:"#简单介绍主要是基础"},{default:a(()=>[s("简单介绍主要是基础")]),_:1})]),n("li",null,[t(e,{to:"#第3章-cuda执行模型"},{default:a(()=>[s("第3章 CUDA执行模型")]),_:1})]),n("li",null,[t(e,{to:"#_3-1-cuda执行模型概述"},{default:a(()=>[s("3.1 CUDA执行模型概述")]),_:1}),n("ul",null,[n("li",null,[t(e,{to:"#_3-1-1-gpu架构概述"},{default:a(()=>[s("3.1.1 GPU架构概述")]),_:1})]),n("li",null,[t(e,{to:"#_3-1-2-fermi架构"},{default:a(()=>[s("3.1.2 Fermi架构")]),_:1})]),n("li",null,[t(e,{to:"#_3-1-3-kepler架构"},{default:a(()=>[s("3.1.3 Kepler架构")]),_:1})]),n("li",null,[t(e,{to:"#_3-1-4-配置文件驱动优化"},{default:a(()=>[s("3.1.4 配置文件驱动优化")]),_:1})])])]),n("li",null,[t(e,{to:"#_3-2-理解线程束执行的本质"},{default:a(()=>[s("3.2 理解线程束执行的本质")]),_:1}),n("ul",null,[n("li",null,[t(e,{to:"#_3-2-1-线程束和线程块"},{default:a(()=>[s("3.2.1 线程束和线程块")]),_:1})]),n("li",null,[t(e,{to:"#_3-2-2-线程束分化"},{default:a(()=>[s("3.2.2 线程束分化")]),_:1})]),n("li",null,[t(e,{to:"#_3-2-3-资源分配"},{default:a(()=>[s("3.2.3 资源分配")]),_:1})]),n("li",null,[t(e,{to:"#_3-2-4-延迟隐藏"},{default:a(()=>[s("3.2.4 延迟隐藏")]),_:1})]),n("li",null,[t(e,{to:"#_3-2-5-占用率"},{default:a(()=>[s("3.2.5 占用率")]),_:1})]),n("li",null,[t(e,{to:"#_3-2-6-同步"},{default:a(()=>[s("3.2.6 同步")]),_:1})]),n("li",null,[t(e,{to:"#_3-2-7-可扩展性"},{default:a(()=>[s("3.2.7 可扩展性")]),_:1})])])]),n("li",null,[t(e,{to:"#_3-3-并行性的表现"},{default:a(()=>[s("3.3 并行性的表现")]),_:1}),n("ul",null,[n("li",null,[t(e,{to:"#_3-3-1-用nvprof检测活跃的线程束"},{default:a(()=>[s("3.3.1 用nvprof检测活跃的线程束")]),_:1})]),n("li",null,[t(e,{to:"#_3-3-2-用nvprof检测内存操作"},{default:a(()=>[s("3.3.2 用nvprof检测内存操作")]),_:1})]),n("li",null,[t(e,{to:"#_3-3-3-增大并行性"},{default:a(()=>[s("3.3.3 增大并行性")]),_:1})])])]),n("li",null,[t(e,{to:"#_3-4-避免分支分化"},{default:a(()=>[s("3.4 避免分支分化")]),_:1}),n("ul",null,[n("li",null,[t(e,{to:"#_3-4-1-并行归约问题"},{default:a(()=>[s("3.4.1 并行归约问题")]),_:1})]),n("li",null,[t(e,{to:"#_3-4-2-并行归约中的分化"},{default:a(()=>[s("3.4.2 并行归约中的分化")]),_:1})]),n("li",null,[t(e,{to:"#_3-4-3-改善并行归约的分化"},{default:a(()=>[s("3.4.3 改善并行归约的分化")]),_:1})]),n("li",null,[t(e,{to:"#_3-4-4-交错配对的归约"},{default:a(()=>[s("3.4.4 交错配对的归约")]),_:1})])])]),n("li",null,[t(e,{to:"#_3-5-展开循环"},{default:a(()=>[s("3.5 展开循环")]),_:1}),n("ul",null,[n("li",null,[t(e,{to:"#_3-5-1-展开的归约"},{default:a(()=>[s("3.5.1 展开的归约")]),_:1})]),n("li",null,[t(e,{to:"#_3-5-2-展开线程的归约"},{default:a(()=>[s("3.5.2 展开线程的归约")]),_:1})]),n("li",null,[t(e,{to:"#_3-5-3-完全展开的归约"},{default:a(()=>[s("3.5.3 完全展开的归约")]),_:1})]),n("li",null,[t(e,{to:"#_3-5-4-模板函数的归约"},{default:a(()=>[s("3.5.4 模板函数的归约")]),_:1})])])]),n("li",null,[t(e,{to:"#_3-6-动态并行"},{default:a(()=>[s("3.6 动态并行")]),_:1}),n("ul",null,[n("li",null,[t(e,{to:"#_3-6-1-嵌套执行"},{default:a(()=>[s("3.6.1 嵌套执行")]),_:1})]),n("li",null,[t(e,{to:"#_3-6-2-在gpu上嵌套hello-world"},{default:a(()=>[s("3.6.2 在GPU上嵌套Hello World")]),_:1})]),n("li",null,[t(e,{to:"#_3-6-3-嵌套归约"},{default:a(()=>[s("3.6.3 嵌套归约")]),_:1})])])]),n("li",null,[t(e,{to:"#_3-7-总结"},{default:a(()=>[s("3.7 总结")]),_:1})]),n("li",null,[t(e,{to:"#_3-8-习题"},{default:a(()=>[s("3.8 习题")]),_:1})])])]),V,n("ul",null,[n("li",null,[s("现在，使用代码清单3-1中的代码可以测量这两个核函数的性能。"),n("a",Q,[s("也可以从Wrox.com"),t(l)]),j,s(" 中下载simpleDivergence.cu文件。因为在设备上第一次运行可能会增加间接开销，并且在此处测量的性能是非常精细的，所以，添加了一个额外的内核启动（warmingup，与 mathKernel2一样）来去除这一间接开销。")])]),n("details",Y,[J,t(i,{id:"942",data:[{id:"源代码"},{id:"编译运行"}],"tab-id":"shell"},{title0:a(({value:o,isActive:p})=>[s("源代码")]),title1:a(({value:o,isActive:p})=>[s("编译运行")]),tab0:a(({value:o,isActive:p})=>[Z]),tab1:a(({value:o,isActive:p})=>[nn]),_:1})]),sn,n("ul",null,[n("li",null,[n("p",null,[s("添加mathKernel3，"),n("a",an,[s("再次编译和运行文件simpleDivergence.cu"),t(l)]),s("，会报告下列性能："),tn,s(" Warmingup elapsed 0.105021 sec"),en,s(" mathKernel1 elapsed 0.000017 sec"),on,s(" mathKernel2 elapsed 0.000014 sec"),pn,s(" mathKernel3 elapsed 0.000014 sec")])]),n("li",null,[n("p",null,[s("使用下面的命令，可以强制CUDA编译器不利用分支预测去优化内核："),cn,s(" $ nvcc -g -G -arch=sm_20 "),n("a",ln,[s("simpleDivergence.cu"),t(l)]),s(" -o simpleDivergence")])]),un]),rn,n("ul",null,[kn,n("li",null,[n("p",null,[s("代码清单3-2 简单设备的属性查询（"),n("a",dn,[s("simpleDeviceQuery.cu"),t(l)]),s("）")])])]),n("details",bn,[mn,t(i,{id:"1303",data:[{id:"源代码"},{id:"编译运行"}],"tab-id":"shell"},{title0:a(({value:o,isActive:p})=>[s("源代码")]),title1:a(({value:o,isActive:p})=>[s("编译运行")]),tab0:a(({value:o,isActive:p})=>[vn]),tab1:a(({value:o,isActive:p})=>[gn]),_:1})]),hn,n("ul",null,[n("li",null,[s("本示例的完整代码可在 "),n("a",fn,[s("sumMatrix.cu"),t(l)]),s(" 中找到，可从 "),n("a",_n,[s("Wrox.com"),t(l)]),s(" 下载。使用以下命令编译代码。"),yn,s(" $ nvcc -O3 -arch=sm_20 "),n("a",xn,[s("sumMatrix.cu"),t(l)]),s(" -o sumMatrix")]),wn]),Dn,n("ul",null,[Mn,n("li",null,[n("p",null,[s("现在已经建立了一个性能基准，可以通过测试sumMatrix使用更大范围的线程配置来"),Un,s(" 回答这些问题："),Sn,s(" $ ./sumMatrix 64 2"),Pn,s(" sumMatrixOnGPU2D <<<(256,8192), (64,2) >>> elapsed 0.033567 sec"),Cn,s(" $ ./sumMatrix 64 4"),Gn,s(" sumMatrixOnGPU2D <<<(256,4096), (64,4) >>> elapsed 0.034908 sec"),In,s(" $ ./sumMatrix 64 8"),An,s(" sumMatrixOnGPU2D <<<(256,2048), (64,8) >>> elapsed 0.036651 sec"),zn,s(" $ ./sumMatrix 128 2"),Rn,s(" sumMatrixOnGPU2D <<<(128,8192), (128,2)>>> elapsed 0.032688 sec"),Wn,s(" $ ./sumMatrix 128 4"),Hn,s(" sumMatrixOnGPU2D <<<(128,4096), (128,4)>>> elapsed 0.034786 sec"),Kn,s(" $ ./sumMatrix 128 8"),Tn,s(" sumMatrixOnGPU2D <<<(128,2048), (128,8)>>> elapsed 0.046157 sec"),En,s(" $ ./sumMatrix 256 2"),Nn,s(" sumMatrixOnGPU2D <<<(64,8192), (256,2)>>> elapsed 0.032793 sec"),On,s(" $ ./sumMatrix 256 4"),$n,s(" sumMatrixOnGPU2D <<<(64,4096), (256,4)>>> elapsed 0.038092 sec"),Bn,s(" $ ./sumMatrix 256 8"),Fn,s(" sumMatrixOnGPU2D <<<(64,2048), (256,8)>>> elapsed 0.000173 sec"),Ln,s(" Error: "),n("a",qn,[s("sumMatrix.cu:163"),t(l)]),s(", code:9, reason: invalid configuration argument")])]),Xn]),Vn,n("details",Qn,[jn,t(i,{id:"1849",data:[{id:"源代码"},{id:"编译运行"}],"tab-id":"shell"},{title0:a(({value:o,isActive:p})=>[s("源代码")]),title1:a(({value:o,isActive:p})=>[s("编译运行")]),tab0:a(({value:o,isActive:p})=>[Yn]),tab1:a(({value:o,isActive:p})=>[Jn]),_:1})]),Zn,n("details",ns,[ss,t(i,{id:"1877",data:[{id:"源代码"},{id:"编译运行"}],"tab-id":"shell"},{title0:a(({value:o,isActive:p})=>[s("源代码")]),title1:a(({value:o,isActive:p})=>[s("编译运行")]),tab0:a(({value:o,isActive:p})=>[as]),tab1:a(({value:o,isActive:p})=>[ts]),_:1})]),es,n("details",os,[ps,t(i,{id:"1907",data:[{id:"源代码"},{id:"编译运行"}],"tab-id":"shell"},{title0:a(({value:o,isActive:p})=>[s("源代码")]),title1:a(({value:o,isActive:p})=>[s("编译运行")]),tab0:a(({value:o,isActive:p})=>[cs]),tab1:a(({value:o,isActive:p})=>[ls]),_:1})]),is,n("details",us,[rs,t(i,{id:"2047",data:[{id:"源代码"},{id:"编译运行"}],"tab-id":"shell"},{title0:a(({value:o,isActive:p})=>[s("源代码")]),title1:a(({value:o,isActive:p})=>[s("编译运行")]),tab0:a(({value:o,isActive:p})=>[ks]),tab1:a(({value:o,isActive:p})=>[ds]),_:1})]),bs,ms,n("details",vs,[gs,t(i,{id:"2067",data:[{id:"源代码"},{id:"编译运行"}],"tab-id":"shell"},{title0:a(({value:o,isActive:p})=>[s("源代码")]),title1:a(({value:o,isActive:p})=>[s("编译运行")]),tab0:a(({value:o,isActive:p})=>[hs]),tab1:a(({value:o,isActive:p})=>[fs]),_:1})]),_s,ys,n("details",xs,[ws,t(i,{id:"2087",data:[{id:"源代码"},{id:"编译运行"}],"tab-id":"shell"},{title0:a(({value:o,isActive:p})=>[s("源代码")]),title1:a(({value:o,isActive:p})=>[s("编译运行")]),tab0:a(({value:o,isActive:p})=>[Ds]),tab1:a(({value:o,isActive:p})=>[Ms]),_:1})]),Us,n("ul",null,[n("li",null,[n("p",null,[s("$ nvcc -arch=sm_35 -rdc=true "),n("a",Ss,[s("nestedHelloWorld.cu"),t(l)]),s(" -o nestedHelloWorld -lcudadevrt")])]),Ps]),Cs,n("details",Gs,[Is,t(i,{id:"2308",data:[{id:"源代码"},{id:"编译运行"}],"tab-id":"shell"},{title0:a(({value:o,isActive:p})=>[s("源代码")]),title1:a(({value:o,isActive:p})=>[s("编译运行")]),tab0:a(({value:o,isActive:p})=>[As]),tab1:a(({value:o,isActive:p})=>[zs]),_:1})]),Rs,n("ul",null,[Ws,Hs,Ks,Ts,n("li",null,[n("p",null,[n("a",Es,[s("8.参考文件nestedHelloWorld.cu"),t(l)]),s("，用图3-30所示的方法实现一个新的核函数。")])]),n("li",null,[n("p",null,[n("a",Ns,[s("9.参考文件nestedHelloWorld.cu"),t(l)]),s("，实现一个新的核函数，使其可以用给定深度来限制"),Os,s(" 嵌套层。")])])])])}const Xs=r(F,[["render",$s],["__file","C-第三章.html.vue"]]);export{Xs as default};
