import{_ as r}from"./plugin-vue_export-helper-c27b6911.js";import{r as o,o as h,c as m,d as c,a as e,b as a,e as t,w as n,f as i}from"./app-2a2d189a.js";const p="/assets/algorithm1-f18a19f2.png",d="/assets/figure1-7f397d65.png",u="/assets/algorithm2-090cf274.png",g="/assets/figure7-0181608e.png",f={},w=e("h1",{id:"k-nsg",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#k-nsg","aria-hidden":"true"},"#"),a(" K-NSG")],-1),b=e("p",null,"K-NSG",-1),y={class:"hint-container info"},x=e("p",{class:"hint-container-title"},"相关信息",-1),N=e("li",null,"可能这里要有一些 关于 其它的对于这篇文章的解读",-1),v=e("li",null,"我们需要一些链接？",-1),_=e("li",null,"paper:",-1),S={href:"https://github.com/ZJULearning/nsg",target:"_blank",rel:"noopener noreferrer"},k=e("li",null,"blog:",-1),M={href:"https://zhuanlan.zhihu.com/p/712991028",target:"_blank",rel:"noopener noreferrer"},G={href:"https://blog.csdn.net/weixin_44839084/article/details/104013138",target:"_blank",rel:"noopener noreferrer"},T={href:"https://blog.csdn.net/chansonzhang/article/details/107775706",target:"_blank",rel:"noopener noreferrer"},A={class:"table-of-contents"},I=i('<h2 id="no-0-摘要" tabindex="-1"><a class="header-anchor" href="#no-0-摘要" aria-hidden="true">#</a> No.0 摘要</h2><h2 id="_1-introduction" tabindex="-1"><a class="header-anchor" href="#_1-introduction" aria-hidden="true">#</a> <strong>1. INTRODUCTION</strong></h2><ul><li><p>对于稀疏离散数据（如文档），最近邻搜索可以在高级索引结构（如反向索引[35]）上有效地进行。</p></li><li><p>For sparse discrete data (like documents), the nearest neighbor search can be carried out efficiently on advanced index structures (<em>e.g</em>., inverted index [35]).</p></li></ul><br><ul><li><p>对于密集连续向量，已经提出了各种解决方案，如基于树结构的方法[2,6,8,17,24,36]、基于哈希的方法[18,20,23,32,40]、基于量化的方法[1,19,26,39]和基于图的方法[3,21,33,41]。其中，基于图的方法最近显示出了巨大的潜力。一些实验结果表明，在常用的欧几里得空间[2,7,15,27,33,34]中，基于图形的方法的性能明显优于其他类型的流行算法。原因可能是这些方法不能像基于图的方法那样表达邻居关系，而且它们比基于图的方法往往会检查邻域子空间中更多的点，以达到相同的精度[39]。因此，它们的搜索时间复杂度涉及维数上指数的大因子，导致性能较差的[22]。</p></li><li><p>For dense continuous vectors, various solutions have been proposed such as tree-structure based approaches [2, 6, 8, 17, 24, 36], hashing-based approaches [18, 20, 23, 32, 40], quantization-based approaches [1, 19, 26, 39], and graph-based approaches [3, 21, 33, 41]. Among them, graph-based methods have shown great potential recently. There are some experimental results showing that the graph-based methods perform much better than some popular algorithms from other types in the commonly used Euclidean Space [2, 7, 15, 27, 33, 34]. The reason may be that these methods cannot express the neighbor relationship as well as the graph-based methods and they tend to check much more points in neighbor-subspaces than the graph-based methods to reach the same accuracy [39]. Thus, their search time complexity involves large factors exponential in the dimension and leads to inferior performance [22].</p></li></ul><br>',6),q=e("ul",null,[e("li",null,[e("p",null,"通过图进行最近邻搜索已经研究了几十年，[3,13,25]。给定d维欧几里得空间Ed中的一组点S，将图G定义为连接这些点（节点）的一组边。边pq定义了节点p和q之间的邻居关系。对边缘提出了各种约束条件，使图适用于ANNS问题。")]),e("li",null,[e("p",null,[a("Nearest neighbor search via graphs has been studied for decades [3,13,25]. Given a set of points "),e("em",null,"S"),a(" in the "),e("em",null,"d"),a("-dimensional Euclidean space "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msup",null,[e("mi",null,"E"),e("mi",null,"d")])]),e("annotation",{encoding:"application/x-tex"},"E^d")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.8491em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"E"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.8491em"}},[e("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mathnormal mtight"},"d")])])])])])])])])])]),a(" , a graph "),e("em",null,"G"),a(" is defined as a set of edges connecting these points (nodes). The edge "),e("em",null,"pq"),a(" defines aneighbor-relationship between node "),e("em",null,"p"),a(" and "),e("em",null,"q"),a(". Various constraints are proposed on the edges to make the graphs suitable for ANNS problem.")])])],-1),z=i('<br><ul><li><p>这些图现在被称为接近图[25]。一些接近图，如德劳内图（或德劳内三角测量）[4]和单调搜索网络（MSNET）[13]，确保从任何节点p到另一个节点q，存在一条路径，中间节点更接近q [13]。然而，我们并没有给出找到这样一条路径所需的计算复杂度。其他工作，如随机邻域图[3]保证多对数搜索时间复杂度。根据经验，在可导航的小世界网络（NSWN）[9,29]上，贪婪路由路径的平均长度随数据大小呈多对数增长。然而，构建这些图的时间复杂度非常高（至少是O（n 2）），这对于大量的问题是不切实际的。</p></li><li><p>These graphs are now referred to as the <em>Proximity Graphs</em> [25]. Some proximity graphs like Delaunay Graphs (or Delaunay Triangulation) [4] and Monotonic Search Networks (MSNET) [13] ensure that from any node <em>p</em> to another node <em>q</em>, there exists a path on which the intermediate nodes are closer and closer to <em>q</em> [13]. However, the computational complexity needed to find such a path is not given. Other works like Randomized Neighborhood Graphs [3] guarantee polylogarithmic search time complexity. Empirically, the average length of greedy-routing paths grows polylogarithmically with the data size on the Navigable Small-World Networks (NSWN) [9, 29]. However, the time complexity of building these graphs is very high (at least <em>O</em>(<em>n</em> 2 )), which is impractical for massive problems.</p></li></ul><br><ul><li><p>GNNS [21], IEH [27], and Efanna [15] are based on the <em>k</em>NN graph, which is an approximation of the Delaunay Graph.</p></li><li><p>对于目前基于图的算法：we find that they are still not powerful enough for billion-node applications</p></li><li><p>To further improve the search-efficiency and scalability of graph-based methods, we start with how ANNS is performed on a graph. Despite the diversity of graph indices, almost all graph-based methods [3, 7, 13, 21, 27, 33] share the same greedy best-first search algorithm (given in Algorithm 1), we refer to it as the <em>search-on-graph</em> algorithm below.</p></li><li><figure><img src="'+p+'" alt="algorithm1" tabindex="0" loading="lazy"><figcaption>algorithm1</figcaption></figure></li><li><p>Algorithm 1 tries to reach the query point with the following greedy process. For a given query <em>q</em>, we are required to retrieve its nearest neighbors from the dataset.</p></li><li><p>Given a starting node <em>p</em>, we follow the out-edges to reach <em>p</em>’s neighibors, and compare them with <em>q</em> to choose one to proceed. The choosing principle is to minimize the distance to <em>q</em>, and the new iteration starts from the chosen node. We can see that the key to improve graph-based search is to shorten the search path formed by the algorithm and reduce the out-degree of the graph (<em>i.e</em>., reduce the number of choices of each node).</p></li><li><p>Intuitively, to improve graph-based search we need to:</p><ul><li>(1) Ensure the connectivity of the graph to make sure the query (or the nearest neighbors of the query) is (are) reachable</li><li>(2) Lower the average out-degree of the graph and</li><li>(3) shorten the search path to lower the search time complexity;</li><li>(4) Reduce the index size (memory usage) to improve scalability.</li></ul></li><li><p>Methods such as IEH [27], Efanna [15], and HNSW [34], use hashing, randomized KD-trees and multilayer graphs to accelerate the search. However, these may result in huge memory usage for massive databases. We aim to reduce the index size and preserve the search-efficiency at the same time. 搜索厉害并且index size小；</p></li></ul><br><ul><li>In this paper, we propose a new graph, named as Monotonic Relative Neighborhood Graph (MRNG), which guarantees a low average search time (very close to logarithmic complexity). To further reduce the indexing complexity, we propose the Navigating Spreading-out Graph (NSG), which is a good approximation of MRNG, inherits low search complexity and takes the four aspects into account. It is worthwhile to highlight our contributions as follows. <ul><li>\\1. We first present comprehensive theoretical analysis on the attractive ANNS properties of a graph family called MSNET. Based on this, we propose a novel graph, MRNG, which ensures a close-logarithmic search complexity in expectation.</li><li>\\2. To further improve the efficiency and scalability of graph-based ANNS methods, we consider four aspects of the graph: ensuring connectivity, lowering the average out-degree, shortening the search path, and reducing the index size. Motivated by these, we design a close approximation of the MRNG, called Navigating Spreading-out Graph (NSG), to address the four aspects simultaneously. The indexing complexity is reduced significantly compared to the MRNG and is practical for massive problems. Extensive experiments show that our approach outperforms the state-of-the-art methods in search performance with the smallest memory usage among graph-based methods.</li><li>\\3. The NSG algorithm is also tested on the E-commercial search scenario of Taobao (Alibaba Group). The algorithm has been integrated into their search engine for billion-node search.</li></ul></li></ul><h2 id="_2-preliminaries" tabindex="-1"><a class="header-anchor" href="#_2-preliminaries" aria-hidden="true">#</a> <strong>2. PRELIMINARIES</strong></h2>',7),E=e("ul",null,[e("li",null,[e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mi",null,"l"),e("mn",null,"2"),e("mo",null,"−"),e("mi",null,"n"),e("mi",null,"o"),e("mi",null,"r"),e("mi",null,"m")]),e("annotation",{encoding:"application/x-tex"},"l2-norm")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.7778em","vertical-align":"-0.0833em"}}),e("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l"),e("span",{class:"mord"},"2"),e("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),e("span",{class:"mbin"},"−"),e("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.4306em"}}),e("span",{class:"mord mathnormal"},"n"),e("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"or"),e("span",{class:"mord mathnormal"},"m")])])]),a(" 是开方的还是没有开方的？？")]),e("li")],-1),R=i('<h3 id="_2-1-problem-setting" tabindex="-1"><a class="header-anchor" href="#_2-1-problem-setting" aria-hidden="true">#</a> <strong>2.1 Problem Setting</strong></h3><ul><li><p>由于精确最近邻搜索的内在困难，大多数研究人员转向AKNNS。主要的动机是用准确性上的小损失来换取更短的搜索时间。</p></li><li><p>Due to the intrinsic difficulty of exact nearest neighbor search, most researchers turn to AKNNS. The main motivation is to trade a little loss in accuracy for much shorter search time.</p></li><li><p>这里的话要注意下 recall 和 <strong>Precision</strong>的 区别；</p></li><li></li></ul><h3 id="_2-2-non-graph-based-anns-methods" tabindex="-1"><a class="header-anchor" href="#_2-2-non-graph-based-anns-methods" aria-hidden="true">#</a> <strong>2.2 Non-Graph-Based ANNS Methods</strong></h3><ul><li><p>图的方法比其它三个基于的更好的原因？</p></li><li><p>这可能是因为非基于图的方法都试图通过划分空间和索引得到的子空间索引以快速检索来解决ANNS问题。不幸的是，不容易对子空间进行索引，以便能够有效地扫描邻居区域，以定位给定查询的最近邻居。</p></li><li><p>This may be because the non-graph-based methods all try to solve the ANNS problem by partitioning the space and indexing the resulting subspaces for fast retrieval. Unfortunately, it is not easy to index the subspaces so that neighbor areas can be scanned efficiently to locate the nearest neighbors of a given query.</p></li><li><p>以图1为例（该图不包括乘积量化（PQ）算法，因为从某些角度来看，它可以被视为一种哈希方法）。非基于图的方法需要检查许多附近的单元才能实现高准确性。大量的远距离点被检查，并且随着维度的增加，这个问题会变得更糟（被称为维度灾难）。基于图的方法可能从离查询较远的位置开始，但它们能快速接近查询，因为它们都是基于邻近图，而邻近图通常能更好地表达“邻居”关系。</p></li><li><p>See Figure 1 as an example (the figure does not include the PQ algorithm because it can be regarded as a hashing method from some perspective). The non-graph-based methods need to check many nearby cells to achieve high accuracy. A large number of distant points are checked and this problem becomes much worse as the dimension increases (known as the curse of the dimensionality). Graph-based methods may start from a distant position to the query, but they approach the query quickly because they are all based on proximity graphs which typically express the “neighbor” relationship better.</p></li><li><figure><img src="'+d+'" alt="figure1" tabindex="0" loading="lazy"><figcaption>figure1</figcaption></figure></li><li><p>总之，非基于图的方法比基于图的方法更倾向于检查更多的点，以获得相同的精度。这将在我们以后的实验中得到展示。</p></li><li><p>In summary, non-graph-based methods tend to check much more points than the graph-based methods to achieve the same accuracy. This will be shown in our later experiments.</p></li></ul><h3 id="_2-3-graph-based-anns-methods" tabindex="-1"><a class="header-anchor" href="#_2-3-graph-based-anns-methods" aria-hidden="true">#</a> <strong>2.3 Graph-Based ANNS Methods</strong></h3><ul><li>很多共同的介绍了；</li></ul><h2 id="_3-algorithms-and-analysis" tabindex="-1"><a class="header-anchor" href="#_3-algorithms-and-analysis" aria-hidden="true">#</a> <strong>3. ALGORITHMS AND ANALYSIS</strong></h2><h3 id="_3-1-motivation" tabindex="-1"><a class="header-anchor" href="#_3-1-motivation" aria-hidden="true">#</a> <strong>3.1 Motivation</strong></h3>',8),L=e("ul",null,[e("li",null,"启发式搜索：The algorithm walks over the graph and tries to reach the query greedily."),e("li",null,[a("Thus, two most crucial factors influencing the search efficiency are "),e("ul",null,[e("li",null,"the number of greedy hops between the starting node and the destination (1)"),e("li",null,"and the computational cost to choose the next node at each step.(2)")])]),e("li",null,[a("In other words, the search time complexity on a graph can be written as "),e("em",null,"O"),a("("),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mi",null,"o"),e("mi",null,"l")]),e("annotation",{encoding:"application/x-tex"},"o l")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.6944em"}}),e("span",{class:"mord mathnormal"},"o"),e("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l")])])]),a("), where "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mi",null,"o")]),e("annotation",{encoding:"application/x-tex"},"o")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.4306em"}}),e("span",{class:"mord mathnormal"},"o")])])]),a(" is the average out-degree of the graph and "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mi",null,"l")]),e("annotation",{encoding:"application/x-tex"},"l")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.6944em"}}),e("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l")])])]),a(" is the length of the search path. 就是说贪婪搜索 可以大致 是 这样的；")])],-1),W=e("br",null,null,-1),P=e("ul",null,[e("li",null,"目前大多数基于图的算法: the out-degree of the graph is a tunable parameter 一个可调节的参数；"),e("li",null,"并且实验研究表明：given a dataset and an expected search accuracy, we find there exist optimal degrees that result in optimal search performance.就是说 通过调节 degrees 进行 优化search performance；"),e("li",null,[a("A possible explanation is that, given an expected accuracy, "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mi",null,"o"),e("mi",null,"l")]),e("annotation",{encoding:"application/x-tex"},"o l")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.6944em"}}),e("span",{class:"mord mathnormal"},"o"),e("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l")])])]),a(" is a convex function of "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mi",null,"o")]),e("annotation",{encoding:"application/x-tex"},"o")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.4306em"}}),e("span",{class:"mord mathnormal"},"o")])])]),a(", and the minima of "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mi",null,"o"),e("mi",null,"l")]),e("annotation",{encoding:"application/x-tex"},"o l")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.6944em"}}),e("span",{class:"mord mathnormal"},"o"),e("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l")])])]),a(" determines the search performance of a given graph. 一个可能的解释：给定精度要求，凸函数关于"),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mi",null,"o")]),e("annotation",{encoding:"application/x-tex"},"o")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.4306em"}}),e("span",{class:"mord mathnormal"},"o")])])]),a(" 的；像是一个优化函数？")]),e("li"),e("li",null,[a("In the high accuracy range, the optimal degrees of some algorithms ("),e("em",null,"e.g"),a("., GNNS [21], NSW [33], DPG [31]) are very large, which leads to very large graph size. The minima of their $o l $ are also very large, leading to inferior performance. 这句话的意思是为了得到比较高的精度，就需要比较大的degrees，所以导致图存储大以及search 慢；")]),e("li",null,[a("Other algorithms [15, 27, 34] use extra index structures to improve their start position in Algorithm 1 in order to minimize "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mi",null,"l")]),e("annotation",{encoding:"application/x-tex"},"l")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.6944em"}}),e("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l")])])]),a(" directly, but this leads to large indices.就是说直接挑好的初始化点进行，这个"),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mi",null,"l")]),e("annotation",{encoding:"application/x-tex"},"l")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.6944em"}}),e("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l")])])]),a(" 就小了即上面的(1)；")])],-1),D=e("br",null,null,-1),F=e("ul",null,[e("li",null,[a("所以根据上面的，我们就可以 减小 "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mi",null,"o")]),e("annotation",{encoding:"application/x-tex"},"o")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.4306em"}}),e("span",{class:"mord mathnormal"},"o")])])]),a(" and "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mi",null,"l")]),e("annotation",{encoding:"application/x-tex"},"l")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.6944em"}}),e("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l")])])]),a(" 进行提高search 性能")]),e("li",null,[a("we can improve the ANNS performance of graph-based methods by minimizing "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mi",null,"o")]),e("annotation",{encoding:"application/x-tex"},"o")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.4306em"}}),e("span",{class:"mord mathnormal"},"o")])])]),a(" and "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mi",null,"l")]),e("annotation",{encoding:"application/x-tex"},"l")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.6944em"}}),e("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l")])])]),a(" simultaneously.")]),e("li",null,"Moreover, we need to make the index as small as possible to handle large-scale data."),e("li",null,"首先第一步：要确定路径的存在"),e("li",null,"we should first ensure the existence of a path from the starting node to the query. Otherwise, the targets will never be reached.")],-1),O=i('<br><ul><li><p>In summary, we aim to design a graph index with high ANNS performance from the following four aspects.</p></li><li><p><strong>(1) ensuring the connectivity of the graph,</strong></p></li><li><p>**(2) lowering the average out-degree of the graph, **</p></li><li><p><strong>(3)shortening the search path,</strong></p></li><li><p><strong>(4) reducing index size.</strong></p></li><li><p>Point (1) is easy to achieve. If the starting node varies with the query, one should ensure that the graph is strongly connected. If the starting node is fixed, one should ensure all other nodes are reachable by a DFS from the starting node.这个是如何进行保证的呢?</p></li><li><p>As for point (2)-(4), we address these points simultaneously by designing a better sparse graph for ANNS problem. Below we will propose a new graph structure called Monotonic Relative Neighborhood Graph (MRNG) and a theoretical analysis of its important properties, which leads to better ANNS performance.所以还是归属到了 图index的设计；</p></li></ul><h3 id="_3-2-graph-monotonicity-and-path-length" tabindex="-1"><a class="header-anchor" href="#_3-2-graph-monotonicity-and-path-length" aria-hidden="true">#</a> <strong>3.2 Graph Monotonicity And Path Length</strong></h3><ul><li><p>two factors:</p><ul><li>the length of the search path</li><li>the average out-degree of the graph</li></ul></li><li><p>Our goal is to find a graph with both low out-degrees and short search paths.</p></li><li><p>We will begin our discussion with how to design a graph with very short search paths.</p></li><li><p>Before we introduce our proposal, we will first provide a detailed analysis of a category of graphs called <em>Monotonic Search Networks (MSNET)</em>, which are first discussed in [13] and have shown great potential[潜力] in ANNS. Here we will present the definition of the MSNETs.</p></li></ul><h3 id="_3-4-mrng-construction" tabindex="-1"><a class="header-anchor" href="#_3-4-mrng-construction" aria-hidden="true">#</a> <strong>3.4 MRNG Construction</strong></h3><figure><img src="'+u+'" alt="algorithm2" tabindex="0" loading="lazy"><figcaption>algorithm2</figcaption></figure><h3 id="_3-5-nsg-practical-approximation-formrng" tabindex="-1"><a class="header-anchor" href="#_3-5-nsg-practical-approximation-formrng" aria-hidden="true">#</a> <strong>3.5 NSG:Practical Approximation ForMRNG</strong></h3><ul><li><p>就是说虽然MRNG的搜索已经很快了，就是这样的图的性质；</p></li><li><p>Though MRNG can guarantee a fast search time, its high indexing time is still not practical for large-scale problems.</p></li><li><p>In this section, we will present a practical approach by approximating our MRNG and starting from the four criteria to design a good graph for ANNS. We name it the <strong>Navigating Spreading-out Graph</strong> (NSG). We first present the NSG construction algorithm (Algorithm 2) as follows:</p><ul><li>We build an approximate <em>k</em>NN graph with the current state-of-the-art methods(<em>e.g</em>., [14, 28]).</li><li>We find the approximate medoid of the dataset. This can be achieved by the following steps. <ul><li>(1) Calculate the centroid of the dataset; （比如质心并不是数据集中的点；）</li><li>(2) Treat the centroid as the query, search on the <em>k</em>NN graph with Algorithm 1, and take the returned nearest neighbor as the approximate medoid. This node is named as the Navigating Node because all the search will start with this fixed node.找到质心的最近邻，就一个当作每次查询的进入点；</li></ul></li><li>For each node, we generate a candidate neighbor set and select neighbors for it from the candidate sets. This can be achieved by the following steps. For a given node <em>p</em>, <ul><li>(1) we treat it as a query and perform Algorithm 1 starting from the Navigating Node on the prebuilt <em>k</em>NN graph.</li><li>(2) During the search, each visited node <em>q</em> (<em>i.e</em>., the distance between <em>p</em> and <em>q</em> is calculated) will be added to the candidate set (the distance is also recorded).</li><li>(3)Select at most <em>m</em> neighbors for <em>p</em> from the candidate set with the edge selection strategy of MRNG.MRNG选边策略</li></ul></li><li>We span a Depth-First-Search tree on the graph produced in previous steps. We treat the Navigating Node as the root. When the DFS terminates, and there are nodes which are not linked to the tree, we link them to their approximate nearest neighbors (from Algorithm 1) and continue the DFS.通过上面得到的结果之后再进行加工；感觉时间复杂度会很高；</li></ul></li></ul><br><ul><li>What follows is the motivation of the NSG construction algorithm. The ultimate goal is to build an approximation of MRNG with low indexing time complexity. 就是说MRNG单说搜索来说的话确实很好，但是其构建太耗费时间了，所以就整个近似的NSG <ul><li><strong>(i)</strong> MRNG ensures there exists at least one monotonic path between any two nodes, however, it is not an easy task. Instead, we just pick one node out and try to guarantee the existence of monotonic paths from this node to all the others. We name this node as the Navigating Node. When we perform the search, we always start from the Navigating Node, which makes the search on an NSG almost as efficient as on an MRNG.就是说不保证所有的任意两点都是单调路径，但是保证了 Navigating Node到其它任何点是单调路径；</li><li><strong>(ii)</strong> The edge selection strategy of the MRNG treats all the other nodes as candidate neighbors of the current node, which causes a high time complexity. To speed up this process, we want to generate a small subset of candidates for each node. These candidates contain two parts: <ul><li>(1) As discussed above, the NNG is essential for monotonicity. Because it is very time-consuming to get the exact NNG, we turn to the approximate kNN graph. A high quality approximate kNN graph usually contains a high quality approximate NNG. It is acceptable when only a few nodes are not linked to their nearest neighbors. (2) Because the search on the NSG always starts from the Navigating Node <em>p**n</em>, for a given node <em>p</em>, we only need to consider those nodes which are on the search path from the <em>p**n</em> to <em>p</em>. Therefore we treat <em>p</em> as the query and perform Algorithm 1 on the prebuilt <em>k</em>NN graph. The nodes visited by the search and <em>p</em>’s nearest neighbor in the approximate NNG are recorded as candidates. The nodes forming the monotonic path from the Navigating Node to <em>p</em> are very likely included in the candidates. When we perform MRNG’s edge selection strategy on these candidates, it’s very likely that the NSG inherits the monotonic path in the MRNG from the Navigating Node to <em>p</em>.</li></ul></li></ul></li></ul><h4 id="_4-1-3-results" tabindex="-1"><a class="header-anchor" href="#_4-1-3-results" aria-hidden="true">#</a> <em>4.1.3 Results</em></h4><h4 id="_4-1-4-complexity-and-parameters" tabindex="-1"><a class="header-anchor" href="#_4-1-4-complexity-and-parameters" aria-hidden="true">#</a> <em>4.1.4 Complexity And Parameters</em></h4>',12),C=e("ul",null,[e("li",null,[e("p",null,[a("There are three parameters in the NSG indexing algorithm, "),e("em",null,"k"),a(" for the "),e("em",null,"k"),a("NN graph; "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mi",null,"l")]),e("annotation",{encoding:"application/x-tex"},"l")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.6944em"}}),e("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l")])])]),a(" and "),e("em",null,"m"),a(" for Algorithm 2. In our experiments, we find that the optimal parameters will not change with the data scale. Therefore we tune the parameters by sampling a small subset from the base data and performing grid search for the optimal parameters.")])]),e("li",null,[e("p",null,"We estimate the search and indexing complexity of the NSG on SIFT1M and GIST1M. Due to the space limitation, please see our technical report [16] for the figures and the detailed analysis. The search complexity is about ”“")]),e("li",null,[e("p",null,[a("The complexity of Algorithm 2 is about ”“ where "),e("em",null,"d"),a(" is approximately equal to the intrinsic dimension. This agrees with our theoretical analysis. We estimate how the search complexity scales with "),e("em",null,"K"),a(', the number of neighbors required. It’s about""')])])],-1),B=i('<h3 id="_4-2-search-on-deep100m" tabindex="-1"><a class="header-anchor" href="#_4-2-search-on-deep100m" aria-hidden="true">#</a> <strong>4.2 Search On DEEP100M</strong></h3><ul><li>The DEEP1B is a dataset containing one billion float vectors of 96 dimension released by Artem <em>et al</em>. [5]. We sample 100 million vectors from it and perform the experiments on a machine with i9-7980 CPU and 96GB memory.</li><li>The dataset occupies 37 GB memory, which is the largest dataset that the NSG can process on this machine. We build the <em>k</em>NN graph with Faiss [28] on four 1080Ti GPUs. The time of building the <em>k</em>NN graph is 6.75 hours and the time of Algorithm 2 is 9.7 hours. The peak memory usage of NSG at indexing stage is 92GB(使用的96GB机器), and it is 55 GB at searching stage. We try to run HNSW, but it always triggers the Out-Of-Memory error no matter how we set the parameters. So we only compare NSG with Faiss. The result is in <strong>Figure 7</strong>.</li></ul><br>',3),U=e("ul",null,[e("li",null,[e("p",null,[e("strong",null,"NSG-1core"),a(" means we build one NSG on the dataset and evaluate its performance with one CPU core. "),e("strong",null,"NSG-16core"),a(" means we break the dataset into 16 subsets (6.25 million vectors each) randomly and build 16 NSG on these subsets respectively. In this way, we can enable inner-query parallel search for NSG by searching on 16 NSGs simultaneously and merging the results to get the final result.")])]),e("li",null,[e("p",null,[a("Webuild one Faiss index (IVFPQ) for the 100 million vectors and evaluate its performance with one CPU-core ("),e("strong",null,"Faiss-"),a(),e("strong",null,"1core"),a("), 16 CPU-core ("),e("strong",null,"Faiss-16 core"),a("), and 1080Ti GPU ("),e("strong",null,"Faiss-GPU"),a(") respectively. Faiss supports inner-query parallel search. "),e("strong",null,"Serial-16core"),a(" means we perform serial scan[线性扫描] in parallel with 16 CPU cores.")])]),e("li",null,[e("figure",null,[e("img",{src:g,alt:"figure7",tabindex:"0",loading:"lazy"}),e("figcaption",null,"figure7")])]),e("li",null,[e("p",null,[a("NSG outperforms Faiss significantly in high-precision region. NSG-16core outperforms Faiss-GPU and is about 430 times faster than Serial-16core at 99% precision. Meanwhile, building NSG on 6.25 million vectors takes 794 seconds. The total time of building 16 NSGs sequentially only spends 3.53 hours, which is much faster than building one NSG on the whole DEEP100M. The reason may be as follows. The complexity of Algorithm 2 is about "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mi",null,"O"),e("mo",{stretchy:"false"},"("),e("mo",{stretchy:"false"},")")]),e("annotation",{encoding:"application/x-tex"},"O()")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),e("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),e("span",{class:"mopen"},"("),e("span",{class:"mclose"},")")])])]),a(" ;")])]),e("li",null,[e("p",null,[a("Suppose we have a dataset "),e("em",null,"D"),a(" with "),e("em",null,"n"),a(" points. We can partition "),e("em",null,"D"),a(" into "),e("em",null,"r"),a(" subsets evenly. The time of building one NSG on "),e("em",null,"D"),a(" is "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msub",null,[e("mi",null,"t"),e("mn",null,"1")])]),e("annotation",{encoding:"application/x-tex"},"t_1")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.7651em","vertical-align":"-0.15em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"t"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t vlist-t2"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.3011em"}},[e("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mtight"},"1")])])]),e("span",{class:"vlist-s"},"​")]),e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.15em"}},[e("span")])])])])])])])]),a(", The time of building an NSG on one subset is "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msub",null,[e("mi",null,"t"),e("mn",null,"2")])]),e("annotation",{encoding:"application/x-tex"},"t_2")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.7651em","vertical-align":"-0.15em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"t"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t vlist-t2"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.3011em"}},[e("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mtight"},"2")])])]),e("span",{class:"vlist-s"},"​")]),e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.15em"}},[e("span")])])])])])])])]),a("; It is easy to verify that we can have "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msub",null,[e("mi",null,"t"),e("mn",null,"1")]),e("mo",null,">"),e("mi",null,"r"),e("msub",null,[e("mi",null,"t"),e("mn",null,"2")])]),e("annotation",{encoding:"application/x-tex"},"t_1 > r t_2")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.7651em","vertical-align":"-0.15em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"t"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t vlist-t2"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.3011em"}},[e("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mtight"},"1")])])]),e("span",{class:"vlist-s"},"​")]),e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.15em"}},[e("span")])])])])]),e("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),e("span",{class:"mrel"},">"),e("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.7651em","vertical-align":"-0.15em"}}),e("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"t"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t vlist-t2"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.3011em"}},[e("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mtight"},"2")])])]),e("span",{class:"vlist-s"},"​")]),e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.15em"}},[e("span")])])])])])])])]),a(" if we select a proper "),e("em",null,"r"),a(". Consequently, sequential indexing on subsets can be faster than on the complete set.因此，在子集上顺序索引可以比在整个数据集上更快。")])])],-1),H=i('<h3 id="_4-3-search-in-e-commercial-scenario" tabindex="-1"><a class="header-anchor" href="#_4-3-search-in-e-commercial-scenario" aria-hidden="true">#</a> <strong>4.3 Search In E-commercial Scenario</strong></h3><ul><li>应用到电子商务中</li><li>on the billion-scale high-dimensional ANNS problem in the E-commercial scenario.</li><li>The billion-scale data, daily updating, and response time limit are the main challenges.</li><li>We evaluate NSG on the E-commercial data (128-dimension vectors of users and commodities) with different scales to work out a solution.</li></ul><br><ul><li>We compare NSG with the baseline (a well-optimized implementation of IVFPQ [26]) on the e-commerce database.</li><li>We use a 10M dataset to test the performance on a single thread, and a 45M dataset to test the <strong>Distributed Search</strong> performance in a simulation environment.</li><li>The simulation environment is a online scenario stress testing system based on MPI. We split the dataset and place the subsets on different machines. At search stage, we search each subset in parallel and merge the results to return.</li><li>In our experiments, we randomly partition the dataset evenly into 12 subsets and build 12 NSGs. NSG is 5-10 times faster than the baseline at the same precision (See our technical report [16] for details) and meet the response time requirement.</li></ul><br><ul><li>On the complete dataset (about 2 billion vectors), we find it impossible to build one NSG within one day.</li><li>So we use the distributed search solution with 32 partitions. The average response time is about 5 ms at 98% precision, and the indexing time is about 12 hours for a partition.</li><li>The baseline method (IVFPQ) cannot reach the response time requirement (responsing within 10 ms at 98% precision) on the complete dataset.</li></ul><h2 id="_5-discussions" tabindex="-1"><a class="header-anchor" href="#_5-discussions" aria-hidden="true">#</a> <strong>5. DISCUSSIONS</strong></h2><ul><li><p>高精度快速响应[需要提前准备和内存大]</p></li><li><p>The NSG can achieve very high search performance at high precision, but it needs much more memory space and data-preprocessing time than many popular quantization-based and hashing-based methods (<em>e.g</em>., IVFPQ and LSH).就是说在高精度的时候search很好；但是呢需要更多的内存和数据处理时间；</p></li><li><p>The NSG is very suitable for high precision and fast response scenarios, given enough memory. In frequent updating scenarios, the indexing time is also important. Building one NSG on the large dataset is impractical. The distributed search solution like our experiments is a good choice.在有足够内存的情况下，NSG非常适用于高精度和快速响应的场景。在频繁更新的场景中，索引时间也很重要。在大型数据集上构建一个 NSG 是不切实际的。像我们实验中的分布式搜索解决方案是一个不错的选择。</p></li><li><p>It’s also possible for NSG to enable incremental indexing. We will leave this to future works.增量的构建未来；</p></li></ul><h2 id="_6-conclusions" tabindex="-1"><a class="header-anchor" href="#_6-conclusions" aria-hidden="true">#</a> <strong>6. CONCLUSIONS</strong></h2><ul><li><p>we propose a new monotonic search network, MRNG, which ensures approximately logarithmic search complexity.</p></li><li><p>We propose four aspects (ensuring the connectivity, lowering the average out-degree, shortening the search paths, and reducing the index size) to design better graph structure for massive problems.</p></li><li><p>Based on the four aspects, we propose NSG, which is a practical approximation of the MRNG and considers the four aspects simultaneously.</p></li></ul>',10);function V(K,Q){const l=o("ExternalLinkIcon"),s=o("router-link");return h(),m("div",null,[w,b,c(" more "),e("div",y,[x,e("ul",null,[N,v,_,e("li",null,[a("code： "),e("a",S,[a("https://github.com/ZJULearning/nsg"),t(l)])]),k,e("li",null,[e("a",M,[a("https://zhuanlan.zhihu.com/p/712991028"),t(l)])]),e("li",null,[e("a",G,[a("https://blog.csdn.net/weixin_44839084/article/details/104013138"),t(l)])]),e("li",null,[e("a",T,[a("https://blog.csdn.net/chansonzhang/article/details/107775706"),t(l)])])])]),e("nav",A,[e("ul",null,[e("li",null,[t(s,{to:"#no-0-摘要"},{default:n(()=>[a("No.0 摘要")]),_:1})]),e("li",null,[t(s,{to:"#_1-introduction"},{default:n(()=>[a("1. INTRODUCTION")]),_:1})]),e("li",null,[t(s,{to:"#_2-preliminaries"},{default:n(()=>[a("2. PRELIMINARIES")]),_:1}),e("ul",null,[e("li",null,[t(s,{to:"#_2-1-problem-setting"},{default:n(()=>[a("2.1 Problem Setting")]),_:1})]),e("li",null,[t(s,{to:"#_2-2-non-graph-based-anns-methods"},{default:n(()=>[a("2.2 Non-Graph-Based ANNS Methods")]),_:1})]),e("li",null,[t(s,{to:"#_2-3-graph-based-anns-methods"},{default:n(()=>[a("2.3 Graph-Based ANNS Methods")]),_:1})])])]),e("li",null,[t(s,{to:"#_3-algorithms-and-analysis"},{default:n(()=>[a("3. ALGORITHMS AND ANALYSIS")]),_:1}),e("ul",null,[e("li",null,[t(s,{to:"#_3-1-motivation"},{default:n(()=>[a("3.1 Motivation")]),_:1})]),e("li",null,[t(s,{to:"#_3-2-graph-monotonicity-and-path-length"},{default:n(()=>[a("3.2 Graph Monotonicity And Path Length")]),_:1})]),e("li",null,[t(s,{to:"#_3-4-mrng-construction"},{default:n(()=>[a("3.4 MRNG Construction")]),_:1})]),e("li",null,[t(s,{to:"#_3-5-nsg-practical-approximation-formrng"},{default:n(()=>[a("3.5 NSG:Practical Approximation ForMRNG")]),_:1})]),e("li",null,[t(s,{to:"#_4-2-search-on-deep100m"},{default:n(()=>[a("4.2 Search On DEEP100M")]),_:1})]),e("li",null,[t(s,{to:"#_4-3-search-in-e-commercial-scenario"},{default:n(()=>[a("4.3 Search In E-commercial Scenario")]),_:1})])])]),e("li",null,[t(s,{to:"#_5-discussions"},{default:n(()=>[a("5. DISCUSSIONS")]),_:1})]),e("li",null,[t(s,{to:"#_6-conclusions"},{default:n(()=>[a("6. CONCLUSIONS")]),_:1})])])]),I,q,z,E,R,L,W,P,D,F,O,C,B,U,H])}const Z=r(f,[["render",V],["__file","NSG.html.vue"]]);export{Z as default};
