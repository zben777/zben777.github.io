import{_ as l}from"./plugin-vue_export-helper-c27b6911.js";import{r as c,o as r,c as i,d as u,a as n,e as s,w as e,b as a,f as o}from"./app-2a2d189a.js";const d="/assets/figure10-1-38581141.png",k="/assets/figure10-2-0647bee0.png",b="/assets/figure10-3-1a261244.png",m="/assets/figure10-4-0cfc2313.png",v="/assets/figure10-5-1e998b34.png",h="/assets/figure10-6-1a891970.png",_="/assets/figure10-7-2aebae91.png",g="/assets/figure10-8-89bd9322.png",f="/assets/figure10-9-84ef721a.png",C="/assets/table10-1-30fac47c.png",A="/assets/figure10-10-5f6cd514.png",U="/assets/figure10-11-3c1c346f.png",y="/assets/figure10-12-8bf2c6fd.png",D="/assets/figure10-13-ed3bb772.png",x="/assets/table10-2-4d07f379.png",P="/assets/figure10-14-990112bb.png",I="/assets/figure10-15-6f572e64.png",S="/assets/figure10-16-b1d57894.png",G="/assets/table10-3-5c26b43a.png",E="/assets/figure10-17-7442ff7b.png",L="/assets/figure10-18-8fe6287b.png",M="/assets/figure10-19-d9a17e4b.png",N="/assets/table10-4-bccd6785.png",w="/assets/figure10-20-4a0c8a84.png",O="/assets/table10-5-11d33171.png",z="/assets/table10-6-795acae1.png",T={},H=n("h1",{id:"j-第十章",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#j-第十章","aria-hidden":"true"},"#"),a(" J-第十章")],-1),$=n("p",null,"J-第十章",-1),R={class:"table-of-contents"},K=o('<h2 id="简单介绍主要是基础" tabindex="-1"><a class="header-anchor" href="#简单介绍主要是基础" aria-hidden="true">#</a> 简单介绍主要是基础</h2><div class="hint-container info"><p class="hint-container-title">说明</p><p>主要是各种搜索找的学习；</p><p>主题：CUDA核心GPU编程</p><p>前置条件：</p><ul><li>应具备C++编程知识</li><li>需理解内存管理，如malloc和free</li><li>理解STL及其模板机制</li><li>需配置NVIDIA显卡，型号需为900系列或更高</li><li>所用扩展要求版本为11或更新</li><li>编译器版本不低于11</li><li>CMake版本需在3.18以上</li></ul></div><h2 id="第10章-程序实现的注意事项" tabindex="-1"><a class="header-anchor" href="#第10章-程序实现的注意事项" aria-hidden="true">#</a> 第10章 程序实现的注意事项</h2><ul><li><p>本章内容：<br> ·了解CUDA的开发过程<br> ·使用性能分析工具探索优化因素<br> ·使用合适的指标/事件确定最有可能的性能限制因素<br> ·结合NVTX库标记出代码的关键部分用于性能分析<br> ·使用CUDA调试工具调试CUDA中的内核和内存错误<br> ·将实际的应用程序由传统的C语言移植到CUDA C中</p></li><li><p>现代的异构和并行系统并不是专门用于高性能计算的，还适用于嵌入式开发，移动设<br> 备开发，平板电脑，笔记本电脑，PC和工作站。这种普遍性使得通用软件开发走向异构<br> 并行编程，因为访问这些系统会变得更为普遍。并行编程从未变得如此方便有利，因此，<br> 知道如何高效正确地实现并行和异构软件是非常重要的。</p></li><li><p>本章包含了CUDA C项目开发的以下几个方面：<br> ·CUDA C的开发过程<br> ·配置文件驱动优化<br> ·CUDA开发工具</p></li><li><p>本章结尾提供了一个案例，逐步将C语言移植到CUDA C中，这会有助于方法的理<br> 解，形象化整个过程并说明本章涉及的工具</p></li></ul><h2 id="_10-1-cudac的开发过程" tabindex="-1"><a class="header-anchor" href="#_10-1-cudac的开发过程" aria-hidden="true">#</a> 10.1 CUDAC的开发过程</h2><ul><li><p>在产品研发过程中的软件开发注重结构，旨在标准化代码并维护最好的范例。现在有<br> 许多软件开发模型，每种模型都描述了一些方法，这些方法都是针对特定情况下的特殊需<br> 求的。CUDA平台的开发过程是建立在现有模型和熟悉软件生命周期的概念之上的。</p></li><li><p>了解GPU内存和执行模型抽象有助于更好地控制大规模并行GPU环境。这样，创建映<br> 射到抽象二维或三维网格的应用子域就变得很正常了，并且可以使核函数像串行一样表<br> 示。重点关注高级区域分解和内存层次结构存储管理的内容，就不会被创建和销毁线程的<br> 烦琐细节所妨碍了。在CUDA的开发过程中，需要关注的重点是以下几个方面：<br> ·以性能为导向<br> ·配置文件驱动<br> ·通过GPU架构的抽象模型进行启发引导</p></li><li><p>了解应用程序如何使用GPU对确定性能提升的因素是至关重要的。NVIDIA提供了许<br> 多功能强大且易于使用的工具，它们能使开发过程引人入胜又轻松愉悦。以下部分包含了<br> CUDA的开发过程和CUDA的性能优化策略</p></li></ul><h4 id="_10-1-1-apod开发周期" tabindex="-1"><a class="header-anchor" href="#_10-1-1-apod开发周期" aria-hidden="true">#</a> 10.1.1 APOD开发周期</h4><ul><li>APOD是由NVIDIA特别为CUDA开发定制的迭代开发过程。APOD有4个阶段，如图10-1所示。<br> ·评估（assessment）<br> ·并行化（parallelization）<br> ·优化（optimization）<br> ·部署（deployment）<br><img src="'+d+'" alt="figure10-1" loading="lazy"></li></ul><h4 id="_10-1-1-1-评估" tabindex="-1"><a class="header-anchor" href="#_10-1-1-1-评估" aria-hidden="true">#</a> 10.1.1.1 评估</h4><ul><li><p>第一阶段的任务是评估应用程序，确定限制性能的瓶颈或具有高计算强度的临界区。<br> 在这里，需要评估用GPU配合CPU的可能性，发展策略以加速这些临界区。</p></li><li><p>在这一阶段，数据并行循环结构包含很重要的计算，应该始终给予其较高的评估优先<br> 级。这种循环类型是GPU加速的理想化情况。为了帮助找出这些临界区，应该使用性能分<br> 析工具来发掘出应用程序的热点。有些代码可能已经被转化为使用主机的并行编程模型<br> （如OpenMP或pthreads）。只要现有的并行部分能够充分并行化，那么它们也将为GPU加<br> 速提供很好的目标。</p></li></ul><h4 id="_10-1-1-2-并行化" tabindex="-1"><a class="header-anchor" href="#_10-1-1-2-并行化" aria-hidden="true">#</a> 10.1.1.2 并行化</h4><ul><li><p>一旦应用程序的瓶颈被确定，下一阶段就是将代码并行化。这里有几种加速主机代码<br> 的方式，包括以下几个方面：<br> ·使用CUDA并行库<br> ·采用并行化及向量化编译器<br> ·手动开发CUDA内核使之并行化</p></li><li><p>将应用程序并行化的最直接方法就是利用现有的GPU加速库。如果应用程序已经使用<br> 了其他的C数学库，如BLAS或FFTW，那么就可以很容易转换成使用CUDA库，如cuBLAS<br> 或cuFFT。另一种相对简单并行化主机代码的方法是利用并行化编译器。Open-ACC使用<br> 开放的、标准的编译指令，它是为加速器环境显式设计的。OpenACC扩展提供了充分的<br> 控制以确保数据常驻于接近处理单元的位置，并提供了一系列的编译指令。这些使得GPU<br> 编程更加简单，可跨并行和多核处理器。</p></li><li><p>如果应用程序所需的功能或性能超出了现有的并行库或并行编译器所能提供的范围，<br> 那么在这种情况下，对并行化使用CUDA C编写内核是必不可少的。通过使用CUDA C，<br> 可以最大限度地使用GPU的并行能力。</p></li><li><p>根据原代码的情况，可能需要重构程序来展现固有并行以提升应用程序的性能。并行<br> 数据分解在这一阶段是不可避免的。大规模并行线程间的数据划分主要有两种不同的方<br> 法：块划分和循环划分。在块划分中，要处理的数据元素被分成块并分配到线程中，内核<br> 的性能与块的大小密切相关。在循环划分中，每个线程在跳跃之前一次处理一个元素，线<br> 程数量和元素数量相同。数据划分要考虑的问题与架构特征和要实现的算法性质相关。</p></li></ul><h4 id="_10-1-1-3-优化" tabindex="-1"><a class="header-anchor" href="#_10-1-1-3-优化" aria-hidden="true">#</a> 10.1.1.3 优化</h4><ul><li><p>当组织好代码且并行运行后，将进入下一阶段：优化实现以提升性能。大致来说，基<br> 于CUDA的优化可以体现在以下两个层次上：<br> ·网格级（grid-level）<br> ·内核级（kernel-level）</p></li><li><p>在网格级优化过程中，重点是整体GPU的利用率和效率。优化网格级性能的方法包括<br> 同时运行多个内核以及使用CUDA流和事件重叠带有数据的内核执行。</p></li><li><p>限制内核性能的主要原因有3个：<br> ·内存带宽<br> ·计算资源<br> ·指令和内存延迟</p></li><li><p>在内核级优化过程中，要关注GPU的内存带宽和计算资源的高效使用，并减少或隐藏<br> 指令和内存延迟。</p></li><li><p>CUDA提供了以下强大且有用的工具，从而可以在网格级和内核级确定影响性能的因素：<br> ·Nsight Eclipse Edition（nsight）<br> ·NVIDIA可视化性能分析工具（nvvp）<br> ·NVIDIA命令行性能分析工具（nvprof）</p></li><li><p>这些性能分析工具在优化处理中是十分有效的，并为提升性能提供了最好的意见。在<br> 本书中，nvprof和nvvp已经用于许多练习和示例中。</p></li></ul><h4 id="_10-1-1-4-部署" tabindex="-1"><a class="header-anchor" href="#_10-1-1-4-部署" aria-hidden="true">#</a> 10.1.1.4 部署</h4><ul><li><p>只要确定了GPU加速应用程序的结果是正确的，那么就进入了APOD的最后阶段，即<br> 如何利用GPU组件部署系统。例如，部署CUDA应用程序时，要确保在目标机器没有支持<br> CUDA的GPU的情况下，程序仍能正常运行。CUDA运行时提供了一些函数，用于检测支<br> 持CUDA的GPU并检查硬件和软件的配置。但是，应用程序必须手动调整以适应检测到的<br> 硬件资源。</p></li><li><p>APOD是一个迭代过程，它的目的是将传统的应用程序转化为性能力良好且稳定的<br> CUDA应用程序。那些包含许多GPU加速申请的应用程序，可能多次经过了APOD的流水<br> 线周期：确定优化因素、应用和测试优化、验证加速实现，并再次重复这个过程。</p></li></ul><h4 id="螺旋模型" tabindex="-1"><a class="header-anchor" href="#螺旋模型" aria-hidden="true">#</a> 螺旋模型</h4><ul><li><p>螺旋模型是一种软件开发方法，它基于关键要素的连续细化概念，使用的迭代周期为：<br> ·分析<br> ·设计<br> ·实现</p></li><li><p>它允许每一次围绕螺旋生命周期时，增加产品发布，或者增加细化。</p></li><li><p>APOD开发模型的基本方法与螺旋模型相同</p></li></ul><h4 id="_10-1-2-优化因素" tabindex="-1"><a class="header-anchor" href="#_10-1-2-优化因素" aria-hidden="true">#</a> 10.1.2 优化因素</h4><ul><li>一旦正确的CUDA程序已作为APOD并行化阶段的一部分实现，那么在优化阶段就能<br> 开始寻找优化因素了。如前文所述，优化可以应用在各个层面，从重叠数据传输和数据计<br> 算这个层面来看，所有的优化方法都在于底层的微调浮点运算。为了取得更好的性能，应<br> 该专注于程序的以下几个方面，按照重要性排列为：<br> ·展现足够的并行性<br> ·优化内存访问<br> ·优化指令执行</li></ul><h4 id="_10-1-2-1-展现足够的并行性" tabindex="-1"><a class="header-anchor" href="#_10-1-2-1-展现足够的并行性" aria-hidden="true">#</a> 10.1.2.1 展现足够的并行性</h4><ul><li><p>为了展现足够的并行性，应该在GPU上安排并发任务，以使指令带宽和内存带宽都达<br> 到饱和。</p></li><li><p>有两种方法可以增强并行性：<br> ·在一个SM中保证有更多活跃的并发线程束<br> ·为每个线程/线程束分配更多独立的工作</p></li><li><p>当在一个SM中活跃线程束的数量为最佳时，必须检查SM的资源占用率的限制因素<br> （如共享内存、寄存器以及计算周期），以找到达到最佳性能的平衡点。活跃线程束的数<br> 量代表了在SM中展示的并行性的数量。但是，高占用率不对应高性能。根据内核算法的<br> 性质，一旦达到了一定程度的占用率，那么再进一步增加占用率就不会提高性能了。但是<br> 仍有机会从其他方面来提高性能</p></li><li><p>能从两个不同的层面调整并行性：<br> ·内核级（kernel level）<br> ·网格级（grid level）</p></li><li><p>在内核级，CUDA采用划分方法分配计算资源：寄存器在线程间被划分，共享内存在<br> 线程块间被划分。因此，内核中的资源消耗可能会限制活跃线程束的数量。</p></li><li><p>在网格级，CUDA使用由线程块组成的网格来组织线程的执行，通过指定如下内容，<br> 可以自由选择最佳的内核启动配置参数：<br> ·每个线程块中线程的数量<br> ·每个网格中线程块的数量</p></li><li><p>通过网格配置，能够控制线程块中安排线程的方式，以向SM展示足够的并行性，并<br> 在SM之间平衡任务。</p></li></ul><h4 id="_10-1-2-2-优化内存访问" tabindex="-1"><a class="header-anchor" href="#_10-1-2-2-优化内存访问" aria-hidden="true">#</a> 10.1.2.2 优化内存访问</h4><ul><li><p>许多算法都是受内存限制的。对于这些应用程序和其他的一些程序，内存访问延迟和<br> 内存访问模式对内核性能有显著的影响。因此，内存优化是提高性能需要关注的重要方面<br> 之一。内存访问优化的目标是最大限度地提高内存带宽的利用率，重点应放在以下两个方<br> 面：<br> ·内存访问模式（最大限度地使用总线上的字节）<br> ·充足的并发内存访问（隐藏内存延迟）</p></li><li><p>来自每一个内核的内存请求（加载或存储）都是由单个线程束发出的。线程束中的每<br> 个线程都提供了一个内存地址，基于提供的内存地址，32个线程一起访问一个设备内存<br> 块。设备硬件将线程束提供的地址转换为内存事务。设备上的内存访问粒度为32字节。因<br> 此，在分析程序的数据传输时需要注意两个指标：程序需要的字节数和硬件传输的字节<br> 数。这两者之间的差值表示了浪费的内存带宽。</p></li><li><p>对于全局内存来说，最好的访问模式是对齐和合并访问。对齐内存访问要求所需的设<br> 备内存的第一个地址是32字节的倍数。合并内存访问指的是，通过线程束中的32个线程来<br> 访问一个连续的内存块。</p></li><li><p>加载内存和存储内存这两个操作的特性和行为是不同的。加载操作可以分为3种不同<br> 的类型：<br> ·缓存（默认，一级缓存可用）<br> ·未缓存（一级缓存禁用）<br> ·只读</p></li><li><p>缓存加载的加载粒度是一个128字节的缓存行。对于未缓存和只读的加载来说，粒度<br> 是一个32字节的段。通常，在Fermi GPU上全局内存的加载，会首先尝试命中一级缓存，<br> 然后是二级缓存，最后是设备全局内存。在Kepler GPU上，全局内存的加载会跳过一级缓<br> 存。对于只读内存的加载来说，CUDA首先尝试命中一个独立的只读缓存，然后是二级缓<br> 存，最后是设备全局内存。对于不规则的访问模式，如未对齐和/或未合并的访问模式，<br> 短加载粒度有助于提高带宽的利用率。在Fermi GPU上，一级缓存可以启用或禁用编译器<br> 选项。在默认情况下，全局存储操作跳过一级缓存并且回收正在匹配的缓存行。</p></li><li><p>由于共享内存是片上内存，所以比本地和设备的全局内存具有更高的带宽和更低的延<br> 迟。在很多方面，共享内存是一个可编程管理的缓存。使用共享内存有两个主要原因：<br> ·通过显式缓存数据来减少全局内存的访问<br> ·通过重新安排数据布局避免未合并的全局内存的访问</p></li><li><p>在物理角度上，共享内存以一种线性方式排列，通过32个存储体（bank）进行访问。<br> Fermi和Kepler各有不同的默认存储体模式：分别是4字节存储体模式和8字节存储体模<br> 式。共享内存地址到存储体的映射关系随着访问模式的不同而不同。当线程束中的多个线<br> 程在同一存储体中访问不同字时，会发生存储体冲突（bank conflict）。由于共享内存重<br> 复请求，所以多路存储体冲突可能要付出很大代价。当使用共享内存时，解决或减少存储<br> 体冲突的一个非常简单有效的方法是填充数组。在合适的位置添加填充字，可以使其跨不<br> 同存储体进行访问，从而减少了延迟并提高了吞吐量。</p></li><li><p>共享内存被划分在所有常驻线程块中，因此，它是一个关键资源，可能会限制内核的<br> 占用率。</p></li></ul><h4 id="_10-1-2-3-优化指令执行" tabindex="-1"><a class="header-anchor" href="#_10-1-2-3-优化指令执行" aria-hidden="true">#</a> 10.1.2.3 优化指令执行</h4><ul><li><p>有以下几种方法可以优化内核执行，包括：<br> ·通过保证有足够多的活跃线程束来隐藏延迟<br> ·通过给线程分配更多独立的工作来隐藏延迟<br> ·避免线程束内出现分化执行路径</p></li><li><p>尽管CUDA内核是以标量方式表示的，就像它在单一CUDA核心上运行一样，但是代<br> 码总是在线程束单元中以SIMT（单指令多线程）方式来执行的。当对线程束发出一条指<br> 令时，每个线程用自己的数据执行相同的操作。</p></li><li><p>可以通过修改内核执行配置来组织线程。线程块的大小会影响在SM上活跃线程束的<br> 数量。GPU通过异步处理运行中的工作来隐藏延迟（如全局加载和存储），以使得线程束<br> 进度、流水线、内存总线都处于饱和状态。我们可以调整内核执行配置获得更多的活跃线<br> 程束，或使每个线程做更多独立的工作，这些工作是可以以流水线方式执行和重叠执行。<br> 拥有不同计算能力的GPU设备有不同的硬件限制条件，因此，在不同的平台上网格/线程<br> 块启发式算法对于优化内核性能有非常重要的作用。</p></li><li><p>因为线程束内的所有线程在每一步都执行相同的指令，如果由于数据依赖的条件分支<br> 造成线程束内有不同的控制流路径，那么线程运行可能会出现分化。当线程束内的线程发<br> 生分化时，线程束必须顺序执行每个分支路径，并禁用不在此执行路径上的线程。如果应<br> 用程序的运行时间大部分花在分化代码中，那么就会显著影响内核的性能。</p></li><li><p>线程间的通信和同步是并行编程中非常重要的特性，但是它会对取得良好的性能造成<br> 障碍。CUDA提供了一些机制，可以在不同层次管理同步。通常，有两种方法来显式同步<br> 内核：<br> ·在网格级进行同步<br> ·在线程块内进行同步</p></li><li><p>同步线程中有潜在的分化代码是很危险的，可能会导致未预料的错误。必须小心以确<br> 保所有线程都收敛于线程块内的显式障碍点。总之，同步增加了内核开销，并且在决定线<br> 程块中哪个线程束符合执行条件时，制约了CUDA调度器的灵活性。</p></li></ul><h4 id="_10-1-3-cuda代码编译" tabindex="-1"><a class="header-anchor" href="#_10-1-3-cuda代码编译" aria-hidden="true">#</a> 10.1.3 CUDA代码编译</h4><ul><li>一个CUDA应用程序的源程序代码通常包含两种类型的源文件：常规的C源文件和<br> CUDA C源文件。在设备代码文件中，通常有两种函数：设备函数以及调用设备函数或管<br> 理设备资源的主机函数。CUDA编译器将编译过程分成了以下两个部分（如图10-2所<br> 示）：<br> ·使用nvcc的设备函数编译<br> ·使用通用型C/C++编译器的主机函数编译</li></ul><figure><img src="'+k+'" alt="figure10-2" tabindex="0" loading="lazy"><figcaption>figure10-2</figcaption></figure><ul><li><p>编译的设备对象作为加载图像被嵌入到主机的目标文件中。通过链接阶段，添加<br> CUDA运行时库来支持设备的函数性。</p></li><li><p>CUDA提供了以下两种方式编译CUDA函数：<br> ·整体程序编译<br> ·独立编译</p></li><li><p>在CUDA 5.0以前，核函数的完整定义与它调用的所有设备函数必须在同一个文件范<br> 围内，不能跨文件调用设备函数或是访问设备变量，这种编译被称为整体程序编译。从<br> CUDA 5.0开始，引入了设备代码的独立编译（虽然整体程序编译仍然是默认的编译模<br> 式）。在独立编译下，一个文件中定义的设备代码可以引用另一个文件中定义的设备代<br> 码。独立编译CUDA项目管理有以下优点：<br> ·使传统的C代码到CUDA的移植更容易<br> ·通过增加库的重新编译减少了构建时间<br> ·有利于代码重用，减少了编译时间<br> ·可将目标文件合并为静态库<br> ·允许链接和调用外部设备代码<br> ·允许创建和使用第三方库</p></li></ul><h4 id="_10-1-3-1-独立编译" tabindex="-1"><a class="header-anchor" href="#_10-1-3-1-独立编译" aria-hidden="true">#</a> 10.1.3.1 独立编译</h4>',31),F=n("li",null,[n("p",null,[a("CUDA编译是将设备代码嵌入到主机对象中的。在整体程序编译中，可执行的设备代"),n("br"),a(" 码被嵌入到主机对象中。而独立编译的过程则不那么简单，主要包含以下3个步骤："),n("br"),a(" 1.设备编译器将可重新定位的设备代码嵌入到主机目标文件中。"),n("br"),a(" 2.设备链接器结合设备对象。"),n("br"),a(" 3.主机链接器将设备和主机对象组合成一个最终可执行的程序。")])],-1),V={href:"http://xn--a-kq6a08hi54a.cu",target:"_blank",rel:"noopener noreferrer"},B={href:"http://b.cu",target:"_blank",rel:"noopener noreferrer"},W=n("br",null,null,-1),Z=n("br",null,null,-1),q=n("br",null,null,-1),X=n("code",null,"$ nvcc –arch=sm_20 –dc a.cu b.cu",-1),J={href:"http://a.xn--cub-bj4e.cu",target:"_blank",rel:"noopener noreferrer"},Y=n("br",null,null,-1),j=n("br",null,null,-1),Q=n("code",null,"$ nvcc –arch=sm_20 –dlink a.o b.o –o link.o",-1),nn=n("li",null,[n("p",null,[a("传到nvcc中的选项-dlink，使所有具有重新定位设备代码（a.o和b.o）的设备目标文件"),n("br"),a(" 被链接到一个可以传递到主机链接器的目标文件（link.o）中，最后，主机链接器生成可"),n("br"),a(" 以执行的程序，如下："),n("br"),n("code",null,"$ g++ -c c.cpp -o c.o"),n("br"),n("code",null,"$ g++ c.o link.o -o test –L<path> -lcudart")])],-1),an=n("li",null,[n("p",null,[a("图10-3说明独立编译过程"),n("br"),n("img",{src:b,alt:"figure10-3",loading:"lazy"})])],-1),sn=o(`<h4 id="_10-1-3-2-makefile示例文件" tabindex="-1"><a class="header-anchor" href="#_10-1-3-2-makefile示例文件" aria-hidden="true">#</a> 10.1.3.2 Makefile示例文件</h4><ul><li><p>代码清单10-1是一个使用独立编译的Makefile示例文件。需要更换Makefile示例文件中<br> 完整的路径名称并更新可执行的文件名，以与工作环境相匹配。你可以扩展示例来编译一<br> 个包含以下内容的项目：<br> ·C和CUDA C文件<br> ·跨CUDA C文件引用的设备函数或设备变量</p></li><li><p>sample-makefile文件可以从Wrox.com上下载。</p></li><li><p>代码清单10-1 Sample Makefi le（Makefile）</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>SRCS <span class="token operator">:</span><span class="token operator">=</span> $<span class="token punctuation">(</span>wildcard <span class="token operator">*</span><span class="token punctuation">.</span>c<span class="token punctuation">)</span>
OBJS <span class="token operator">:</span><span class="token operator">=</span> $<span class="token punctuation">(</span>patsubst <span class="token operator">%</span><span class="token punctuation">.</span>c<span class="token punctuation">,</span> <span class="token operator">%</span><span class="token punctuation">.</span>o<span class="token punctuation">,</span> $<span class="token punctuation">(</span>SRCS<span class="token punctuation">)</span><span class="token punctuation">)</span>
CUDA_SRCS <span class="token operator">:</span><span class="token operator">=</span> $<span class="token punctuation">(</span>wildcard <span class="token operator">*</span><span class="token punctuation">.</span>cu<span class="token punctuation">)</span>
CUDA_OBJS <span class="token operator">:</span><span class="token operator">=</span> $<span class="token punctuation">(</span>patsubst <span class="token operator">%</span><span class="token punctuation">.</span>cu<span class="token punctuation">,</span> <span class="token operator">%</span><span class="token punctuation">.</span>o<span class="token punctuation">,</span> $<span class="token punctuation">(</span>CUDA_SRCS<span class="token punctuation">)</span><span class="token punctuation">)</span>
CUDA_PATH <span class="token operator">:</span><span class="token operator">=</span> <span class="token operator">/</span>usr<span class="token operator">/</span>local<span class="token operator">/</span>cuda<span class="token operator">-</span><span class="token number">6.0</span># specify your CUDA root path
NVCC <span class="token operator">:</span><span class="token operator">=</span> $<span class="token punctuation">(</span>CUDA_PATH<span class="token punctuation">)</span><span class="token operator">/</span>bin<span class="token operator">/</span>nvcc 
CC <span class="token operator">:</span><span class="token operator">=</span> icc
LD <span class="token operator">:</span><span class="token operator">=</span> icc <span class="token operator">-</span>openmp
CUDA_LIB <span class="token operator">:</span><span class="token operator">=</span> <span class="token operator">-</span>L$<span class="token punctuation">(</span>CUDA_PATH<span class="token punctuation">)</span><span class="token operator">/</span>lib64 <span class="token operator">-</span>lcublas <span class="token operator">-</span>lcufft <span class="token operator">-</span>lcudart
CUDA_INC <span class="token operator">+=</span> <span class="token operator">-</span>I$<span class="token punctuation">(</span>CUDA_PATH<span class="token punctuation">)</span><span class="token operator">/</span>include

CFLAGS <span class="token operator">+=</span> <span class="token operator">-</span>std<span class="token operator">=</span>c99
INCLUDES <span class="token operator">:</span><span class="token operator">=</span> # specify include path <span class="token keyword">for</span> host code
GPU_CARD <span class="token operator">:</span><span class="token operator">=</span> <span class="token operator">-</span>arch<span class="token operator">=</span>sm_35 # specify your device compute capability
NVCC_FLAGS <span class="token operator">+=</span> <span class="token operator">-</span>O3 <span class="token operator">-</span>dc # separate compilation
NVCC_FLAGS <span class="token operator">+=</span> <span class="token operator">-</span>Xcompiler <span class="token operator">-</span>fopenmp
CUDA_LINK_FLAGS <span class="token operator">:</span><span class="token operator">=</span> <span class="token operator">-</span>dlink # device linker option
EXEC <span class="token operator">:</span><span class="token operator">=</span> test # specify your executable name 
CUDA_LINK_OBJ <span class="token operator">:</span><span class="token operator">=</span> cuLink<span class="token punctuation">.</span>o
all<span class="token operator">:</span> $<span class="token punctuation">(</span>EXEC<span class="token punctuation">)</span>
$<span class="token punctuation">(</span>EXEC<span class="token punctuation">)</span><span class="token operator">:</span> $<span class="token punctuation">(</span>OBJS<span class="token punctuation">)</span> $<span class="token punctuation">(</span>CUDA_OBJS<span class="token punctuation">)</span>
 $<span class="token punctuation">(</span>NVCC<span class="token punctuation">)</span> $<span class="token punctuation">(</span>GPU_CARD<span class="token punctuation">)</span> $<span class="token punctuation">(</span>CUDA_LINK_FLAGS<span class="token punctuation">)</span> <span class="token operator">-</span>o $<span class="token punctuation">(</span>CUDA_LINK_OBJ<span class="token punctuation">)</span> $<span class="token punctuation">(</span>CUDA_OBJS<span class="token punctuation">)</span>
 $<span class="token punctuation">(</span>LD<span class="token punctuation">)</span> <span class="token operator">-</span>o $@ $<span class="token punctuation">(</span>OBJS<span class="token punctuation">)</span> $<span class="token punctuation">(</span>CUDA_OBJS<span class="token punctuation">)</span> $<span class="token punctuation">(</span>CUDA_LINK_OBJ<span class="token punctuation">)</span> $<span class="token punctuation">(</span>CUDA_LIB<span class="token punctuation">)</span>
<span class="token operator">%</span><span class="token punctuation">.</span>o <span class="token operator">:</span> <span class="token operator">%</span><span class="token punctuation">.</span>c
 $<span class="token punctuation">(</span>CC<span class="token punctuation">)</span> <span class="token operator">-</span>o $@ <span class="token operator">-</span>c $<span class="token punctuation">(</span>CFLAGS<span class="token punctuation">)</span> $<span class="token punctuation">(</span>INCLUDES<span class="token punctuation">)</span> $<span class="token operator">&lt;</span>
<span class="token operator">%</span><span class="token punctuation">.</span>o <span class="token operator">:</span> <span class="token operator">%</span><span class="token punctuation">.</span>cu
 $<span class="token punctuation">(</span>NVCC<span class="token punctuation">)</span> $<span class="token punctuation">(</span>GPU_CARD<span class="token punctuation">)</span> $<span class="token punctuation">(</span>NVCC_FLAGS<span class="token punctuation">)</span> <span class="token operator">-</span>o $@ <span class="token operator">-</span>c $<span class="token operator">&lt;</span> $<span class="token punctuation">(</span>CUDA_INC<span class="token punctuation">)</span>
clean<span class="token operator">:</span>
 rm <span class="token operator">-</span>f $<span class="token punctuation">(</span>OBJS<span class="token punctuation">)</span> $<span class="token punctuation">(</span>EXEC<span class="token punctuation">)</span> <span class="token operator">*</span><span class="token punctuation">.</span>o a<span class="token punctuation">.</span>out
install<span class="token operator">:</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_10-1-3-3-将cuda文件整合到c项目中" tabindex="-1"><a class="header-anchor" href="#_10-1-3-3-将cuda文件整合到c项目中" aria-hidden="true">#</a> 10.1.3.3 将CUDA文件整合到C项目中</h4><ul><li><p>CUDA提供了两套运行时API接口：<br> ·C++规范接口<br> ·C规范接口</p></li><li><p>当把C代码移植到CUDA中时，需要通过调用CUDA运行时函数来从C函数中准备设备<br> 内存和数据。例如，从a.c文件中调用cudaMalloc函数是必须的。从C代码中调用CUDA运<br> 行时函数，需要在主机代码中包含C运行时头文件，如下所示：<code>#include &lt;cuda_runtime_api.h&gt;</code></p></li><li><p>组织CUDA核函数时，可以像基于C的项目一样，使用独立的文件。然后必须在设备<br> 源文件中创建内核封装函数，使之可以像正常的C函数那样被调用，但却执行CUDA内核<br> 启动。因为设备源文件中声明的主机函数默认C++规范，所以也需要用以下的声明来解决<br> C++引用混乱的问题：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">extern</span> <span class="token string">&quot;C&quot;</span> <span class="token keyword">void</span> <span class="token function">wrapper_kernel_launch</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>关键字extern&quot;C&quot;指示编译器该主机函数名应该是正确的，以便它可以与C代码链接。<br> 图10-4展示了在独立的文件中如何使用C规范组织内核封装函数：<br><img src="`+m+`" alt="figure10-4" loading="lazy"></li></ul><h4 id="_10-1-4-cuda错误处理" tabindex="-1"><a class="header-anchor" href="#_10-1-4-cuda错误处理" aria-hidden="true">#</a> 10.1.4 CUDA错误处理</h4><ul><li><p>错误处理可以说是程序开发中最不迷人却又最重要的一个环节。构建一个程序，在把<br> 应用程序部署到具体生产环境前，确保它经得起各种未设定的错误考验是很必要的。</p></li><li><p>幸运的是，CUDA有一个很方便的检错机制。每一个CUDA API和库调用都会返回一<br> 个错误代码来指示成功或失败的具体细节。这些错误代码有利于从错误中恢复执行，或向<br> 用户显示有用的信息，正如在任何系统级软件开发项目中一样，为了稳定性，需要检查每<br> 一个函数调用的错误代码。</p></li><li><p>CUDA检错机制的一个特性是异步。CUDA函数调用返回的错误代码可能是也可能不<br> 是该特定函数调用执行操作的结果。函数可能返回一个错误信息，这个错误可能是由之前<br> 的任何异步函数调用而引起的，而且该调用仍在执行。这使得给用户提供有用的错误信息<br> 或是从错误中恢复这一过程变得更加复杂。通过定义哪些操作可以并行运行，并准备处理<br> 任何函数中的错误，可以在一定程度上减少这些问题。</p></li><li><p>CUDA提供了3个用于错误检查的函数调用。cudaGetLastError为报告的所有错误都检<br> 查CUDA当前的状态。如果没有错误记录，返回cudaSuccess。如果一旦一个错误被记录，<br> 那么它将返回该错误，并将CUDA的内部状态清理为cudaSuccess。因此，如果多次调用<br> cudaGetLastError返回一个错误代码，那么调用cudaGetLastError的应用程序就能区别这些<br> 不同的错误（虽然它们出错的原因是相关的）。</p></li><li><p>cudaPeekLastError和cudaGetLastError有同样的检测功能，但是它不会将内部的错误状<br> 态变为cudaSuccess。</p></li><li><p>cudaGetErrorString会对CUDA错误返回一个可读的字符串，这对于面向用户的错误处<br> 理是很有用的。</p></li><li><p>你会注意到本书上每一个可以从网站上下载的示例都用到了不同的错误处理办法，最<br> 常见的就是用CHECK或是CALL_CUDA宏来退出错误。</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name function">CHECK</span><span class="token expression"><span class="token punctuation">(</span>call<span class="token punctuation">)</span> <span class="token punctuation">{</span> </span><span class="token punctuation">\\</span>
 <span class="token expression">cudaError_t err<span class="token punctuation">;</span> </span><span class="token punctuation">\\</span>
 <span class="token expression"><span class="token keyword">if</span> <span class="token punctuation">(</span> <span class="token punctuation">(</span>err <span class="token operator">=</span> <span class="token punctuation">(</span>call<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">!=</span> cudaSuccess<span class="token punctuation">)</span> <span class="token punctuation">{</span> </span><span class="token punctuation">\\</span>
 <span class="token expression"><span class="token function">fprintf</span><span class="token punctuation">(</span><span class="token constant">stderr</span><span class="token punctuation">,</span> </span><span class="token string">&quot;Got error %s at %s:%d\\n&quot;</span><span class="token expression"><span class="token punctuation">,</span> <span class="token function">cudaGetErrorString</span><span class="token punctuation">(</span>err<span class="token punctuation">)</span><span class="token punctuation">,</span> </span><span class="token punctuation">\\</span>
 <span class="token expression"><span class="token constant">__FILE__</span><span class="token punctuation">,</span> <span class="token constant">__LINE__</span><span class="token punctuation">)</span><span class="token punctuation">;</span> </span><span class="token punctuation">\\</span>
 <span class="token expression"><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span> </span><span class="token punctuation">\\</span>
 <span class="token expression"><span class="token punctuation">}</span> </span><span class="token punctuation">\\</span>
<span class="token expression"><span class="token punctuation">}</span></span></span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>在许多应用程序中，从CUDA错误中恢复是有可能的，所以在这种情况下立即退出是<br> 没有必要的。</li></ul><h2 id="_10-2-配置文件驱动优化" tabindex="-1"><a class="header-anchor" href="#_10-2-配置文件驱动优化" aria-hidden="true">#</a> 10.2 配置文件驱动优化</h2><ul><li><p>因为对本书中每个例子都用配置文件驱动的方法进行了核函数的优化，所以你对于该<br> 方法一定非常熟悉了。有两种类型的性能分析工具可用于CUDA编程：<br> ·NVIDIA性能分析工具<br> ·第三方性能分析工具</p></li><li><p>大多数开发者选择使用NVIDIA性能分析工具，因为它不仅免费并且功能强大，第三<br> 方性能分析工具利用了NVIDIA性能分析工具的接口。CUDA工具包包含了图形和命令行<br> 性能分析工具。</p></li><li><p>配置文件驱动优化是一个迭代的过程，基于性能分析信息进行程序优化。通常，使用<br> 以下迭代方法：<br> 1.用性能分析工具收集应用程序信息。<br> 2.确定应用程序热点。<br> 3.确定性能抑制因素。<br> 4.优化代码。<br> 5.重复前面的步骤，直到达到所需要的性能。</p></li><li><p>关键步骤是确定性能抑制因素。CUDA性能分析工具会帮助我们找到代码中的性能抑<br> 制因素。对于内核来说最可能的性能抑制因素有以下几个：<br> ·内存带宽<br> ·指令吞吐量<br> ·延迟</p></li><li><p>在前面的章节中，介绍了使用NVIDIA性能分析工具来确定这些抑制因素的方法。本<br> 节简要概括了用可视化性能分析工具和命令行性能分析工具的配置文件驱动优化。</p></li></ul><h3 id="_10-2-1-使用nvprof寻找优化因素" tabindex="-1"><a class="header-anchor" href="#_10-2-1-使用nvprof寻找优化因素" aria-hidden="true">#</a> 10.2.1 使用nvprof寻找优化因素</h3><ul><li>用在CUDA应用程序中的主要性能分析工具是nvprof。简单地说，使用nvprof可以收集<br> 到两种类型的配置文件的数据：<br> ·CPU和GPU上的与CUDA相关的活动时间轴<br> ·核函数的事件和指标</li></ul><h4 id="_10-2-1-1-性能分析模式" tabindex="-1"><a class="header-anchor" href="#_10-2-1-1-性能分析模式" aria-hidden="true">#</a> 10.2.1.1 性能分析模式</h4><ul><li><p>在命令行中使用下述语句调用nvprof：<code>nvprof [nvprof-options] &lt;application&gt; [application-arguments]</code></p></li><li><p>可以在下列4种模式中运行nvprof：<br> ·简易模式（summary mode）<br> ·追踪模式（trace mode）<br> ·事件/指标简易模式（event/metric summary mode）<br> ·事件/指标追踪模式（event/metric trace mode）</p></li><li><p>默认情况下，nvprof运行简易模式。可以使用nvprof-options将其转换成其他模式。例<br> 如，使用下列命令可以启用追踪模式:<br><code>--print-gpu-trace</code><br><code>--print-api-trace</code></p></li><li><p>GPU追踪和API追踪模式可以单独被启用或者同时被启用。GPU追踪模式在GPU上提<br> 供了按时间顺序发生的所有活动的时间轴。API追踪模式在主机上提供了按时间顺序调用<br> 的所有CUDA运行时和驱动API调用的时间轴。</p></li><li><p>可以通过以下选项启动事件/指标简易模式：<br><code>--events &lt;event names&gt; </code><br><code>--metrics &lt;metric names&gt;</code></p></li><li><p>事件/指标简易模式收集在应用程序中发生的不同事件/指标的统计资料。事件是指在<br> 应用程序的执行过程中观察到的硬件计数器。指标是基于事件进行计算的。例如，全局内<br> 存访问的次数和一级缓存的命中次数是由nvprof支持的两个事件。使用这些事件，可以得<br> 出应用程序使用缓存程度的指标。虽然有内置的指标，但也可以根据性能分析工具收集的<br> 硬件计数器来定义自己的指标。使用以下选项，可以查询所有nvprof支持的内置事件和指<br> 标：<br><code>--query-events</code><br><code>--query-metrics</code></p></li><li><p>可以通过以下选项启用事件/指标追踪模式：<code>--aggregate-mode off [events|metrics]</code></p></li><li><p>在事件/指标追踪模式中，事件和指标值显示了每个内核的执行。在默认情况下，事<br> 件和指标值在GPU中跨全部SM进行聚合。</p></li></ul><h4 id="_10-2-1-2-性能分析的范围" tabindex="-1"><a class="header-anchor" href="#_10-2-1-2-性能分析的范围" aria-hidden="true">#</a> 10.2.1.2 性能分析的范围</h4><ul><li><p>默认情况下，nvprof可以分析可见CUDA设备上的所有内核启动。分析范围可由以下<br> 选项限制：<code>--devices &lt;device IDs&gt;</code></p></li><li><p>此代码可用于以下模式/选项：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token operator">--</span>events
<span class="token operator">--</span>metrics
<span class="token operator">--</span>query<span class="token operator">-</span>events
<span class="token operator">--</span>query<span class="token operator">-</span>metrics
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>当与以前的模式/选项结合时，--devices选项用于限制<code>由&lt;device IDs&gt;指定</code>的设备事件/<br> 指标的收集。</li></ul><h4 id="_10-2-1-3-内存带宽" tabindex="-1"><a class="header-anchor" href="#_10-2-1-3-内存带宽" aria-hidden="true">#</a> 10.2.1.3 内存带宽</h4><ul><li><p>内核可以在各种存储类型上运转，主要包括以下几种类型：<br> ·共享内存<br> ·一级/二级缓存<br> ·纹理内存<br> ·设备内存<br> ·系统内存（通过PCIe）</p></li><li><p>使用nvprof可以收集到许多与内存操作相关的事件/指标。使用这些事件/指标，可以<br> 在不同类型的内存上评估内核的效率。在下面的小节中，通过一些典型案例总结了应该收<br> 集哪种事件/指标。</p></li></ul><h4 id="_10-2-1-4-全局内存访问模式" tabindex="-1"><a class="header-anchor" href="#_10-2-1-4-全局内存访问模式" aria-hidden="true">#</a> 10.2.1.4 全局内存访问模式</h4><ul><li><p>在最佳情况下，全局内存访问应该是对齐的并且是合并的。除了对齐和合并之外的任<br> 何访问模式都会导致重新进行内存请求。在内核中可以用以下指标查看全局内存加载和存<br> 储操作的效率：<br><code>gld_efficiency</code><br><code>gst_efficiency</code></p></li><li><p>指标gld_efficiency被定义为请求的全局内存加载吞吐量与需要的全局内存加载吞吐量<br> 的比值。请求的全局内存加载吞吐量不包括内存重新操作，但是需要的全局内存加载吞吐<br> 量包括它。对于全局内存的存储，gst_efficiency和gld_efficiency是一样的。</p></li><li><p>也可以用以下指标来查看全局内存加载和存储效率：<br><code>gld_transactions_per_request</code><br><code>gst_transactions_per_request</code></p></li><li><p>指标gld_transactions_per_request是被每个全局内存加载请求执行的全局内存加载事务<br> 的平均数。指标gst_transactions_per_request是被每个全局内存存储请求执行的全局内存存<br> 储事物的平均数。如果单一的全局加载或存储请求了很多事务，那么设备内存带宽可能就<br> 会被浪费。</p></li><li><p>可以使用以下指标查看内存操作的总数：<br><code>gld_transactions</code><br><code>gst_transactions</code></p></li><li><p>指标gld_transactions是每个内核启动的全局内存加载事务的数量，指标gst_transactions<br> 是每个内核启动的全局内存存储事务的数量。</p></li><li><p>可以通过以下指标查看内存操作的吞吐量：<br><code>gst_throughput</code><br><code>gld_throughput</code></p></li><li><p>指标gst_throughput是全局内存存储吞吐量，指标gld_throughput是全局内存加载吞吐<br> 量。可以将这些测量出的吞吐量与理论峰值进行比较，以确定内核是否接近理想性能，或<br> 者是否还有提升的空间。</p></li></ul><h4 id="_10-2-1-5-共享内存存储体冲突" tabindex="-1"><a class="header-anchor" href="#_10-2-1-5-共享内存存储体冲突" aria-hidden="true">#</a> 10.2.1.5 共享内存存储体冲突</h4><ul><li><p>当使用共享内存时存储体冲突是主要担心的问题。可以使用以下指标来检查应用程序<br> 中是否出现了存储体冲突。<br><code>shared_load_transactions_per_request</code><br><code>shared_store_transactions_per_request</code></p></li><li><p>存储体冲突会导致重新请求内存，任何一个加载或存储的相应值都将大于1。</p></li><li><p>也可以用以下事件直接检查存储体冲突：<code>l1_shared_bank_conflic</code></p></li><li><p>此事件报告了当两个或多个共享内存请求访问同一个内存存储体时共享存储体冲突的<br> 数量。</p></li><li><p>用以下事件收集共享内存加载/存储指令的数量，但不包括重新执行的次数。<br><code>shared_load</code><br><code>shared_store</code></p></li><li><p>然后可以通过以下方法计算每一条指令重新执行的次数：<code>l1_shared_bank_conflict/(shared_load + shared_store)</code></p></li><li><p>也可以用以下指标来查看共享内存的效率<code>shared_efficiency</code></p></li><li><p>指标shared_efficiency被定义为请求的共享内存吞吐量与需要的共享内存吞吐量的比<br> 值。因为需要的共享内存吞吐量包含了重新执行，所以shared_efficiency比值越小，意味着<br> 存储体冲突越多。</p></li></ul><h4 id="_10-2-1-6-寄存器溢出" tabindex="-1"><a class="header-anchor" href="#_10-2-1-6-寄存器溢出" aria-hidden="true">#</a> 10.2.1.6 寄存器溢出</h4><ul><li>当内核使用的寄存器变量多于单个线程允许的最大值（Fermi是63个，Kepler是255<br> 个）时，编译器会把多余的值溢出到本地内存中。溢出到本地内存可能会大大降低内核的<br> 性能。为了评估寄存器溢出的严重程度，首先要收集以下事件：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>l1_local_load_hit
l1_local_load_miss
l1_local_store_hit
l1_local_store_miss
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>然后计算下列比值：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>local_load_hit_ratio <span class="token operator">=</span> l1_local_load_hit <span class="token operator">/</span> <span class="token punctuation">(</span>l1_local_load_hit <span class="token operator">+</span> l1_local_load_miss<span class="token punctuation">)</span>
local_store_hit_ratio <span class="token operator">=</span> l1_local_store_hit <span class="token operator">/</span>
 <span class="token punctuation">(</span>l1_local_store_hit <span class="token operator">+</span> l1_local_store_miss<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>较低的比值表示着严重的寄存器溢出。也可以查看以下指标：<code>l1_cache_local_hit_rate</code></p></li><li><p>这个指标显示了本地加载和存储时一级缓存的命中率。如果执行更多的本地加载和存<br> 储，则意味着产生更多的溢出。</p></li></ul><h4 id="_10-2-1-7-指令吞吐量" tabindex="-1"><a class="header-anchor" href="#_10-2-1-7-指令吞吐量" aria-hidden="true">#</a> 10.2.1.7 指令吞吐量</h4><ul><li><p>指令的吞吐量主要受指令串行化和线程束分化的影响。可以用以下指标查看指令的串行化：<br><code>inst_executed</code><br><code>inst_issued</code></p></li><li><p>指令inst_issued的数量包含了指令的重新执行，inst_executed则没有包括它。可以通过<br> 比较这两个指标来确定重新执行（或串行化）的百分比。</p></li><li><p>线程束分化也通过减少每个线程束中活跃线程的数量来影响指令吞吐量。可以通过以<br> 下指标来查看线程束分化：<code>branch_efficiency</code></p></li><li><p>这个指标定义了非分化分支与总分支的比值。branch_efficiency数值大，则表示较低<br> 的线程束分化。也可以使用以下事件来查看线程束分化：<br><code>branch</code><br><code>divergent_branch</code></p></li><li><p>通过比较这两个指标，可以确定分支分化的百分比。</p></li></ul><h3 id="_10-2-2-使用nvvp指导优化" tabindex="-1"><a class="header-anchor" href="#_10-2-2-使用nvvp指导优化" aria-hidden="true">#</a> 10.2.2 使用nvvp指导优化</h3><ul><li><p>NVIDIA可视化性能分析工具是一个图形工具，有两个特点可以区别于nvprof：<br> ·显示CPU和GPU活动的时间轴<br> ·自动性能分析以帮助确定优化因素</p></li><li><p>NVIDIA可视化性能分析工具可作为一个独立的应用程序，即为nvvp，或作为Nsight<br> Eclipse Edition的一部分，即为一个集成开发环境，在集成GUI环境中允许进行开发、调试<br> 以及优化CUDA应用程序。NVIDIA可视化性能分析工具是一个独立的应用程序，为优化<br> CUDA C/C++应用程序提供跨平台支持。</p></li><li><p>可视化性能分析工具由以下6个视图组成，用于分析并可视化应用程序的性能：<br> ·时间轴视图<br> ·分析视图<br> ·细节视图<br> ·属性视图<br> ·控制台视图<br> ·设置视图</p></li><li><p>时间轴视图，在之前的章节中使用过，用来显示被分析的应用程序中的CPU和GPU活<br> 动。在同一时间可以分析不同的时间轴。每个时间轴由视图的不同示例来表示。当显示多<br> 个时间轴视图时，状态更新对最后操作的时间轴视图是上下文敏感的。图10-5展示了应用<br> 程序的一个时间轴视图。</p></li><li><p>分析视图用于进行性能分析，它有两种分析模式：<br> ·导向分析<br> ·无导向分析<br><img src="`+v+'" alt="figure10-5" loading="lazy"></p></li></ul><h4 id="_10-2-2-1-导向分析" tabindex="-1"><a class="header-anchor" href="#_10-2-2-1-导向分析" aria-hidden="true">#</a> 10.2.2.1 导向分析</h4><ul><li><p>在导向模式中，如图10-6所示，nvvp将一步步引导以对整个应用程序的全面分析。</p></li><li><p>在这种模式中，nvvp将会通过多个分析阶段来帮助我们理解可能的性能限制因素以及<br> 优化因素，包括：<br> ·CUDA应用程序分析<br> ·关键性能的内核<br> ·计算、带宽或延迟范围<br> ·计算资源<br><img src="'+h+'" alt="figure10-6" loading="lazy"></p></li></ul><h4 id="_10-2-2-2-无导向分析" tabindex="-1"><a class="header-anchor" href="#_10-2-2-2-无导向分析" aria-hidden="true">#</a> 10.2.2.2 无导向分析</h4><ul><li><p>在nvvp无导向模式中，如图10-7所示，nvvp展示了应用程序的具体分析项目。在每个<br> 分析项目旁边有一个Run Analysis按钮，它可以用来生成该项目的分析结果。当点击该按<br> 钮时，nvvp将执行应用程序以收集所需要的数据进行性能分析。每个分析结果包含一个简<br> 要的分析说明和一个More链接，该链接指向详细分析文档。<br><img src="'+_+`" alt="figure10-7" loading="lazy"></p></li><li><p>当在时间轴中选择一个内核示例时，额外的特定内核分析项目可以被获得。每个特定<br> 的内核分析项目都有一个和应用程序分析相同操作的Run Analysis按钮。</p></li></ul><h3 id="_10-2-3-nvidia工具扩展" tabindex="-1"><a class="header-anchor" href="#_10-2-3-nvidia工具扩展" aria-hidden="true">#</a> 10.2.3 NVIDIA工具扩展</h3><ul><li><p>NVIDIA提供了一种功能，其允许开发者注释应用程序内的事件、代码范围和资源。<br> 然后使用可视化性能分析工具捕捉和可视化这些事件和代码范围。这个扩展，即NVTX，<br> 有着以C为基础的API，其包含以下两个核心服务：<br> ·追踪CPU事件和代码范围<br> ·OS和CUDA资源命名</p></li><li><p>本节展示了如何使用矩阵和实例整合NVTX库到应用程序中。从Wrox.com上可以下载<br> sumMatrixGPU.cu文件，其中包含该实例，使用nvvp编译并运行，代码如下：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>$ nvcc <span class="token operator">-</span>o sumMatrix sumMatrixGPU<span class="token punctuation">.</span>cu
$ nvvp <span class="token punctuation">.</span><span class="token operator">/</span>sumMatrix
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>图10-8展示了这个简单程序的时间轴。只有和GPU计算或通信相关的事件才被记录在<br> 这个时间轴里。为了在时间轴中显示主机事件，可以使用nvtx API来标记相关的代码范<br> 围，然后nvvp能够为主机事件产生一条时间轴。</p></li><li><p>由sumMatrixGPU.cu开始，包含了以下头文件：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;nvToolsExt.h&gt;</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;nvToolsExtCuda.h&gt;</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;nvToolsExtCudaRt.h&gt;</span></span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>核心NVTX API函数被定义在nvToolsExt.h中。CUDA特有的NVTX接口扩展被定义在<br> nvToolsExtCuda.h和nvToolsExtCudaRt.h中。</p></li><li><p>接下来，在sumMatrixGPU.cu中定义以下新变量，新变量将被用于标记主机代码的范围<br><img src="`+g+`" alt="figure10-8" loading="lazy"></p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>nvtxEventAttributes_t eventAttrib <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token number">0</span><span class="token punctuation">}</span><span class="token punctuation">;</span> 
eventAttrib<span class="token punctuation">.</span>version <span class="token operator">=</span> NVTX_VERSION<span class="token punctuation">;</span> 
eventAttrib<span class="token punctuation">.</span>size <span class="token operator">=</span> NVTX_EVENT_ATTRIB_STRUCT_SIZE<span class="token punctuation">;</span> 
eventAttrib<span class="token punctuation">.</span>colorType <span class="token operator">=</span> NVTX_COLOR_ARGB<span class="token punctuation">;</span> 
eventAttrib<span class="token punctuation">.</span>messageType <span class="token operator">=</span> NVTX_MESSAGE_TYPE_ASCII<span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>例如，如果想要分析并可视化主机内存。首先，像下面这样定义标记名称和标记颜<br> 色：<code>eventAttrib.color = RED; </code><br><code>eventAttrib.message.ascii = &quot;HostMalloc&quot;;</code></p></li><li><p>在分配主机内存之前，先用唯一的标识符变量hostMalloc标记代码范围的开始处：<br><code>nvtxRangeId_t hostMalloc = nvtxRangeStartEx(&amp;eventAttrib);</code></p></li><li><p>分配主机内存后，用相同的标识符标记代码范围的结尾处：<code>nvtxRangeEnd(hostMalloc);</code></p></li><li><p>这个方法可用于标记任何范围的主机代码。如果也想标记sumMatrixGPU中释放内存<br> 的那段代码，只需要按如下方式定义标记名称和标记颜色：<br><code>eventAttrib.color = AQUA; </code><br><code>eventAttrib.message.ascii = &quot;ReleaseResource&quot;;</code></p></li><li><p>释放所有资源前，用唯一的标识符变量releaseResource标记代码范围的开始处：<code>nvtxRangeId_t releaseResource = nvtxRangeStartEx(&amp;eventAttrib);</code></p></li><li><p>分配的内存被释放后，用相同的标识符标记代码范围的结尾处，如下所示：<code>nvtxRangeEnd(releaseResource);</code><br> 在Wrox.com中可以下载sumMatrixGPU_nvToolExt.cu文件，该文件是在sumMatrixGPU.cu文件基础上加了些改动。像下面这样编译文件并链接到扩展工具库中：<br><code>$ nvcc -arch=sm_35 sumMatrixGPU_nvToolsExt.cu -o sumMatrixExt -lnvToolsExt</code></p></li><li><p>然后使用nvvp，就可以生成带有添加事件的自定义时间轴：<code>$ nvvp ./sumMatrixExt</code></p></li><li><p>如图10-9所示，名为Markers and Ranges的新行被添加到时间轴视图中了。所有被标记<br> 的主机端事件现在都会以特定颜色在这一行中被展现出来。<br><img src="`+f+`" alt="figure10-9" loading="lazy"></p></li></ul><h2 id="_10-3-cuda调试" tabindex="-1"><a class="header-anchor" href="#_10-3-cuda调试" aria-hidden="true">#</a> 10.3 CUDA调试</h2><ul><li><p>本节包含了许多专门为CUDA应用程序设计的调试工具和方法。设计这些工具和方法<br> 的目的是让我们可以在代码运行的时候检查应用程序。在本节，代码检查将被分成两个独<br> 立但是相关的部分，分别是内核调试和内存调试。</p></li><li><p>内核调试是指在运行中检查内核执行的流和状态的能力。CUDA调试工具让我们能检<br> 查GPU上任何线程以及任何代码位置的任何变量的状态。在检查应用程序正确性的时候，<br> 这会变得非常有用。</p></li><li><p>内存调试专注于发现程序的怪异行为，如无效的内存访问、对同一内存地址的冲突访<br> 问以及其他具有未定义结果的行为。因为内存调试工具比内核调试工具更加自动化，所以<br> 在用内核调试工具进行更深入的探索前，它们为找出错误或判断应用程序的正确性提供了<br> 快捷的方法。</p></li></ul><h3 id="_10-3-1-内核调试" tabindex="-1"><a class="header-anchor" href="#_10-3-1-内核调试" aria-hidden="true">#</a> 10.3.1 内核调试</h3><ul><li>内核调试是通过检查一个或多个线程的执行和状态来确定内核的正确性。在CUDA里<br> 内核调试有3种主要的方法：cuda-gdb、printf和assert。</li></ul><h4 id="_10-3-1-1-使用cuda-gdb" tabindex="-1"><a class="header-anchor" href="#_10-3-1-1-使用cuda-gdb" aria-hidden="true">#</a> 10.3.1.1 使用cuda-gdb</h4><ul><li><p>如果你已经熟悉了主机调试工具gdb，那么会发现cuda-gdb是一种很自然的延伸。利<br> 用现有的gdb知识，能很快熟练地掌握调试CUDA程序。</p></li><li><p>在用cuda-gdb调试CUDA应用程序之前，必须先用特定标志编译程序。这个过程与用<br> gdb和类似的工具编译用于调试的主机程序是很接近的。只要添加两个标志到nvcc中：-g<br> 和-G：<code>$ nvcc -g -G foo.cu -o foo</code></p></li><li><p>这些标志嵌入到主机和设备代码的调试信息中，并且关闭了大多数优化以确保程序执<br> 行时程序状态能被检查到。只要使用调试标志编译了应用程序，就能像用gdb那样用cuda-gdb启动一个CUDA应用<br> 程序了。给定一个编译和链接应用程序foo，可以通过以下方法将可执行文件传给cudagdb：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>$ cuda<span class="token operator">-</span>gdb foo
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>提示符（cuda-gdb），意味着cuda-gdb加载了来自可执行文件的符号并准备执行。要<br> 想运行该程序，只要输入run命令即可。run命令或者使用set args命令设置后，它可以包含<br> 命令行参数。</p></li><li><p>通常来说，cuda-gdb完全支持gdb提供的很多功能，包括断点、观察点和检查程序状<br> 态的能力等。然而，cuda-gdb还提供CUDA特定的调试功能。接下来的几节将简单总结这<br> 些扩展功能和它们使用的实例。</p></li></ul><h4 id="cuda焦点" tabindex="-1"><a class="header-anchor" href="#cuda焦点" aria-hidden="true">#</a> CUDA焦点</h4><ul><li><p>虽然CUDA程序能包含多个主机线程和许多CUDA线程，但是cuda-gdb调试会话一次<br> 只处理一个线程。为了能在同一应用程序中调试多个设备线程，cuda-gdb提供了一种功<br> 能，即可以指定被检查的上下文（即设备线程）。可以使用cuda-gdb报告当前的焦点信<br> 息，包括当前设备、当前块、当前线程等。</p></li><li><p>例如，如果cuda-gdb调试会话的当前焦点是设备上正在执行的CUDA线程，那么你可<br> 以使用下面的语句检索该焦点的完整说明：<br><code>(cuda-gdb) cuda thread lane warp block sm grid device kernel</code></p></li><li><p>该命令示例输出如下：<br><code>kernel 1026, grid 1027, block (0,0,0), thread (64,0,0), device 0, sm 1, warp 2, lane 0</code></p></li><li><p>可以使用类似的语句将焦点改为不同的设备线程。除了线程属性，还能提供一个特定<br> 的线程，例如，当前块中的第128个线程，用以下语句：<code>(cuda-gdb) cuda thread (128)</code></p></li><li><p>如果没有显式地设置焦点属性，那么cuda-gdb将重新使用当前焦点的属性。</p></li><li><p>使用gdb help命令可以获得CUDA焦点选项的更多信息：<code>(cuda-gdb) help cuda</code></p></li></ul><h4 id="检查cuda内存" tabindex="-1"><a class="header-anchor" href="#检查cuda内存" aria-hidden="true">#</a> 检查CUDA内存</h4><ul><li>与gdb一样，cuda-gdb支持检查变量，在堆（即CUDA全局内存）和寄存器中使用print<br> 语句：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span> print <span class="token function">scalar</span>
<span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span> print arr<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span> <span class="token function">print</span> <span class="token punctuation">(</span><span class="token operator">*</span>arr<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>cuda-gdb还能用于检查CUDA的共享内存。例如，可以用以下命令访问共享内存的第<br> 二个字：<code>(cuda-gdb) print *(@shared int*)0x4</code></p></li><li><p>请注意，因为对于每个SM来说共享内存都是本地的，所以这一语句可能不会对每个<br> 焦点中相同内存单元进行评估：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span> cuda sm
sm <span class="token number">1</span>
<span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span> print <span class="token operator">*</span><span class="token punctuation">(</span>@shared <span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token number">0x4</span>
$<span class="token number">1</span> <span class="token operator">=</span> <span class="token number">0</span>
<span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span> cuda sm <span class="token number">8</span>
<span class="token punctuation">[</span>Switching focus to CUDA kernel <span class="token number">1026</span><span class="token punctuation">,</span> grid <span class="token number">1027</span><span class="token punctuation">,</span> <span class="token function">block</span> <span class="token punctuation">(</span><span class="token number">18</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">thread</span> 
<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> device <span class="token number">0</span><span class="token punctuation">,</span> sm <span class="token number">8</span><span class="token punctuation">,</span> warp <span class="token number">0</span><span class="token punctuation">,</span> lane <span class="token number">0</span><span class="token punctuation">]</span>
<span class="token number">27</span> <span class="token keyword">int</span> tid <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
<span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span> print <span class="token operator">*</span><span class="token punctuation">(</span>@shared <span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token number">0x4</span>
$<span class="token number">2</span> <span class="token operator">=</span> <span class="token number">4</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>因此，使用cuda-gdb能检查任何共享内存数据</li></ul><h4 id="获取环境信息" tabindex="-1"><a class="header-anchor" href="#获取环境信息" aria-hidden="true">#</a> 获取环境信息</h4><ul><li>你能用gdb info命令检索当前CUDA环境和平台的相关信息。可以用以下语句查找完整<br> 的环境信息列表：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span> help info cuda
Print informations about the current CUDA activities<span class="token punctuation">.</span> Available options<span class="token operator">:</span>
 devices <span class="token operator">:</span> information about all the devices
 sms <span class="token operator">:</span> information about all the SMs in the current device
 warps <span class="token operator">:</span> information about all the warps in the current SM
 lanes <span class="token operator">:</span> information about all the lanes in the current warp
 kernels <span class="token operator">:</span> information about all the active kernels
 contexts <span class="token operator">:</span> information about all the contexts
 blocks <span class="token operator">:</span> information about all the active blocks in the current kernel
 threads <span class="token operator">:</span> information about all the active threads in the current kernel
 launch trace <span class="token operator">:</span> information about the parent kernels of the kernel in focus
 launch children <span class="token operator">:</span> information about the kernels launched by the kernels in focus
 managed <span class="token operator">:</span> information about global managed variables
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>为了报告当前系统中所有设备的信息，可以使用info cuda devices子命令。两个Fermi<br> M2090 GPU的系统中其输出如下：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span> info cuda devices
Dev Description SM Type SMs Warps<span class="token operator">/</span>SM Lanes<span class="token operator">/</span>Warp Max Regs<span class="token operator">/</span>Lane Active SMs Mask 
<span class="token operator">*</span> <span class="token number">0</span> GF100GL sm_20 <span class="token number">14</span> <span class="token number">48</span> <span class="token number">32</span> <span class="token number">64</span> <span class="token number">0x00003fff</span> 
 <span class="token number">1</span> GF100GL sm_20 <span class="token number">14</span> <span class="token number">48</span> <span class="token number">32</span> <span class="token number">64</span> <span class="token number">0x00000000</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>请注意，许多子命令复制了本章前面“CUDA焦点”部分已描述过的功能，并且这些子<br> 命令相对于当前cuda-gdb焦点进行操作。然而，更多种类的元数据可通过info cuda子命令<br> 访问到。cuda命令和info cuda子命令都有各自的作用，这取决于要查找的信息的类型和数<br> 量。</li></ul><h4 id="cuda调试可调参数" tabindex="-1"><a class="header-anchor" href="#cuda调试可调参数" aria-hidden="true">#</a> CUDA调试可调参数</h4><ul><li>cuda-gdb通过set子命令展示了许多可调参数，对cuda-gdb行为的调整是非常有用的：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span> help set cuda
Generic command <span class="token keyword">for</span> setting gdb cuda variables
List of set cuda subcommands<span class="token operator">:</span>
set cuda api_failures <span class="token operator">--</span> Set the api_failures to ignore<span class="token operator">/</span>stop<span class="token operator">/</span>hide on CUDA driver 
API call errors
set cuda break_on_launch <span class="token operator">--</span> Automatically set a breakpoint at the entrance of 
kernels
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>表10-1总结了cuda-gdb提供的有用的可调参数。通过使用<code>help set cuda&lt;tunable-name&gt;</code>命<br> 令，可以得到每个参数附加的信息。这些参数能用<code>set cuda&lt;tunable-name&gt;&lt;value&gt;</code>命令进行<br> 设置。对于许多命令，<code>&lt;value&gt;的选择是on/off</code>，但是对于其他一些命令，还可以选择非布<br> 尔值。<br><img src="`+C+'" alt="table10-1" loading="lazy"></p></li><li><p>操作这些cuda-gdb参数能获得更多的cuda-gdb调试会话信息，你可以自定义它的行为<br> 使之符合你的要求。</p></li></ul><h4 id="实践cuda-gdb" tabindex="-1"><a class="header-anchor" href="#实践cuda-gdb" aria-hidden="true">#</a> 实践CUDA-GDB</h4>',76),pn=n("br",null,null,-1),en=n("br",null,null,-1),tn={href:"http://xn--debug-segfault-km79a.cu",target:"_blank",rel:"noopener noreferrer"},on=o(`<div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>$ cuda<span class="token operator">-</span>gdb <span class="token punctuation">.</span><span class="token operator">/</span>debug<span class="token operator">-</span>segfault
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>用run命令启动debug-segfault，它不需要任何命令行参数：<code>(cuda-gdb) run</code></p></li><li><p>执行该命令后很可能会看到许多滚动的文本，它提供了CUDA上下文和内核事件的信<br> 息。最终，当内核中发生内存错误时，调试对话将恢复到提示符（cuda-gdb）。下面的输<br> 出显示了在文件debug-segfault.cu的第34行出现了错误：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>Program received signal CUDA_EXCEPTION_10<span class="token punctuation">,</span> Device Illegal Address<span class="token punctuation">.</span>
<span class="token punctuation">[</span>Switching focus to CUDA kernel <span class="token number">1026</span><span class="token punctuation">,</span> grid <span class="token number">1027</span><span class="token punctuation">,</span> <span class="token function">block</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">thread</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
device <span class="token number">0</span><span class="token punctuation">,</span> sm <span class="token number">1</span><span class="token punctuation">,</span> warp <span class="token number">0</span><span class="token punctuation">,</span> lane <span class="token number">0</span><span class="token punctuation">]</span>
kernel<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token punctuation">(</span>arr<span class="token operator">=</span><span class="token number">0xf00100000</span><span class="token punctuation">)</span> at debug<span class="token operator">-</span>segfault<span class="token punctuation">.</span>cu<span class="token operator">:</span><span class="token number">34</span>
<span class="token number">25</span> arr<span class="token punctuation">[</span>tid<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">foo</span><span class="token punctuation">(</span>tid<span class="token punctuation">,</span> i<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>可以使用list命令来检查上下文周围的代码：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span> list
<span class="token number">28</span> __global__ <span class="token keyword">void</span> <span class="token function">kernel</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token operator">*</span><span class="token operator">*</span>arr<span class="token punctuation">)</span> <span class="token punctuation">{</span>
<span class="token number">29</span> <span class="token keyword">int</span> tid <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
<span class="token number">30</span> <span class="token keyword">int</span> i<span class="token punctuation">;</span>
<span class="token number">31</span>
<span class="token number">32</span> <span class="token keyword">for</span> <span class="token punctuation">(</span> <span class="token punctuation">;</span> tid <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> tid<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
<span class="token number">33</span> <span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> M<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
<span class="token number">34</span> arr<span class="token punctuation">[</span>tid<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">foo</span><span class="token punctuation">(</span>tid<span class="token punctuation">,</span> i<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token number">35</span> <span class="token punctuation">}</span>
<span class="token number">36</span> <span class="token punctuation">}</span>
<span class="token number">37</span> <span class="token punctuation">}</span>
<span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>非法地址访问行是第34行。这一行包含了对input arr的多次间接解引用。通过输出<br><code>arr[tid]</code>中的地址，来测试由偏移量tid引用的数组内容。</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span> print arr<span class="token punctuation">[</span>tid<span class="token punctuation">]</span>
$<span class="token number">1</span> <span class="token operator">=</span> <span class="token punctuation">(</span>@global <span class="token keyword">int</span> <span class="token operator">*</span> @global<span class="token punctuation">)</span> <span class="token number">0x0</span>
<span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>这看起来似乎不太正确，一个空的内存地址不能被解引用。可以尝试解除cuda-gdb调<br> 试会话内部地址的引用，来二次检查问题：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span> print <span class="token operator">*</span>arr<span class="token punctuation">[</span>tid<span class="token punctuation">]</span>
Error<span class="token operator">:</span> Failed to read global memory at address <span class="token number">0x0</span> on device <span class="token number">0</span> sm <span class="token number">1</span> warp <span class="token number">0</span> lane <span class="token number">0</span> 
<span class="token punctuation">(</span>error<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">.</span>
<span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>显然地址是无效的，这就意味着arr中的内容被写入了无效值，或者没有进行合适的<br> 初始化。再看最初的源代码，你应该会发现没有cudaMemcpy真正填满了设备数组<br> d_matrix。在内核启动前加入下面这一行能避免这个内存错误。<br><code>cudaMemcpy(d_matrix, d_ptrs, N * sizeof(int *), cudaMemcpyHostToDevice);</code></p></li><li><p>修正之后的版本可以从Wrox.com下载的debug-segfault.fixed.cu文件中找到。如果你仍<br> 然在那个cuda-gdb调试会话中，那么还可以检查GPU上其他线程的状态。使用cuda命令获<br> 取当前设备、块和线程，代码如下所示：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span> cuda device block thread
<span class="token function">block</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">thread</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> device <span class="token number">0</span>
<span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>试着在一个设备里转换到其他的线程上，并检查不同线程的状态：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span> cuda block <span class="token number">1</span> thread <span class="token number">1</span>
<span class="token punctuation">[</span>Switching focus to CUDA kernel <span class="token number">1026</span><span class="token punctuation">,</span> grid <span class="token number">1027</span><span class="token punctuation">,</span> <span class="token function">block</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">thread</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
device <span class="token number">0</span><span class="token punctuation">,</span> sm <span class="token number">5</span><span class="token punctuation">,</span> warp <span class="token number">0</span><span class="token punctuation">,</span> lane <span class="token number">1</span><span class="token punctuation">]</span>
<span class="token number">25</span> arr<span class="token punctuation">[</span>tid<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">foo</span><span class="token punctuation">(</span>tid<span class="token punctuation">,</span> i<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span> print tid
$<span class="token number">2</span> <span class="token operator">=</span> <span class="token number">257</span>
<span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span> print arr<span class="token punctuation">[</span>tid<span class="token punctuation">]</span>
$<span class="token number">3</span> <span class="token operator">=</span> <span class="token punctuation">(</span>@global <span class="token keyword">int</span> <span class="token operator">*</span> @global<span class="token punctuation">)</span> <span class="token number">0x0</span>
<span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span>  
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>显然有许多线程都存在内存错误。焦点很容易放在具有最低逻辑ID的线程中。</p></li><li><p>输入quit和y可以退出cuda-gdb会话：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token punctuation">(</span>cuda<span class="token operator">-</span>gdb<span class="token punctuation">)</span> quit
A debugging session is active<span class="token punctuation">.</span>
 Inferior <span class="token number">1</span> <span class="token punctuation">[</span>process <span class="token number">11330</span><span class="token punctuation">]</span> will be killed<span class="token punctuation">.</span>
Quit anyway<span class="token operator">?</span> <span class="token punctuation">(</span>y <span class="token operator">or</span> n<span class="token punctuation">)</span> y
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="有关cuda-gdb的总结" tabindex="-1"><a class="header-anchor" href="#有关cuda-gdb的总结" aria-hidden="true">#</a> 有关CUDA-GDB的总结</h4><ul><li>本小节简单介绍了用于检查内核执行的cuda-gdb调试工具的使用。cuda-gdb的用法和<br> gdb很像，因此，当熟练调试基于CUDA的应用程序时，前面所有和主机调试工具相关的<br> 经验都能用到。想获得更多关于cuda-gdb的详细信息，可以阅读CUDA Toolkit里的CUDAGDB在线文档。</li></ul><h4 id="_10-3-1-2-uda的printf" tabindex="-1"><a class="header-anchor" href="#_10-3-1-2-uda的printf" aria-hidden="true">#</a> 10.3.1.2 UDA的printf</h4><ul><li><p>在主机调试时，可能会经常用到printf输出主机应用程序的状态。如果能在GPU设备<br> 代码中使用printf来简单检查内部设备的状态那就太好了。但是，内核在有着上千个线程<br> 的设备上运行着，要整理这些内核的输出是一个很有趣的挑战。从CUDA 4.0开始，<br> NVIDIA在设备上支持printf功能。基于CUDA的printf接口，与我们在主机上C/C++研发中<br> 习惯使用的一样（甚至有着相同的头文件，stdio.h），这使得我们能直接过渡到基于<br> CUDA的printf中。</p></li><li><p>这里有一些基于CUDA的printf语句使用的说明。首先，它只能在计算能力是2.0或更<br> 高的版本中实现。第二，除非显式使用CUDA同步，否则在线程间没有输出顺序。第三，<br> 在内核上将执行的printf输出返回到主机显示前，需要使用一个固定大小的循环设备缓冲<br> 区临时存储该输出。因此，如果产生输出的速度比显示输出的速度快，那么缓冲区就会覆<br> 盖掉原有的输出。这个缓冲区的大小可以用cudaGetDeviceLimit检索，并用cudaSetDeviceLimit进行设置。</p></li><li><p>以下常见事件会导致固定大小的缓冲区转回到主机以用于显示：<br> 1.任何CUDA内核启动。<br> 2.用CUDA主机API的任何同步（例如，cudaDeviceSynchronize、cudaStreamSynchronize、cudaEventSynchronize等）。<br> 3.任何同步内存复制，如cudaMemcpy。</p></li><li><p>否则，在CUDA内核中使用printf和在主机C/C++程序中使用的printf一样：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">kernel</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token keyword">int</span> tid <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">&quot;Hello from CUDA thread %d\\n&quot;</span><span class="token punctuation">,</span> tid<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>这为快速调试内核提供了一个可用且友好的方法。但是，谨防过多地使用printf。可<br> 以使用线程和块索引来限制输出调试信息的线程，以避免过多地输出线程，导致调试信息<br> 缓冲区超载。</li></ul><h4 id="_10-3-1-3-cuda的assert工具" tabindex="-1"><a class="header-anchor" href="#_10-3-1-3-cuda的assert工具" aria-hidden="true">#</a> 10.3.1.3 CUDA的assert工具</h4><ul><li><p>另一个常见的主机错误检查工具是assert。assert能让我们声明某一的条件，在程序正<br> 确执行时该条件必须为真。如果assert失败，则应用程序执行有以下两种情况中的一种：<br> 1）有assert失败的消息时，立即中止；2）如果在cuda-gdb会话中运行，控制将会传到<br> cuda-gdb，以便可以在assert失败的位置检查应用程序的状态。和printf一样，只有GPU计算<br> 能力为2.0及以上时才提供assert功能。它依赖和主机相同的头文件，assert.h。</p></li><li><p>在GPU中使用assert与在主机上使用assert有一点不同。一旦设备上有失败的assert（即<br> 任何包含表达式的计算结果为0的assert），就会有一个CUDA线程将在存储失败的assert信<br> 息后立即退出。但是，这个信息只会显示到主机上下一个CUDA同步点的stderr中（例如，<br> cudaDeviceSynchronize、cudaStreamSynchronize等）。这意味着在每一个同步点上，信息将<br> 显示自上一个同步点开始有失败assert的线程。如果在检测到第一个assert失败后，使用任<br> 何CUDA主机API调用，那么应用程序都将返回CUDA错误代码cudaErrorAssert。</p></li><li><p>和printf一样，在内核里使用assert就和在主机里一样，如下所示：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">kernel</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token keyword">int</span> <span class="token operator">*</span>ptr <span class="token operator">=</span> <span class="token constant">NULL</span><span class="token punctuation">;</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
 <span class="token function">assert</span><span class="token punctuation">(</span>ptr <span class="token operator">!=</span> <span class="token constant">NULL</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token operator">*</span>ptr <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>与主机的assert一样，通过使用在包含assert.h头文件前定义的NDEBUG预处理器宏编<br> 译，可以对代码发行版本禁用assert评估。</li></ul><h4 id="_10-3-1-4-内核调试总结" tabindex="-1"><a class="header-anchor" href="#_10-3-1-4-内核调试总结" aria-hidden="true">#</a> 10.3.1.4 内核调试总结</h4><ul><li><p>本小节的重点是CUDA里的内核调试工具。cuda-gdb、printf和assert都是很有用的工<br> 具，它们能实现细粒度调试，并对运行的CUDA内核进行错误检查。每一个工具都有各自<br> 的优点和缺点。</p></li><li><p>cuda-gdb是最有用的，能控制GPU中的内核执行，同时可以交互式检查整个内核中线<br> 程的状态。因此，cuda-gdb要求有大量的手动作业，且对应用程序的性能影响很大。</p></li><li><p>虽然printf并不是交互式的，但它允许你有选择性地输出CUDA线程中的调试信息，以<br> 快速检查出代码中的错误。</p></li><li><p>在调试过程中出现已知问题或退化时，尤其是和cuda-gdb一起使用的时候，assert对于<br> 检查应用程序状态是十分有用的。但是，在调试一个新的未知问题时很难高效地使用它。</p></li><li><p>下一部分将焦点由直接调试内核转移到使用内核内存访问错误以帮助精确查找问题。</p></li></ul><h3 id="_10-3-2-内存调试" tabindex="-1"><a class="header-anchor" href="#_10-3-2-内存调试" aria-hidden="true">#</a> 10.3.2 内存调试</h3><ul><li><p>cuda-gdb对CUDA内核执行进行细粒度检查是很有效的，虽然printf/assert对于大量的<br> 错误检测来说是简单的机制，但是用于调试CUDA内存错误的主要工具是cuda-memcheck。<br> cuda-memcheck的操作在用户交互方面更加自动化和粗粒度，但是对于CUDA内核中的内存<br> 错误，cuda-memcheck提供了更详细的数据。cuda-memcheck包含两个独立的工具：<br> ·memcheck工具<br> ·racecheck工具</p></li><li><p>memcheck工具用于检查CUDA内核中越界和未对齐的访问。racecheck工具用于检查共<br> 享内存的冲突访问，这些冲突访问会导致未定义的行为。这些工具用于调试不稳定内核行<br> 为是非常有用的，这些行为是因为线程读取或写入到意外的位置而引起的。</p></li></ul><h4 id="_10-3-2-1-cuda-memcheck的编译" tabindex="-1"><a class="header-anchor" href="#_10-3-2-1-cuda-memcheck的编译" aria-hidden="true">#</a> 10.3.2.1 cuda-memcheck的编译</h4><ul><li><p>使用cuda-memcheck编译应用程序比使用cuda-gdb更为复杂。当使用-g-G建立应用程序<br> 后，这些选项会对性能起负面影响。当使用cuda-memcheck工具时，很重要的是，为保证<br> 错误可复写，应用程序的性能必须稳定。但是，一些编译标志对仔细分析cuda-memcheck<br> 信息和准确找到问题发生的位置是必需的。</p></li><li><p>有一些可用的编译选项对性能影响很小，但却能彻底提升cuda-memcheck信息的可读<br> 性。首先，应该使用-lineinfo选项进行编译。这个标志把信息嵌入到可执行文件中，该可<br> 执行文件使用设备指令将文件名和行号联系起来。可执行文件应该总是使用符号信息进行<br> 编译。这可以使cuda-memcheck输出主机的堆栈踪迹，这些堆栈踪迹可以准确地找出内核<br> 的启动位置。包含符号信息的编译标志是平台特有的，它使用nvcc中的-Xcompiler选项将<br> 参数传递到主机编译器中。例如，在带有gcc的Linux系统中，会用到-Xcompiler-rdynamic；在Windows系统中，会用到-Xcompiler/Zi。</p></li><li><p>当使用这些编译标志时，会生成一个可执行文件，它包含了足够多的用于显示memcheck和racecheck帮助信息的元数据，<br> 这会使其性能特性与原始的应用程序非常接近。</p></li></ul><h4 id="_10-3-2-2-memcheck工具" tabindex="-1"><a class="header-anchor" href="#_10-3-2-2-memcheck工具" aria-hidden="true">#</a> 10.3.2.2 memcheck工具</h4><ul><li><p>memcheck工具可以检查6种类型的错误：<br> ·内存访问错误：对全局内存、本地内存或共享内存的越界或未对齐访问。未对齐的<br> 原子操作会触发内存访问错误，但是这只有当引用全局内存时才会发生。<br> ·硬件异常：硬件报告错误。参考CUDAMEMCHECK指南的附录B（包括在CUDA工具<br> 包文件中），其中包括每一个可能的硬件错误的详细信息。<br> ·malloc/free错误：使用CUDA内核里的CUDA动态内存分配时，memcheck能找到<br> malloc和free API调用的非正常使用。<br> ·CUDA API错误：任何由CUDA API调用返回的错误代码。<br> ·cudaMalloc内存泄漏：任何被应用程序使用cudaMalloc的内存分配，在执行完成前没<br> 有被释放。<br> ·设备堆内存泄漏：使用CUDA内核中的CUDA动态内存分配时，memcheck会找到未释<br> 放的分配。</p></li><li><p>因为用cuda-gdb调试的debug-segfault程序显示了内存访问错误，所以可以对来自于<br> memcheck工具的诊断信息和来自cuda-gdb的诊断信息进行比较。</p></li><li><p>假设想检查一个名为app的应用程序的内存错误。app能正确编译以维持性能，但仍会<br> 报告堆栈和行信息，memcheck能用以下语句调用：<code>$ cuda-memcheck [memcheck_options] app [app_options]</code></p></li><li><p>在debug-segfault上使用默认的选项运行memcheck会产生下面的输出：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>$ nvcc <span class="token operator">-</span>lineinfo <span class="token operator">-</span>Xcompiler <span class="token operator">-</span>rdynamic <span class="token operator">-</span>o debug<span class="token operator">-</span>segfault debug<span class="token operator">-</span>segfault<span class="token punctuation">.</span>cu
$ cuda<span class="token operator">-</span>memcheck <span class="token punctuation">.</span><span class="token operator">/</span>debug<span class="token operator">-</span>segfault
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> CUDA<span class="token operator">-</span>MEMCHECK
Got error unspecified launch failure at debug<span class="token operator">-</span>segfault<span class="token punctuation">.</span>cu<span class="token operator">:</span><span class="token number">52</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Invalid __global__ write of size <span class="token number">4</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> at <span class="token number">0x00000078</span> in debug<span class="token operator">-</span>segfault<span class="token punctuation">.</span>cu<span class="token operator">:</span><span class="token number">25</span><span class="token operator">:</span><span class="token function">kernel</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> by <span class="token function">thread</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span> in <span class="token function">block</span> <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Address <span class="token number">0x00000000</span> is out of bounds
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Saved host backtrace up to driver entry point at kernel launch time
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Host Frame<span class="token operator">:</span><span class="token operator">/</span>opt<span class="token operator">/</span>apps<span class="token operator">/</span>cuda<span class="token operator">/</span>driver<span class="token operator">/</span>lib64<span class="token operator">/</span>libcuda<span class="token punctuation">.</span><span class="token function">so</span> <span class="token punctuation">(</span>cuLaunchKernel <span class="token operator">+</span>
 <span class="token number">0x3dc</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token number">0xc9edc</span><span class="token punctuation">]</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Host Frame<span class="token operator">:</span><span class="token operator">/</span>opt<span class="token operator">/</span>apps<span class="token operator">/</span>cuda<span class="token operator">/</span><span class="token number">5.0</span><span class="token punctuation">.</span><span class="token number">35</span><span class="token operator">/</span>lib64<span class="token operator">/</span>libcudart<span class="token punctuation">.</span>so<span class="token punctuation">.</span><span class="token number">5.0</span> <span class="token punctuation">[</span><span class="token number">0x11d54</span><span class="token punctuation">]</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Host Frame<span class="token operator">:</span><span class="token operator">/</span>opt<span class="token operator">/</span>apps<span class="token operator">/</span>cuda<span class="token operator">/</span><span class="token number">5.0</span><span class="token punctuation">.</span><span class="token number">35</span><span class="token operator">/</span>lib64<span class="token operator">/</span>libcudart<span class="token punctuation">.</span>so<span class="token punctuation">.</span><span class="token number">5.0</span> <span class="token punctuation">(</span>cudaLaunch <span class="token operator">+</span>
 <span class="token number">0x182</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token number">0x38152</span><span class="token punctuation">]</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Host Frame<span class="token operator">:</span>debug<span class="token operator">-</span><span class="token function">segfault</span> <span class="token punctuation">(</span>_Z10cudaLaunchIcE9cudaErrorPT_ <span class="token operator">+</span> <span class="token number">0x18</span><span class="token punctuation">)</span>
 <span class="token punctuation">[</span><span class="token number">0x138c</span><span class="token punctuation">]</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Host Frame<span class="token operator">:</span>debug<span class="token operator">-</span><span class="token function">segfault</span> <span class="token punctuation">(</span>_Z26__device_stub__Z6kernelPPiPPi <span class="token operator">+</span> <span class="token number">0x44</span><span class="token punctuation">)</span>
 <span class="token punctuation">[</span><span class="token number">0x127c</span><span class="token punctuation">]</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Host Frame<span class="token operator">:</span>debug<span class="token operator">-</span><span class="token function">segfault</span> <span class="token punctuation">(</span>_Z6kernelPPi <span class="token operator">+</span> <span class="token number">0x18</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token number">0x1299</span><span class="token punctuation">]</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Host Frame<span class="token operator">:</span>debug<span class="token operator">-</span><span class="token function">segfault</span> <span class="token punctuation">(</span>main <span class="token operator">+</span> <span class="token number">0x277</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token number">0x109a</span><span class="token punctuation">]</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Host Frame<span class="token operator">:</span><span class="token operator">/</span>lib64<span class="token operator">/</span>libc<span class="token punctuation">.</span>so<span class="token punctuation">.</span><span class="token number">6</span> <span class="token punctuation">(</span>__libc_start_main <span class="token operator">+</span> <span class="token number">0xfd</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token number">0x1ecdd</span><span class="token punctuation">]</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Host Frame<span class="token operator">:</span>debug<span class="token operator">-</span>segfault <span class="token punctuation">[</span><span class="token number">0xd49</span><span class="token punctuation">]</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Program hit error <span class="token number">4</span> on CUDA API call to cudaMemcpy 
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Saved host backtrace up to driver entry point at error
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Host Frame<span class="token operator">:</span><span class="token operator">/</span>opt<span class="token operator">/</span>apps<span class="token operator">/</span>cuda<span class="token operator">/</span>driver<span class="token operator">/</span>lib64<span class="token operator">/</span>libcuda<span class="token punctuation">.</span>so <span class="token punctuation">[</span><span class="token number">0x26a180</span><span class="token punctuation">]</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Host Frame<span class="token operator">:</span><span class="token operator">/</span>opt<span class="token operator">/</span>apps<span class="token operator">/</span>cuda<span class="token operator">/</span><span class="token number">5.0</span><span class="token punctuation">.</span><span class="token number">35</span><span class="token operator">/</span>lib64<span class="token operator">/</span>libcudart<span class="token punctuation">.</span>so<span class="token punctuation">.</span><span class="token number">5.0</span> <span class="token punctuation">(</span>cudaMemcpy <span class="token operator">+</span>
 <span class="token number">0x28c</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token number">0x3305c</span><span class="token punctuation">]</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Host Frame<span class="token operator">:</span>debug<span class="token operator">-</span><span class="token function">segfault</span> <span class="token punctuation">(</span>main <span class="token operator">+</span> <span class="token number">0x2b8</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token number">0x10db</span><span class="token punctuation">]</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Host Frame<span class="token operator">:</span><span class="token operator">/</span>lib64<span class="token operator">/</span>libc<span class="token punctuation">.</span>so<span class="token punctuation">.</span><span class="token number">6</span> <span class="token punctuation">(</span>__libc_start_main <span class="token operator">+</span> <span class="token number">0xfd</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token number">0x1ecdd</span><span class="token punctuation">]</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Host Frame<span class="token operator">:</span>debug<span class="token operator">-</span>segfault <span class="token punctuation">[</span><span class="token number">0xd49</span><span class="token punctuation">]</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> ERROR SUMMARY<span class="token operator">:</span> <span class="token number">2</span> errors
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>memcheck工具不仅在debug-segfault.cu的第25行指出了一个无效的内存访问，还提供了<br> 无效访问的方向（写）、<code>被写入（__global__）的内存空间</code>、写入的大小（4字节）、执行<br> 写操作的线程以及造成无效引用的具体地址。相比于cuda-gdb，memcheck工具需要的手动<br> 工作较少，而且为debug-segfault提供了更详细和精确的内存错误信息。</p></li><li><p>你可能注意到memcheck也报告了第二次错误，调用cudaMemcpy返回的是CUDA错误<br> 4。回想可知，memcheck处理的错误类型之一是由CUDA API调用返回的错误代码。参考<br> cuda.h，CUDA错误4是CUDA_ERROR_DEINITIALIZED，这表明CUDA驱动器处于关闭过<br> 程中。这个错误可能是由于之前的内存访问错误引起的：该驱动器正在从意外的设备行为<br> 中恢复过来。</p></li></ul><h4 id="_10-3-2-3-racecheck工具" tabindex="-1"><a class="header-anchor" href="#_10-3-2-3-racecheck工具" aria-hidden="true">#</a> 10.3.2.3 racecheck工具</h4>`,36),cn=o("<li><p>racecheck用于识别共享内存中存储数据的冲突访问（一般被称为冲突）。另一方面，<br> racecheck在同一线程块中寻找多个线程，这些线程块引用共享内存中的同一位置，这些共<br> 享内存是不同步的，这些引用中至少有一个引用对这个位置进行写操作。调试共享内存的<br> 正确性是非常重要的，理由如下：<br> 首先，因为共享内存在片上的且被一个线程块共享，所以它常被用作多线程间的低<br> 延迟通信通道。如果不合理地同步那些多线程访问，那么就可能发生冲突。因此，需要一<br> 个工具来处理这种常见情况，因为共享内存更容易被误用，导致冲突访问。<br> ·第二，共享内存的正确性不能直接通过主机的应用程序来检查。全局内存的调试被<br> 简化了，因为主机有立即检查全局状态的能力，但共享内存不存在这样的直接通道。支持<br> 这种性能首先需要将这种状态传输到全局内存，然后再返回主机。racecheck工具帮我们做<br> 了这些事。</p></li><li><p>考虑一个简单的且使用共享内存和本地同步的单一线程块的并行归约问题。为了研究<br> racecheck的效果，下面的例子去掉了本地同步，因此在冲突访问存在时可以观察到由racecheck产生的诊断。<br> 从Wrox.com上可以下载到源代码到debug-hazards.cu中。</p></li>",2),ln={href:"http://xn--debug-hazards-ol3v786kkv3ed3em28ba1745d2ka2qb544vipbd69hqfg.cu",target:"_blank",rel:"noopener noreferrer"},rn=n("code",null,"$ nvcc -arch=sm_20 -lineinfo -Xcompiler –rdynamic –o debug-hazards debug-hazards.cu",-1),un=n("li",null,[n("p",null,[a("在运行debug-hazards前，要知道racecheck在应用程序执行中会生成一个大的被后处理"),n("br"),a(" 的转储文件。racecheck也会在命令行的终端生成一个详细的报告，所以为了以后分析可以"),n("br"),a(" 将终端输出保存成文件。该例子使用--save CLI参数将转储文件的位置设置在有几百MB可"),n("br"),a(" 用磁盘空间的地方。对于较大的应用程序，转储文件将占用更多的磁盘空间。这个例子将"),n("br"),a(" 终端输出转向日志文件，用于以后的检查。")])],-1),dn=n("li",null,[n("p",null,[a("现在，可以使用以下命令运行racecheck，分析debug-hazards："),n("code",null,"$ cuda-memcheck --tool racecheck --save racecheck.dump ./debug-hazards > log")])],-1),kn=n("li",null,[n("p",null,"检查日志文件，将看到很多重复的部分，类似于以下代码：")],-1),bn=o(`<div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> WARN<span class="token operator">:</span><span class="token punctuation">(</span>Warp Level Programming<span class="token punctuation">)</span> Potential RAW hazard detected at __shared__ 
<span class="token number">0x7f</span> in <span class="token function">block</span> <span class="token punctuation">(</span><span class="token number">63</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">:</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Write <span class="token function">Thread</span> <span class="token punctuation">(</span><span class="token number">31</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span> at <span class="token number">0x000000c8</span> in debug<span class="token operator">-</span>hazards<span class="token punctuation">.</span>cu<span class="token operator">:</span><span class="token number">50</span><span class="token operator">:</span>simple_
<span class="token function">reduction</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">)</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Read <span class="token function">Thread</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span> at <span class="token number">0x00000128</span> in debug<span class="token operator">-</span>hazards<span class="token punctuation">.</span>cu<span class="token operator">:</span><span class="token number">66</span><span class="token operator">:</span>simple_
<span class="token function">reduction</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">)</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Current Value <span class="token operator">:</span> <span class="token number">0</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Saved host backtrace up to driver entry point at kernel launch time
<span class="token number">460</span> ❘ CHAPTER <span class="token number">10</span> IMPLEMENTATION CONSIDERATIONS
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Host Frame<span class="token operator">:</span><span class="token operator">/</span>opt<span class="token operator">/</span>apps<span class="token operator">/</span>cuda<span class="token operator">/</span>driver<span class="token operator">/</span>lib64<span class="token operator">/</span>libcuda<span class="token punctuation">.</span><span class="token function">so</span> <span class="token punctuation">(</span>cuLaunchKernel <span class="token operator">+</span> 
<span class="token number">0x3dc</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token number">0xc9edc</span><span class="token punctuation">]</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Host Frame<span class="token operator">:</span><span class="token operator">/</span>opt<span class="token operator">/</span>apps<span class="token operator">/</span>cuda<span class="token operator">/</span><span class="token number">5.0</span><span class="token punctuation">.</span><span class="token number">35</span><span class="token operator">/</span>lib64<span class="token operator">/</span>libcudart<span class="token punctuation">.</span>so<span class="token punctuation">.</span><span class="token number">5.0</span> <span class="token punctuation">[</span><span class="token number">0x11d54</span><span class="token punctuation">]</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Host Frame<span class="token operator">:</span><span class="token operator">/</span>opt<span class="token operator">/</span>apps<span class="token operator">/</span>cuda<span class="token operator">/</span><span class="token number">5.0</span><span class="token punctuation">.</span><span class="token number">35</span><span class="token operator">/</span>lib64<span class="token operator">/</span>libcudart<span class="token punctuation">.</span>so<span class="token punctuation">.</span><span class="token number">5.0</span> <span class="token punctuation">(</span>cudaLaunch <span class="token operator">+</span> 
<span class="token number">0x182</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token number">0x38152</span><span class="token punctuation">]</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Host Frame<span class="token operator">:</span><span class="token punctuation">.</span><span class="token operator">/</span>debug<span class="token operator">-</span><span class="token function">hazards</span> <span class="token punctuation">(</span>_Z10cudaLaunchIcE9cudaErrorPT_ <span class="token operator">+</span> <span class="token number">0x18</span><span class="token punctuation">)</span> 
<span class="token punctuation">[</span><span class="token number">0x1490</span><span class="token punctuation">]</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Host Frame<span class="token operator">:</span><span class="token punctuation">.</span><span class="token operator">/</span>debug<span class="token operator">-</span><span class="token function">hazards</span> 
<span class="token punctuation">(</span>_Z40__device_stub__Z16simple_reductionPiS_iiPiS_ii <span class="token operator">+</span> <span class="token number">0xab</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token number">0x135a</span><span class="token punctuation">]</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Host Frame<span class="token operator">:</span><span class="token punctuation">.</span><span class="token operator">/</span>debug<span class="token operator">-</span><span class="token function">hazards</span> <span class="token punctuation">(</span>_Z16simple_reductionPiS_ii <span class="token operator">+</span> <span class="token number">0x30</span><span class="token punctuation">)</span> 
<span class="token punctuation">[</span><span class="token number">0x1398</span><span class="token punctuation">]</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Host Frame<span class="token operator">:</span><span class="token punctuation">.</span><span class="token operator">/</span>debug<span class="token operator">-</span><span class="token function">hazards</span> <span class="token punctuation">(</span>main <span class="token operator">+</span> <span class="token number">0x2c2</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token number">0x1142</span><span class="token punctuation">]</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Host Frame<span class="token operator">:</span><span class="token operator">/</span>lib64<span class="token operator">/</span>libc<span class="token punctuation">.</span>so<span class="token punctuation">.</span><span class="token number">6</span> <span class="token punctuation">(</span>__libc_start_main <span class="token operator">+</span> <span class="token number">0xfd</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token number">0x1ecdd</span><span class="token punctuation">]</span>
<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> Host Frame<span class="token operator">:</span><span class="token punctuation">.</span><span class="token operator">/</span>debug<span class="token operator">-</span>hazards <span class="token punctuation">[</span><span class="token number">0xd99</span><span class="token punctuation">]</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>从第一行开始看：这一行表明了3个重要的事情。首先，检测到一个潜在的冲突！这是否是一个好的<br> （或可怕的）开始，取决于你的看法。<br><code>========= WARN:(Warp Level Programming) Potential RAW hazard detected at __shared__ 0x7f in block (63, 0, 0) :</code></p></li><li><p>第二，这一行报告了一个Read-After-Write（RAW）冲突。这意味着两个线程没有按<br> 照任何顺序访问了相同地址，一个执行读操作，一个执行写操作。因为没有顺序，所以读<br> 线程应该在写线程之前还是之后加载数值是未定义的。这个未定义行为是不可取的，因此<br> 造成了冲突。</p></li><li><p>第三，这一行指出了哪个线程块存在冲突（共享内存上的风险只能发生在单一线程块<br> 上）。这个信息是否有用取决于应用程序。因为这个应用程序的每个块都在做相同的工<br> 作，它可能对调试没有什么帮助。</p></li><li><p>现在，看下一行：<br><code>========= Write Thread (31, 0, 0) at 0x000000c8 in debug-hazards.cu:50:simple_ reduction(int*, int*, int, int)</code></p></li><li><p>这一行提供了线程上的信息，这个线程在RAW风险中执行写操作。它指出了线程<br> ID（31，0，0）、正在执行的指令地址（0xc8）和正在执行的源代码行。</p></li><li><p>下一行在读线程上提供了相同的信息：</p></li><li><p><mark>后面再补充吧</mark></p></li></ul><h3 id="_10-3-3-调试小结" tabindex="-1"><a class="header-anchor" href="#_10-3-3-调试小结" aria-hidden="true">#</a> 10.3.3 调试小结</h3><ul><li><p>本章简要介绍了CUDA中内核和内存调试工具的常见用法。</p></li><li><p>测试cuda-gdb的能力用于检查GPU设备上运行程序的状态、动态暂停和恢复线程以检<br> 查正确性。用一个例子展示了如何用cuda-gdb来调试内存错误。</p></li><li><p>还能测试cuda-memcheck的内存调试特性，以及它的两个工具：memcheck和racecheck。<br> memcheck能够提供详细的内存错误信息，例如，越界访问、空指针引用、设备内<br> 存泄漏等。racecheck可以提供共享内存中详细的潜在冲突指标，这使调试疑难问题变得更<br> 简单了。</p></li><li><p>调试一个基于CUDA的应用程序涉及到几个检查，包括在独立地址空间上运行的进<br> 程、在物理分离的硬件上和在独立于任何操作系统之外的检查。虽然这是具有挑战性的，<br> 但是本章介绍的工具使得调试CUDA程序就像调试主机程序一样简单。使用这些工具对成<br> 为一个高效的CUDA开发者是至关重要的，尤其是开始探索更高级的话题时。</p></li></ul><h2 id="_10-4-将c程序移植到cudac的案例研究" tabindex="-1"><a class="header-anchor" href="#_10-4-将c程序移植到cudac的案例研究" aria-hidden="true">#</a> 10.4 将C程序移植到CUDAC的案例研究</h2><ul><li><p>本章的前面部分介绍了APOD工作流，并描述了它如何将传统的主机应用程序转到<br> CUDA中。本节将通过列举一个例子具体说明这些概念，即讲一个传统的应用程序通过<br> APOD全过程最终转化为优化的CUDA应用程序的例子。</p></li><li><p>从Wrox.com上可以下载到这个传统应用程序的代码，名为crypt.c。crypt实现了IDEA<br> 加密和解密。crypt应用程序由3个主要部分组成：<br> 1.应用程序设置在main中。设置包括读取输入、预分配输出空间和读取密钥，密钥是<br> 一个二进制串，消息的发送者和接收者都必须知道该密钥以成功加密或解密信息。<br> 2.加密和解密输入信息的关键是使用generateEncryptKey和generateDecryptKey产生共享密钥。<br> 3.实际上输入数据的加密和解密是encrypt_decrypt中的8字节块完成的。</p></li><li><p>crypt最初输入的是文件，该文件既不是加密文件也不是解密文件。此外，crypt需要一<br> 个密钥文件，用于存储加密或解密输入数据的64位密钥。Wrox.com提供了产生示例输入<br> 数据（generate_data.c）和密钥（generate_userkey.c）的文件。图10-10通过crypt应用程序概<br> 述了高级数据流。花一点时间来熟悉crypt.c的执行情况。<br><img src="`+A+`" alt="figure10-10" loading="lazy"></p></li></ul><h3 id="_10-4-1-评估crypt" tabindex="-1"><a class="header-anchor" href="#_10-4-1-评估crypt" aria-hidden="true">#</a> 10.4.1 评估crypt</h3><ul><li><p>用来评估主机应用程序性能的工具有很多。在下面的示例中会使用gprof，因为它使<br> 用范围非常广、免费并且提供了低开销的性能分析。</p></li><li><p>在评估crypt之前，需要生成样本密钥和1GB的样本数据，代码如下所示：<br><code>$ ./generate_userkey key</code><br><code>$ ./generate_data data 1073741824</code></p></li><li><p>使用提供的Makefile文件进行编译crypt后，通过gprof运行它，生成以下性能信息：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token operator">%</span> cumulative self self total
 time seconds seconds calls s<span class="token operator">/</span>call s<span class="token operator">/</span>call name
 <span class="token number">87.03</span> <span class="token number">49.78</span> <span class="token number">49.78</span> <span class="token number">1</span> <span class="token number">49.78</span> <span class="token number">49.78</span> encrypt_decrypt
 <span class="token number">6.79</span> <span class="token number">53.67</span> <span class="token number">3.89</span> <span class="token number">2</span> <span class="token number">1.94</span> <span class="token number">1.94</span> cleanupList
 <span class="token number">3.59</span> <span class="token number">55.72</span> <span class="token number">2.05</span> <span class="token number">1</span> <span class="token number">2.05</span> <span class="token number">2.05</span> readInputData
 <span class="token number">2.66</span> <span class="token number">57.24</span> <span class="token number">1.52</span> main
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>这里只考虑最左边和最右边的列。右边是crypt应用程序中不同函数的名称。左边是该<br> 函数的执行时间占应用程序总执行时间的百分比。可以预料，总执行时间的87.03%花费<br> encrypt_decrypt函数中，该函数实现主要的加密和解密逻辑。从这些信息可以总结出，如<br> 果crypt被并行化，那么并行化策略应该应用于encrypt_decrypt中。</p></li><li><p>发现性能热点仅仅是评估步骤的一半。还必须要分析这些热点是否适合并行化，也就<br> 是说，是否存在一种方法可以将一些循环或热点内部或周围的代码部分进行并行化，这个<br> 并行化策略在GPU上是否存在潜在的提速作用。</p></li><li><p>对crypt来说，这个步骤很简单：encrypt_decrypt在一个循环中执行大量的计算。在每<br> 次迭代中，这个函数会处理块列表中的一个数据块。因为在这个循环中读和写都在不同的<br> 块中进行，所以这个循环可以跨输入列表实现并行。但是也会带来一些问题。下一次迭代<br> 要处理的数据块通过当前元素被指出，因此，下一次迭代（i＋1）和当前迭代（i）之间<br> 是存在依赖性的。决定如何解除这种依赖性是crypt并行阶段中很重要的部分。</p></li></ul><h3 id="_10-4-2-并行crypt" tabindex="-1"><a class="header-anchor" href="#_10-4-2-并行crypt" aria-hidden="true">#</a> 10.4.2 并行crypt</h3><ul><li><p>通过两个步骤可以将crypt并行运行。第一，需要改变传统应用程序的控制流和数据结<br> 构，使它更适合并行化。第二，需要将计算内核转化到CUDA C中，并插入必要的CUDA<br> API调用（比如，cudaMalloc或cudaMemcpy）来建立主机和设备之间联系。</p></li><li><p>crypt并行化之后的结果可以在Wrox.com上的crypt.parallelized.cu文件中找到。有几个<br> 转化需要进一步解释，以助于理解最终的产品是如何为并行化做准备的。</p></li><li><p>首先，用于存储输入和输出数据的数据结构由链表改为数组。这有几个好处。首先，<br> 它消除了评估阶段发现的第i＋1次迭代和第i次迭代之间的依赖关系。属于块i的数据现在<br> 可以用偏移索引在数组中被检索到，而不用遍历整个链表元素。另外，数组转化到GPU中<br> 也更简单了。因为链表依赖于指针，所以，将链表由主机地址空间转化到设备地址空间，<br> 意味着也要将这些指针指向正确设备的正确元素上。数组可以直接用cudaMemcpy来拷<br> 贝。</p></li><li><p>除了改变crypt的主要数据结构，核心的计算内核也要提取到一个独立的函数doCrypt<br> 中，以使并行化更明显。doCrypt使用全局指针进行输入、输出和处理数据块。使用这个<br> 函数作为抽象，调用的内核可以跨数据块实现并行。</p></li><li><p>并行化的下一步是在crypt的合适位置处插入CUDA API调用。这一过程的变化可以分<br> 为两部分：内核实现和内存管理。</p></li><li><p>改变crypt的内核实现很简单。第一，将关键字__device__加到doCrypt中，表明它应该<br> 在GPU中被执行。第二，将encrypt_decrypt声明为__global__函数，它包含的循环基于线程<br> ID被转化为在相邻设备线程上执行的每一个数据块。第三，添加了一个名为<br> encrypt_decrypt_driver的新函数，用于启动encrypt_decrypt内核，该内核的执行配置由输入<br> 数据块的数量来决定。</p></li><li><p>encrypt_decrypt_driver内核也为移植内核执行内存管理，包括：<br> 1.给任何输入输出数据分配需要的所有内存。<br> 2.将所有应用程序的数据传输到设备中。<br> 3.释放所有已分配的设备内存。</p></li><li><p>有了这些简单的改变后，crypt应用程序可以在CUDA中执行大部分计算了。不过，你<br> 可能注意到这个实现的性能还有许多方法可以去提高。下一部分将关注这个并行化过程的<br> 结果并使用配置文件驱动优化提升性能。</p></li></ul><h3 id="_10-4-3-优化crypt" tabindex="-1"><a class="header-anchor" href="#_10-4-3-优化crypt" aria-hidden="true">#</a> 10.4.3 优化crypt</h3><ul><li><p>在本书中，一直在使用配置文件驱动优化。NVIDIA的可视化性能分析工具nvvp是一<br> 个图形化工具，nvvp通过提供提示来引导你优化应用程序中可以达到最优的部分。在本节<br> 中，在充分理解crypt应用程序的同时，将使用配置文件驱动的方法，对并行化阶段产生的<br> 实现进行优化，并把它变成一个出色的CUDA应用程序。</p></li><li><p>在配置文件驱动优化的第一阶段，使用CUDA性能分析工具深入了解应用程序的性能<br> 特点，有了这些信息，就可以确定在哪个地方进行优化了。一旦做出了改变，就可以重新<br> 分析应用程序以帮助确定下一步需要做的工作，不断迭代改进性能。</p></li><li><p>在开始的时候，使用nvvp的无导向模式生成一个综合性能分析，包括总体的提升建<br> 议。在nvvp中设置crypt，就像在“创建新会话”弹出窗口中指定可执行文件的名字和输入输<br> 出文件的位置一样简单，如图10-11所示。<br><img src="`+U+'" alt="figure10-11" loading="lazy"></p></li><li><p>通过nvvp运行crypt，收集性能分析数据后，时间轴如图10-12所示。<br><img src="'+y+'" alt="figure10-12" loading="lazy"></p></li><li><p>值得注意的是，内核占用了执行时间的很大一部分，调用cudaMemcpy也占用了应用<br> 程序运行时间的重要的一部分。此外，由于使用同步副本，所以没有重叠通信和计算。你<br> 可能会注意到，从主机到设备的传输（HtoD）发生在内核启动前，而且主要分为了两次<br> cudaMemcpy调用：一次用于plain数据，另一次用于crypt数据。基于你所知道的应用程序<br> 的知识，确定这些传输是必要的吗？显然，答案是否定的。crypt数据仅仅是一个输出数<br> 组，所以在启动内核之前将其状态转移到设备上没有任何意义。对于获取工作实现作为并<br> 行化阶段一部分，虽然保守决定向设备传输什么内容是很有用的，但在优化阶段更加重<br> 要。在这种情况下，通信实际上可以被删除。</p></li><li><p>图10-13所示的为分析视图的时间轴标签，其中的建议来自于nvvp性能统计。这些建<br> 议表明低复制带宽和低计算利用率是限制性能的明显因素。一些nvvp建议提示我们可以将<br> 重叠计算和通信作为提高计算和内存性能的一种方式。<br><img src="'+D+`" alt="figure10-13" loading="lazy"></p></li><li><p>有了这些了解后，下一步便是实施一个重叠计划。在crypt这个例子中，可以将输入分<br> 为更小的块，并在同一时间将一块传送到独立流中的设备上来完成这一步骤。然后，对于<br> 每个块进行异步cudaMemcpyAsync调用和内核启动。因为这些操作将被放置在不同的<br> CUDA流中，所以CUDA运行时可以以任何顺序执行它们，实现计算和通信之间的重叠，<br> 以及更好的利用率。从Wrox.com上下载的crypt.overlap.cu文件中，包括加入这些改变的<br> crypt新版本。为了方便，这里列出了一段核心代码。</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token function">CALL_CUDA</span><span class="token punctuation">(</span><span class="token function">cudaEventRecord</span><span class="token punctuation">(</span>start<span class="token punctuation">,</span> streams<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> 
 <span class="token function">CALL_CUDA</span><span class="token punctuation">(</span><span class="token function">cudaMemcpyAsync</span><span class="token punctuation">(</span>dKey<span class="token punctuation">,</span> key<span class="token punctuation">,</span> KEY_LENGTH <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
 cudaMemcpyHostToDevice<span class="token punctuation">,</span> streams<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token function">CALL_CUDA</span><span class="token punctuation">(</span><span class="token function">cudaStreamSynchronize</span><span class="token punctuation">(</span>streams<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span>b <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> b <span class="token operator">&lt;</span> nBlocks<span class="token punctuation">;</span> b<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> 
 <span class="token keyword">int</span> blockOffset <span class="token operator">=</span> b <span class="token operator">*</span> BLOCK_SIZE_IN_CHUNKS <span class="token operator">*</span> CHUNK_SIZE<span class="token punctuation">;</span> 
 <span class="token keyword">int</span> localChunks <span class="token operator">=</span> BLOCK_SIZE_IN_CHUNKS<span class="token punctuation">;</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>b <span class="token operator">*</span> BLOCK_SIZE_IN_CHUNKS <span class="token operator">+</span> localChunks <span class="token operator">&gt;</span> nChunks<span class="token punctuation">)</span> <span class="token punctuation">{</span> 
 localChunks <span class="token operator">=</span> nChunks <span class="token operator">-</span> b <span class="token operator">*</span> BLOCK_SIZE_IN_CHUNKS<span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 <span class="token function">CALL_CUDA</span><span class="token punctuation">(</span><span class="token function">cudaMemcpyAsync</span><span class="token punctuation">(</span>dPlain <span class="token operator">+</span> blockOffset<span class="token punctuation">,</span> plain <span class="token operator">+</span> blockOffset<span class="token punctuation">,</span> 
 localChunks <span class="token operator">*</span> CHUNK_SIZE <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">signed</span> <span class="token keyword">char</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 cudaMemcpyHostToDevice<span class="token punctuation">,</span> streams<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 encrypt_decrypt<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span>nThreadBlocks<span class="token punctuation">,</span> nThreadsPerBlock<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> streams<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span> 
 dPlain <span class="token operator">+</span> blockOffset<span class="token punctuation">,</span> dCrypt <span class="token operator">+</span> blockOffset<span class="token punctuation">,</span> dKey<span class="token punctuation">,</span> localChunks<span class="token punctuation">)</span><span class="token punctuation">;</span> 
 <span class="token function">CALL_CUDA</span><span class="token punctuation">(</span><span class="token function">cudaMemcpyAsync</span><span class="token punctuation">(</span>crypt <span class="token operator">+</span> blockOffset<span class="token punctuation">,</span> dCrypt <span class="token operator">+</span> blockOffset<span class="token punctuation">,</span> 
 localChunks <span class="token operator">*</span> CHUNK_SIZE <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">signed</span> <span class="token keyword">char</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
 cudaMemcpyDeviceToHost<span class="token punctuation">,</span> streams<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token function">CALL_CUDA</span><span class="token punctuation">(</span><span class="token function">cudaEventRecord</span><span class="token punctuation">(</span>finishes<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">,</span> streams<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span> 
 <span class="token function">CALL_CUDA</span><span class="token punctuation">(</span><span class="token function">cudaDeviceSynchronize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>注意下面的循环：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">for</span> <span class="token punctuation">(</span>b <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> b <span class="token operator">&lt;</span> nBlocks<span class="token punctuation">;</span> b<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
  <span class="token comment">//块大小和偏移量的值计算如下</span>
 <span class="token keyword">int</span> blockOffset <span class="token operator">=</span> b <span class="token operator">*</span> BLOCK_SIZE_IN_CHUNKS <span class="token operator">*</span> CHUNK_SIZE<span class="token punctuation">;</span>
 <span class="token keyword">int</span> localChunks <span class="token operator">=</span> BLOCK_SIZE_IN_CHUNKS<span class="token punctuation">;</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>b <span class="token operator">*</span> BLOCK_SIZE_IN_CHUNKS <span class="token operator">+</span> localChunks <span class="token operator">&gt;</span> nChunks<span class="token punctuation">)</span> <span class="token punctuation">{</span> 
 localChunks <span class="token operator">=</span> nChunks <span class="token operator">-</span> b <span class="token operator">*</span> BLOCK_SIZE_IN_CHUNKS<span class="token punctuation">;</span>
 <span class="token punctuation">}</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>这种优化实现了在cudaMemcpyAsync和encrypt_decrypt之间基于流的重叠，用于由<br> blockoffset和localChunks定义的块。</p></li><li><p>这些改变所带来的性能提升，总结在表10-2中。<br><img src="`+x+'" alt="table10-2" loading="lazy"></p></li><li><p>现在可以在代码的其他部分进行重新分析和重新定位优化的工作了。这个过程与之前<br> 相同，但需使用新的基于流的可执行文件。</p></li><li><p>时间轴视图（见图10-14）和时间轴分析（见图10-15）的最新结果表明，所有第一次<br> 运行时产生的问题已经被消除或减少。程序执行时间轴清楚地显示了通信和计算的重叠，<br> 而不是展示了大规模的阻塞cudaMemcpy调用。<br><img src="'+P+'" alt="figure10-14" loading="lazy"></p></li></ul><figure><img src="'+I+'" alt="figure10-15" tabindex="0" loading="lazy"><figcaption>figure10-15</figcaption></figure><ul><li><p>下一步的决定没有之前的结果明显。有几个突出的问题可能是下一阶段关注的重点。<br> 首先，时间轴分析显示了低内存吞吐量的警告。这是由于为每个块进行很多小的内存复制<br> 而不是一个大的复制而产生的。然而，导致这种改变的重叠变换很显著地提升了性能，所<br> 以低内存吞吐量的代价是可以接受的。</p></li><li><p>多处理器分析视图（见图10-16）表明了寄存器的压力也可能是一个问题。然而，这<br> 可以通过修改内核代码得到改变，所以在早期的优化阶段进行寄存器的使用优化，可能是<br> 无用功。</p></li></ul><figure><img src="'+S+'" alt="figure10-16" tabindex="0" loading="lazy"><figcaption>figure10-16</figcaption></figure><ul><li><p>时间轴分析视图表明SM的利用率仍然很低。这意味着SM很可能会花费很多时间，要<br> 么没有符合条件的任何线程块来调度，要么等待I/O完成。内核内存面板还警告全局内存<br> 存储效率低。从这两个指标可以总结出，这个应用程序的全局内存操作可能会限制它的性<br> 能。下一步更加依赖如何使用全局内存中应用程序的特定知识。</p></li><li><p>那么，当前存储在全局内存中的对象是什么？目前，输入text、输出crypt、加密/解密<br> key的存储和访问都在全局内存中进行。因为数据块是跨线程ID进行处理的，所以每个线<br> 程都读和写text和crypt中相邻的8字节块。虽然4字节是最优的，但是因为访问是合并和对<br> 齐的，这仍然可以使缓存和带宽得到合理有效的利用。</p></li><li><p>key的访问模式是一个非常不同的故事。每一个线程在同一时间读取key的相同位置。<br> 这将产生更低的全局带宽利用率，因为线程的完整线程束从全局内存中读取相同的4字节<br> 时将被阻塞。因为key，text和crypt都在GPU多处理器中共享全局一级和二级缓存，如果通<br> 过text或crypt中写入或读取来删除缓存中的读操作，那么可能要进行多次读操作。基于这<br> 样的分析和由nvvp报告的指标，看起来下一步较好的选择是优化key的使用。</p></li><li><p>优化key的使用，方法之一就是改变存储key的内存。哪种CUDA内存类型支持只读数<br> 据结构并且对于广播单一元素到所有线程是最优的？看起来这应该是常量内存！在常量内<br> 存中放置key，有可能提高全局内存带宽和全局内存缓存效率。</p></li><li><p>在crypt的新版本中key存储在常量内存中，这个新版本可以从Wrox.com上的<br> crypt.constant.cu文件中获得。所进行的更改包括：<br> 1.加入了一个__constant__dkey变量：<code>__constant__ int dkey[KEY_LENGTH];</code><br> 2.修改doCrypt内核以引用新的dkey变量。<br> 3.调用cudaMemcpyToSymbolAsync，将key中的内容传输到设备中：<br><code>CALL_CUDA(cudaMemcpyToSymbolAsync(dkey, key, KEY_LENGTH * sizeof(int), 0, cudaMemcpyHostToDevice, streams[0]));</code></p></li><li><p>这一变化获得的性能改进在表10-3中进行了总结。<br><img src="'+G+'" alt="table10-3" loading="lazy"></p></li><li><p>与原始版本的CUDA实现相比，性能几乎增加了一倍。迭代时间和重新定位增加了更<br> 多的优化机会！</p></li><li><p>使用nvvp再一次进行性能分析，从时间轴和多处理器分析视图（分别如图10-17和图<br> 10-18所示）的指标可以看出了改进。<br><img src="'+E+'" alt="figure10-17" loading="lazy"></p></li></ul><figure><img src="'+L+'" alt="figure10-18" tabindex="0" loading="lazy"><figcaption>figure10-18</figcaption></figure><ul><li><p>然而，图10-19所示的内核内存面板仍然报告全局存储带宽的利用率低。</p></li><li><p>这似乎需要更多的调查。首先，重要的是要了解数值12.5%来自于哪里。例如，考虑<br> doCrypt里每个线程执行的第一次读操作，对plain输入的单字节进行访问：<br><code>x1 = (((unsigned int)plain[chunk * CHUNK_SIZE]) &amp; 0xff);</code></p></li><li><p>因为线程是跨块的，每块是8字节，所以线程束里的线程在每次加载过程中通常访问<br> plain中的每8字节。然而，缓存硬件把这些稀疏的单字节加载调整为双字节，这样就有128<br> 字节的加载来自全局内存。因此，从性能分析工具的角度来看，来自全局内存的每8字节<br> 加载中，仅有1字节真正被使用，所以1/8＝12.5%就是利用率。<br><img src="'+M+'" alt="figure10-19" loading="lazy"></p></li><li><p>然而，这并不是整个故事。作为这128字节加载的结果，以后的每个plain引用可能会<br> 命中一级缓存也可能会命中二级缓存，这取决于GPU的架构，所以全局内存引用不是必需<br> 的。每个加载到缓存中的字节都会被使用，但可能不是特定加载指令的一部分。因此，这<br> 就是nvvp报告的次优资源利用的情况，通过更多的调查得到实际上不是性能的问题，因为<br> 数据被缓存了。</p></li><li><p>然而，时间轴分析仍然显示出一个低计算利用率的警告。回想一下可知，之前的运行<br> 中多处理器分析也显示过一个占用警告，这是由于寄存器消耗产生的。这些警告都表明，<br> 用于这个内核的线程配置可能不是最优的。因此，每个SM寄存器通过块中的线程被稀疏<br> 传播，当值从寄存器溢出后会导致I/O上更多的阻塞，因此计算利用率降低。通过分析代<br> 码很难验证这一结论。相反，可以使用不同的线程配置进行实验，从而查看是否可以提升<br> 性能。带有这些改变的crypt应用程序的新副本可以从Wrox.com上下载的crypt.config.cu文件<br> 中得到。这个新版本允许我们使用命令行参数配置每个块的线程数。在一组线程配置上测<br> 试新的代码，所产生的结果如表10-4所示。<br><img src="'+N+'" alt="table10-4" loading="lazy"></p></li><li><p>虽然在每块512个线程的原始配置下，执行性能是可接受的，但是每块128个线程可以<br> 获得19%的性能提升。因为减少线程块的大小改进了性能，一个合乎逻辑的结论是，与最<br> 佳情况相比，每块512个线程导致给每个线程分配了更少的寄存器。</p></li><li><p>现在可以重新进行性能分析，看看是否可以确定新的性能问题。请注意，使用每块<br> 128个线程重新分析crypt.config，需要在nvvp交互式会话配置中添加命令行参数。</p></li><li><p>图10-20所示为时间轴分析视图，SM利用率的提升要归功于更好的寄存器分配。<br><img src="'+w+'" alt="figure10-20" loading="lazy"></p></li><li><p>在这一点上，nvvp将会提供不能解释的性能问题。crypt通过优化阶段已成功被转化。<br> 如表10-5总结的那样，相较于并行阶段的非优化实现，性能提升增加了一倍多。使用配置<br> 文件驱动优化，在应用程序中可以针对最影响执行时间的特性进行优化，高效利用开发时间。<br><img src="'+O+`" alt="table10-5" loading="lazy"></p></li><li><p>目前，已经开发出了一种高性能实现，现在可以进入到下一个也是APOD最后的阶段：部署。</p></li></ul><h3 id="_10-4-4-部署crypt" tabindex="-1"><a class="header-anchor" href="#_10-4-4-部署crypt" aria-hidden="true">#</a> 10.4.4 部署crypt</h3><ul><li>在主机和设备函数的错误处理方面，crypt已经准备好部署了。然而，还可以提高其能<br> 力以适应新的硬件平台，这个平台可以有不同数量的GPU，也可以没有GPU。</li></ul><h4 id="_10-4-4-1-多gpu的crypt" tabindex="-1"><a class="header-anchor" href="#_10-4-4-1-多gpu的crypt" aria-hidden="true">#</a> 10.4.4.1 多GPU的crypt</h4><ul><li><p>云提供商提供了更多的GPU部署，组织机构越来越多地将他们的产品系统移动到云<br> 上，在执行环境中已经增加了灵活地支持重大改变的重要性。对crypt来说，这意味着增加<br> 了跨所有可用GPU分担工作量的能力，以及在没有GPU被检测到的情况下回到主机执行。</p></li><li><p>crypt.flexible.cu中的源代码是crypt应用程序灵活实现的例子，程序可以在任何数量的<br> GPU上运行，包括GPU数量为0的情况。crypt.flexible根据有没有GPU来选择主机或设备执<br> 行，这由cudaErrorNoDevice错误代码来显示。注意，doCrypt使用__host____device__函数<br> 在两种实现间共享代码，减少了复制代码和维护相同算法的两个副本的开销。</p></li><li><p>为了方便，这里列出了通过多GPU划分工作的核心逻辑：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">for</span> <span class="token punctuation">(</span>d <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> d <span class="token operator">&lt;</span> nDevices<span class="token punctuation">;</span> d<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token function">CALL_CUDA</span><span class="token punctuation">(</span><span class="token function">cudaSetDevice</span><span class="token punctuation">(</span>d<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token keyword">int</span> start <span class="token operator">=</span> d <span class="token operator">*</span> chunksPerDevice <span class="token operator">*</span> CHUNK_SIZE<span class="token punctuation">;</span>
 <span class="token keyword">int</span> len <span class="token operator">=</span> chunksPerDevice <span class="token operator">*</span> CHUNK_SIZE<span class="token punctuation">;</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>start <span class="token operator">+</span> len <span class="token operator">&gt;</span> textLen<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 len <span class="token operator">=</span> textLen <span class="token operator">-</span> start<span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 <span class="token function">encrypt_decrypt_driver</span><span class="token punctuation">(</span>text <span class="token operator">+</span> start<span class="token punctuation">,</span> crypt <span class="token operator">+</span> start<span class="token punctuation">,</span> key<span class="token punctuation">,</span> len<span class="token punctuation">,</span>
 nThreadsPerBlock<span class="token punctuation">,</span> ctxs <span class="token operator">+</span> d<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 <span class="token function">CALL_CUDA</span><span class="token punctuation">(</span><span class="token function">cudaEventRecord</span><span class="token punctuation">(</span>finishEvent<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> 
 <span class="token comment">// Wait for each device to finish its work.</span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span>d <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> d <span class="token operator">&lt;</span> nDevices<span class="token punctuation">;</span> d<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token function">CALL_CUDA</span><span class="token punctuation">(</span><span class="token function">cudaSetDevice</span><span class="token punctuation">(</span>d<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token function">CALL_CUDA</span><span class="token punctuation">(</span><span class="token function">cudaDeviceSynchronize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>在这段代码中，修改后的encrypt_decrypt_driver是在每个GPU中被调用的，用来异步<br> 初始化数据传输和内核启动。然后，一旦每个设备开始工作，主机暂停并等待每个设备完<br> 成工作。</li></ul><h4 id="_10-4-4-2-混合openmp-cuda-crypt" tabindex="-1"><a class="header-anchor" href="#_10-4-4-2-混合openmp-cuda-crypt" aria-hidden="true">#</a> 10.4.4.2 混合OpenMP-CUDA Crypt</h4><ul><li><p>因为没有可用于执行的GPU，所以前面的crypt.flexibile.cu例子中使用了CPU，如果发<br> 现了任何GPU，则将CPU闲置。虽然在一个系统的GPU上执行所有的计算可能会提高性<br> 能，但是这同时也导致可用的硬件未被充分利用。一些应用程序支持混合并行：CPU和<br> GPU在同一个问题上协同并行。</p></li><li><p>在一般情况下，有两种类型的混合并行：<br> 1.数据并行的混合并行：CPU与GPU执行相同的数据并行计算，但跨越的是CPU核心<br> 而不是GPU的SM。本质上CPU成为了系统中的另一个设备。在这种情况下，可以使用<br> __host____device__函数在两个处理器上执行相同的逻辑。<br> 2.任务并行的混合并行：CPU与GPU执行不同的计算，该计算更适合于基于主机的体<br> 系结构。例如，CPU可以执行具有更复杂的控制流或不规则访问模式的任务。</p></li><li><p>在这两种情况下，有必要使用CUDA流（和可能的事件）来重叠CPU和GPU的执行<br> （如第6章所述）。</p></li><li><p>crypt.openmp.cu包含了一个例子，这个示例中，在单一的应用程序中使用了CPU上的<br> OpenMP并行和GPU上的CUDA并行。OpenMP是一种针对主机的并行编程模型，它使用编<br> 译器指令标记并行区域，类似于OpenACC。只有加入了OpenMP的特定代码才是对<br> omp_set_num_threads的调用，用来配置CPU核心使用的数量，并且在主机端的计算函数<br> h_encrypt_decrypt中加入OpenMP编译指示。编译器提示#pragma omp parallel for标记了下述<br> 可并行化的循环，并指示OpenMP在多个CPU线程上运行它。</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">omp parallel <span class="token keyword">for</span></span></span>
<span class="token keyword">for</span> <span class="token punctuation">(</span>c <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> c <span class="token operator">&lt;</span> nChunks<span class="token punctuation">;</span> c<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token function">doCrypt</span><span class="token punctuation">(</span>c<span class="token punctuation">,</span> plain<span class="token punctuation">,</span> crypt<span class="token punctuation">,</span> key<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>crypt.openmp.cu还增加了跨CPU和GPU划分工作量的逻辑，在这里使用了一个新的命<br> 令行参数cpu-percent，它指定了在CPU上被加密或是解密的字节百分比，以及转到GPU上<br> 的剩余工作量。</p></li><li><p>CPU和GPU的计算是被并行执行的，通过在不同的流中为每个设备排队数据传输和内<br> 核执行，然后一旦异步CUDA调用返回控制到主机就启动CPU线程：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token function">CALL_CUDA</span><span class="token punctuation">(</span><span class="token function">cudaEventRecord</span><span class="token punctuation">(</span>startEvent<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span>d <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> d <span class="token operator">&lt;</span> nDevices<span class="token punctuation">;</span> d<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token function">CALL_CUDA</span><span class="token punctuation">(</span><span class="token function">cudaSetDevice</span><span class="token punctuation">(</span>d<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token keyword">int</span> start <span class="token operator">=</span> d <span class="token operator">*</span> chunksPerGpu <span class="token operator">*</span> CHUNK_SIZE<span class="token punctuation">;</span>
 <span class="token keyword">int</span> len <span class="token operator">=</span> chunksPerGpu <span class="token operator">*</span> CHUNK_SIZE<span class="token punctuation">;</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>start <span class="token operator">+</span> len <span class="token operator">&gt;</span> gpuLen<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 len <span class="token operator">=</span> gpuLen <span class="token operator">-</span> start<span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 <span class="token function">encrypt_decrypt_driver</span><span class="token punctuation">(</span>text <span class="token operator">+</span> start<span class="token punctuation">,</span> crypt <span class="token operator">+</span> start<span class="token punctuation">,</span> key<span class="token punctuation">,</span> len<span class="token punctuation">,</span>
 nThreadsPerBlock<span class="token punctuation">,</span> ctxs <span class="token operator">+</span> d<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 <span class="token keyword">int</span> cpuStart <span class="token operator">=</span> gpuLen<span class="token punctuation">;</span>
 <span class="token function">h_encrypt_decrypt</span><span class="token punctuation">(</span>text <span class="token operator">+</span> cpuStart<span class="token punctuation">,</span> crypt <span class="token operator">+</span> cpuStart<span class="token punctuation">,</span> key<span class="token punctuation">,</span> 
 textLen <span class="token operator">-</span> cpuStart<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token function">CALL_CUDA</span><span class="token punctuation">(</span><span class="token function">cudaEventRecord</span><span class="token punctuation">(</span>finishEvent<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>crypt.openmp.cu必须在OpenMP的支持下进行编译和链接。如果NVIDIA编译器使用的<br> 是gcc主机编译器，那么可以使用如下语句：<br><code>$ nvcc -Xcompiler -fopenmp -arch=sm_20 crypt.openmp.cu -o crypt.openmp -lgomp</code></p></li><li><p>注意，crypt.openmp添加了两个新的命令行参数：使用的CPU内核的数量（ncpus）和<br> 在CPU上处理数据的百分比（cpu-percent）。应该使用0.0～1.0之间的数值来指定cpupercent命令行的选项。</p></li><li><p>通过使用cpu-percent命令行参数，可以研究随着CPU上工作量的增加，性能是如何变<br> 化的。在表10-6中，一系列工作量的分配结果显示，将工作放置在CPU上是不利于crypt<br> 的。对于这个特定的应用程序，将产生新的CPU线程的开销和较慢的CPU计算性能，这意<br> 味着在CPU上运行任何数量的工作都将导致性能降低。<br><img src="`+z+'" alt="table10-6" loading="lazy"></p></li><li><p>其他的应用程序在某种程度上可以同时使用CPU和GPU并产生互补的效果，这比处理<br> 器单独运行时实现了更好的性能。例如，用于分类世界排名前500的超级计算机的高性能<br> LINPACK（HPL）标准检查程序在混合执行体系下表现得最好.</p></li></ul><h3 id="_10-4-5-移植crypt小结" tabindex="-1"><a class="header-anchor" href="#_10-4-5-移植crypt小结" aria-hidden="true">#</a> 10.4.5 移植crypt小结</h3><ul><li><p>在这一部分中，通过APOD过程将一个应用程序示例进行了完全地转化。首先，在评<br> 估阶段，使用gprof分析crypt，确定性能的关键区域，因此获得了一种具有最大的潜在优<br> 化性能的代码部分。然后，并行化阶段产生了crypt的CUDA实现工作，具体是先将主机代<br> 码转化成更适合并行的代码，然后加入CUDA API调用来传输数据和启动内核。优化阶段<br> 将并行化阶段的输出变为一个高性能的CUDA应用程序，使用配置文件驱动优化确定次优<br> 的性能特点。在整个优化阶段中，反复进行性能检查，目的是为了验证相应的变化对性能<br> 是进行了提升，而不是降低。最后，在部署阶段，使crypt可以运行在任何数量的GPU上以<br> 达到更适应执行环境变化的目的。</p></li><li><p>通过这4个简单的步骤，APOD将crypt从一个传统的、过时的、性能弱的实现转向了<br> 一个现代的、高性能的CUDA应用程序，并准备迎接未来应用程序的需求</p></li></ul><h2 id="_10-5-总结" tabindex="-1"><a class="header-anchor" href="#_10-5-总结" aria-hidden="true">#</a> 10.5 总结</h2><ul><li><p>本章涵盖了各种各样的主题。然而，每个主题都旨在使用CUDA开发的流程和工具来<br> 提高效率，让我们成为更高效的CUDA开发者，从应用程序中获得更多的性能。</p></li><li><p>APOD，一个有4个步骤的迭代过程，将一个传统的、串行的C应用程序转变为高性<br> 能、耐用的CUDA应用程序，为部署该应用做准备。APOD是抽象的开发模型，但是用这<br> 个规定的方法可以大大简化移植过程。</p></li><li><p>我们学习了本书中使用的配置文件驱动优化策略。也学习了nvprof、nvvp和NVIDIA工<br> 具扩展如何帮助我们找到应用程序的性能限制因素。</p></li><li><p>同时也介绍了CUDA内核和内存调试的内容。cuda-gdb、cuda-memcheck，以及多种使<br> 用CUDA语言的建立工具，在GPU上调试CUDA内核时都体现出来了。</p></li><li><p>最后，介绍了一个案例，这个案例对传统的密码应用程序转化到一个高性能的CUDA<br> 应用程序的全过程进行了演示。由于使用配置文件驱动优化，性能是初始CUDA实现的两<br> 倍多。</p></li></ul><h2 id="_10-6-习题" tabindex="-1"><a class="header-anchor" href="#_10-6-习题" aria-hidden="true">#</a> 10.6 习题</h2><ul><li><p>1.写出APOD中4个阶段的名称及其目标。</p></li><li><p>2.一个应用程序可以使用CUDA库、OpenACC或手工编码的CUDA内核进行加速。<br> APOD的哪个阶段需要在两种方法间进行决定？根据所选择的方法，引入到APOD的每一<br> 个阶段后，你预想的主要区别是什么？</p></li><li><p>3.在CUDA 5.0中什么功能是通过独立编译增加的？使用独立编译时必须添加哪些编译<br> 器标志？</p></li><li><p>4.为了分析内核越界访问，最好的工具是什么？为什么？</p></li><li><p>5.为了分析__shared__内存的使用，最好的工具是什么？</p></li><li><p>6.nvprof中的3种分析模式是什么？各自擅长收集哪些信息？</p></li><li><p>7.相对于其他性能分析工具，使用nvvp的优点是什么？</p></li><li><p>8.考虑日常的开发环境。nvprof和nvvp怎样能最合适它？例如，如果你经常与一个有<br> GPU的远程设备一起工作，并且它和你的本地工作站在同一个局域网下，那么可以使用<br> nvprof收集远程设备上的性能分析转储文件，将它转移到你的本地工作站中，并用nvvp对<br> 其进行分析。</p></li></ul>',42);function mn(vn,hn){const p=c("router-link"),t=c("ExternalLinkIcon");return r(),i("div",null,[H,$,u(" more "),n("nav",R,[n("ul",null,[n("li",null,[s(p,{to:"#简单介绍主要是基础"},{default:e(()=>[a("简单介绍主要是基础")]),_:1})]),n("li",null,[s(p,{to:"#第10章-程序实现的注意事项"},{default:e(()=>[a("第10章 程序实现的注意事项")]),_:1})]),n("li",null,[s(p,{to:"#_10-1-cudac的开发过程"},{default:e(()=>[a("10.1 CUDAC的开发过程")]),_:1})]),n("li",null,[s(p,{to:"#_10-2-配置文件驱动优化"},{default:e(()=>[a("10.2 配置文件驱动优化")]),_:1}),n("ul",null,[n("li",null,[s(p,{to:"#_10-2-1-使用nvprof寻找优化因素"},{default:e(()=>[a("10.2.1 使用nvprof寻找优化因素")]),_:1})]),n("li",null,[s(p,{to:"#_10-2-2-使用nvvp指导优化"},{default:e(()=>[a("10.2.2 使用nvvp指导优化")]),_:1})]),n("li",null,[s(p,{to:"#_10-2-3-nvidia工具扩展"},{default:e(()=>[a("10.2.3 NVIDIA工具扩展")]),_:1})])])]),n("li",null,[s(p,{to:"#_10-3-cuda调试"},{default:e(()=>[a("10.3 CUDA调试")]),_:1}),n("ul",null,[n("li",null,[s(p,{to:"#_10-3-1-内核调试"},{default:e(()=>[a("10.3.1 内核调试")]),_:1})]),n("li",null,[s(p,{to:"#_10-3-2-内存调试"},{default:e(()=>[a("10.3.2 内存调试")]),_:1})]),n("li",null,[s(p,{to:"#_10-3-3-调试小结"},{default:e(()=>[a("10.3.3 调试小结")]),_:1})])])]),n("li",null,[s(p,{to:"#_10-4-将c程序移植到cudac的案例研究"},{default:e(()=>[a("10.4 将C程序移植到CUDAC的案例研究")]),_:1}),n("ul",null,[n("li",null,[s(p,{to:"#_10-4-1-评估crypt"},{default:e(()=>[a("10.4.1 评估crypt")]),_:1})]),n("li",null,[s(p,{to:"#_10-4-2-并行crypt"},{default:e(()=>[a("10.4.2 并行crypt")]),_:1})]),n("li",null,[s(p,{to:"#_10-4-3-优化crypt"},{default:e(()=>[a("10.4.3 优化crypt")]),_:1})]),n("li",null,[s(p,{to:"#_10-4-4-部署crypt"},{default:e(()=>[a("10.4.4 部署crypt")]),_:1})]),n("li",null,[s(p,{to:"#_10-4-5-移植crypt小结"},{default:e(()=>[a("10.4.5 移植crypt小结")]),_:1})])])]),n("li",null,[s(p,{to:"#_10-5-总结"},{default:e(()=>[a("10.5 总结")]),_:1})]),n("li",null,[s(p,{to:"#_10-6-习题"},{default:e(()=>[a("10.6 习题")]),_:1})])])]),K,n("ul",null,[F,n("li",null,[n("p",null,[a("考虑一个简单例子，"),n("a",V,[a("其中有a.cu"),s(t)]),a("，"),n("a",B,[a("b.cu"),s(t)]),a("，c.cpp 3个文件。假设a.cu文件中的一些核函数"),W,a(" 引用b.cu文件中的一些函数或变量，因为是跨文件引用的，所以就必须使用独立编译来生"),Z,a(" 成可执行文件。如果是一个Fermi设备（计算能力为2.x），则可以使用以下命令产生可重"),q,a(" 新定位的对象："),X])]),n("li",null,[n("p",null,[a("传到nvcc中的选项-dc，命令编译器编译每一个输入文件（"),n("a",J,[a("a.cu和b.cu"),s(t)]),a("），生成一个包"),Y,a(" 含可重新定位设备代码的目标文件。下一步，使用以下命令将所有设备对象链接在一起："),j,Q])]),nn,an]),sn,n("ul",null,[n("li",null,[a("要想得到使用cuda-gdb的实践经验，在Wrox.com上下载debug-segfault.cu文件，使用该"),pn,a(" 文件在CUDA中调试一个无效的内存访问以进行试验。首先，用已给出的Makefile文件建"),en,n("a",tn,[a("立debug-segfault.cu"),s(t)]),a("，该过程会设置标志-g和-G。然后，将应用程序载入到cuda-gdb中：")])]),on,n("ul",null,[cn,n("li",null,[n("p",null,[n("a",ln,[a("用前面已讨论过的编译选项编译debug-hazards.cu"),s(t)]),a("："),rn])]),un,dn,kn]),bn])}const fn=l(T,[["render",mn],["__file","J-第十章.html.vue"]]);export{fn as default};
