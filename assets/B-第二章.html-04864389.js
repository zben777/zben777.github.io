import{_ as r}from"./plugin-vue_export-helper-c27b6911.js";import{r as u,o as k,c as d,d as m,a as n,e as t,w as a,b as s,f as p}from"./app-2a2d189a.js";const b="/assets/figure2-1-c97f252d.png",v="/assets/figure2-2-fab831ba.png",f="/assets/table2-1-ed11923c.png",h="/assets/figure2-3-a56f26ea.png",y="/assets/figure2-4-bdc940f9.png",g="/assets/figure2-5-8a9119a8.png",_="/assets/figure2-6-67b6674d.png",x="/assets/figure2-7-a72f8c5d.png",w="/assets/figure2-8-1835327c.png",D="/assets/figure2-9-db2e228a.png",U="/assets/figure2-10-777d9939.png",A="/assets/figure2-11-a0de4153.png",C="/assets/figure2-12-24c1d6bb.png",P="/assets/figure2-13-24b53286.png",M="/assets/figure2-14-7c2ffbab.png",G="/assets/table2-4-3bbd8a51.png",I={},B=n("h1",{id:"b-第二章节",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#b-第二章节","aria-hidden":"true"},"#"),s(" B-第二章节")],-1),E=n("p",null,"B-第二章节",-1),z={class:"table-of-contents"},S=p('<h2 id="简单介绍主要是基础" tabindex="-1"><a class="header-anchor" href="#简单介绍主要是基础" aria-hidden="true">#</a> 简单介绍主要是基础</h2><div class="hint-container info"><p class="hint-container-title">说明</p><p>主要是各种搜索找的学习；</p><p>主题：CUDA核心GPU编程</p><p>前置条件：</p><ul><li>应具备C++编程知识</li><li>需理解内存管理，如malloc和free</li><li>理解STL及其模板机制</li><li>需配置NVIDIA显卡，型号需为900系列或更高</li><li>所用扩展要求版本为11或更新</li><li>编译器版本不低于11</li><li>CMake版本需在3.18以上</li></ul></div>',2),T={class:"hint-container info"},R=n("p",{class:"hint-container-title"},"问题",-1),O=p("<li><p>这章 关于 组织规划 线程组织 基本都是 一个thread一个数据点；</p></li><li><p>即导致，如果多大的数据，就需要多大的线程数量；</p></li><li><p>还有就是：如果进一步将块的维度降低到256，系统将提示以下错误信息，信息表示块的总数：65536超过了一维网格的限制。</p></li><li><p>意思是说 一维网格grid 在 包含 65536个 block的时候是 不允许的在这里？硬件限制？？</p></li><li><p>但是在运行RAFT的时候肯定是可行的啊</p></li><li><p><mark>了解自身局限性</mark></p></li><li><p>在调整执行配置时需要了解的一个关键点是对网格和块维度的限制。</p></li><li><p>线程层次结构中每个层级的最大尺寸取决于设备。</p></li><li><p>CUDA提供了通过查询GPU来了解这些限制的能力。在本章的2.4节有详细的介绍。</p></li><li><p>对于Fermi设备，每个块的最大线程数是1024，且网格的x、y、z三个方向上的维度最大值是65535。</p></li><li><p>Maximum sizes of each dimension of a block: 1024 x 1024 x 64</p></li><li><p>Maximum sizes of each dimension of a grid: 65535 x 65535 x 65535</p></li>",12),N=n("mark",null,"nvprof",-1),H=n("br",null,null,-1),L=n("br",null,null,-1),V=n("br",null,null,-1),F={href:"https://developer.nvidia.com/tools-overview",target:"_blank",rel:"noopener noreferrer"},$=n("li",null,[n("p",null,[n("mark",null,"分析")])],-1),q=n("li",null,[n("p",null,"单从第二章这章节来看的话==")],-1),K=n("li",null,[n("p",null,"确实是 通过 组织 不同的 方式，可以提高矩阵求和的性能；")],-1),W=n("li",null,[n("p",null,"但是 是不是因为其 简单呢？")],-1),j=p('<h2 id="第2章-cuda编程模型" tabindex="-1"><a class="header-anchor" href="#第2章-cuda编程模型" aria-hidden="true">#</a> 第2章 CUDA编程模型</h2><ul><li><p><mark>WHAT’S IN THIS CHAPTER?</mark></p></li><li><p>Writing a CUDA program写一个CUDA程序</p></li><li><p>Executing a kernel function执行一个核函数</p></li><li><p>Organizing threads with grids and blocks用网格和线程块组织线程</p></li><li><p>Measuring GPU performance(测试GPU性能)</p></li><li><p>CUDA是一种通用的并行计算平台和编程模型(不仅是一个平台也是一个编程模型)，<br> 是在C语言基础上扩展的。借助于<br> CUDA，你可以像编写C语言程序一样实现并行算法。你可以在NVIDIA的GPU平台上用<br> CUDA为多种系统编写应用程序，范围从嵌入式设备、平板电脑、笔记本电脑、台式机、<br> 工作站到HPC集群（高性能计算集群）。熟悉C语言编程工具有助于在整个项目周期中编<br> 写、调试和分析你的CUDA程序。在本章中，我们将通过向量加法和矩阵加法这两个简单<br> 的例子来学习如何编写一个CUDA程序。</p></li></ul><h2 id="_2-1-cuda编程模型概述" tabindex="-1"><a class="header-anchor" href="#_2-1-cuda编程模型概述" aria-hidden="true">#</a> 2.1 CUDA编程模型概述</h2><p>INTRODUCING THE CUDA PROGRAMMING MODEL</p><ul><li>CUDA编程模型提供了一个计算机架构抽象作为应用程序和其可用硬件之间的桥梁。<br> 图2-1说明了程序和编程模型实现之间的抽象结构的重要。通信抽象是程序与编程模型实<br> 现之间的分界线，它通过专业的硬件原语和操作系统的编译器或库来实现。利用编程模型<br> 所编写的程序指定了程序的各组成部分是如何共享信息及相互协作的。编程模型从逻辑上<br> 提供了一个特定的计算机架构，通常它体现在编程语言或编程环境中。</li></ul><figure><img src="'+b+'" alt="figure2-1" tabindex="0" loading="lazy"><figcaption>figure2-1</figcaption></figure><ul><li>除了与其他并行编程模型共有的抽象外，CUDA编程模型还利用GPU架构的计算能力<br> 提供了以下几个特有功能。 <ul><li>A way to organize threads on the GPU through a hierarchy structure(一种通过层次结构在GPU中组织线程的方法)</li><li>A way to access memory on the GPU through a hierarchy structure(一种通过层次结构在GPU中访问内存的方法)</li></ul></li><li>在本章和下一章你将重点学习第一个主题，而在第4章和第5章将学习第二个主题。</li></ul><br><ul><li><p>从程序员的角度来看，您可以从不同层面来看待并行计算、 例如</p><ul><li>Domain level领域层</li><li>Logic level逻辑层</li><li>Hardware level硬件层</li></ul></li><li><p>在编程与算法设计的过程中，你最关心的应是在领域层如何解析数据和函数，以便在<br> 并行运行环境中能正确、高效地解决问题。当进入编程阶段，你的关注点应转向如何组织<br> 并发线程。在这个阶段，你需要从逻辑层面来思考，以确保你的线程和计算能正确地解决<br> 问题。在C语言并行编程中，需要使用pthreads或OpenMP技术来显式地管理线程。CUDA<br> 提出了一个线程层次结构抽象的概念，以允许控制线程行为。在阅读本书中的示例时，你<br> 会发现这个抽象为并行编程提供了良好的可扩展性。在硬件层，通过理解线程是如何映射<br> 到核心可以帮助提高其性能。CUDA线程模型在不强调较低级别细节的情况下提供了充足<br> 的信息，具体内容详见第3章。</p></li></ul><h3 id="_2-1-1-cuda编程结构" tabindex="-1"><a class="header-anchor" href="#_2-1-1-cuda编程结构" aria-hidden="true">#</a> 2.1.1 CUDA编程结构</h3><p>CUDA Programming Structure</p><ul><li><p>CUDA编程模型使用由C语言扩展生成的注释代码在异构计算系统中执行应用程序。<br> 在一个异构环境中包含多个CPU和GPU，每个GPU和CPU的内存都由一条PCI-Express总线<br> 分隔开。因此，需要注意区分以下内容。</p><ul><li>Host: the CPU and its memory (host memory)主机：CPU及其内存（主机内存）</li><li>Device: the GPU and its memory (device memory)·设备：GPU及其内存（设备内存）</li></ul></li><li><p>为了清楚地指明不同的内存空间，在本书的示例代码中，主机内存中的变量名以h_为<br> 前缀，设备内存中的变量名以d_为前缀.</p></li><li><p>从CUDA 6.0开始，NVIDIA提出了名为“统一寻址”（Unified Memory）的编程模型的改进，它连接了主机内存和设备内存空间，可使用单个指针访问CPU和GPU内存，无须彼此之间手动拷贝数据。更多细节详见第4章。现在，重要的是应学会如何为主机和设备分配<br> 内存空间以及如何在CPU和GPU之间拷贝共享数据。这种程序员管理模式控制下的内存和<br> 数据可以优化应用程序并实现硬件系统利用率的最大化。</p></li><li><p>内核（kernel）是CUDA编程模型的一个重要组成部分，其代码在GPU上运行。作为<br> 一个开发人员，你可以串行执行核函数。在此背景下，CUDA的调度管理程序员在GPU线<br> 程上编写核函数。在主机上，基于应用程序数据以及GPU的性能定义如何让设备实现算法<br> 功能。这样做的目的是使你专注于算法的逻辑（通过编写串行代码），且在创建和管理大<br> 量的GPU线程时不必拘泥于细节。</p></li><li><p>多数情况下，主机可以独立地对设备进行操作。内核一旦被启动，管理权立刻返回给<br> 主机，释放CPU来执行由设备上运行的并行代码实现的额外的任务。CUDA编程模型主要<br> 是异步的，因此在GPU上进行的运算可以与主机-设备通信重叠。一个典型的CUDA程序包<br> 括由并行代码互补的串行代码。如图2-2所示，串行代码（及任务并行代码）在主机CPU上执行，而并行代码在GPU上执行。主机代码按照ANSI C标准进行编写，而设备代码使<br> 用CUDA C进行编写。你可以将所有的代码统一放在一个源文件中，也可以使用多个源文<br> 件来构建应用程序和库。NVIDIA的C编译器（nvcc）为主机和设备生成可执行代码。</p></li><li><p>A typical processing fl ow of a CUDA program follows this pattern:</p><ul><li>1、Copy data from CPU memory to GPU memory.</li><li>2、nvoke kernels to operate on the data stored in GPU memory.</li><li>3、Copy data back from GPU memory to CPU memory.</li></ul></li><li><p>首先，你要学习的是内存管理及主机和设备之间的数据传输。在本章后面你将学到更<br> 多GPU核函数执行的细节内容。</p></li></ul><figure><img src="'+v+'" alt="figure2-2" tabindex="0" loading="lazy"><figcaption>figure2-2</figcaption></figure><h3 id="_2-1-2-内存管理" tabindex="-1"><a class="header-anchor" href="#_2-1-2-内存管理" aria-hidden="true">#</a> 2.1.2 内存管理</h3><p>Managing Memory</p><ul><li><p>CUDA编程模型假设系统是由一个主机和一个设备组成的，而且各自拥有独立的内存。<br> 核函数是在设备上运行的。为使你拥有充分的控制权并使系统达到最佳性能，CUDA<br> 运行时负责分配与释放设备内存，并且在主机内存和设备内存之间传输数据。表2-1列出<br> 了标准的C函数以及相应地针对内存操作的CUDA C函数。<br><img src="'+f+'" alt="table2-1" loading="lazy"></p></li><li><p>用于执行GPU内存分配的是cudaMalloc函数，其函数原型为：</p><ul><li>cudaError_t cudaMalloc ( void** devPtr, size_t size )</li></ul></li><li><p>该函数负责向设备分配一定字节的线性内存，并以devPtr的形式返回指向所分配内存<br> 的指针。cudaMalloc与标准C语言中的malloc函数几乎一样，只是此函数在GPU的内存里分配内存。通过充分保持与标准C语言运行库中的接口一致性，可以实现CUDA应用程序的轻松接入。</p></li><li><p>cudaMemcpy函数负责主机和设备之间的数据传输，其函数原型为：<br> - cudaError_t cudaMemcpy ( void* dst, const void* src, size_t count, cudaMemcpyKind kind )</p></li><li><p>该函数将指定字节从 src 指向的源内存区域复制到 dst 指向的目标内存区域，复制方向由 kind 指定，其中 kind 可以是以下类型之一：</p><ul><li>cudaMemcpyHostToHost</li><li>cudaMemcpyHostToDevice</li><li>cudaMemcpyDeviceToHost</li><li>cudaMemcpyDeviceToDevice</li></ul></li><li><p>这个函数以同步方式执行，因为在cudaMemcpy函数返回以及传输操作完成之前主机<br> 应用程序是阻塞的。除了内核启动之外的CUDA调用都会返回一个错误的枚举类型cuda<br> Error_t。如果GPU内存分配成功，函数返回：cudaSuccess。否则返回： cudaErrorMemoryAllocation</p></li><li><p>您可以使用以下 CUDA 运行时函数将错误代码转换为人类可读的错误信息：</p><ul><li>char* cudaGetErrorString(cudaError_t error)</li><li>cudaGetErrorString 函数类似于标准 C 语言的 strerror 函数。</li></ul></li><li><p>CUDA 编程模型从 GPU 架构中抽象出内存层次结构。图 2-3 展示了一个简化的 GPU 内存结构，其中包含两个主要部分：全局内存和共享内存。您将在第 4 章和第 5 章中进一步了解 GPU 内存层次结构。</p></li></ul><br><ul><li><mark>内存层次结构</mark></li><li>CUDA编程模型最显著的一个特点就是揭示了内存层次结构。每一个GPU设备都有用<br> 于不同用途的存储类型。在第4章和第5章将会详细介绍。</li><li>在GPU内存层次结构中，最主要的两种内存是全局内存和共享内存。全局类似于CPU<br> 的系统内存，而共享内存类似于CPU的缓存。然而GPU的共享内存可以由CUDA C的内核<br> 直接控制。</li></ul><figure><img src="'+h+'" alt="figure2-3" tabindex="0" loading="lazy"><figcaption>figure2-3</figcaption></figure><ul><li>下面，我们将通过一个简单的两个数组相加的例子来学习如何在主机和设备之间进行数据传输，以及如何使用CUDA C编程。如图2-4所示，数组a的第一个元素与数组b的第一个元素相加，得到的结果作为数组c的第一个元素，重复这个过程直到数组中的所有元素都进行了一次运算。</li></ul><figure><img src="'+y+'" alt="figure2-4" tabindex="0" loading="lazy"><figcaption>figure2-4</figcaption></figure><ul><li>首先，执行主机端代码使两个数组相加（如代码清单2-1所示）。</li></ul>',22),Y={class:"hint-container details"},X=n("summary",null,"Click me to view the code!",-1),Q=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s(),n("span",{class:"token macro property"},[n("span",{class:"token directive-hash"},"#"),n("span",{class:"token directive keyword"},"include"),s(),n("span",{class:"token string"},"<stdlib.h>")]),s(`
 `),n("span",{class:"token macro property"},[n("span",{class:"token directive-hash"},"#"),n("span",{class:"token directive keyword"},"include"),s(),n("span",{class:"token string"},"<string.h>")]),s(`
 `),n("span",{class:"token macro property"},[n("span",{class:"token directive-hash"},"#"),n("span",{class:"token directive keyword"},"include"),s(),n("span",{class:"token string"},"<time.h>")]),s(`
 `),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"sumArraysOnHost"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),s("A"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),s("B"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),s("C"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"const"),s(),n("span",{class:"token keyword"},"int"),s(" N"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
   `),n("span",{class:"token keyword"},"for"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" idx"),n("span",{class:"token operator"},"="),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(" idx"),n("span",{class:"token operator"},"<"),s("N"),n("span",{class:"token punctuation"},";"),s(" idx"),n("span",{class:"token operator"},"++"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
      C`),n("span",{class:"token punctuation"},"["),s("idx"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" A"),n("span",{class:"token punctuation"},"["),s("idx"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+"),s(" B"),n("span",{class:"token punctuation"},"["),s("idx"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"initialData"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),s("ip"),n("span",{class:"token punctuation"},","),n("span",{class:"token keyword"},"int"),s(" size"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
   `),n("span",{class:"token comment"},"// generate different seed for random number"),s(`
   time_t t`),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"srand"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token function"},"time"),n("span",{class:"token punctuation"},"("),n("span",{class:"token operator"},"&"),s("t"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"for"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" i"),n("span",{class:"token operator"},"="),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(" i"),n("span",{class:"token operator"},"<"),s("size"),n("span",{class:"token punctuation"},";"),s(" i"),n("span",{class:"token operator"},"++"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
      ip`),n("span",{class:"token punctuation"},"["),s("i"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},"("),s(),n("span",{class:"token function"},"rand"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"&"),s(),n("span",{class:"token number"},"0xFF"),s(),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"/"),n("span",{class:"token number"},"10.0f"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token function"},"main"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" argc"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"char"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),s("argv"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" nElem "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"1024"),n("span",{class:"token punctuation"},";"),s(`
   size_t nBytes `),n("span",{class:"token operator"},"="),s(" nElem "),n("span",{class:"token operator"},"*"),s(),n("span",{class:"token keyword"},"sizeof"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),s("h_A"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token operator"},"*"),s("h_B"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token operator"},"*"),s("h_C"),n("span",{class:"token punctuation"},";"),s(`
   h_A `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token function"},"malloc"),n("span",{class:"token punctuation"},"("),s("nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   h_B `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token function"},"malloc"),n("span",{class:"token punctuation"},"("),s("nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   h_C `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token function"},"malloc"),n("span",{class:"token punctuation"},"("),s("nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"initialData"),n("span",{class:"token punctuation"},"("),s("h_A"),n("span",{class:"token punctuation"},","),s(" nElem"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"initialData"),n("span",{class:"token punctuation"},"("),s("h_B"),n("span",{class:"token punctuation"},","),s(" nElem"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"sumArraysOnHost"),n("span",{class:"token punctuation"},"("),s("h_A"),n("span",{class:"token punctuation"},","),s(" h_B"),n("span",{class:"token punctuation"},","),s(" h_C"),n("span",{class:"token punctuation"},","),s(" nElem"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"free"),n("span",{class:"token punctuation"},"("),s("h_A"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"free"),n("span",{class:"token punctuation"},"("),s("h_B"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"free"),n("span",{class:"token punctuation"},"("),s("h_C"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"return"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`

`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),Z=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s(`
由于这是一个纯 C 语言程序，因此可以使用 C 编译器进行编译。
你也可以用 nvcc 来编译和运行这个示例，如下所示。 它将无声地结束
 $ nvcc `),n("span",{class:"token operator"},"-"),s("Xcompiler "),n("span",{class:"token operator"},"-"),s("std"),n("span",{class:"token operator"},"="),s("c99 sumArraysOnHost"),n("span",{class:"token punctuation"},"."),s(`c –o sum
 $ `),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s(`sum


现在，你可以修改代码，在 GPU 上执行数组求和。使用 cudaMalloc 在 GPU 上分配内存。
`),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),s("d_A"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token operator"},"*"),s("d_B"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token operator"},"*"),s("d_C"),n("span",{class:"token punctuation"},";"),s(`
`),n("span",{class:"token function"},"cudaMalloc"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"&"),s("d_A"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
`),n("span",{class:"token function"},"cudaMalloc"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"&"),s("d_B"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
`),n("span",{class:"token function"},"cudaMalloc"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"&"),s("d_C"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`

使用 cudaMemcpy 将数据从主机内存传输到 GPU 全局内存，参数 cudaMemcpyHostToDevice 指定了传输方向。
 `),n("span",{class:"token function"},"cudaMemcpy"),n("span",{class:"token punctuation"},"("),s("d_A"),n("span",{class:"token punctuation"},","),s(" h_A"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},","),s(" cudaMemcpyHostToDevice"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"cudaMemcpy"),n("span",{class:"token punctuation"},"("),s("d_B"),n("span",{class:"token punctuation"},","),s(" h_B"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},","),s(" cudaMemcpyHostToDevice"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`

当数据传输到 GPU 全局存储器后，就可以从主机端调用内核函数，在 GPU 上执行数组求和。
一旦内核被调用，控制权就会立即返回主机。
此时，当内核在 GPU 上运行时，主机可以执行其他功能。
因此，内核对于主机来说是异步的。


当内核处理完 GPU 上的所有数组元素后，结果将存储在 GPU 全局内存的数组 d_C 中。
使用 cudaMemcpy 将结果从 GPU 内存复制回主机数组 gpuRef。
`),n("span",{class:"token function"},"cudaMemcpy"),n("span",{class:"token punctuation"},"("),s("gpuRef"),n("span",{class:"token punctuation"},","),s(" d_C"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},","),s(" cudaMemcpyDeviceToHost"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`



cudaMemcpy 调用会导致主机阻塞。存储在 GPU 上数组 d_C 中的结果会按照 cudaMemcpyDeviceToHost 的指定复制到 gpuRef 中。
最后，使用 cudaFree 释放 GPU 上使用的内存。
`),n("span",{class:"token function"},"cudaFree"),n("span",{class:"token punctuation"},"("),s("d_A"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
`),n("span",{class:"token function"},"cudaFree"),n("span",{class:"token punctuation"},"("),s("d_B"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
`),n("span",{class:"token function"},"cudaFree"),n("span",{class:"token punctuation"},"("),s("d_C"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`


`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),J={href:"http://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html",target:"_blank",rel:"noopener noreferrer"},nn=p('<br><ul><li><mark>不同的存储空间</mark></li><li>使用CUDA C进行编程的人最常犯的错误就是对不同内存空间的不恰当引用。对于在<br> GPU上被分配的内存来说，设备指针在主机代码中可能并没有被引用。如果你执行了错误<br> 的内存分配，如： <ul><li>gpuRef = d_C</li></ul></li><li>而不是用： <ul><li>cudaMemcpy(gpuRef, d_C, nBytes, cudaMemcpyDeviceToHost)</li></ul></li><li>the application will crash at runtime. 应用程序就会在运行时崩溃。</li><li>为了避免这类错误，CUDA 6.0提出了统一寻址，使用一个指针来访问CPU和GPU的内<br> 存。有关统一寻址的内容详见第4章。</li></ul><h3 id="_2-1-3-线程管理" tabindex="-1"><a class="header-anchor" href="#_2-1-3-线程管理" aria-hidden="true">#</a> 2.1.3 线程管理</h3><p>Organizing Threads</p><ul><li>当核函数在主机端启动时，它的执行会移动到设备上，此时设备中会产生大量的线程<br> 并且每个线程都执行由核函数指定的语句。了解如何组织线程是CUDA编程的一个关键部<br> 分。CUDA明确了线程层次抽象的概念以便于你组织线程。这是一个两层的线程层次结<br> 构，由线程块和线程块网格构成，如图2-5所示。</li></ul><figure><img src="'+g+'" alt="figure2-5" tabindex="0" loading="lazy"><figcaption>figure2-5</figcaption></figure><ul><li><p>由一个内核启动所产生的所有线程统称为一个网格。同一网格中的所有线程共享相同<br> 的全局内存空间。一个网格由多个线程块构成，一个线程块包含一组线程，同一线程块内<br> 的线程协作可以通过以下方式来实现。</p><ul><li>Block-local synchronization：同步(所以好像块内经常使用 块内同步？)</li><li>Block-local shared memory：块共享内存</li></ul></li><li><p>不同块内的线程不能协作。</p></li><li><p>线程依靠以下两个坐标变量来区分彼此。</p><ul><li>blockIdx（线程块在线程格内的索引）</li><li>threadIdx（块内的线程索引）</li></ul></li><li><p>这些变量是核函数中需要预初始化的内置变量。当执行一个核函数时，CUDA运行时<br> 为每个线程分配坐标变量blockIdx和threadIdx。基于这些坐标，你可以将部分数据分配给不同的线程。</p></li><li><p>该坐标变量是基于uint3定义的CUDA内置的向量类型，是一个包含3个无符号整数的<br> 结构，可以通过x、y、z三个字段来指定。</p><ul><li>blockIdx.x</li><li>blockIdx.y</li><li>blockIdx.z</li><li>threadIdx.x</li><li>threadIdx.y</li><li>threadIdx.z</li></ul></li><li><p>CUDA可以组织三维的网格和块。图2-5展示了一个线程层次结构的示例，其结构是<br> 一个包含二维块的二维网格。网格和块的维度由下列两个内置变量指定。</p><ul><li>blockDim (block dimension, measured in threads)blockDim（线程块的维度，用每个线程块中的线程数来表示）</li><li>gridDim (grid dimension, measured in blocks)gridDim（线程格的维度，用每个线程格中的线程数来表示）</li></ul></li><li><p>它们是dim3类型的变量，是基于uint3定义的整数型向量，用来表示维度。当定义一个<br> dim3类型的变量时，所有未指定的元素都被初始化为1。dim3类型变量中的每个组件可以<br> 通过它的x、y、z字段获得。如下所示。</p><ul><li>blockDim.x</li><li>blockDim.y</li><li>blockDim.z</li></ul></li><li><p><mark>网格和线程块的维度</mark></p></li><li><p>通常，一个线程格会被组织成线程块的二维数组形式，一个线程块会被组织成线程的<br> 三维数组形式。</p></li><li><p>线程格和线程块均使用3个dim3类型的无符号整型字段，而未使用的字段将被初始化<br> 为1且忽略不计。(3,1,1) = (3);</p></li></ul><br>',8),sn=p("<li><p>在CUDA程序中有两组不同的网格和块变量：手动定义的dim3数据类型和预定义的<br> uint3数据类型。在主机端，作为内核调用的一部分，你可以使用dim3数据类型定义一个网格和块的维度。</p></li><li><p>当执行核函数时，CUDA运行时会生成相应的内置预初始化的网格、块和<br> 线程变量，它们在核函数内均可被访问到且为unit3类型。手动定义的dim3类型的网格和块变量仅在主机端可见，而unit3类型的内置预初始化的网格和块变量仅在设备端可见。</p></li><li><p>你可以通过代码清单2-2来验证这些变量如何使用。首先，定义程序所用的数据大<br> 小，为了对此进行说明，我们定义一个较小的数据。</p><ul><li>int nElem = 6;</li></ul></li><li><p>接下来，定义块的尺寸并基于块和数据的大小计算网格尺寸。在下面的例子中，定义<br> 了一个包含3个线程的一维线程块，以及一个基于块和数据大小定义的一定数量线程块的<br> 一维线程网格。(<mark>这里是根据数据规模进行组织规划线程的，但是实际中可能不是这样的？</mark>)</p><ul><li>dim3 block(3);</li><li>dim3 grid((nElem+block.x-1)/block.x);</li></ul></li><li><p>您可能已经注意到，网格大小四舍五入为块大小的倍数。在下一章中，你将了解为什么必须以这种方式计算网格大小。下面的代码段在主机端检查网格和区块的尺寸：</p><ul><li>printf(&quot;grid.x %d grid.y %d grid.z %d\\n&quot;,grid.x, grid.y, grid.z);</li><li>printf(&quot;block.x %d block.y %d block.z %d\\n&quot;,block.x, block.y, block.z);</li></ul></li><li><p>在内核函数中，每个线程都会打印出自己的线程索引、块索引、块维度和网格维度，如下所示：</p><ul><li>printf(&quot;threadIdx:(%d, %d, %d) blockIdx:(%d, %d, %d) blockDim:(%d, %d, %d) &quot;<br> &quot;gridDim:(%d, %d, %d)\\n&quot;, threadIdx.x, threadIdx.y, threadIdx.z,<br> blockIdx.x, blockIdx.y, blockIdx.z, blockDim.x, blockDim.y, blockDim.z,<br> gridDim.x,gridDim.y,gridDim.z);</li></ul></li>",6),an={href:"http://checkDimension.cu",target:"_blank",rel:"noopener noreferrer"},tn={class:"hint-container details"},en=n("summary",null,"Click me to view the code!",-1),on=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s(),n("span",{class:"token macro property"},[n("span",{class:"token directive-hash"},"#"),n("span",{class:"token directive keyword"},"include"),s(),n("span",{class:"token string"},"<cuda_runtime.h>")]),s(`
 `),n("span",{class:"token macro property"},[n("span",{class:"token directive-hash"},"#"),n("span",{class:"token directive keyword"},"include"),s(),n("span",{class:"token string"},"<stdio.h>")]),s(`
 __global__ `),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"checkIndex"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"void"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
    `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"threadIdx:(%d, %d, %d)  blockIdx:(%d, %d, %d)  blockDim:(%d, %d, %d) "'),s(`
        `),n("span",{class:"token string"},'"gridDim:(%d, %d, %d)\\n"'),n("span",{class:"token punctuation"},","),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("y"),n("span",{class:"token punctuation"},","),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("z"),n("span",{class:"token punctuation"},","),s(`
        blockIdx`),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("y"),n("span",{class:"token punctuation"},","),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("z"),n("span",{class:"token punctuation"},","),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("y"),n("span",{class:"token punctuation"},","),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("z"),n("span",{class:"token punctuation"},","),s(`
        gridDim`),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s("gridDim"),n("span",{class:"token punctuation"},"."),s("y"),n("span",{class:"token punctuation"},","),s("gridDim"),n("span",{class:"token punctuation"},"."),s("z"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token function"},"main"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" argc"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"char"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),s("argv"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
   `),n("span",{class:"token comment"},"// define total data element"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" nElem "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"6"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// define grid and block structure"),s(`
   dim3 `),n("span",{class:"token function"},"block"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"3"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   dim3 `),n("span",{class:"token function"},"grid"),s("  "),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),s("nElem"),n("span",{class:"token operator"},"+"),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"-"),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"/"),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// check grid and block dimension from host side"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"grid.x %d grid.y %d grid.z %d\\n"'),n("span",{class:"token punctuation"},","),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s(" grid"),n("span",{class:"token punctuation"},"."),s("y"),n("span",{class:"token punctuation"},","),s(" grid"),n("span",{class:"token punctuation"},"."),s("z"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"block.x %d block.y %d block.z %d\\n"'),n("span",{class:"token punctuation"},","),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token punctuation"},"."),s("y"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token punctuation"},"."),s("z"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// check grid and block dimension from device side"),s(`
   checkIndex `),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// reset device before you leave"),s(`
   `),n("span",{class:"token function"},"cudaDeviceReset"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"return"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`

`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),cn=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s(" Now you are ready to compile "),n("span",{class:"token operator"},"and"),s(" run "),n("span",{class:"token keyword"},"this"),s(" example "),n("span",{class:"token keyword"},"using"),n("span",{class:"token operator"},":"),s(`
 $ nvcc `),n("span",{class:"token operator"},"-"),s("arch"),n("span",{class:"token operator"},"="),s("sm_20 checkDimension"),n("span",{class:"token punctuation"},"."),s("cu "),n("span",{class:"token operator"},"-"),s(`o check
 $ `),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s(`check


 由于 printf 函数仅支持从 Fermi GPU 开始的架构，因此必须添加 `),n("span",{class:"token operator"},"-"),s("arch"),n("span",{class:"token operator"},"="),s(`sm_20 编译器选项。
 默认情况下，nvcc 将为最低的 GPU 架构生成代码。该应用的结果如下所示。
 可以看到，每个线程都有自己的坐标，所有线程的块维度和网格维度都相同。
grid`),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token number"},"2"),s(" grid"),n("span",{class:"token punctuation"},"."),s("y "),n("span",{class:"token number"},"1"),s(" grid"),n("span",{class:"token punctuation"},"."),s("z "),n("span",{class:"token number"},"1"),s(`
block`),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token number"},"3"),s(" block"),n("span",{class:"token punctuation"},"."),s("y "),n("span",{class:"token number"},"1"),s(" block"),n("span",{class:"token punctuation"},"."),s("z "),n("span",{class:"token number"},"1"),s(`
threadIdx`),n("span",{class:"token operator"},":"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s("  blockIdx"),n("span",{class:"token operator"},":"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s(" blockDim"),n("span",{class:"token operator"},":"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"3"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),s(" gridDim"),n("span",{class:"token operator"},":"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"2"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),s(`
threadIdx`),n("span",{class:"token operator"},":"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s("  blockIdx"),n("span",{class:"token operator"},":"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s(" blockDim"),n("span",{class:"token operator"},":"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"3"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),s(" gridDim"),n("span",{class:"token operator"},":"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"2"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),s(`
threadIdx`),n("span",{class:"token operator"},":"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"2"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s("  blockIdx"),n("span",{class:"token operator"},":"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s(" blockDim"),n("span",{class:"token operator"},":"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"3"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),s(" gridDim"),n("span",{class:"token operator"},":"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"2"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),s(`
threadIdx`),n("span",{class:"token operator"},":"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s("  blockIdx"),n("span",{class:"token operator"},":"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s(" blockDim"),n("span",{class:"token operator"},":"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"3"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),s(" gridDim"),n("span",{class:"token operator"},":"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"2"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),s(`
threadIdx`),n("span",{class:"token operator"},":"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s("  blockIdx"),n("span",{class:"token operator"},":"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s(" blockDim"),n("span",{class:"token operator"},":"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"3"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),s(" gridDim"),n("span",{class:"token operator"},":"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"2"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),s(`
threadIdx`),n("span",{class:"token operator"},":"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"2"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s("  blockIdx"),n("span",{class:"token operator"},":"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s(" blockDim"),n("span",{class:"token operator"},":"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"3"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),s(" gridDim"),n("span",{class:"token operator"},":"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"2"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),s(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),pn=p(`<ul><li><mark>从主机端和设备端访问网格/块变量</mark></li><li>区分主机端和设备端的网格和块变量的访问是很重要的。例如，声明一个主机端的块变量，你按如下定义它的坐标并对其进行访问： <ul><li>block.x, block.y, and block.z</li></ul></li><li>在设备方面，您可以使用预先初始化的内置块大小变量： <ul><li><pre><code>blockDim.x, blockDim.y, and blockDim.z
</code></pre></li></ul></li><li>总之，在启动内核前，需要在主机上定义网格和块的变量，并在主机端使用向量结构的 x、y 和 z 字段访问它们。启动内核后，就可以在内核中使用预先初始化的内置变量。</li></ul><br><ul><li><mark>对于给定的数据大小，确定网格和区块尺寸的一般步骤是</mark></li><li><mark>这些感觉都是对与普通的模式的设计的</mark><ul><li>Decide the block size.确定块的大小</li><li>Calculate the grid dimension based on the application data size and the block size.在已知数据大小和块大小的基础上计算网格维度</li></ul></li><li>要确定block dimension，通常需要考虑以下因素： <ul><li>Performance characteristics of the kernel内核的性能特性</li><li>Limitations on GPU resources GPU资源的限制</li></ul></li><li>本书的后续章节会对以上几点因素进行详细介绍。代码清单2-3使用了一个一维网格<br> 和一个一维块来说明当块的大小改变时，网格的尺寸也会随之改变。</li></ul>`,3),ln={class:"hint-container details"},un=n("summary",null,"Click me to view the code!",-1),rn=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s(),n("span",{class:"token macro property"},[n("span",{class:"token directive-hash"},"#"),n("span",{class:"token directive keyword"},"include"),s(),n("span",{class:"token string"},"<cuda_runtime.h>")]),s(`
 `),n("span",{class:"token macro property"},[n("span",{class:"token directive-hash"},"#"),n("span",{class:"token directive keyword"},"include"),s(),n("span",{class:"token string"},"<stdio.h>")]),s(`
 `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token function"},"main"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" argc"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"char"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),s("argv"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
   `),n("span",{class:"token comment"},"// define total data elements"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" nElem "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"1024"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// define grid and block structure"),s(`
   dim3 `),n("span",{class:"token function"},"block"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"1024"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   dim3 `),n("span",{class:"token function"},"grid"),s("  "),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),s("nElem"),n("span",{class:"token operator"},"+"),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"-"),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"/"),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"grid.x %d block.x %d \\n"'),n("span",{class:"token punctuation"},","),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// reset block"),s(`
   block`),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"512"),n("span",{class:"token punctuation"},";"),s(`
   grid`),n("span",{class:"token punctuation"},"."),s("x  "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),s("nElem"),n("span",{class:"token operator"},"+"),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"-"),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"/"),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"grid.x %d block.x %d \\n"'),n("span",{class:"token punctuation"},","),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// reset block"),s(`
   block`),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"256"),n("span",{class:"token punctuation"},";"),s(`
   grid`),n("span",{class:"token punctuation"},"."),s("x  "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),s("nElem"),n("span",{class:"token operator"},"+"),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"-"),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"/"),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"grid.x %d block.x %d \\n"'),n("span",{class:"token punctuation"},","),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// reset block"),s(`
   block`),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"128"),n("span",{class:"token punctuation"},";"),s(`
   grid`),n("span",{class:"token punctuation"},"."),s("x  "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),s("nElem"),n("span",{class:"token operator"},"+"),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"-"),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"/"),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"grid.x %d block.x %d \\n"'),n("span",{class:"token punctuation"},","),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// reset device before you leave"),s(`
   `),n("span",{class:"token function"},"cudaDeviceReset"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"return"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),kn=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s("Compile "),n("span",{class:"token operator"},"and"),s(" run "),n("span",{class:"token keyword"},"this"),s(" example with the following command"),n("span",{class:"token operator"},":"),s(`
$ nvcc defineGridBlock`),n("span",{class:"token punctuation"},"."),s("cu "),n("span",{class:"token operator"},"-"),s(`o block
$ `),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s(`block

以下是输出示例。由于应用程序数据大小是固定的，因此当数据块大小发生变化时，网格大小也会相应变化。
 grid`),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token number"},"1"),s(" block"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token number"},"1024"),s(`
 grid`),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token number"},"2"),s(" block"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token number"},"512"),s(`
 grid`),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token number"},"4"),s(" block"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token number"},"256"),s(`
 grid`),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token number"},"8"),s(" block"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token number"},"128"),s(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),dn=p('<ul><li><mark>线程层次结构</mark></li><li>CUDA的特点之一就是通过编程模型揭示了一个两层的线程层次结构。由于一个内核<br> 启动的网格和块的维数会影响性能，这一结构为程序员优化程序提供了一个额外的途径。</li><li>网格和块的维度存在几个限制因素，对于块大小的一个主要限制因素就是可利用的计<br> 算资源，如寄存器，共享内存等。某些限制可以通过查询GPU设备撤回。比如一个block最大可能是1024</li><li>网格和块从逻辑上代表了一个核函数的线程层次结构。在第3章中，你会发现这种线<br> 程组织方式能使你在不同的设备上有效地执行相同的程序代码，而且每一个线程组织具有<br> 不同数量的计算和内存资源。</li></ul><h3 id="_2-1-4-启动一个cuda核函数" tabindex="-1"><a class="header-anchor" href="#_2-1-4-启动一个cuda核函数" aria-hidden="true">#</a> 2.1.4 启动一个CUDA核函数</h3><p>Launching a CUDA Kernel</p><ul><li>您已熟悉以下 C 函数调用语法： <ul><li>function_name (argument list);</li></ul></li><li>CUDA内核调用是对C语言函数调用语句的延伸，&lt;&lt;&lt;&gt;&gt;&gt;运算符内是核函数的执行配置。 <ul><li>kernel_name &lt;&lt;&lt;grid, block&gt;&gt;&gt;(argument list);</li></ul></li><li>正如上一节所述，CUDA编程模型揭示了线程层次结构。利用执行配置可以指定线程<br> 在GPU上调度运行的方式。执行配置的第一个值是网格维度，也就是启动块的数目。第二<br> 个值是块维度，也就是每个块中线程的数目。通过指定网格和块的维度，你可以进行以下<br> 配置： <ul><li>The total number of threads for a kernel内核中线程的数目</li><li>The layout of the threads you want to employ for a kernel内核中使用的线程布局</li></ul></li><li>同一个块中的线程之间可以相互协作，不同块内的线程不能协作。对于一个给定的问题，可以使用不同的网格和块布局来组织你的线程。例如，假设你有32个数据元素用于计算，每8个元素一个块，需要启动4个块： <ul><li>kernel_name &lt;&lt;&lt;4, 8&gt;&gt;&gt;(argument list);</li></ul></li><li>Figure 2-6 illustrates the layout of threads in the above configuration.</li></ul><figure><img src="'+_+`" alt="figure2-6" tabindex="0" loading="lazy"><figcaption>figure2-6</figcaption></figure><ul><li><p>由于数据是线性存储在全局内存中，因此可以使用内置变量 blockIdx.x 和 threadIdx.x：</p><ul><li>Identify a unique thread in the grid在网格中标识一个唯一的线程</li><li>Establish a mapping between threads and data elements建立线程和数据元素之间的映射关系</li></ul></li><li><p>如果将所有 32 个元素都归入一个区块，那么就只有一个区块，如下所示</p><ul><li>kernel_name&lt;&lt;&lt;1, 32&gt;&gt;&gt;(argument list);</li></ul></li><li><p>If you let each block just have one element, you have 32 blocks as follows:<br> - kernel_name&lt;&lt;&lt;32, 1&gt;&gt;&gt;(argument list);</p></li><li><p>内核调用与主机线程是异步的。调用内核后，控制权会立即返回主机端。您可以调用以下函数，强制主机应用程序等待所有内核调用完成。</p><ul><li>cudaError_t cudaDeviceSynchronize(void);</li></ul></li><li><p>某些 CUDA 运行时 API 会在主机和设备之间执行隐式同步。当您使用 cudaMemcpy 在主机和设备之间复制数据时，主机端会执行隐式同步，主机应用程序必须等待数据复制完成。</p><ul><li>cudaError_t cudaMemcpy(void* dst, const void* src, size_t count, cudaMemcpyKind kind);</li></ul></li><li><p>在之前的内核调用全部完成后，它才开始复制。复制完成后，控制权立即返回主机端。</p></li><li><p><mark>异步行为</mark></p></li><li><p>与 C 函数调用不同，所有 CUDA 内核启动都是异步的。调用 CUDA 内核后，控制权会立即返回 CPU。</p></li></ul><h3 id="_2-1-5-编写核函数" tabindex="-1"><a class="header-anchor" href="#_2-1-5-编写核函数" aria-hidden="true">#</a> 2.1.5 编写核函数</h3><p>Writing Your Kernel</p><ul><li>核函数是在设备端执行的代码。在核函数中，需要为一个线程规定要进行的计算以及要进行的数据访问。当核函数被调用时，许多不同的CUDA线程并行执行同一个计算任<br> 务。以下是用__global__声明定义核函数： <ul><li><strong>global</strong> void kernel_name(argument list);</li></ul></li><li>A kernel function must have a void return type.</li><li>表2-2总结了CUDA C程序中的函数类型限定符。函数类型限定符指定一个函数在主机<br> 上执行还是在设备上执行，以及可被主机调用还是被设备调用。</li><li><mark>TABLE 2-2: Function Type Qualifiers</mark></li><li><strong>device</strong> 和 <strong>host</strong> 限定符可以一起使用，在这种情况下，函数将同时针对主机和设备进行编译。</li><li><mark>CUDA KERNELS ARE FUNCTIONS WITH RESTRICTIONS</mark></li><li>The following restrictions apply for all kernels: <ul><li>Access to device memory only只能访问设备内存(就算是固定页内存也是CPU内存)</li><li>Must have void return type必须是无效返回类型</li><li>No support for a variable number of arguments 不支持参数数量可变</li><li>No support for static variables 不支持静态变量</li><li>No support for function pointers 不支持函数指针</li><li>Exhibit an asynchronous behavior 表现出异步行为</li></ul></li><li>下面给出了在主机上进行向量加法运算的 C 代码：<br> void sumArraysOnHost(float *A, float *B, float *C, const int N) {<br> for (int i = 0; i &lt; N; i++)<br> C[i] = A[i] + B[i];<br> }</li><li>这是一个迭代 N 次的顺序代码。剥离循环将产生以下内核函数：<br><strong>global</strong> void sumArraysOnGPU(float *A, float *B, float *C) {<br> int i = threadIdx.x;<br> C[i] = A[i] + B[i];<br> }</li><li>C 函数和内核函数有什么不同？你会发现缺少了循环，使用内置线程坐标变量代替了数组索引，而且没有引用 N，因为它是通过只启动 N 个线程来隐式定义的。</li><li>Supposing a vector with the length of 32 elements, you can invoke the kernel with 32 threads as follows:</li><li>假设有一个长度为32个元素的向量，你可以按以下方法用32个线程来调用核函数： <ul><li>sumArraysOnGPU&lt;&lt;&lt;1,32&gt;&gt;&gt;(float *A, float *B, float *C);</li></ul></li></ul><h3 id="_2-1-6-验证核函数" tabindex="-1"><a class="header-anchor" href="#_2-1-6-验证核函数" aria-hidden="true">#</a> 2.1.6 验证核函数</h3><p>Verifying Your Kernel</p><ul><li>现在您已经编写了内核，但如何知道它是否能正常运行呢？你需要一个主机函数来验证内核的结果:</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">void</span> <span class="token function">checkResult</span><span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span>hostRef<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>gpuRef<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">int</span> N<span class="token punctuation">)</span> <span class="token punctuation">{</span>
   <span class="token keyword">double</span> epsilon <span class="token operator">=</span> <span class="token number">1.0E-8</span><span class="token punctuation">;</span>
   <span class="token keyword">int</span> match <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>
   <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
      <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">abs</span><span class="token punctuation">(</span>hostRef<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">-</span> gpuRef<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> epsilon<span class="token punctuation">)</span> <span class="token punctuation">{</span>
         match <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
         <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">&quot;Arrays do not match!\\n&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
         <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">&quot;host %5.2f gpu %5.2f at current %d\\n&quot;</span><span class="token punctuation">,</span>
            hostRef<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> gpuRef<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> i<span class="token punctuation">)</span><span class="token punctuation">;</span>
         <span class="token keyword">break</span><span class="token punctuation">;</span>
      <span class="token punctuation">}</span>
   <span class="token punctuation">}</span>
   <span class="token keyword">if</span> <span class="token punctuation">(</span>match<span class="token punctuation">)</span> <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">&quot;Arrays match.\\n\\n&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
   <span class="token keyword">return</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><mark>验证核函数代码</mark></li><li>除了许多有用的调试工具外，还有两种非常基本但有用的方法可以验证内核代码。</li><li>首先，您可以在内核中使用 printf 来处理 Fermi 和更新一代的设备。</li><li>其次，可以将执行配置设置为 &lt;&lt;&lt;1,1&gt;&gt;&gt;，这样就可以强制内核只运行一个程序块和一个线程。这可以模拟顺序执行。这对调试和验证正确结果非常有用。此外，如果遇到运算顺序问题，这还有助于验证数字结果在运行过程中的位精确性。</li></ul><h3 id="_2-1-7-处理错误" tabindex="-1"><a class="header-anchor" href="#_2-1-7-处理错误" aria-hidden="true">#</a> 2.1.7 处理错误</h3><p>Handling Errors</p><ul><li>由于许多 CUDA 调用都是异步的，因此可能很难确定是哪个例程导致了错误。定义一个错误处理宏来封装所有的 CUDA API 调用，可以简化错误检查过程:</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name function">CHECK</span><span class="token expression"><span class="token punctuation">(</span>call<span class="token punctuation">)</span>                                                       </span><span class="token punctuation">\\</span>
 <span class="token expression"><span class="token punctuation">{</span>                                                                         </span><span class="token punctuation">\\</span>
   <span class="token expression"><span class="token keyword">const</span> cudaError_t error <span class="token operator">=</span> call<span class="token punctuation">;</span>                                        </span><span class="token punctuation">\\</span>
   <span class="token expression"><span class="token keyword">if</span> <span class="token punctuation">(</span>error <span class="token operator">!=</span> cudaSuccess<span class="token punctuation">)</span>                                              </span><span class="token punctuation">\\</span>
   <span class="token expression"><span class="token punctuation">{</span>                                                                      </span><span class="token punctuation">\\</span>
      <span class="token expression"><span class="token function">printf</span><span class="token punctuation">(</span></span><span class="token string">&quot;Error: %s:%d, &quot;</span><span class="token expression"><span class="token punctuation">,</span> <span class="token constant">__FILE__</span><span class="token punctuation">,</span> <span class="token constant">__LINE__</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                       </span><span class="token punctuation">\\</span>
      <span class="token expression"><span class="token function">printf</span><span class="token punctuation">(</span></span><span class="token string">&quot;code:%d, reason: %s\\n&quot;</span><span class="token expression"><span class="token punctuation">,</span> error<span class="token punctuation">,</span> <span class="token function">cudaGetErrorString</span><span class="token punctuation">(</span>error<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  </span><span class="token punctuation">\\</span>
      <span class="token expression"><span class="token function">exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                                                            </span><span class="token punctuation">\\</span>
   <span class="token expression"><span class="token punctuation">}</span>                                                                      </span><span class="token punctuation">\\</span>
 <span class="token expression"><span class="token punctuation">}</span></span></span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>For example, you can use the macro on the following code:<br> - CHECK(cudaMemcpy(d_C, gpuRef, nBytes, cudaMemcpyHostToDevice));</li><li>如果内存复制或之前的异步操作导致错误，宏会报告错误代码，打印人可读信息，然后停止程序。在调用内核后，还可以使用该宏检查内核是否出错：<br> - kernel_function&lt;&lt;&lt;grid, block&gt;&gt;&gt;(argument list);<br> - CHECK(cudaDeviceSynchronize());</li><li>CHECK(cudaDeviceSynchronize())会阻塞主机线程，直到设备完成之前请求的所有任务，并确保上次内核启动时没有发生错误。此技术应仅用于调试目的，因为在内核启动后添加此检查点会阻塞主机线程，并使该点成为全局屏障.(因为说到底这个CHECK还是CPU的host代码)</li></ul><h3 id="_2-1-8-编译和执行" tabindex="-1"><a class="header-anchor" href="#_2-1-8-编译和执行" aria-hidden="true">#</a> 2.1.8 编译和执行</h3><p>Compiling and Executing</p>`,21),mn={href:"http://sumArraysOnGPU-small-case.cu",target:"_blank",rel:"noopener noreferrer"},bn={class:"hint-container details"},vn=n("summary",null,"Click me to view the code!",-1),fn=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s(),n("span",{class:"token macro property"},[n("span",{class:"token directive-hash"},"#"),n("span",{class:"token directive keyword"},"include"),s(),n("span",{class:"token string"},"<cuda_runtime.h>")]),s(`
 `),n("span",{class:"token macro property"},[n("span",{class:"token directive-hash"},"#"),n("span",{class:"token directive keyword"},"include"),s(),n("span",{class:"token string"},"<stdio.h>")]),s(`
 `),n("span",{class:"token macro property"},[n("span",{class:"token directive-hash"},"#"),n("span",{class:"token directive keyword"},"define"),s(),n("span",{class:"token macro-name function"},"CHECK"),n("span",{class:"token expression"},[n("span",{class:"token punctuation"},"("),s("call"),n("span",{class:"token punctuation"},")"),s("                                                      ")]),n("span",{class:"token punctuation"},"\\"),s(`
 `),n("span",{class:"token expression"},[n("span",{class:"token punctuation"},"{"),s("                                                                        ")]),n("span",{class:"token punctuation"},"\\"),s(`
   `),n("span",{class:"token expression"},[n("span",{class:"token keyword"},"const"),s(" cudaError_t error "),n("span",{class:"token operator"},"="),s(" call"),n("span",{class:"token punctuation"},";"),s("                                       ")]),n("span",{class:"token punctuation"},"\\"),s(`
   `),n("span",{class:"token expression"},[n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("error "),n("span",{class:"token operator"},"!="),s(" cudaSuccess"),n("span",{class:"token punctuation"},")"),s("                                             ")]),n("span",{class:"token punctuation"},"\\"),s(`
   `),n("span",{class:"token expression"},[n("span",{class:"token punctuation"},"{"),s("                                                                     ")]),n("span",{class:"token punctuation"},"\\"),s(`
      `),n("span",{class:"token expression"},[n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"(")]),n("span",{class:"token string"},'"Error: %s:%d, "'),n("span",{class:"token expression"},[n("span",{class:"token punctuation"},","),s(),n("span",{class:"token constant"},"__FILE__"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token constant"},"__LINE__"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s("                      ")]),n("span",{class:"token punctuation"},"\\"),s(`
      `),n("span",{class:"token expression"},[n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"(")]),n("span",{class:"token string"},'"code:%d, reason: %s\\n"'),n("span",{class:"token expression"},[n("span",{class:"token punctuation"},","),s(" error"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token function"},"cudaGetErrorString"),n("span",{class:"token punctuation"},"("),s("error"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s()]),n("span",{class:"token punctuation"},"\\"),s(`
      `),n("span",{class:"token expression"},[n("span",{class:"token function"},"exit"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s("                                                           ")]),n("span",{class:"token punctuation"},"\\"),s(`
   `),n("span",{class:"token expression"},[n("span",{class:"token punctuation"},"}"),s("                                                                     ")]),n("span",{class:"token punctuation"},"\\"),s(`
 `),n("span",{class:"token expression"},[n("span",{class:"token punctuation"},"}")])]),s(`
 `),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"checkResult"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),s("hostRef"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),s("gpuRef"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"const"),s(),n("span",{class:"token keyword"},"int"),s(" N"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
   `),n("span",{class:"token keyword"},"double"),s(" epsilon "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"1.0E-8"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"bool"),s(" match "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"for"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" i"),n("span",{class:"token operator"},"="),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(" i"),n("span",{class:"token operator"},"<"),s("N"),n("span",{class:"token punctuation"},";"),s(" i"),n("span",{class:"token operator"},"++"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
      `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token function"},"abs"),n("span",{class:"token punctuation"},"("),s("hostRef"),n("span",{class:"token punctuation"},"["),s("i"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"-"),s(" gpuRef"),n("span",{class:"token punctuation"},"["),s("i"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},">"),s(" epsilon"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
         match `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(`
         `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"Arrays do not match!\\n"'),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
         `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"host %5.2f gpu %5.2f at current %d\\n"'),n("span",{class:"token punctuation"},","),s("hostRef"),n("span",{class:"token punctuation"},"["),s("i"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},","),s("gpuRef"),n("span",{class:"token punctuation"},"["),s("i"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},","),s("i"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
         `),n("span",{class:"token keyword"},"break"),n("span",{class:"token punctuation"},";"),s(`
      `),n("span",{class:"token punctuation"},"}"),s(`
   `),n("span",{class:"token punctuation"},"}"),s(`
   `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("match"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"Arrays match.\\n\\n"'),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"initialData"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),s("ip"),n("span",{class:"token punctuation"},","),n("span",{class:"token keyword"},"int"),s(" size"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
   `),n("span",{class:"token comment"},"// generate different seed for random number"),s(`
   time_t t`),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"srand"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"unsigned"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token function"},"time"),n("span",{class:"token punctuation"},"("),n("span",{class:"token operator"},"&"),s("t"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"for"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" i"),n("span",{class:"token operator"},"="),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(" i"),n("span",{class:"token operator"},"<"),s("size"),n("span",{class:"token punctuation"},";"),s(" i"),n("span",{class:"token operator"},"++"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
      ip`),n("span",{class:"token punctuation"},"["),s("i"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},"("),s(),n("span",{class:"token function"},"rand"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"&"),s(),n("span",{class:"token number"},"0xFF"),s(),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"/"),n("span",{class:"token number"},"10.0f"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"sumArraysOnHost"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),s("A"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),s("B"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),s("C"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"const"),s(),n("span",{class:"token keyword"},"int"),s(" N"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
   `),n("span",{class:"token keyword"},"for"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" idx"),n("span",{class:"token operator"},"="),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(" idx"),n("span",{class:"token operator"},"<"),s("N"),n("span",{class:"token punctuation"},";"),s(" idx"),n("span",{class:"token operator"},"++"),n("span",{class:"token punctuation"},")"),s(`
      C`),n("span",{class:"token punctuation"},"["),s("idx"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" A"),n("span",{class:"token punctuation"},"["),s("idx"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+"),s(" B"),n("span",{class:"token punctuation"},"["),s("idx"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 __global__ `),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"sumArraysOnGPU"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),s("A"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),s("B"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),s("C"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" i "),n("span",{class:"token operator"},"="),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
   C`),n("span",{class:"token punctuation"},"["),s("i"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" A"),n("span",{class:"token punctuation"},"["),s("i"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+"),s(" B"),n("span",{class:"token punctuation"},"["),s("i"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token function"},"main"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" argc"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"char"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),s("argv"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"%s Starting...\\n"'),n("span",{class:"token punctuation"},","),s(" argv"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// set up device"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" dev "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaSetDevice"),n("span",{class:"token punctuation"},"("),s("dev"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// set up data size of vectors"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" nElem "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"32"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"Vector size %d\\n"'),n("span",{class:"token punctuation"},","),s(" nElem"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// malloc host memory"),s(`
   size_t nBytes `),n("span",{class:"token operator"},"="),s(" nElem "),n("span",{class:"token operator"},"*"),s(),n("span",{class:"token keyword"},"sizeof"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),s("h_A"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token operator"},"*"),s("h_B"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token operator"},"*"),s("hostRef"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token operator"},"*"),s("gpuRef"),n("span",{class:"token punctuation"},";"),s(`
   h_A     `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token function"},"malloc"),n("span",{class:"token punctuation"},"("),s("nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   h_B     `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token function"},"malloc"),n("span",{class:"token punctuation"},"("),s("nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   hostRef `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token function"},"malloc"),n("span",{class:"token punctuation"},"("),s("nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   gpuRef  `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token function"},"malloc"),n("span",{class:"token punctuation"},"("),s("nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
`),n("span",{class:"token comment"},"// initialize data at host side"),s(`
   `),n("span",{class:"token function"},"initialData"),n("span",{class:"token punctuation"},"("),s("h_A"),n("span",{class:"token punctuation"},","),s(" nElem"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"initialData"),n("span",{class:"token punctuation"},"("),s("h_B"),n("span",{class:"token punctuation"},","),s(" nElem"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"memset"),n("span",{class:"token punctuation"},"("),s("hostRef"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"memset"),n("span",{class:"token punctuation"},"("),s("gpuRef"),n("span",{class:"token punctuation"},","),s("  "),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// malloc device global memory"),s(`
   `),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),s("d_A"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token operator"},"*"),s("d_B"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token operator"},"*"),s("d_C"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaMalloc"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"&"),s("d_A"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaMalloc"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"&"),s("d_B"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaMalloc"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"&"),s("d_C"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// transfer data from host to device"),s(`
   `),n("span",{class:"token function"},"cudaMemcpy"),n("span",{class:"token punctuation"},"("),s("d_A"),n("span",{class:"token punctuation"},","),s(" h_A"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},","),s(" cudaMemcpyHostToDevice"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaMemcpy"),n("span",{class:"token punctuation"},"("),s("d_B"),n("span",{class:"token punctuation"},","),s(" h_B"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},","),s(" cudaMemcpyHostToDevice"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// invoke kernel at host side"),s(`
   dim3 `),n("span",{class:"token function"},"block"),s(),n("span",{class:"token punctuation"},"("),s("nElem"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   dim3 `),n("span",{class:"token function"},"grid"),s("  "),n("span",{class:"token punctuation"},"("),s("nElem"),n("span",{class:"token operator"},"/"),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   sumArraysOnGPU`),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s(" grid"),n("span",{class:"token punctuation"},","),s(" block  "),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),n("span",{class:"token punctuation"},"("),s("d_A"),n("span",{class:"token punctuation"},","),s(" d_B"),n("span",{class:"token punctuation"},","),s(" d_C"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"Execution configuration <<<%d, %d>>>\\n"'),n("span",{class:"token punctuation"},","),s("grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// copy kernel result back to host side"),s(`
   `),n("span",{class:"token function"},"cudaMemcpy"),n("span",{class:"token punctuation"},"("),s("gpuRef"),n("span",{class:"token punctuation"},","),s(" d_C"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},","),s(" cudaMemcpyDeviceToHost"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// add vector at host side for result checks"),s(`
   `),n("span",{class:"token function"},"sumArraysOnHost"),n("span",{class:"token punctuation"},"("),s("h_A"),n("span",{class:"token punctuation"},","),s(" h_B"),n("span",{class:"token punctuation"},","),s(" hostRef"),n("span",{class:"token punctuation"},","),s(" nElem"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// check device results"),s(`
   `),n("span",{class:"token function"},"checkResult"),n("span",{class:"token punctuation"},"("),s("hostRef"),n("span",{class:"token punctuation"},","),s(" gpuRef"),n("span",{class:"token punctuation"},","),s(" nElem"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// free device global memory"),s(`
   `),n("span",{class:"token function"},"cudaFree"),n("span",{class:"token punctuation"},"("),s("d_A"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaFree"),n("span",{class:"token punctuation"},"("),s("d_B"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaFree"),n("span",{class:"token punctuation"},"("),s("d_C"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// free host memory"),s(`
   `),n("span",{class:"token function"},"free"),n("span",{class:"token punctuation"},"("),s("h_A"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"free"),n("span",{class:"token punctuation"},"("),s("h_B"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"free"),n("span",{class:"token punctuation"},"("),s("hostRef"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"free"),n("span",{class:"token punctuation"},"("),s("gpuRef"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"return"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),hn=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s("在这段代码中，向量大小被设置为"),n("span",{class:"token number"},"32"),s(`，如下所示：
`),n("span",{class:"token keyword"},"int"),s(" nElem "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"32"),n("span",{class:"token punctuation"},";"),s(`


执行配置被放入一个块内，其中包含`),n("span",{class:"token number"},"32"),s(`个元素：
dim3 `),n("span",{class:"token function"},"block"),s(),n("span",{class:"token punctuation"},"("),s("nElem"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
dim3 `),n("span",{class:"token function"},"grid"),s("  "),n("span",{class:"token punctuation"},"("),s("nElem"),n("span",{class:"token operator"},"/"),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`


使用以下命令编译和执行该代码：
$ nvcc sumArraysOnGPU`),n("span",{class:"token operator"},"-"),s("small"),n("span",{class:"token operator"},"-"),n("span",{class:"token keyword"},"case"),n("span",{class:"token punctuation"},"."),s("cu "),n("span",{class:"token operator"},"-"),s(`o addvector
$ `),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s(`addvector

系统报告结果如下：
 `),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s("addvector Starting"),n("span",{class:"token punctuation"},"."),n("span",{class:"token punctuation"},"."),n("span",{class:"token punctuation"},"."),s(`
 Vector size `),n("span",{class:"token number"},"32"),s(`
 Execution configuration `),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"32"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s(`
 Arrays match`),n("span",{class:"token punctuation"},"."),s(`

如果你将执行配置重新定义为`),n("span",{class:"token number"},"32"),s(`个块，每个块只有一个元素，如下所示：
dim3 `),n("span",{class:"token function"},"block"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
dim3 `),n("span",{class:"token function"},"grid"),s("  "),n("span",{class:"token punctuation"},"("),s("nElem"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`


那么就需要在代码清单`),n("span",{class:"token number"},"2"),n("span",{class:"token operator"},"-"),n("span",{class:"token number"},"4"),s(`中对核函数sumArraysOnGPU进行修改：
`),n("span",{class:"token keyword"},"int"),s(" i "),n("span",{class:"token operator"},"="),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(` 
替换
`),n("span",{class:"token keyword"},"int"),s(" i "),n("span",{class:"token operator"},"="),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`


一般情况下，可以基于给定的一维网格和块的信息来计算全局数据访问的唯一索引：
__global__ `),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"sumArraysOnGPU"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),s("A"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),s("B"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),s("C"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
       `),n("span",{class:"token keyword"},"int"),s(" i "),n("span",{class:"token operator"},"="),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"+"),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
       C`),n("span",{class:"token punctuation"},"["),s("i"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" A"),n("span",{class:"token punctuation"},"["),s("i"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+"),s(" B"),n("span",{class:"token punctuation"},"["),s("i"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
你需要确保一般情况下进行更改所产生结果的正确性。
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),yn=p(`<h2 id="_2-2-给核函数计时" tabindex="-1"><a class="header-anchor" href="#_2-2-给核函数计时" aria-hidden="true">#</a> 2.2 给核函数计时</h2><p>TIMING YOUR KERNEL</p><ul><li>在内核的性能转换过程中，了解核函数的执行需要多长时间是很有帮助并且十分关键的。衡量核函数性能的方法有很多。最简单的方法是在主机端使用一个CPU或GPU计时器<br> 来计算内核的执行时间。在本节，你需要设置一个CPU计时器，并学习使用NVIDIA分析<br> 工具来计算执行时间。第6章将教你如何使用CUDA特定的计时程序。</li></ul><h3 id="_2-2-1-用cpu计时器计时" tabindex="-1"><a class="header-anchor" href="#_2-2-1-用cpu计时器计时" aria-hidden="true">#</a> 2.2.1 用CPU计时器计时</h3><p>Timing with CPU Timer</p><ul><li>可以使用gettimeofday系统调用来创建一个CPU计时器，以获取系统的时钟时间，它将返回自1970年1月1日零点以来，到现在的秒数。程序中需要添加sys/time.h头文件，如代码清单2-5所示。</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">double</span> <span class="token function">cpuSecond</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
   <span class="token keyword">struct</span> <span class="token class-name">timeval</span> tp<span class="token punctuation">;</span>
   <span class="token function">gettimeofday</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>tp<span class="token punctuation">,</span><span class="token constant">NULL</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
   <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">double</span><span class="token punctuation">)</span>tp<span class="token punctuation">.</span>tv_sec <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token keyword">double</span><span class="token punctuation">)</span>tp<span class="token punctuation">.</span>tv_usec<span class="token operator">*</span><span class="token number">1.e-6</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>你可以用cpuSecond函数来测试你的核函数：<br> double iStart = cpuSecond();<br> kernel_name&lt;&lt;&lt;grid, block&gt;&gt;&gt;(argument list);<br> cudaDeviceSynchronize();<br> double iElaps = cpuSecond() - iStart;</li><li>由于内核调用与主机是异步的，因此需要使用 cudaDeviceSynchronize 来等待所有 GPU 线程完成。变量 iElaps 会报告所花费的时间，就像你用手表测量内核执行一样（单位：秒）</li><li>现在测试一个有 1600 万元素的大矢量，数据集大小设置如下 <ul><li>int nElem = 1&lt;&lt;24;</li></ul></li><li>由于GPU的可扩展性，你需要借助块和线程的索引来计算一个按行优先的数组索引<br> i，并对核函数进行修改，添加限定条件（i＜N）来检验索引值是否越界，如下所示：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code> __global__ <span class="token keyword">void</span> <span class="token function">sumArraysOnGPU</span><span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span>A<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>B<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>C<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">int</span> N<span class="token punctuation">)</span> <span class="token punctuation">{</span>
   <span class="token keyword">int</span> i <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
   <span class="token keyword">if</span> <span class="token punctuation">(</span>i <span class="token operator">&lt;</span> N<span class="token punctuation">)</span> C<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> A<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> B<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>做出这些更改后，您就可以使用不同的执行配置来测量内核了。要处理创建的线程总数大于向量元素总数的情况，需要限制内核非法访问全局内存，如图 2-7 所示。</li></ul><figure><img src="`+x+'" alt="figure2-7" tabindex="0" loading="lazy"><figcaption>figure2-7</figcaption></figure><ul><li>Listing 2-5 shows you how to measure the vector addition kernel with the CPU timer in the main function.</li></ul>',12),gn={class:"hint-container details"},_n=n("summary",null,"Click me to view the code!",-1),xn=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[n("span",{class:"token macro property"},[n("span",{class:"token directive-hash"},"#"),n("span",{class:"token directive keyword"},"include"),s(),n("span",{class:"token string"},"<cuda_runtime.h>")]),s(`
 `),n("span",{class:"token macro property"},[n("span",{class:"token directive-hash"},"#"),n("span",{class:"token directive keyword"},"include"),s(),n("span",{class:"token string"},"<stdio.h>")]),s(`
 `),n("span",{class:"token macro property"},[n("span",{class:"token directive-hash"},"#"),n("span",{class:"token directive keyword"},"include"),s(),n("span",{class:"token string"},"<sys/time.h>")]),s(`
 `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token function"},"main"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" argc"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"char"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),s("argv"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"%s Starting...\\n"'),n("span",{class:"token punctuation"},","),s(" argv"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// set up device"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" dev "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(`
   cudaDeviceProp deviceProp`),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"CHECK"),n("span",{class:"token punctuation"},"("),n("span",{class:"token function"},"cudaGetDeviceProperties"),n("span",{class:"token punctuation"},"("),n("span",{class:"token operator"},"&"),s("deviceProp"),n("span",{class:"token punctuation"},","),s(" dev"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"Using Device %d: %s\\n"'),n("span",{class:"token punctuation"},","),s(" dev"),n("span",{class:"token punctuation"},","),s(" deviceProp"),n("span",{class:"token punctuation"},"."),s("name"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"CHECK"),n("span",{class:"token punctuation"},"("),n("span",{class:"token function"},"cudaSetDevice"),n("span",{class:"token punctuation"},"("),s("dev"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// set up date size of vectors"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" nElem "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"1"),n("span",{class:"token operator"},"<<"),n("span",{class:"token number"},"24"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"Vector size %d\\n"'),n("span",{class:"token punctuation"},","),s(" nElem"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// malloc host memory"),s(`
   size_t nBytes `),n("span",{class:"token operator"},"="),s(" nElem "),n("span",{class:"token operator"},"*"),s(),n("span",{class:"token keyword"},"sizeof"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),s("h_A"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token operator"},"*"),s("h_B"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token operator"},"*"),s("hostRef"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token operator"},"*"),s("gpuRef"),n("span",{class:"token punctuation"},";"),s(`
   h_A     `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token function"},"malloc"),n("span",{class:"token punctuation"},"("),s("nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   h_B     `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token function"},"malloc"),n("span",{class:"token punctuation"},"("),s("nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   hostRef `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token function"},"malloc"),n("span",{class:"token punctuation"},"("),s("nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   gpuRef  `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token function"},"malloc"),n("span",{class:"token punctuation"},"("),s("nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"double"),s(" iStart"),n("span",{class:"token punctuation"},","),s("iElaps"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// initialize data at host side"),s(`
   iStart `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"cpuSecond"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"initialData"),s(),n("span",{class:"token punctuation"},"("),s("h_A"),n("span",{class:"token punctuation"},","),s(" nElem"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"initialData"),s(),n("span",{class:"token punctuation"},"("),s("h_B"),n("span",{class:"token punctuation"},","),s(" nElem"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   iElaps `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"cpuSecond"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"-"),s(" iStart"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"memset"),n("span",{class:"token punctuation"},"("),s("hostRef"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"memset"),n("span",{class:"token punctuation"},"("),s("gpuRef"),n("span",{class:"token punctuation"},","),s("  "),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// add vector at host side for result checks"),s(`
   iStart `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"cpuSecond"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"sumArraysOnHost"),s(),n("span",{class:"token punctuation"},"("),s("h_A"),n("span",{class:"token punctuation"},","),s(" h_B"),n("span",{class:"token punctuation"},","),s(" hostRef"),n("span",{class:"token punctuation"},","),s(" nElem"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   iElaps `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"cpuSecond"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"-"),s(" iStart"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// malloc device global memory"),s(`
   `),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),s("d_A"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token operator"},"*"),s("d_B"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token operator"},"*"),s("d_C"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaMalloc"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"&"),s("d_A"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaMalloc"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"&"),s("d_B"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaMalloc"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"&"),s("d_C"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// transfer data from host to device"),s(`
   `),n("span",{class:"token function"},"cudaMemcpy"),n("span",{class:"token punctuation"},"("),s("d_A"),n("span",{class:"token punctuation"},","),s(" h_A"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},","),s(" cudaMemcpyHostToDevice"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaMemcpy"),n("span",{class:"token punctuation"},"("),s("d_B"),n("span",{class:"token punctuation"},","),s(" h_B"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},","),s(" cudaMemcpyHostToDevice"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// invoke kernel at host side"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" iLen "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"1024"),n("span",{class:"token punctuation"},";"),s(`
   dim3 `),n("span",{class:"token function"},"block"),s(),n("span",{class:"token punctuation"},"("),s("iLen"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   dim3 `),n("span",{class:"token function"},"grid"),s("  "),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),s("nElem"),n("span",{class:"token operator"},"+"),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"-"),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"/"),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   iStart `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"cpuSecond"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   sumArraysOnGPU `),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s("grid"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),n("span",{class:"token punctuation"},"("),s("d_A"),n("span",{class:"token punctuation"},","),s(" d_B"),n("span",{class:"token punctuation"},","),s(" d_C"),n("span",{class:"token punctuation"},","),s("nElem"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaDeviceSynchronize"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   iElaps `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"cpuSecond"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"-"),s(" iStart"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"sumArraysOnGPU <<<%d,%d>>> Time elapsed %f"'),s(` \\
    `),n("span",{class:"token string"},'"sec\\n"'),n("span",{class:"token punctuation"},","),s(" grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s(" iElaps"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// copy kernel result back to host side"),s(`
   `),n("span",{class:"token function"},"cudaMemcpy"),n("span",{class:"token punctuation"},"("),s("gpuRef"),n("span",{class:"token punctuation"},","),s(" d_C"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},","),s(" cudaMemcpyDeviceToHost"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// check device results"),s(`
   `),n("span",{class:"token function"},"checkResult"),n("span",{class:"token punctuation"},"("),s("hostRef"),n("span",{class:"token punctuation"},","),s(" gpuRef"),n("span",{class:"token punctuation"},","),s(" nElem"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// free device global memory"),s(`
   `),n("span",{class:"token function"},"cudaFree"),n("span",{class:"token punctuation"},"("),s("d_A"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaFree"),n("span",{class:"token punctuation"},"("),s("d_B"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaFree"),n("span",{class:"token punctuation"},"("),s("d_C"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// free host memory"),s(`
   `),n("span",{class:"token function"},"free"),n("span",{class:"token punctuation"},"("),s("h_A"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"free"),n("span",{class:"token punctuation"},"("),s("h_B"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"free"),n("span",{class:"token punctuation"},"("),s("hostRef"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"free"),n("span",{class:"token punctuation"},"("),s("gpuRef"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"return"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),wn=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s("默认的执行配置被设置为一个包含"),n("span",{class:"token number"},"16384"),s("个块的一维网格，每个块包含"),n("span",{class:"token number"},"1024"),s(`个线程。用以下命令编译并运行程序：
$ nvcc sumArraysOnGPU`),n("span",{class:"token operator"},"-"),s("timer"),n("span",{class:"token punctuation"},"."),s("cu "),n("span",{class:"token operator"},"-"),s("o sumArraysOnGPU"),n("span",{class:"token operator"},"-"),s(`timer
$ `),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s("sumArraysOnGPU"),n("span",{class:"token operator"},"-"),s(`timer


在基于英特尔Sandy Bridge架构的系统上进行测试，从代码清单`),n("span",{class:"token number"},"2"),n("span",{class:"token operator"},"-"),n("span",{class:"token number"},"5"),s(`的示例中可以看
出，在GPU上进行的向量加法的运算速度是在CPU上运行向量加法的`),n("span",{class:"token number"},"3.86"),s(`倍。
`),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s("sumArraysOnGPU"),n("span",{class:"token operator"},"-"),s("timer Starting"),n("span",{class:"token punctuation"},"."),n("span",{class:"token punctuation"},"."),n("span",{class:"token punctuation"},"."),s(`
Using Device `),n("span",{class:"token number"},"0"),n("span",{class:"token operator"},":"),s(` Tesla M2070
Vector size `),n("span",{class:"token number"},"16777216"),s(`
sumArraysOnGPU `),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),n("span",{class:"token number"},"16384"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1024"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s("  Time elapsed "),n("span",{class:"token number"},"0.002456"),s(` sec
Arrays match`),n("span",{class:"token punctuation"},"."),s(`



把块的维度减少到`),n("span",{class:"token number"},"512"),s("可以创建"),n("span",{class:"token number"},"32768"),s("个块。在这个新的配置下，内核的性能提升了 "),n("span",{class:"token number"},"1.19"),s(`倍。
sumArraysOnGPU `),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),n("span",{class:"token number"},"32768"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"512"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s("   Time elapsed "),n("span",{class:"token number"},"0.002058"),s(` sec


如果进一步将块的维度降低到`),n("span",{class:"token number"},"256"),s(`，系统将提示以下错误信息，信息表示块的总数超
过了一维网格的限制。
`),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s("sumArraysOnGPU"),n("span",{class:"token operator"},"-"),s("timer Starting"),n("span",{class:"token punctuation"},"."),n("span",{class:"token punctuation"},"."),n("span",{class:"token punctuation"},"."),s(`
Using Device `),n("span",{class:"token number"},"0"),n("span",{class:"token operator"},":"),s(` Tesla M2070
Vector size `),n("span",{class:"token number"},"16777216"),s(`
sumArraysOnGPU `),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),n("span",{class:"token number"},"65536"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"256"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s("  Time elapsed "),n("span",{class:"token number"},"0.000183"),s(` sec
Error`),n("span",{class:"token operator"},":"),s(" sumArraysOnGPU"),n("span",{class:"token operator"},"-"),s("timer"),n("span",{class:"token punctuation"},"."),s("cu"),n("span",{class:"token operator"},":"),n("span",{class:"token number"},"153"),n("span",{class:"token punctuation"},","),s(" code"),n("span",{class:"token operator"},":"),n("span",{class:"token number"},"9"),n("span",{class:"token punctuation"},","),s(" reason"),n("span",{class:"token operator"},":"),s(` invalid configuration argument
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),Dn=p(`<ul><li><mark>了解自身局限性</mark></li><li>在调整执行配置时需要了解的一个关键点是对网格和块维度的限制。线程层次结构中<br> 每个层级的最大尺寸取决于设备。</li><li>CUDA提供了通过查询GPU来了解这些限制的能力。在本章的2.4节有详细的介绍。</li><li>对于Fermi设备，每个块的最大线程数是1024，且网格的x、y、z三个方向上的维度最<br> 大值是65535。</li></ul><h3 id="_2-2-2-用nvprof工具计时" tabindex="-1"><a class="header-anchor" href="#_2-2-2-用nvprof工具计时" aria-hidden="true">#</a> 2.2.2 用nvprof工具计时</h3><p>Timing with nvprof</p><ul><li>自 CUDA 5.0 起，名为 nvprof 的命令行配置工具可帮助您从应用程序的 CPU 和 GPU 活动（包括内核执行、内存传输和 CUDA API 调用）中收集时间轴信息。其使用方法如下所示。<br> - <code>$ nvprof [nvprof_args] &lt;application&gt; [application_args]</code></li><li>有关 nvprof 选项的更多信息，请使用以下命令：<br> - <code>$ nvprof --help</code></li><li>您可以使用 nvprof 对内核进行如下测量：<br> - <code>$ nvprof ./sumArraysOnGPU-timer </code></li><li>nvprof 报告的输出结果因您使用的 GPU 类型而异。以下报告是在 Tesla GPU 上收集的：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code> <span class="token punctuation">.</span><span class="token operator">/</span>sumArraysOnGPU<span class="token operator">-</span>timer Starting<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
 Using Device <span class="token number">0</span><span class="token operator">:</span> Tesla M2070
 <span class="token operator">==</span><span class="token number">17770</span><span class="token operator">==</span> NVPROF is profiling process <span class="token number">17770</span><span class="token punctuation">,</span> command<span class="token operator">:</span> <span class="token punctuation">.</span><span class="token operator">/</span>sumArraysOnGPU<span class="token operator">-</span>timer
 Vector size <span class="token number">16777216</span>
 sumArraysOnGPU <span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token number">16384</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span>  Time elapsed <span class="token number">0.003266</span> sec
 Arrays match<span class="token punctuation">.</span>
 <span class="token operator">==</span><span class="token number">17770</span><span class="token operator">==</span> Profiling application<span class="token operator">:</span> <span class="token punctuation">.</span><span class="token operator">/</span>sumArraysOnGPU<span class="token operator">-</span>timer
 <span class="token operator">==</span><span class="token number">17770</span><span class="token operator">==</span> Profiling result<span class="token operator">:</span>
 <span class="token function">Time</span><span class="token punctuation">(</span><span class="token operator">%</span><span class="token punctuation">)</span>      Time     Calls       Avg       Min       Max  Name
 <span class="token number">70.35</span><span class="token operator">%</span>  <span class="token number">52.667</span>ms         <span class="token number">3</span>  <span class="token number">17.556</span>ms  <span class="token number">17.415</span>ms  <span class="token number">17.800</span>ms  <span class="token punctuation">[</span>CUDA memcpy HtoD<span class="token punctuation">]</span>
 <span class="token number">25.77</span><span class="token operator">%</span>  <span class="token number">19.291</span>ms         <span class="token number">1</span>  <span class="token number">19.291</span>ms  <span class="token number">19.291</span>ms  <span class="token number">19.291</span>ms  <span class="token punctuation">[</span>CUDA memcpy DtoH<span class="token punctuation">]</span>
  <span class="token number">3.88</span><span class="token operator">%</span>  <span class="token number">2.9024</span>ms         <span class="token number">1</span>  <span class="token number">2.9024</span>ms  <span class="token number">2.9024</span>ms  <span class="token number">2.9024</span>ms  <span class="token function">sumArraysOnGPU</span>
 <span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>以上结果的前半部分来自于程序的输出，后半部分来自于nvprof的输出。可以注意<br> 到，CPU计时器显示消耗的内核时间为3.26ms，而nvprof显示消耗的内核时间为2.90ms。<br> 在这个例子中，nvprof的结果更为精确，因为CPU计时器测量的时间中包含了来自nvprof<br> 附加的时间。</li><li>nvprof是一个能帮助你理解在执行应用程序时所花费的时间主要用在何处的强大工<br> 具。可以注意到，在这个例子中，主机和设备之间的数据传输需要的时间比内核执行的时<br> 间要多。图2-8所描绘的时间线（未按比例绘制），显示了在CPU上消耗的时间、数据传<br> 输所用的时间以及在GPU上计算所用的时间。</li></ul><figure><img src="`+w+'" alt="figure2-8" tabindex="0" loading="lazy"><figcaption>figure2-8</figcaption></figure><ul><li><p>对于HPC工作负载，理解程序中通信比的计算是非常重要的。如果你的应用程序用于<br> 计算的时间大于数据传输所用的时间，那么或许可以压缩这些操作，并完全隐藏与传输数<br> 据有关的延迟。如果你的应用程序用于计算的时间少于数据传输所用的时间，那么需要尽<br> 量减少主机和设备之间的传输。在第6章中，你将会学习如何使用CUDA流和事件来压缩<br> 计算量和通信量。</p></li><li><p><mark>比较应用程序的性能将理论界限最大化</mark></p></li><li><p>在进行程序优化时，如何将应用程序和理论界限进行比较是很重要的。由nvprof得到<br> 的计数器可以帮助你获取应用程序的指令和内存吞吐量。如果将应用程序的测量值与理论<br> 峰值进行比较，可以判定你的应用程序的性能是受限于算法还是受限于内存带宽的。以<br> Tesla K10为例，可以得到理论上的比率：</p></li><li><p>daikan</p></li></ul><h2 id="_2-3-组织并行线程" tabindex="-1"><a class="header-anchor" href="#_2-3-组织并行线程" aria-hidden="true">#</a> 2.3 组织并行线程</h2><p>ORGANIZING PARALLEL THREADS</p><ul><li>从前面的例子可以看出，如果使用了合适的网格和块大小来正确地组织线程，那么可<br> 以对内核性能产生很大的影响。在向量加法的例子中，为了实现最佳性能我们调整了块的<br> 大小，并基于块大小和向量数据大小计算出了网格大小。</li><li>现在通过一个矩阵加法的例子来进一步说明这一点。对于矩阵运算，传统的方法是在内核中使用一个包含二维网格与二维块的布局来组织线程。但是，这种传统的方法无法获得最佳性能。在矩阵加法中使用以下布局将有助于了解更多关于网格和块的启发性的用法:<br> - 2D grid with 2D blocks<br> - 1D grid with 1D blocks<br> - 2D grid with 1D blocks</li></ul><h3 id="_2-3-1-使用块和线程建立矩阵索引" tabindex="-1"><a class="header-anchor" href="#_2-3-1-使用块和线程建立矩阵索引" aria-hidden="true">#</a> 2.3.1 使用块和线程建立矩阵索引</h3><p>Indexing Matrices with Blocks and Threads</p><ul><li>通常情况下，一个矩阵用行优先的方法在全局内存中进行线性存储。图2-9所示的是<br> 一个8×6矩阵的小例子。</li></ul><figure><img src="'+D+'" alt="figure2-9" tabindex="0" loading="lazy"><figcaption>figure2-9</figcaption></figure><ul><li>在一个矩阵加法核函数中，一个线程通常被分配一个数据元素来处理。首先要完成的任务是使用块和线程索引从全局内存中访问指定的数据。通常情况下，对一个二维示例来说，需要管理3种索引：<br> - 线程和块索引<br> - 矩阵中给定点的坐标<br> - 全局线性内存中的偏移量</li><li>对于一个给定的线程，首先可以通过把线程和块索引映射到矩阵坐标上来获取线程块<br> 和线程索引的全局内存偏移量，然后将这些矩阵坐标映射到全局内存的存储单元中。</li><li>第一步，可以用以下公式把线程和块索引映射到矩阵坐标上：<br> - ix = threadIdx.x + blockIdx.x * blockDim.x<br> - iy = threadIdx.y + blockIdx.y * blockDim.y</li><li>第二步，可以用以下公式把矩阵坐标映射到全局内存中的索引/存储单元上 <ul><li>idx = iy * nx + ix</li></ul></li><li>图2-10说明了块和线程索引、矩阵坐标以及线性全局内存索引之间的对应关系。</li></ul><figure><img src="'+U+'" alt="figure2-10" tabindex="0" loading="lazy"><figcaption>figure2-10</figcaption></figure>',17),Un=n("li",null,[n("p",null,[s("函数 printThreadInfo 用于打印每个线程的以下信息："),n("br"),s(" - 线程索引"),n("br"),s(" - 块索引"),n("br"),s(" - 矩阵坐标"),n("br"),s(" - 线性全局内存偏移量"),n("br"),s(" - 相应元素的值")])],-1),An=n("br",null,null,-1),Cn={href:"http://checkThreadIndex.cu",target:"_blank",rel:"noopener noreferrer"},Pn=n("br",null,null,-1),Mn=n("li",null,[n("p",null,"对于每个线程，你可以获取以下信息："),n("ul",null,[n("li",null,"thread_id (2,1) block_id (1,0) coordinate (6,1) global index 14 ival 14")])],-1),Gn=n("li",null,[n("p",null,[s("图2-11说明了这三项索引之间的关系。"),n("br"),n("img",{src:A,alt:"figure2-11",loading:"lazy"})])],-1),In={class:"hint-container details"},Bn=n("summary",null,"Click me to view the code!",-1),En=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s(),n("span",{class:"token macro property"},[n("span",{class:"token directive-hash"},"#"),n("span",{class:"token directive keyword"},"include"),s(),n("span",{class:"token string"},"<cuda_runtime.h>")]),s(`
 `),n("span",{class:"token macro property"},[n("span",{class:"token directive-hash"},"#"),n("span",{class:"token directive keyword"},"include"),s(),n("span",{class:"token string"},"<stdio.h>")]),s(`
 `),n("span",{class:"token macro property"},[n("span",{class:"token directive-hash"},"#"),n("span",{class:"token directive keyword"},"define"),s(),n("span",{class:"token macro-name function"},"CHECK"),n("span",{class:"token expression"},[n("span",{class:"token punctuation"},"("),s("call"),n("span",{class:"token punctuation"},")"),s("                                                      ")]),n("span",{class:"token punctuation"},"\\"),s(`
 `),n("span",{class:"token expression"},[n("span",{class:"token punctuation"},"{"),s("                                                                        ")]),n("span",{class:"token punctuation"},"\\"),s(`
   `),n("span",{class:"token expression"},[n("span",{class:"token keyword"},"const"),s(" cudaError_t error "),n("span",{class:"token operator"},"="),s(" call"),n("span",{class:"token punctuation"},";"),s("                                       ")]),n("span",{class:"token punctuation"},"\\"),s(`
   `),n("span",{class:"token expression"},[n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("error "),n("span",{class:"token operator"},"!="),s(" cudaSuccess"),n("span",{class:"token punctuation"},")"),s("                                             ")]),n("span",{class:"token punctuation"},"\\"),s(`
   `),n("span",{class:"token expression"},[n("span",{class:"token punctuation"},"{"),s("                                                                     ")]),n("span",{class:"token punctuation"},"\\"),s(`
      `),n("span",{class:"token expression"},[n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"(")]),n("span",{class:"token string"},'"Error: %s:%d, "'),n("span",{class:"token expression"},[n("span",{class:"token punctuation"},","),s(),n("span",{class:"token constant"},"__FILE__"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token constant"},"__LINE__"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s("                      ")]),n("span",{class:"token punctuation"},"\\"),s(`
      `),n("span",{class:"token expression"},[n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"(")]),n("span",{class:"token string"},'"code:%d, reason: %s\\n"'),n("span",{class:"token expression"},[n("span",{class:"token punctuation"},","),s(" error"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token function"},"cudaGetErrorString"),n("span",{class:"token punctuation"},"("),s("error"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s()]),n("span",{class:"token punctuation"},"\\"),s(`
      `),n("span",{class:"token expression"},[n("span",{class:"token function"},"exit"),n("span",{class:"token punctuation"},"("),n("span",{class:"token operator"},"-"),n("span",{class:"token number"},"10"),n("span",{class:"token operator"},"*"),s("error"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s("                                                   ")]),n("span",{class:"token punctuation"},"\\"),s(`
   `),n("span",{class:"token expression"},[n("span",{class:"token punctuation"},"}"),s("                                                                     ")]),n("span",{class:"token punctuation"},"\\"),s(`
 `),n("span",{class:"token expression"},[n("span",{class:"token punctuation"},"}")])]),s(`
 `),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"initialInt"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("ip"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"int"),s(" size"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
   `),n("span",{class:"token keyword"},"for"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" i"),n("span",{class:"token operator"},"="),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(" i"),n("span",{class:"token operator"},"<"),s("size"),n("span",{class:"token punctuation"},";"),s(" i"),n("span",{class:"token operator"},"++"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
      ip`),n("span",{class:"token punctuation"},"["),s("i"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" i"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"printMatrix"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("C"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"const"),s(),n("span",{class:"token keyword"},"int"),s(" nx"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"const"),s(),n("span",{class:"token keyword"},"int"),s(" ny"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
   `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("ic "),n("span",{class:"token operator"},"="),s(" C"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"\\nMatrix: (%d.%d)\\n"'),n("span",{class:"token punctuation"},","),s("nx"),n("span",{class:"token punctuation"},","),s("ny"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"for"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" iy"),n("span",{class:"token operator"},"="),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(" iy"),n("span",{class:"token operator"},"<"),s("ny"),n("span",{class:"token punctuation"},";"),s(" iy"),n("span",{class:"token operator"},"++"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
      `),n("span",{class:"token keyword"},"for"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" ix"),n("span",{class:"token operator"},"="),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(" ix"),n("span",{class:"token operator"},"<"),s("nx"),n("span",{class:"token punctuation"},";"),s(" ix"),n("span",{class:"token operator"},"++"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
         `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"%3d"'),n("span",{class:"token punctuation"},","),s("ic"),n("span",{class:"token punctuation"},"["),s("ix"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
      `),n("span",{class:"token punctuation"},"}"),s(`
      ic `),n("span",{class:"token operator"},"+="),s(" nx"),n("span",{class:"token punctuation"},";"),s(`
      `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"\\n"'),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token punctuation"},"}"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"\\n"'),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 __global__ `),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"printThreadIndex"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("A"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"const"),s(),n("span",{class:"token keyword"},"int"),s(" nx"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"const"),s(),n("span",{class:"token keyword"},"int"),s(" ny"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" ix "),n("span",{class:"token operator"},"="),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"+"),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" iy "),n("span",{class:"token operator"},"="),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("y "),n("span",{class:"token operator"},"+"),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("y "),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("y"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" idx "),n("span",{class:"token operator"},"="),s(" iy"),n("span",{class:"token operator"},"*"),s("nx "),n("span",{class:"token operator"},"+"),s(" ix"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"thread_id (%d,%d) block_id (%d,%d) coordinate (%d,%d) "'),s(`
      `),n("span",{class:"token string"},'"global index %2d ival %2d\\n"'),n("span",{class:"token punctuation"},","),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("y"),n("span",{class:"token punctuation"},","),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s(`
      blockIdx`),n("span",{class:"token punctuation"},"."),s("y"),n("span",{class:"token punctuation"},","),s(" ix"),n("span",{class:"token punctuation"},","),s(" iy"),n("span",{class:"token punctuation"},","),s(" idx"),n("span",{class:"token punctuation"},","),s(" A"),n("span",{class:"token punctuation"},"["),s("idx"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token function"},"main"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" argc"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"char"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),s("argv"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"%s Starting...\\n"'),n("span",{class:"token punctuation"},","),s(" argv"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// get device information"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" dev "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(`
   cudaDeviceProp deviceProp`),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"CHECK"),n("span",{class:"token punctuation"},"("),n("span",{class:"token function"},"cudaGetDeviceProperties"),n("span",{class:"token punctuation"},"("),n("span",{class:"token operator"},"&"),s("deviceProp"),n("span",{class:"token punctuation"},","),s(" dev"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"Using Device %d: %s\\n"'),n("span",{class:"token punctuation"},","),s(" dev"),n("span",{class:"token punctuation"},","),s(" deviceProp"),n("span",{class:"token punctuation"},"."),s("name"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"CHECK"),n("span",{class:"token punctuation"},"("),n("span",{class:"token function"},"cudaSetDevice"),n("span",{class:"token punctuation"},"("),s("dev"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// set matrix dimension"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" nx "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"8"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" ny "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"6"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" nxy "),n("span",{class:"token operator"},"="),s(" nx"),n("span",{class:"token operator"},"*"),s("ny"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" nBytes "),n("span",{class:"token operator"},"="),s(" nxy "),n("span",{class:"token operator"},"*"),s(),n("span",{class:"token keyword"},"sizeof"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// malloc host memory"),s(`
   `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("h_A"),n("span",{class:"token punctuation"},";"),s(`
   h_A `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token function"},"malloc"),n("span",{class:"token punctuation"},"("),s("nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// iniitialize host matrix with integer"),s(`
   `),n("span",{class:"token function"},"initialInt"),n("span",{class:"token punctuation"},"("),s("h_A"),n("span",{class:"token punctuation"},","),s(" nxy"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printMatrix"),n("span",{class:"token punctuation"},"("),s("h_A"),n("span",{class:"token punctuation"},","),s(" nx"),n("span",{class:"token punctuation"},","),s(" ny"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// malloc device memory"),s(`
   `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("d_MatA"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaMalloc"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"&"),s("d_MatA"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// transfer data from host to device"),s(`
   `),n("span",{class:"token function"},"cudaMemcpy"),n("span",{class:"token punctuation"},"("),s("d_MatA"),n("span",{class:"token punctuation"},","),s(" h_A"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},","),s(" cudaMemcpyHostToDevice"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// set up execution configuration"),s(`
   dim3 `),n("span",{class:"token function"},"block"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"4"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"2"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   dim3 `),n("span",{class:"token function"},"grid"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),s("nx"),n("span",{class:"token operator"},"+"),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"-"),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"/"),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token punctuation"},"("),s("ny"),n("span",{class:"token operator"},"+"),s("block"),n("span",{class:"token punctuation"},"."),s("y"),n("span",{class:"token operator"},"-"),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"/"),s("block"),n("span",{class:"token punctuation"},"."),s("y"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// invoke the kernel"),s(`
   printThreadIndex `),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s(" grid"),n("span",{class:"token punctuation"},","),s(" block "),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),n("span",{class:"token punctuation"},"("),s("d_MatA"),n("span",{class:"token punctuation"},","),s(" nx"),n("span",{class:"token punctuation"},","),s(" ny"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaDeviceSynchronize"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// free host and devide memory"),s(`
   `),n("span",{class:"token function"},"cudaFree"),n("span",{class:"token punctuation"},"("),s("d_MatA"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"free"),n("span",{class:"token punctuation"},"("),s("h_A"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// reset device"),s(`
   `),n("span",{class:"token function"},"cudaDeviceReset"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"return"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`

`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),zn=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s("yarn add "),n("span",{class:"token operator"},"-"),s("D vuepress"),n("span",{class:"token operator"},"-"),s("theme"),n("span",{class:"token operator"},"-"),s(`hope
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"})])],-1),Sn=p(`<h3 id="_2-3-2-使用二维网格和二维块对矩阵求和" tabindex="-1"><a class="header-anchor" href="#_2-3-2-使用二维网格和二维块对矩阵求和" aria-hidden="true">#</a> 2.3.2 使用二维网格和二维块对矩阵求和</h3><p>Summing Matrices with a 2D Grid and 2D Blocks</p><ul><li>在本节中，我们将使用一个二维网格和二维块来编写一个矩阵加法核函数。首先，应<br> 编写一个校验主函数以验证矩阵加法核函数是否能得出正确的结果：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">void</span> <span class="token function">sumMatrixOnHost</span> <span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span>A<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>B<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>C<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">int</span> nx<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">int</span> ny<span class="token punctuation">)</span> <span class="token punctuation">{</span>
   <span class="token keyword">float</span> <span class="token operator">*</span>ia <span class="token operator">=</span> A<span class="token punctuation">;</span>
   <span class="token keyword">float</span> <span class="token operator">*</span>ib <span class="token operator">=</span> B<span class="token punctuation">;</span>
   <span class="token keyword">float</span> <span class="token operator">*</span>ic <span class="token operator">=</span> C<span class="token punctuation">;</span>
   <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> iy<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span> iy<span class="token operator">&lt;</span>ny<span class="token punctuation">;</span> iy<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
      <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> ix<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span> ix<span class="token operator">&lt;</span>nx<span class="token punctuation">;</span> ix<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
         ic<span class="token punctuation">[</span>ix<span class="token punctuation">]</span> <span class="token operator">=</span> ia<span class="token punctuation">[</span>ix<span class="token punctuation">]</span> <span class="token operator">+</span> ib<span class="token punctuation">[</span>ix<span class="token punctuation">]</span><span class="token punctuation">;</span>
      <span class="token punctuation">}</span>
      ia <span class="token operator">+=</span> nx<span class="token punctuation">;</span> ib <span class="token operator">+=</span> nx<span class="token punctuation">;</span> ic <span class="token operator">+=</span> nx<span class="token punctuation">;</span>
   <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>然后，创建一个新的核函数，目的是采用一个二维线程块来进行矩阵求和：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">sumMatrixOnGPU2D</span><span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span>MatA<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>MatB<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>MatC<span class="token punctuation">,</span> <span class="token keyword">int</span> nx<span class="token punctuation">,</span> <span class="token keyword">int</span> ny<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">int</span> ix <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">int</span> iy <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>y <span class="token operator">+</span> blockIdx<span class="token punctuation">.</span>y <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>y<span class="token punctuation">;</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">int</span> idx <span class="token operator">=</span> iy<span class="token operator">*</span>nx <span class="token operator">+</span> ix<span class="token punctuation">;</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>ix <span class="token operator">&lt;</span> nx <span class="token operator">&amp;&amp;</span> iy <span class="token operator">&lt;</span> ny<span class="token punctuation">)</span>
        MatC<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> MatA<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">+</span> MatB<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>该内核的关键是将每个线程从其线程索引映射到全局线性内存索引的步骤，如图 2-12 所示</li></ul><figure><img src="`+C+'" alt="figure2-12" tabindex="0" loading="lazy"><figcaption>figure2-12</figcaption></figure>',8),Tn=n("li",null,[s("接下来，每个维度下的矩阵大小可以按如下方法设置为16384个元素： "),n("ul",null,[n("li",null,"int nx = 1<<14;"),n("li",null,"int ny = 1<<14;")])],-1),Rn=n("li",null,[s("然后，内核执行配置可以设置为使用二维网格和二维块，如下所示： "),n("ul",null,[n("li",null,"int dimx = 32;"),n("li",null,"int dimy = 32;"),n("li",null,"dim3 block(dimx, dimy);"),n("li",null,"dim3 grid((nx + block.x - 1) / block.x, (ny + block.y - 1) / block.y);")])],-1),On={href:"http://sumMatrixOnGPU-2D-grid-2D-block.cu",target:"_blank",rel:"noopener noreferrer"},Nn={class:"hint-container details"},Hn=n("summary",null,"Click me to view the code!",-1),Ln=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token function"},"main"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" argc"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"char"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),s("argv"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"%s Starting...\\n"'),n("span",{class:"token punctuation"},","),s(" argv"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// set up device"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" dev "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(`
   cudaDeviceProp deviceProp`),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"CHECK"),n("span",{class:"token punctuation"},"("),n("span",{class:"token function"},"cudaGetDeviceProperties"),n("span",{class:"token punctuation"},"("),n("span",{class:"token operator"},"&"),s("deviceProp"),n("span",{class:"token punctuation"},","),s(" dev"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"Using Device %d: %s\\n"'),n("span",{class:"token punctuation"},","),s(" dev"),n("span",{class:"token punctuation"},","),s(" deviceProp"),n("span",{class:"token punctuation"},"."),s("name"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"CHECK"),n("span",{class:"token punctuation"},"("),n("span",{class:"token function"},"cudaSetDevice"),n("span",{class:"token punctuation"},"("),s("dev"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// set up date size of matrix"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" nx "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"1"),n("span",{class:"token operator"},"<<"),n("span",{class:"token number"},"14"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" ny "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"1"),n("span",{class:"token operator"},"<<"),n("span",{class:"token number"},"14"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" nxy "),n("span",{class:"token operator"},"="),s(" nx"),n("span",{class:"token operator"},"*"),s("ny"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" nBytes "),n("span",{class:"token operator"},"="),s(" nxy "),n("span",{class:"token operator"},"*"),s(),n("span",{class:"token keyword"},"sizeof"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"Matrix size: nx %d ny %d\\n"'),n("span",{class:"token punctuation"},","),s("nx"),n("span",{class:"token punctuation"},","),s(" ny"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// malloc host memory"),s(`
   `),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),s("h_A"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token operator"},"*"),s("h_B"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token operator"},"*"),s("hostRef"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token operator"},"*"),s("gpuRef"),n("span",{class:"token punctuation"},";"),s(`
   h_A `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token function"},"malloc"),n("span",{class:"token punctuation"},"("),s("nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   h_B `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token function"},"malloc"),n("span",{class:"token punctuation"},"("),s("nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   hostRef `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token function"},"malloc"),n("span",{class:"token punctuation"},"("),s("nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   gpuRef `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token function"},"malloc"),n("span",{class:"token punctuation"},"("),s("nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// initialize data at host side"),s(`
   `),n("span",{class:"token keyword"},"double"),s(" iStart "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"cpuSecond"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"initialData"),s(),n("span",{class:"token punctuation"},"("),s("h_A"),n("span",{class:"token punctuation"},","),s(" nxy"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"initialData"),s(),n("span",{class:"token punctuation"},"("),s("h_B"),n("span",{class:"token punctuation"},","),s(" nxy"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"double"),s(" iElaps "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"cpuSecond"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"-"),s(" iStart"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"memset"),n("span",{class:"token punctuation"},"("),s("hostRef"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"memset"),n("span",{class:"token punctuation"},"("),s("gpuRef"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// add matrix at host side for result checks"),s(`
   iStart `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"cpuSecond"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"sumMatrixOnHost"),s(),n("span",{class:"token punctuation"},"("),s("h_A"),n("span",{class:"token punctuation"},","),s(" h_B"),n("span",{class:"token punctuation"},","),s(" hostRef"),n("span",{class:"token punctuation"},","),s(" nx"),n("span",{class:"token punctuation"},","),s("ny"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   iElaps `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"cpuSecond"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"-"),s(" iStart"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// malloc device global memory"),s(`
   `),n("span",{class:"token keyword"},"float"),s(),n("span",{class:"token operator"},"*"),s("d_MatA"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token operator"},"*"),s("d_MatB"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token operator"},"*"),s("d_MatC"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaMalloc"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"&"),s("d_MatA"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaMalloc"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"&"),s("d_MatB"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaMalloc"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"&"),s("d_MatC"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// transfer data from host to device"),s(`
   `),n("span",{class:"token function"},"cudaMemcpy"),n("span",{class:"token punctuation"},"("),s("d_MatA"),n("span",{class:"token punctuation"},","),s(" h_A"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},","),s(" cudaMemcpyHostToDevice"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaMemcpy"),n("span",{class:"token punctuation"},"("),s("d_MatB"),n("span",{class:"token punctuation"},","),s(" h_B"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},","),s(" cudaMemcpyHostToDevice"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
  `),n("span",{class:"token comment"},"// invoke kernel at host side"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" dimx "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"32"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" dimy "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"32"),n("span",{class:"token punctuation"},";"),s(`
   dim3 `),n("span",{class:"token function"},"block"),n("span",{class:"token punctuation"},"("),s("dimx"),n("span",{class:"token punctuation"},","),s(" dimy"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   dim3 `),n("span",{class:"token function"},"grid"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),s("nx"),n("span",{class:"token operator"},"+"),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"-"),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"/"),s("block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token punctuation"},"("),s("ny"),n("span",{class:"token operator"},"+"),s("block"),n("span",{class:"token punctuation"},"."),s("y"),n("span",{class:"token operator"},"-"),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"/"),s("block"),n("span",{class:"token punctuation"},"."),s("y"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   iStart `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"cpuSecond"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   sumMatrixOnGPU2D `),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),s(" grid"),n("span",{class:"token punctuation"},","),s(" block "),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),n("span",{class:"token punctuation"},"("),s("d_MatA"),n("span",{class:"token punctuation"},","),s(" d_MatB"),n("span",{class:"token punctuation"},","),s(" d_MatC"),n("span",{class:"token punctuation"},","),s(" nx"),n("span",{class:"token punctuation"},","),s(" ny"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaDeviceSynchronize"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   iElaps `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"cpuSecond"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"-"),s(" iStart"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"sumMatrixOnGPU2D <<<(%d,%d), (%d,%d)>>> elapsed %f sec\\n"'),n("span",{class:"token punctuation"},","),s(" grid"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s(`
    grid`),n("span",{class:"token punctuation"},"."),s("y"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s(" block"),n("span",{class:"token punctuation"},"."),s("y"),n("span",{class:"token punctuation"},","),s(" iElaps"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// copy kernel result back to host side"),s(`
   `),n("span",{class:"token function"},"cudaMemcpy"),n("span",{class:"token punctuation"},"("),s("gpuRef"),n("span",{class:"token punctuation"},","),s(" d_MatC"),n("span",{class:"token punctuation"},","),s(" nBytes"),n("span",{class:"token punctuation"},","),s(" cudaMemcpyDeviceToHost"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// check device results"),s(`
   `),n("span",{class:"token function"},"checkResult"),n("span",{class:"token punctuation"},"("),s("hostRef"),n("span",{class:"token punctuation"},","),s(" gpuRef"),n("span",{class:"token punctuation"},","),s(" nxy"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// free device global memory"),s(`
   `),n("span",{class:"token function"},"cudaFree"),n("span",{class:"token punctuation"},"("),s("d_MatA"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaFree"),n("span",{class:"token punctuation"},"("),s("d_MatB"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaFree"),n("span",{class:"token punctuation"},"("),s("d_MatC"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// free host memory"),s(`
   `),n("span",{class:"token function"},"free"),n("span",{class:"token punctuation"},"("),s("h_A"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"free"),n("span",{class:"token punctuation"},"("),s("h_B"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"free"),n("span",{class:"token punctuation"},"("),s("hostRef"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"free"),n("span",{class:"token punctuation"},"("),s("gpuRef"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token comment"},"// reset device"),s(`
   `),n("span",{class:"token function"},"cudaDeviceReset"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"return"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),Vn=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s(`用以下命令编译并运行该代码：
$ nvcc `),n("span",{class:"token operator"},"-"),s("arch"),n("span",{class:"token operator"},"="),s("sm_20 sumMatrixOnGPU"),n("span",{class:"token operator"},"-"),n("span",{class:"token number"},"2"),s("D"),n("span",{class:"token operator"},"-"),s("grid"),n("span",{class:"token operator"},"-"),n("span",{class:"token number"},"2"),s("D"),n("span",{class:"token operator"},"-"),s("block"),n("span",{class:"token punctuation"},"."),s("cu "),n("span",{class:"token operator"},"-"),s(`o matrix2D
$ `),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s(`matrix2D


在Tesla M2070上运行的结果：
`),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s("a"),n("span",{class:"token punctuation"},"."),s("out Starting"),n("span",{class:"token punctuation"},"."),n("span",{class:"token punctuation"},"."),n("span",{class:"token punctuation"},"."),s(`
Using Device `),n("span",{class:"token number"},"0"),n("span",{class:"token operator"},":"),s(` Tesla M2070
Matrix size`),n("span",{class:"token operator"},":"),s(" nx "),n("span",{class:"token number"},"16384"),s(" ny "),n("span",{class:"token number"},"16384"),s(`
sumMatrixOnGPU2D `),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"512"),n("span",{class:"token punctuation"},","),n("span",{class:"token number"},"512"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"32"),n("span",{class:"token punctuation"},","),n("span",{class:"token number"},"32"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s(" elapsed "),n("span",{class:"token number"},"0.060323"),s(` sec
Arrays match`),n("span",{class:"token punctuation"},"."),s(`


接下来，调整块的尺寸为`),n("span",{class:"token number"},"32"),s("×"),n("span",{class:"token number"},"16"),s(`并重新编译和运行该代码。核函数的执行速度几乎快了两倍：
sumMatrixOnGPU2D `),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"512"),n("span",{class:"token punctuation"},","),n("span",{class:"token number"},"1024"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"32"),n("span",{class:"token punctuation"},","),n("span",{class:"token number"},"16"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),s(" elapsed "),n("span",{class:"token number"},"0.038041"),s(` sec

`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),Fn=p('<ul><li>你可能会问，为什么仅仅改变执行配置，内核性能就提高了近一倍？直觉上，你可能会认为第二个配置的块数是第一个配置的两倍，因此并行性也是第一个配置的两倍。这种直觉是正确的。但是，如果进一步将数据块大小减小到 16 x 16，那么数据块的数量就是第一个配置的四倍。如下图所示，这种配置的结果比第一种好，但比第二种差。</li><li>sumMatrixOnGPU2D &lt;&lt;&lt; (1024,1024), (16,16) &gt;&gt;&gt; elapsed 0.045535 sec</li><li>表 2-3 总结了不同执行配置下的性能。从结果可以看出，增加块数并不一定总能提高内核性能。在第 3 章中，您将了解不同执行配置影响内核性能的原因。</li><li><mark>TABLE 2-3: Matrix Summation with Different Execution Confi guration</mark></li><li>内核配置 内核执行时间 线程块数</li><li>(32,32) 0.060323 sec 512 x 512</li><li>(32,16) 0.038041 sec 512 x 1024</li><li>(16,16) 0.045535 sec 1024 x 1024</li><li>&lt;&lt;&lt;(512,512), (32,32)&gt;&gt;&gt; elapsed 0.060323 sec</li><li>&lt;&lt;&lt;(512,1024), (32,16)&gt;&gt;&gt; elapsed 0.038041 sec</li><li>&lt;&lt;&lt; (1024,1024), (16,16) &gt;&gt;&gt; elapsed 0.045535 sec</li></ul><h3 id="_2-3-3-使用一维网格和一维块对矩阵求和" tabindex="-1"><a class="header-anchor" href="#_2-3-3-使用一维网格和一维块对矩阵求和" aria-hidden="true">#</a> 2.3.3 使用一维网格和一维块对矩阵求和</h3><p>Summing Matrices with a 1D Grid and 1D Blocks</p><ul><li>为了使用一维网格和一维块，你需要写一个新的核函数，其中每个线程处理ny个数据元素，如图2-13所示。</li></ul><figure><img src="'+P+`" alt="figure2-13" tabindex="0" loading="lazy"><figcaption>figure2-13</figcaption></figure><ul><li>由于在新的核函数中每个线程都要处理ny个元素，与使用二维网格和二维块的矩阵求和的核函数相比，从线程和块索引到全局线性内存索引的映射都将会有很大不同。由于在这个核函数启动中使用了一个一维块布局，因此只有threadIdx.x是有用的，并且使用内核中的一个循环来处理每个线程中的ny个元素。</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">sumMatrixOnGPU1D</span><span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span>MatA<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>MatB<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>MatC<span class="token punctuation">,</span> 
    <span class="token keyword">int</span> nx<span class="token punctuation">,</span> <span class="token keyword">int</span> ny<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">unsigned</span> <span class="token keyword">int</span> ix <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>ix <span class="token operator">&lt;</span> nx <span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> iy<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span> iy<span class="token operator">&lt;</span>ny<span class="token punctuation">;</span> iy<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token keyword">int</span> idx <span class="token operator">=</span> iy<span class="token operator">*</span>nx <span class="token operator">+</span> ix<span class="token punctuation">;</span>
            MatC<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> MatA<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">+</span> MatB<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,7),$n=n("li",null,[n("p",null,[s("一维网格和块的配置如下："),n("br"),s(" - dim3 block(32,1);"),n("br"),s(" - dim3 grid((nx+block.x-1)/block.x,1);")])],-1),qn=n("li",null,[n("p",null,[s("使用以下配置调用核函数："),n("br"),s(" - sumMatrixOnGPU1D <<< grid, block >>>(d_MatA, d_MatB, d_MatC, nx, ny);")])],-1),Kn=n("br",null,null,-1),Wn={href:"http://sumMatrixOnGPU-1D-grid-1D-block.cu",target:"_blank",rel:"noopener noreferrer"},jn=n("br",null,null,-1),Yn=p("<li><p>结果显示，与使用一个二维网格和块（32×32）的配置结果相比，两者的性能基本相同。<br> Starting...<br> Using Device 0: Tesla M2070<br> Matrix size: nx 16384 ny 16384<br> sumMatrixOnGPU1D &lt;&lt;&lt;(512,1), (32,1)&gt;&gt;&gt; elapsed 0.061352 sec<br> Arrays match.</p></li><li><p>接下来，按如下所示的方法增加块的大小：<br> dim3 block(128,1);<br> dim3 grid((nx+block.x-1)/block.x,1);</p></li><li><p>重新编译并运行，可以看出核函数运行得更快了：<br> sumMatrixOnGPU1D &lt;&lt;&lt;(128,1),(128,1)&gt;&gt;&gt; elapsed 0.044701 sec</p></li>",3),Xn=p('<h3 id="_2-3-4-使用二维网格和一维块对矩阵求和" tabindex="-1"><a class="header-anchor" href="#_2-3-4-使用二维网格和一维块对矩阵求和" aria-hidden="true">#</a> 2.3.4 使用二维网格和一维块对矩阵求和</h3><p>Summing Matrices with a 2D Grid and 1D Blocks</p><ul><li><p>当使用一个包含一维块的二维网格时，每个线程都只关注一个数据元素并且网格的第<br> 二个维数等于ny，如图2-14所示。<br><img src="'+M+`" alt="figure2-14" loading="lazy"></p></li><li><p>这可以看作是含有一个二维块的二维网格的特殊情况，其中块的第二个维数是1。因<br> 此，从块和线程索引到矩阵坐标的映射就变成：<br> - ix = threadIdx.x + blockIdx.x * blockDim.x;<br> - iy = blockIdx.y;</p></li><li><p>从矩阵坐标到全局线性内存偏移量的映射保持不变。新的核函数如下：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code> __global__ <span class="token keyword">void</span> <span class="token function">sumMatrixOnGPUMix</span><span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span>MatA<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>MatB<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>MatC<span class="token punctuation">,</span> 
      <span class="token keyword">int</span> nx<span class="token punctuation">,</span> <span class="token keyword">int</span> ny<span class="token punctuation">)</span> <span class="token punctuation">{</span>
   <span class="token keyword">unsigned</span> <span class="token keyword">int</span> ix <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
   <span class="token keyword">unsigned</span> <span class="token keyword">int</span> iy <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>y<span class="token punctuation">;</span>
   <span class="token keyword">unsigned</span> <span class="token keyword">int</span> idx <span class="token operator">=</span> iy<span class="token operator">*</span>nx <span class="token operator">+</span> ix<span class="token punctuation">;</span>
   <span class="token keyword">if</span> <span class="token punctuation">(</span>ix <span class="token operator">&lt;</span> nx <span class="token operator">&amp;&amp;</span> iy <span class="token operator">&lt;</span> ny<span class="token punctuation">)</span>
      MatC<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> MatA<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">+</span> MatB<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,4),Qn=n("li",null,[n("p",null,[s("注意，二维核函数sumMatrixOnGPU2D也为这个执行配置工作。编写新内核的唯一优"),n("br"),s(" 点是每个线程省去了一次整数乘法和一次整数加法的运算。")])],-1),Zn=n("li",null,[n("p",null,[s("将块尺寸设置为32，并在此基础上计算网格大小："),n("br"),s(" - dim3 block(32);"),n("br"),s(" - dim3 grid((nx + block.x - 1) / block.x,ny);")])],-1),Jn=n("li",null,[n("p",null,[s("如下所示调用内核："),n("br"),s(" - sumMatrixOnGPUMIx <<< grid, block >>>(d_MatA, d_MatB, d_MatC, nx, ny);")])],-1),ns={href:"http://sumMatrixOnGPU-2D-grid-1D-block.cu",target:"_blank",rel:"noopener noreferrer"},ss=n("br",null,null,-1),as={href:"http://sumMatrixOnGPU-2D-grid-1D-block.cu",target:"_blank",rel:"noopener noreferrer"},ts=n("br",null,null,-1),es=p('<li><p>运行结果为：<br> ./a.out Starting...<br> Using Device 0: Tesla M2070<br> Matrix size nx 16384 ny 16384<br> Matrix initialization<br> elapsed 0.397689 sec<br> sumMatrixOnGPUMix &lt;&lt;&lt;(512,16384), (32,1)&gt;&gt;&gt; elapsed 0.073727 sec<br> Arrays match.</p></li><li><p>如下所示，将线程块的大小增加到256：</p></li><li><p>然后重新编译运行，系统会表现出目前为止最佳的性能（见表2-4）：<br> - sumMatrixOnGPUMix &lt;&lt;&lt;(64,16384), (256,1)&gt;&gt;&gt; elapsed 0.030765 sec</p></li><li><p><mark>TABLE 2-4: Results Comparison of Different Kernel Implementations</mark><br><img src="'+G+'" alt="table2-4" loading="lazy"></p></li><li><p>从矩阵加法的例子中可以看出：<br> - ·改变执行配置对内核性能有影响<br> - ·传统的核函数实现一般不能获得最佳性能.<br> - 对于一个给定的核函数，尝试使用不同的网格和线程块大小可以获得更好的性能.</p></li><li><p>在第3章，将会从硬件的角度学习产生这些问题的原因。</p></li>',6),os=p('<h2 id="_2-4-设备管理" tabindex="-1"><a class="header-anchor" href="#_2-4-设备管理" aria-hidden="true">#</a> 2.4 设备管理</h2><p>MANAGING DEVICES</p><ul><li>NVIDIA提供了几个查询和管理GPU设备的方法。学会如何查询GPU设备信息是很重<br> 要的，因为在运行时你可以使用它来帮助设置内核执行配置。</li><li>在本节中，您将学习到以下两种查询和管理 GPU 设备的基本且强大的方法： <ul><li>The CUDA runtime API functions·CUDA运行时API函数</li><li>The NVIDIA Systems Management Interface (nvidia-smi) command-line utility-NVIDIA系统管理界面（nvidia-smi）命令行实用程序</li></ul></li></ul><h3 id="_2-4-1-使用运行时api查询gpu信息" tabindex="-1"><a class="header-anchor" href="#_2-4-1-使用运行时api查询gpu信息" aria-hidden="true">#</a> 2.4.1 使用运行时API查询GPU信息</h3><p>Using the Runtime API to Query GPU Information</p>',5),cs=n("li",null,[n("p",null,[s("在CUDA运行时API中有很多函数可以帮助管理这些设备。可以使用以下函数查询关"),n("br"),s(" 于GPU设备的所有信息："),n("br"),s(" - cudaError_t cudaGetDeviceProperties(cudaDeviceProp* prop, int device);")])],-1),ps={href:"http://docs.nvidia.com/cuda/cuda-runtime-api/index.html#structcudaDeviceProp",target:"_blank",rel:"noopener noreferrer"},ls=n("li",null,[n("p",null,"Listing 2-8 provides an example that queries generally useful properties of general interest. Compile and run it with the following command:代码清单2-8提供了一个示例，查询了大家通常感兴趣的一般属性。可以使用下列命令编译并运行：")],-1),is={class:"hint-container details"},us=n("summary",null,"Click me to view the code!",-1),rs=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s(),n("span",{class:"token macro property"},[n("span",{class:"token directive-hash"},"#"),n("span",{class:"token directive keyword"},"include"),s(),n("span",{class:"token string"},"<cuda_runtime.h>")]),s(`
 `),n("span",{class:"token macro property"},[n("span",{class:"token directive-hash"},"#"),n("span",{class:"token directive keyword"},"include"),s(),n("span",{class:"token string"},"<stdio.h>")]),s(`
 `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token function"},"main"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" argc"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"char"),s(),n("span",{class:"token operator"},"*"),n("span",{class:"token operator"},"*"),s("argv"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"%s Starting...\\n"'),n("span",{class:"token punctuation"},","),s(" argv"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" deviceCount "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(`
   cudaError_t error_id `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"cudaGetDeviceCount"),n("span",{class:"token punctuation"},"("),n("span",{class:"token operator"},"&"),s("deviceCount"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("error_id "),n("span",{class:"token operator"},"!="),s(" cudaSuccess"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
       `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"cudaGetDeviceCount returned %d\\n-> %s\\n"'),n("span",{class:"token punctuation"},","),s(` 
         `),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),n("span",{class:"token punctuation"},")"),s("error_id"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token function"},"cudaGetErrorString"),n("span",{class:"token punctuation"},"("),s("error_id"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
       `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"Result = FAIL\\n"'),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
       `),n("span",{class:"token function"},"exit"),n("span",{class:"token punctuation"},"("),s("EXIT_FAILURE"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token punctuation"},"}"),s(`
   `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("deviceCount "),n("span",{class:"token operator"},"=="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
       `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"There are no available device(s) that support CUDA\\n"'),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token punctuation"},"}"),s(),n("span",{class:"token keyword"},"else"),s(),n("span",{class:"token punctuation"},"{"),s(`
       `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"Detected %d CUDA Capable device(s)\\n"'),n("span",{class:"token punctuation"},","),s(" deviceCount"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token punctuation"},"}"),s(`
   `),n("span",{class:"token keyword"},"int"),s(" dev"),n("span",{class:"token punctuation"},","),s(" driverVersion "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},","),s(" runtimeVersion "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(`
   dev `),n("span",{class:"token operator"},"="),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaSetDevice"),n("span",{class:"token punctuation"},"("),s("dev"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   cudaDeviceProp deviceProp`),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaGetDeviceProperties"),n("span",{class:"token punctuation"},"("),n("span",{class:"token operator"},"&"),s("deviceProp"),n("span",{class:"token punctuation"},","),s(" dev"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"Device %d: \\"%s\\"\\n"'),n("span",{class:"token punctuation"},","),s(" dev"),n("span",{class:"token punctuation"},","),s(" deviceProp"),n("span",{class:"token punctuation"},"."),s("name"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaDriverGetVersion"),n("span",{class:"token punctuation"},"("),n("span",{class:"token operator"},"&"),s("driverVersion"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"cudaRuntimeGetVersion"),n("span",{class:"token punctuation"},"("),n("span",{class:"token operator"},"&"),s("runtimeVersion"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"  CUDA Driver Version / Runtime Version          %d.%d / %d.%d\\n"'),n("span",{class:"token punctuation"},","),s(`
      driverVersion`),n("span",{class:"token operator"},"/"),n("span",{class:"token number"},"1000"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token punctuation"},"("),s("driverVersion"),n("span",{class:"token operator"},"%"),n("span",{class:"token number"},"100"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"/"),n("span",{class:"token number"},"10"),n("span",{class:"token punctuation"},","),s(` 
      runtimeVersion`),n("span",{class:"token operator"},"/"),n("span",{class:"token number"},"1000"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token punctuation"},"("),s("runtimeVersion"),n("span",{class:"token operator"},"%"),n("span",{class:"token number"},"100"),n("span",{class:"token punctuation"},")"),n("span",{class:"token operator"},"/"),n("span",{class:"token number"},"10"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"  CUDA Capability Major/Minor version number:    %d.%d\\n"'),n("span",{class:"token punctuation"},","),s(`
      deviceProp`),n("span",{class:"token punctuation"},"."),s("major"),n("span",{class:"token punctuation"},","),s(" deviceProp"),n("span",{class:"token punctuation"},"."),s("minor"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"  Total amount of global memory:                 %.2f MBytes (%llu bytes)\\n"'),n("span",{class:"token punctuation"},","),s(`
      `),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"float"),n("span",{class:"token punctuation"},")"),s("deviceProp"),n("span",{class:"token punctuation"},"."),s("totalGlobalMem"),n("span",{class:"token operator"},"/"),n("span",{class:"token punctuation"},"("),n("span",{class:"token function"},"pow"),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"1024.0"),n("span",{class:"token punctuation"},","),n("span",{class:"token number"},"3"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},","),s(` 
      `),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"long"),s(),n("span",{class:"token keyword"},"long"),n("span",{class:"token punctuation"},")"),s(" deviceProp"),n("span",{class:"token punctuation"},"."),s("totalGlobalMem"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"  GPU Clock rate:                                %.0f MHz (%0.2f GHz)\\n"'),n("span",{class:"token punctuation"},","),s(` 
      deviceProp`),n("span",{class:"token punctuation"},"."),s("clockRate "),n("span",{class:"token operator"},"*"),s(),n("span",{class:"token number"},"1e-3f"),n("span",{class:"token punctuation"},","),s(" deviceProp"),n("span",{class:"token punctuation"},"."),s("clockRate "),n("span",{class:"token operator"},"*"),s(),n("span",{class:"token number"},"1e-6f"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"  Memory Clock rate:                             %.0f Mhz\\n"'),n("span",{class:"token punctuation"},","),s(`
      deviceProp`),n("span",{class:"token punctuation"},"."),s("memoryClockRate "),n("span",{class:"token operator"},"*"),s(),n("span",{class:"token number"},"1e-3f"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"  Memory Bus Width:                              %d-bit\\n"'),n("span",{class:"token punctuation"},","),s(`
      deviceProp`),n("span",{class:"token punctuation"},"."),s("memoryBusWidth"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("deviceProp"),n("span",{class:"token punctuation"},"."),s("l2CacheSize"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
      `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"  L2 Cache Size:                                 %d bytes\\n"'),n("span",{class:"token punctuation"},","),s(`
         deviceProp`),n("span",{class:"token punctuation"},"."),s("l2CacheSize"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token punctuation"},"}"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"  Max Texture Dimension Size (x,y,z)            "'),s(` 
      `),n("span",{class:"token string"},'"   1D=(%d), 2D=(%d,%d), 3D=(%d,%d,%d)\\n"'),n("span",{class:"token punctuation"},","),s(`
      deviceProp`),n("span",{class:"token punctuation"},"."),s("maxTexture1D   "),n("span",{class:"token punctuation"},","),s(" deviceProp"),n("span",{class:"token punctuation"},"."),s("maxTexture2D"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},","),s(` 
      deviceProp`),n("span",{class:"token punctuation"},"."),s("maxTexture2D"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},","),s(`
      deviceProp`),n("span",{class:"token punctuation"},"."),s("maxTexture3D"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},","),s(" deviceProp"),n("span",{class:"token punctuation"},"."),s("maxTexture3D"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},","),s(` 
      deviceProp`),n("span",{class:"token punctuation"},"."),s("maxTexture3D"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"2"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),s('"  Max Layered Texture '),n("span",{class:"token function"},"Size"),s(),n("span",{class:"token punctuation"},"("),s("dim"),n("span",{class:"token punctuation"},")"),s(` x layers
   `),n("span",{class:"token number"},"1"),s("D"),n("span",{class:"token operator"},"="),n("span",{class:"token punctuation"},"("),n("span",{class:"token operator"},"%"),s("d"),n("span",{class:"token punctuation"},")"),s(" x "),n("span",{class:"token operator"},"%"),s("d"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"2"),s("D"),n("span",{class:"token operator"},"="),n("span",{class:"token punctuation"},"("),n("span",{class:"token operator"},"%"),s("d"),n("span",{class:"token punctuation"},","),n("span",{class:"token operator"},"%"),s("d"),n("span",{class:"token punctuation"},")"),s(" x "),n("span",{class:"token operator"},"%"),s('d\\n"'),n("span",{class:"token punctuation"},","),s(`
      deviceProp`),n("span",{class:"token punctuation"},"."),s("maxTexture1DLayered"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},","),s(" deviceProp"),n("span",{class:"token punctuation"},"."),s("maxTexture1DLayered"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},","),s(`
      deviceProp`),n("span",{class:"token punctuation"},"."),s("maxTexture2DLayered"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},","),s(" deviceProp"),n("span",{class:"token punctuation"},"."),s("maxTexture2DLayered"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},","),s(` 
      deviceProp`),n("span",{class:"token punctuation"},"."),s("maxTexture2DLayered"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"2"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
  `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"  Total amount of constant memory:               %lu bytes\\n"'),n("span",{class:"token punctuation"},","),s(`
      deviceProp`),n("span",{class:"token punctuation"},"."),s("totalConstMem"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"  Total amount of shared memory per block:       %lu bytes\\n"'),n("span",{class:"token punctuation"},","),s(`
      deviceProp`),n("span",{class:"token punctuation"},"."),s("sharedMemPerBlock"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"  Total number of registers available per block: %d\\n"'),n("span",{class:"token punctuation"},","),s(`
      deviceProp`),n("span",{class:"token punctuation"},"."),s("regsPerBlock"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"  Warp size:                                     %d\\n"'),n("span",{class:"token punctuation"},","),s(" deviceProp"),n("span",{class:"token punctuation"},"."),s("warpSize"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"  Maximum number of threads per multiprocessor:  %d\\n"'),n("span",{class:"token punctuation"},","),s(`
      deviceProp`),n("span",{class:"token punctuation"},"."),s("maxThreadsPerMultiProcessor"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"  Maximum number of threads per block:           %d\\n"'),n("span",{class:"token punctuation"},","),s(`
      deviceProp`),n("span",{class:"token punctuation"},"."),s("maxThreadsPerBlock"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"  Maximum sizes of each dimension of a block:    %d x %d x %d\\n"'),n("span",{class:"token punctuation"},","),s(`
      deviceProp`),n("span",{class:"token punctuation"},"."),s("maxThreadsDim"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},","),s(`
      deviceProp`),n("span",{class:"token punctuation"},"."),s("maxThreadsDim"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},","),s(`
      deviceProp`),n("span",{class:"token punctuation"},"."),s("maxThreadsDim"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"2"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"  Maximum sizes of each dimension of a grid:     %d x %d x %d\\n"'),n("span",{class:"token punctuation"},","),s(`
      deviceProp`),n("span",{class:"token punctuation"},"."),s("maxGridSize"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},","),s(`
      deviceProp`),n("span",{class:"token punctuation"},"."),s("maxGridSize"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},","),s(`
      deviceProp`),n("span",{class:"token punctuation"},"."),s("maxGridSize"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"2"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"printf"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"  Maximum memory pitch:                          %lu bytes\\n"'),n("span",{class:"token punctuation"},","),s(" deviceProp"),n("span",{class:"token punctuation"},"."),s(`
 memPitch`),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
   `),n("span",{class:"token function"},"exit"),n("span",{class:"token punctuation"},"("),s("EXIT_SUCCESS"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),ks=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s(" $ nvcc checkDeviceInfor"),n("span",{class:"token punctuation"},"."),s("cu "),n("span",{class:"token operator"},"-"),s(`o checkDeviceInfor
 $ `),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s(`checkDeviceInfor


根据你的配置，checkDeviceInfor将返回所安装设备的不同信息。下面是一个输出示例：
 `),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s("checkDeviceInfor Starting"),n("span",{class:"token punctuation"},"."),n("span",{class:"token punctuation"},"."),n("span",{class:"token punctuation"},"."),s(`
 Detected `),n("span",{class:"token number"},"2"),s(" CUDA Capable "),n("span",{class:"token function"},"device"),n("span",{class:"token punctuation"},"("),s("s"),n("span",{class:"token punctuation"},")"),s(`
 Device `),n("span",{class:"token number"},"0"),n("span",{class:"token operator"},":"),s(),n("span",{class:"token string"},'"Tesla M2070"'),s(`
  CUDA Driver Version `),n("span",{class:"token operator"},"/"),s(" Runtime Version          "),n("span",{class:"token number"},"5.5"),s(),n("span",{class:"token operator"},"/"),s(),n("span",{class:"token number"},"5.5"),s(`
  CUDA Capability Major`),n("span",{class:"token operator"},"/"),s("Minor version number"),n("span",{class:"token operator"},":"),s("    "),n("span",{class:"token number"},"2.0"),s(`
  Total amount of global memory`),n("span",{class:"token operator"},":"),s("                 "),n("span",{class:"token number"},"5.25"),s(),n("span",{class:"token function"},"MBytes"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"5636554752"),s(" bytes"),n("span",{class:"token punctuation"},")"),s(`
  GPU Clock rate`),n("span",{class:"token operator"},":"),s("                                "),n("span",{class:"token number"},"1147"),s(),n("span",{class:"token function"},"MHz"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"1.15"),s(" GHz"),n("span",{class:"token punctuation"},")"),s(`
  Memory Clock rate`),n("span",{class:"token operator"},":"),s("                             "),n("span",{class:"token number"},"1566"),s(` Mhz
  Memory Bus Width`),n("span",{class:"token operator"},":"),s("                              "),n("span",{class:"token number"},"384"),n("span",{class:"token operator"},"-"),s(`bit
  L2 Cache Size`),n("span",{class:"token operator"},":"),s("                                 "),n("span",{class:"token number"},"786432"),s(` bytes
  Max Texture Dimension `),n("span",{class:"token function"},"Size"),s(),n("span",{class:"token punctuation"},"("),s("x"),n("span",{class:"token punctuation"},","),s("y"),n("span",{class:"token punctuation"},","),s("z"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token number"},"1"),s("D"),n("span",{class:"token operator"},"="),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"65536"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"2"),s("D"),n("span",{class:"token operator"},"="),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"65536"),n("span",{class:"token punctuation"},","),n("span",{class:"token number"},"65535"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"3"),s("D"),n("span",{class:"token operator"},"="),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"2048"),n("span",{class:"token punctuation"},","),n("span",{class:"token number"},"2048"),n("span",{class:"token punctuation"},","),n("span",{class:"token number"},"2048"),n("span",{class:"token punctuation"},")"),s(`
  Max Layered Texture `),n("span",{class:"token function"},"Size"),s(),n("span",{class:"token punctuation"},"("),s("dim"),n("span",{class:"token punctuation"},")"),s(" x layers "),n("span",{class:"token number"},"1"),s("D"),n("span",{class:"token operator"},"="),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"16384"),n("span",{class:"token punctuation"},")"),s(" x "),n("span",{class:"token number"},"2048"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"2"),s("D"),n("span",{class:"token operator"},"="),n("span",{class:"token punctuation"},"("),n("span",{class:"token number"},"16384"),n("span",{class:"token punctuation"},","),n("span",{class:"token number"},"16384"),n("span",{class:"token punctuation"},")"),s(" x "),n("span",{class:"token number"},"2048"),s(`
  Total amount of constant memory`),n("span",{class:"token operator"},":"),s("               "),n("span",{class:"token number"},"65536"),s(` bytes
  Total amount of shared memory per block`),n("span",{class:"token operator"},":"),s("       "),n("span",{class:"token number"},"49152"),s(` bytes
  Total number of registers available per block`),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"32768"),s(`
  Warp size`),n("span",{class:"token operator"},":"),s("                                     "),n("span",{class:"token number"},"32"),s(`
  Maximum number of threads per multiprocessor`),n("span",{class:"token operator"},":"),s("  "),n("span",{class:"token number"},"1536"),s(`
  Maximum number of threads per block`),n("span",{class:"token operator"},":"),s("           "),n("span",{class:"token number"},"1024"),s(`
  Maximum sizes of each dimension of a block`),n("span",{class:"token operator"},":"),s("    "),n("span",{class:"token number"},"1024"),s(" x "),n("span",{class:"token number"},"1024"),s(" x "),n("span",{class:"token number"},"64"),s(`
  Maximum sizes of each dimension of a grid`),n("span",{class:"token operator"},":"),s("     "),n("span",{class:"token number"},"65535"),s(" x "),n("span",{class:"token number"},"65535"),s(" x "),n("span",{class:"token number"},"65535"),s(`
  Maximum memory pitch`),n("span",{class:"token operator"},":"),s("                          "),n("span",{class:"token number"},"2147483647"),s(` bytes
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),ds=p(`<h3 id="_2-4-2-确定最优gpu" tabindex="-1"><a class="header-anchor" href="#_2-4-2-确定最优gpu" aria-hidden="true">#</a> 2.4.2 确定最优GPU</h3><p>Determining the Best GPU</p><ul><li>一些系统支持多GPU。在每个GPU都不同的情况下，选择性能最好的GPU运行核函数<br> 是非常重要的。通过比较GPU包含的多处理器的数量选出计算能力最佳的GPU。如果你有<br> 一个多GPU系统，可以使用以下代码来选择计算能力最优的设备：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>  <span class="token keyword">int</span> numDevices <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
   <span class="token function">cudaGetDeviceCount</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>numDevices<span class="token punctuation">)</span><span class="token punctuation">;</span>
   <span class="token keyword">if</span> <span class="token punctuation">(</span>numDevices <span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
      <span class="token keyword">int</span> maxMultiprocessors <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> maxDevice <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
      <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> device<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span> device<span class="token operator">&lt;</span>numDevices<span class="token punctuation">;</span> device<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
         cudaDeviceProp props<span class="token punctuation">;</span>
         <span class="token function">cudaGetDeviceProperties</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>props<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">;</span>
         <span class="token keyword">if</span> <span class="token punctuation">(</span>maxMultiprocessors <span class="token operator">&lt;</span> props<span class="token punctuation">.</span>multiProcessorCount<span class="token punctuation">)</span> <span class="token punctuation">{</span>
            maxMultiprocessors <span class="token operator">=</span> props<span class="token punctuation">.</span>multiProcessorCount<span class="token punctuation">;</span>
            maxDevice <span class="token operator">=</span> device<span class="token punctuation">;</span>
         <span class="token punctuation">}</span>
      <span class="token punctuation">}</span>
      <span class="token function">cudaSetDevice</span><span class="token punctuation">(</span>maxDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>
   <span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-4-3-使用nvidia-smi查询gpu信息" tabindex="-1"><a class="header-anchor" href="#_2-4-3-使用nvidia-smi查询gpu信息" aria-hidden="true">#</a> 2.4.3 使用nvidia-smi查询GPU信息</h3><p>Using nvidia-smi to Query GPU Information</p><ul><li><p>nvidia-smi是一个命令行工具，用于管理和监控GPU设备，并允许查询和修改设备状态。</p></li><li><p>你可以从命令行调用nvidia-smi。例如，要确定系统中安装了多少个GPU以及每个<br> GPU的设备ID，可以使用以下命令：<br> $ nvidia-smi -L<br> GPU 0: Tesla M2070 (UUID: GPU-68df8aec-e85c-9934-2b81-0c9e689a43a7)<br> GPU 1: Tesla M2070 (UUID: GPU-382f23c1-5160-01e2-3291-ff9628930b70)</p></li><li><p>你可以使用以下命令获取GPU 0的详细信息：<br> $ nvidia-smi -q -i 0</p></li><li><p>可以利用下列参数精简nvidia-smi的显示信息：</p></li><li><p>例如，若只显示设备内存信息，可使用以下命令：<br> $ nvidia-smi -q -i 0 -d MEMORY | tail -n 5<br> Memory Usage<br> Total : 5375 MB<br> Used : 9 MB<br> Free : 5366 MB</p></li><li><p>若只显示设备使用信息，可使用以下命令：<br> $ nvidia-smi -q -i 0 -d UTILIZATION | tail -n 4<br> Utilization<br> Gpu : 0 %<br> Memory : 0 %</p></li></ul><h3 id="_2-4-4-在运行时设置设备" tabindex="-1"><a class="header-anchor" href="#_2-4-4-在运行时设置设备" aria-hidden="true">#</a> 2.4.4 在运行时设置设备</h3><p>Setting Devices at Runtime</p><ul><li>支持多GPU的系统是很常见的。对于一个有N个GPU的系统，nvidia-smi从0到N―1标<br> 记设备ID。使用环境变量CUDA_VISIBLE_DEVICES，就可以在运行时指定所选的GPU且<br> 无须更改应用程序。</li><li>设置运行时环境变量CUDA_VISIBLE_DEVICES=2。nvidia驱动程序会屏蔽其他GPU，<br> 这时设备2作为设备0出现在应用程序中。</li><li>也可以使用CUDA_VISIBLE_DEVICES指定多个设备。例如，如果想测试GPU 2和GPU<br> 3，可以设置CUDA_VISIBLE_DEVICES=2，3。然后，在运行时，nvidia驱动程序将只使用<br> ID为2和3的设备，并且会将设备ID分别映射为0和1。</li></ul><h2 id="_2-5-总结" tabindex="-1"><a class="header-anchor" href="#_2-5-总结" aria-hidden="true">#</a> 2.5 总结</h2><p>SUMMARY</p><ul><li>与C语言中的并行编程相比，CUDA程序中的线程层次结构是其独有的结构。通过一<br> 个抽象的两级线程层次结构，CUDA能够控制一个大规模并行环境。通过本章的例子，你<br> 也学习到了网格和线程块的尺寸对内核性能有很大的影响。</li><li>对于一个给定的问题，你可以有多种选择来实现核函数和多种不同的配置来执行核函<br> 数。通常情况下，传统的实现方法无法获得最佳的内核性能。因此，学习如何组织线程是<br> CUDA编程的重点之一。理解网格和线程块的启发性的最好方法就是编写程序，通过反复<br> 试验来扩展你的技能和知识。</li><li>对于内核执行来说网格和线程块代表了线程布局的逻辑视角。在第3章，你将会从硬<br> 件视角研究相同的问题</li></ul><h2 id="_2-6-习题" tabindex="-1"><a class="header-anchor" href="#_2-6-习题" aria-hidden="true">#</a> 2.6 习题</h2><p>CHAPTER 2 EXERCISES</p>`,15),ms=n("li",null,[n("p",null,[s("1.在文件sumArraysOnGPU-timer.cu中，设置block.x＝1023，重新编译并运行。与执行"),n("br"),s(" 配置为block.x＝1024的运行结果进行比较，试着解释其区别和原因。")])],-1),bs={href:"http://2.xn--sumArraysOnGPU-timer-vl85a481emn7ge3sg.cu",target:"_blank",rel:"noopener noreferrer"},vs=n("br",null,null,-1),fs={href:"http://3.xn--sumMatrixOnGPU-2D-grid-2D-block-my83c2x5fbj1j8yri.cu",target:"_blank",rel:"noopener noreferrer"},hs=n("br",null,null,-1),ys={href:"http://4.xn--sumMatrixOnGPU-2D-grid-1D-block-my83c2x5fbj1j8yri.cu",target:"_blank",rel:"noopener noreferrer"},gs=n("br",null,null,-1),_s={href:"http://5.xn--checkDeviceInfor-l46zk84at30dt4xh.cu",target:"_blank",rel:"noopener noreferrer"};function xs(ws,Ds){const c=u("router-link"),l=u("ExternalLinkIcon"),i=u("CodeTabs");return k(),d("div",null,[B,E,m(" more "),n("nav",z,[n("ul",null,[n("li",null,[t(c,{to:"#简单介绍主要是基础"},{default:a(()=>[s("简单介绍主要是基础")]),_:1})]),n("li",null,[t(c,{to:"#第2章-cuda编程模型"},{default:a(()=>[s("第2章 CUDA编程模型")]),_:1})]),n("li",null,[t(c,{to:"#_2-1-cuda编程模型概述"},{default:a(()=>[s("2.1 CUDA编程模型概述")]),_:1}),n("ul",null,[n("li",null,[t(c,{to:"#_2-1-1-cuda编程结构"},{default:a(()=>[s("2.1.1 CUDA编程结构")]),_:1})]),n("li",null,[t(c,{to:"#_2-1-2-内存管理"},{default:a(()=>[s("2.1.2 内存管理")]),_:1})]),n("li",null,[t(c,{to:"#_2-1-3-线程管理"},{default:a(()=>[s("2.1.3 线程管理")]),_:1})]),n("li",null,[t(c,{to:"#_2-1-4-启动一个cuda核函数"},{default:a(()=>[s("2.1.4 启动一个CUDA核函数")]),_:1})]),n("li",null,[t(c,{to:"#_2-1-5-编写核函数"},{default:a(()=>[s("2.1.5 编写核函数")]),_:1})]),n("li",null,[t(c,{to:"#_2-1-6-验证核函数"},{default:a(()=>[s("2.1.6 验证核函数")]),_:1})]),n("li",null,[t(c,{to:"#_2-1-7-处理错误"},{default:a(()=>[s("2.1.7 处理错误")]),_:1})]),n("li",null,[t(c,{to:"#_2-1-8-编译和执行"},{default:a(()=>[s("2.1.8 编译和执行")]),_:1})])])]),n("li",null,[t(c,{to:"#_2-2-给核函数计时"},{default:a(()=>[s("2.2 给核函数计时")]),_:1}),n("ul",null,[n("li",null,[t(c,{to:"#_2-2-1-用cpu计时器计时"},{default:a(()=>[s("2.2.1 用CPU计时器计时")]),_:1})]),n("li",null,[t(c,{to:"#_2-2-2-用nvprof工具计时"},{default:a(()=>[s("2.2.2 用nvprof工具计时")]),_:1})])])]),n("li",null,[t(c,{to:"#_2-3-组织并行线程"},{default:a(()=>[s("2.3 组织并行线程")]),_:1}),n("ul",null,[n("li",null,[t(c,{to:"#_2-3-1-使用块和线程建立矩阵索引"},{default:a(()=>[s("2.3.1 使用块和线程建立矩阵索引")]),_:1})]),n("li",null,[t(c,{to:"#_2-3-2-使用二维网格和二维块对矩阵求和"},{default:a(()=>[s("2.3.2 使用二维网格和二维块对矩阵求和")]),_:1})]),n("li",null,[t(c,{to:"#_2-3-3-使用一维网格和一维块对矩阵求和"},{default:a(()=>[s("2.3.3 使用一维网格和一维块对矩阵求和")]),_:1})]),n("li",null,[t(c,{to:"#_2-3-4-使用二维网格和一维块对矩阵求和"},{default:a(()=>[s("2.3.4 使用二维网格和一维块对矩阵求和")]),_:1})])])]),n("li",null,[t(c,{to:"#_2-4-设备管理"},{default:a(()=>[s("2.4 设备管理")]),_:1}),n("ul",null,[n("li",null,[t(c,{to:"#_2-4-1-使用运行时api查询gpu信息"},{default:a(()=>[s("2.4.1 使用运行时API查询GPU信息")]),_:1})]),n("li",null,[t(c,{to:"#_2-4-2-确定最优gpu"},{default:a(()=>[s("2.4.2 确定最优GPU")]),_:1})]),n("li",null,[t(c,{to:"#_2-4-3-使用nvidia-smi查询gpu信息"},{default:a(()=>[s("2.4.3 使用nvidia-smi查询GPU信息")]),_:1})]),n("li",null,[t(c,{to:"#_2-4-4-在运行时设置设备"},{default:a(()=>[s("2.4.4 在运行时设置设备")]),_:1})])])]),n("li",null,[t(c,{to:"#_2-5-总结"},{default:a(()=>[s("2.5 总结")]),_:1})]),n("li",null,[t(c,{to:"#_2-6-习题"},{default:a(()=>[s("2.6 习题")]),_:1})])])]),S,n("div",T,[R,n("ul",null,[O,n("li",null,[n("p",null,[N,H,s(" ======== Warning: nvprof is not supported on devices with compute capability 8.0 and higher."),L,s(" Use NVIDIA Nsight Systems for GPU tracing and CPU sampling and NVIDIA Nsight Compute for GPU profiling."),V,s(" Refer "),n("a",F,[s("https://developer.nvidia.com/tools-overview"),t(l)]),s(" for more details.")])]),$,q,K,W])]),j,n("details",Y,[X,t(i,{id:"458",data:[{id:"源代码"},{id:"编译运行"}],"tab-id":"shell"},{title0:a(({value:e,isActive:o})=>[s("源代码")]),title1:a(({value:e,isActive:o})=>[s("编译运行")]),tab0:a(({value:e,isActive:o})=>[Q]),tab1:a(({value:e,isActive:o})=>[Z]),_:1})]),n("ul",null,[n("li",null,[s("CUDA 编译器允许您将许多选项直接传递给 nvcc 封装的内部编译工具。标记 -Xcompiler 可直接将选项指定给 C 编译器或预处理器。在前面的例子中，-std=c99 被传递给编译器，因为这里的 C 代码是按照 C99 标准的代码风格编写的。您可以在 CUDA 编译器文档中找到编译器选项 ("),n("a",J,[s("http://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html"),t(l)]),s(")")])]),nn,n("ul",null,[sn,n("li",null,[n("p",null,[s("You combine the code together into a fi le named "),n("a",an,[s("checkDimension.cu"),t(l)]),s(", as shown in Listing 2-2.")])])]),n("details",tn,[en,t(i,{id:"749",data:[{id:"源代码"},{id:"编译运行"}],"tab-id":"shell"},{title0:a(({value:e,isActive:o})=>[s("源代码")]),title1:a(({value:e,isActive:o})=>[s("编译运行")]),tab0:a(({value:e,isActive:o})=>[on]),tab1:a(({value:e,isActive:o})=>[cn]),_:1})]),pn,n("details",ln,[un,t(i,{id:"840",data:[{id:"源代码"},{id:"编译运行"}],"tab-id":"shell"},{title0:a(({value:e,isActive:o})=>[s("源代码")]),title1:a(({value:e,isActive:o})=>[s("编译运行")]),tab0:a(({value:e,isActive:o})=>[rn]),tab1:a(({value:e,isActive:o})=>[kn]),_:1})]),dn,n("ul",null,[n("li",null,[s("Now combine all the code together into a fi le named "),n("a",mn,[s("sumArraysOnGPU-small-case.cu"),t(l)]),s(", as shown in Listing 2-4.")])]),n("details",bn,[vn,t(i,{id:"1210",data:[{id:"源代码"},{id:"编译运行"}],"tab-id":"shell"},{title0:a(({value:e,isActive:o})=>[s("源代码")]),title1:a(({value:e,isActive:o})=>[s("编译运行")]),tab0:a(({value:e,isActive:o})=>[fn]),tab1:a(({value:e,isActive:o})=>[hn]),_:1})]),yn,n("details",gn,[_n,t(i,{id:"1294",data:[{id:"源代码"},{id:"编译运行"}],"tab-id":"shell"},{title0:a(({value:e,isActive:o})=>[s("源代码")]),title1:a(({value:e,isActive:o})=>[s("编译运行")]),tab0:a(({value:e,isActive:o})=>[xn]),tab1:a(({value:e,isActive:o})=>[wn]),_:1})]),Dn,n("ul",null,[Un,n("li",null,[n("p",null,[s("用以下命令编译并运行该程序："),An,s(" - $ nvcc -arch=sm_20 "),n("a",Cn,[s("checkThreadIndex.cu"),t(l)]),s(" -o checkIndex"),Pn,s(" - $ ./checkIndexs")])]),Mn,Gn]),n("details",In,[Bn,t(i,{id:"1492",data:[{id:"源代码"},{id:"编译运行"}],"tab-id":"shell"},{title0:a(({value:e,isActive:o})=>[s("源代码")]),title1:a(({value:e,isActive:o})=>[s("编译运行")]),tab0:a(({value:e,isActive:o})=>[En]),tab1:a(({value:e,isActive:o})=>[zn]),_:1})]),Sn,n("ul",null,[Tn,Rn,n("li",null,[s("将所有代码合并到 "),n("a",On,[s("sumMatrixOnGPU-2D-grid-2D-block.cu"),t(l)]),s(" 文件中。主函数如清单 2-7 所示。")])]),n("details",Nn,[Hn,t(i,{id:"1585",data:[{id:"源代码"},{id:"编译运行"}],"tab-id":"shell"},{title0:a(({value:e,isActive:o})=>[s("源代码")]),title1:a(({value:e,isActive:o})=>[s("编译运行")]),tab0:a(({value:e,isActive:o})=>[Ln]),tab1:a(({value:e,isActive:o})=>[Vn]),_:1})]),Fn,n("ul",null,[$n,qn,n("li",null,[n("p",null,[s("使用一维网格和一维块的更改替换代码清单2-7中的部分，并保存到文件sumMatrixOnGPU-1D-grid-1D-block.cu中，使用以下命令编译并运行该程序："),Kn,s(" $ nvcc -arch=sm_20 "),n("a",Wn,[s("sumMatrixOnGPU-1D-grid-1D-block.cu"),t(l)]),s(" -o matrix1D"),jn,s(" $ ./matrix1D")])]),Yn]),Xn,n("ul",null,[Qn,Zn,Jn,n("li",null,[n("p",null,[s("将清单 2-7 中的更改替换为 "),n("a",ns,[s("sumMatrixOnGPU-2D-grid-1D-block.cu"),t(l)]),s("。编译并运行以下命令："),ss,s(" $ nvcc -arch=sm_20 "),n("a",as,[s("sumMatrixOnGPU-2D-grid-1D-block.cu"),t(l)]),s(" -o mat2D1D"),ts,s(" $ ./mat2D1D")])]),es]),os,n("ul",null,[cs,n("li",null,[n("p",null,[s("cudaDeviceProp结构体返回GPU设备的属性，可以通过以下网址查看其内容： "),n("a",ps,[s("http://docs.nvidia.com/cuda/cuda-runtime-api/index.html#structcudaDeviceProp"),t(l)]),s(".")])]),ls]),n("details",is,[us,t(i,{id:"1837",data:[{id:"源代码"},{id:"编译运行"}],"tab-id":"shell"},{title0:a(({value:e,isActive:o})=>[s("源代码")]),title1:a(({value:e,isActive:o})=>[s("编译运行")]),tab0:a(({value:e,isActive:o})=>[rs]),tab1:a(({value:e,isActive:o})=>[ks]),_:1})]),ds,n("ul",null,[ms,n("li",null,[n("p",null,[n("a",bs,[s("2.参考文件sumArraysOnGPU-timer.cu"),t(l)]),s("，设置block.x＝256。新建一个内核，使得每个线"),vs,s(" 程处理两个元素。将此结果和其他的执行配置进行比较。")])]),n("li",null,[n("p",null,[n("a",fs,[s("3.参考文件sumMatrixOnGPU-2D-grid-2D-block.cu"),t(l)]),s("，并将它用于整数矩阵的加法运算"),hs,s(" 中，获取最佳的执行配置。")])]),n("li",null,[n("p",null,[n("a",ys,[s("4.参考文件sumMatrixOnGPU-2D-grid-1D-block.cu"),t(l)]),s("，新建一个内核，使得每个线程处理"),gs,s(" 两个元素，获取最佳的执行配置。")])]),n("li",null,[n("p",null,[n("a",_s,[s("5.借助程序checkDeviceInfor.cu"),t(l)]),s("，找到你的系统所支持的网格和块的最大尺寸。")])])])])}const Cs=r(I,[["render",xs],["__file","B-第二章.html.vue"]]);export{Cs as default};
