import{_ as o}from"./plugin-vue_export-helper-c27b6911.js";import{r,o as m,c as h,d as p,a as e,b as s,e as a,w as n,f as l}from"./app-2a2d189a.js";const c="/assets/algorithm1-ea699695.png",u="/assets/vamana-91e258d6.png",d="/assets/algorithm2-88fb369e.png",g="/assets/algorithm3-b3dfb02a.png",f="/assets/figure1-1aa6d79e.png",w="/assets/figure2-185348ae.png",b="/assets/figure3-9f0a4549.png",v={},y=e("h1",{id:"diskann",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#diskann","aria-hidden":"true"},"#"),s(" DiskANN")],-1),x=e("p",null,"DiskANN",-1),S={class:"hint-container info"},k=e("p",{class:"hint-container-title"},"ç›¸å…³ä¿¡æ¯",-1),N=e("li",null,[e("p",null,"å¯èƒ½è¿™é‡Œè¦æœ‰ä¸€äº› å…³äº å…¶å®ƒçš„å¯¹äºè¿™ç¯‡æ–‡ç« çš„è§£è¯»")],-1),_=e("li",null,[e("p",null,"æˆ‘ä»¬éœ€è¦ä¸€äº›é“¾æ¥ï¼Ÿ")],-1),G=e("li",null,[e("p",null,"paper:")],-1),M={href:"https://github.com/microsoft/DiskANN",target:"_blank",rel:"noopener noreferrer"},D=e("li",null,[e("p",null,"blogsï¼š")],-1),A={href:"https://www.zhihu.com/search?type=content&q=diskANN",target:"_blank",rel:"noopener noreferrer"},V={href:"https://blog.csdn.net/whenever5225/article/details/106863674",target:"_blank",rel:"noopener noreferrer"},z={href:"https://blog.csdn.net/weixin_44839084/article/details/119217569",target:"_blank",rel:"noopener noreferrer"},P={href:"https://blog.csdn.net/weixin_44839084/article/details/129679691",target:"_blank",rel:"noopener noreferrer"},q={class:"table-of-contents"},I=l('<h2 id="no-0-abstract" tabindex="-1"><a class="header-anchor" href="#no-0-abstract" aria-hidden="true">#</a> No.0 Abstract</h2><ul><li><mark>æ€»ç»“</mark></li><li>â€œ64GB RAMâ€é€šå¸¸æŒ‡çš„æ˜¯ 64GB çš„éšæœºå­˜å–å­˜å‚¨å™¨ï¼ˆRandom Access Memoryï¼‰ï¼Œä¹Ÿå°±æ˜¯è®¡ç®—æœºçš„è¿è¡Œå†…å­˜ã€‚è¿è¡Œå†…å­˜ç”¨äºæš‚æ—¶å­˜å‚¨æ­£åœ¨è¿è¡Œçš„ç¨‹åºå’Œæ•°æ®ï¼Œä»¥ä¾¿ CPU èƒ½å¤Ÿå¿«é€Ÿè®¿é—®å’Œå¤„ç†ã€‚</li><li></li><li><mark>åŸæ–‡ç¿»è¯‘</mark></li><li>å½“å‰æœ€å…ˆè¿›(state-of-the-art)çš„è¿‘ä¼¼æœ€è¿‘é‚»æœç´¢ï¼ˆANNSï¼‰ç®—æ³•ç”Ÿæˆçš„ç´¢å¼•å¿…é¡»<mark>å­˜å‚¨åœ¨ä¸»å†…å­˜ä¸­</mark>ï¼Œä»¥ä¾¿è¿›è¡Œå¿«é€Ÿã€é«˜å¬å›ç‡çš„æœç´¢ã€‚è¿™ä½¿å¾—å®ƒä»¬å¼€é”€é«˜æ˜‚å¹¶é™åˆ¶äº†æ•°æ®é›†çš„å¤§å°ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ–°çš„åŸºäºå›¾çš„ç´¢å¼•å’Œæœç´¢ç³»ç»Ÿï¼Œåä¸ºDiskANNï¼Œå®ƒèƒ½å¤Ÿåœ¨ä¸€å°åªæœ‰64GB RAMå’Œä¸€å—ä¾¿å®œçš„å›ºæ€ç¡¬ç›˜ï¼ˆSSDï¼‰çš„å•ä¸ªå·¥ä½œç«™ä¸Šç»™åäº¿ç‚¹çš„æ•°æ®åº“å»ºç´¢å¼•ã€å­˜å‚¨å’Œæœç´¢ã€‚ä¸å½“å‰çš„æ™ºæ…§ç›¸åï¼Œæˆ‘ä»¬è¯æ˜äº†DiskANNæ„å»ºçš„åŸºäºSSDçš„ç´¢å¼•èƒ½å¤Ÿæ»¡è¶³å¤§è§„æ¨¡ANNSçš„å…¨éƒ¨ä¸‰ä¸ªæ„¿æœ›ï¼šé«˜å¬å›ç‡ã€ä½æŸ¥è¯¢å»¶è¿Ÿå’Œé«˜å¯†åº¦ï¼ˆæ¯ä¸ªèŠ‚ç‚¹ç´¢å¼•çš„ç‚¹ï¼‰ã€‚åœ¨åäº¿ç‚¹çš„SIFT1B bigannæ•°æ®é›†ä¸Šï¼ŒDiskANNèƒ½å¤Ÿåœ¨ä¸€å°16æ ¸æœºå™¨ä¸Š(QPS)æ¯ç§’æœåŠ¡è¶…è¿‡5000ä¸ªæŸ¥è¯¢ï¼Œå¹³å‡å»¶è¿Ÿ&lt;3msï¼Œå¹¶ä¸”ä¿æŒ95%ä»¥ä¸Šçš„1-recall@1ï¼Œè€Œä½¿ç”¨ç±»ä¼¼å†…å­˜å ç”¨çš„æœ€å…ˆè¿›åäº¿ç‚¹ANNSç®—æ³•ï¼Œå¦‚FAISS [18] å’Œ IVFOADC+G+P [8] åœ¨1-recall@1çš„å‡†ç¡®ç‡çº¦ä¸º50%ã€‚å¦å¤–ï¼Œåœ¨é«˜å¬å›ç‡æ¨¡å¼ä¸‹ï¼ŒDiskANNå¯ä»¥æ¯”å¦‚HNSW [21] å’Œ NSG [13]è¿™æ ·çš„æœ€å…ˆè¿›å›¾å½¢åŸºæ–¹æ³•åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šç´¢å¼•å’ŒæœåŠ¡5è‡³10å€æ›´å¤šçš„ç‚¹ã€‚æœ€åï¼Œä½œä¸ºæˆ‘ä»¬æ•´ä½“DiskANNç³»ç»Ÿçš„ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å¼•å…¥äº†Vamanaï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„åŸºäºå›¾çš„ANNSç´¢å¼•ï¼Œå³ä½¿å¯¹äºå†…å­˜ä¸­çš„ç´¢å¼•æ¥è¯´ï¼Œå®ƒä¹Ÿæ¯”ç°æœ‰çš„å›¾ç´¢å¼•æ›´åŠ é€šç”¨ã€‚</li></ul><h2 id="no-1-introduction" tabindex="-1"><a class="header-anchor" href="#no-1-introduction" aria-hidden="true">#</a> No.1 Introduction</h2><ul><li><p><mark>åŸæ–‡ç¿»è¯‘</mark></p></li><li><p>åœ¨æœ€è¿‘é‚»æœç´¢é—®é¢˜ä¸­ï¼Œç»™å‡ºäº†ä¸€ä¸ªç‰¹å®šç©ºé—´ä¸­ç‚¹çš„æ•°æ®é›†Pã€‚ç›®æ ‡æ˜¯<mark>è®¾è®¡ä¸€ä¸ªå°å°ºå¯¸çš„æ•°æ®ç»“æ„</mark>ï¼Œè¿™æ ·ï¼Œå¯¹äºç›¸åŒåº¦é‡ç©ºé—´ä¸­çš„ä»»ä½•æŸ¥è¯¢qå’Œç›®æ ‡kï¼Œæˆ‘ä»¬å°±å¯ä»¥å¿«é€Ÿåœ°ä»æ•°æ®é›†Pä¸­æ£€ç´¢åˆ°qçš„kä¸ªæœ€è¿‘é‚»ã€‚è¿™æ˜¯ç®—æ³•ç ”ç©¶ä¸­çš„ä¸€ä¸ªåŸºæœ¬é—®é¢˜ï¼Œä¹Ÿæ˜¯åœ¨è®¡ç®—æœºè§†è§‰ã€æ–‡æ¡£æ£€ç´¢å’Œæ¨èç³»ç»Ÿç­‰ä¸åŒé¢†åŸŸä¸­å¸¸ç”¨çš„( sub-routine)å­ä¾‹ç¨‹ï¼Œç­‰ç­‰ã€‚åœ¨è¿™äº›åº”ç”¨ä¸­ï¼Œå®é™…çš„å®ä½“â€”â€”å›¾åƒã€æ–‡æ¡£ã€ç”¨æˆ·æ¡£æ¡ˆâ€”â€”è¢«åµŒå…¥åˆ°ç™¾ç»´æˆ–åƒç»´ç©ºé—´ä¸­ï¼Œä»¥ä¾¿æ‰€éœ€çš„å®ä½“ç›¸ä¼¼æ€§æ¦‚å¿µè¢«ç¼–ç ä¸ºå®ƒä»¬åµŒå…¥çš„è·ç¦»ã€‚</p></li><li><p>In the nearest neighbor search problem, we are given a dataset <em>P</em> of points in some space. The goal is to design a data structure of small size, such that, for any query <em>q</em> in the same metric space, and target <em>k</em>, we can retrieve the <em>k</em> nearest neighbors of <em>q</em> from the dataset <em>P</em> quickly.</p><ul><li>a small size data structure, for query q and retrieve knn quickly.</li></ul></li><li><p>This is a fundamental problem in algorithms research, and also a commonly used sub-routine in a diverse set of areas such as computer vision, document retrieval and recommendation systems, to name a few. In these applications, the actual entities â€” images, documents, user profiles â€” are <em>embedded</em> into a hundred or thousand dimensional space such that a desired notion of the entitiesâ€™ similarity is encoded as distance between their embeddings.</p><ul><li>be embedded a hundred or thousand dimensional space;</li></ul></li><li><p>ä¸å¹¸çš„æ˜¯ï¼Œç”±äºæ‰€è°“çš„ç»´åº¦è¯…å’’ç°è±¡ï¼Œé€šå¸¸ä¸å¯èƒ½åœ¨ä¸è¿›è¡Œæ•°æ®çš„çº¿æ€§æ‰«æçš„æƒ…å†µä¸‹æ£€ç´¢åˆ°ç²¾ç¡®çš„æœ€è¿‘é‚»ï¼ˆä¾‹å¦‚ï¼Œè§[15, 23]ï¼‰ã€‚å› æ­¤ï¼Œäººä»¬è½¬è€Œå¯»æ‰¾è¿‘ä¼¼æœ€è¿‘é‚»ï¼ˆANNï¼‰ï¼Œå…¶ç›®æ ‡æ˜¯æ£€ç´¢åˆ°æ¥è¿‘æœ€ä¼˜çš„kä¸ªé‚»å±…ã€‚æ›´æ­£å¼åœ°ï¼Œå‡è®¾æœ‰ä¸€ä¸ªæŸ¥è¯¢qï¼Œå¹¶ä¸”å‡è®¾ç®—æ³•è¾“å‡ºäº†ä¸€ç»„kä¸ªå€™é€‰è¿‘é‚»Xï¼Œå‡è®¾Gæ˜¯åŸºç¡€æ•°æ®é›†ä¸­qçš„kä¸ªæœ€è¿‘é‚»çš„çœŸå®é›†åˆ(ground-truth)ã€‚é‚£ä¹ˆï¼Œæˆ‘ä»¬å®šä¹‰è¿™ä¸ªé›†åˆXçš„k-recall@kä¸º|Xâˆ©G|/kã€‚é‚£ä¹ˆï¼ŒANNç®—æ³•çš„ç›®æ ‡å°±æ˜¯åœ¨å°½å¯èƒ½å¿«é€Ÿæ£€ç´¢ç»“æœçš„åŒæ—¶æœ€å¤§åŒ–å¬å›ç‡ï¼Œè¿™å°±å¯¼è‡´äº†å¬å›ç‡ä¸å»¶è¿Ÿä¹‹é—´çš„æƒè¡¡ã€‚</p></li><li><p>Unfortunately, it is often impossible to retrieve the exact nearest neighbors without essentially resorting to a linear scan of the data (see, e.g., [15, 23]) due to a phenomenon known as the <em>curse of</em> <em>dimensionality</em> [10].</p><ul><li>å¦‚æœæˆ‘ä»¬æš´åŠ›çš„è¯ é‚£ä¹ˆè¿›è¡Œ linear scanï¼Œå…¶ æ—¶é—´å¤æ‚åº¦ä¸ºO(n d);</li></ul></li><li><p>As a result, one resorts to finding the <em>approximate nearest neighbors</em> (ANN) where the goal is to retrieve <em>k</em> neighbors which are close to being optimal.</p><ul><li>ANNSï¼šå…¶ç›®æ ‡æ˜¯æ£€ç´¢åˆ°æ¥è¿‘æœ€ä¼˜çš„kä¸ªé‚»å±…</li></ul></li><li><p>More formally, consider a query <em>q</em>, and suppose the algorithm outputs a set <em>X</em> of <em>k</em> candidate near neighbors, and suppose <em>G</em> is the ground-truth set of the <em>k</em> closest neighbors to <em>q</em> from among the points of the base dataset.</p></li><li><p>Then, we define the <em>k</em>-recall@<em>k</em> of this set <em>X</em> to be |Xâˆ©G|/k. The goal of an ANN algorithm then is to maximize recall while retrieving the results as quickly as possible, which results in the recall-vs-latency tradeoff.ï¼ˆrecall-vs-time tradeoffï¼‰</p></li><li><p><mark>åŸæ–‡ç¿»è¯‘</mark></p></li><li><p>è¿™ä¸ªé—®é¢˜æœ‰è®¸å¤šç®—æ³•ï¼Œå®ƒä»¬æœ‰ç€å¤šæ ·çš„ç´¢å¼•æ„å»ºæ–¹æ³•ï¼Œå¹¶åœ¨ç´¢å¼•æ—¶é—´ã€å¬å›ç‡å’ŒæŸ¥è¯¢æ—¶é—´ç­‰æ–¹é¢æœ‰ä¸€ç³»åˆ—çš„æƒè¡¡ã€‚ä¾‹å¦‚ï¼Œè™½ç„¶k-dæ ‘ç”Ÿæˆçš„ç´¢å¼•ç´§å‡‘ï¼Œä¸”åœ¨ä½ç»´åº¦æ—¶æœç´¢é€Ÿåº¦å¿«ï¼Œä½†å½“ç»´åº¦dè¶…è¿‡å¤§çº¦20æ—¶å®ƒä»¬é€šå¸¸ä¼šéå¸¸æ…¢ã€‚å¦ä¸€æ–¹é¢ï¼ŒåŸºäºå±€éƒ¨æ•æ„Ÿå“ˆå¸Œï¼ˆLSHï¼‰çš„æ–¹æ³•[2, 4]åœ¨æœ€åæƒ…å†µä¸‹æä¾›äº†ç´¢å¼•å¤§å°å’Œæœç´¢æ—¶é—´ä¹‹é—´å‡ ä¹æœ€ä¼˜çš„ä¿è¯ï¼Œä½†å®ƒä»¬æœªèƒ½åˆ©ç”¨ç‚¹çš„åˆ†å¸ƒï¼Œå¹¶ä¸”åœ¨ç°å®ä¸–ç•Œæ•°æ®é›†ä¸Šè¢«æ›´å¤šè¿‘æœŸçš„åŸºäºå›¾çš„æ–¹æ³•è¶…è¶Šã€‚æœ€è¿‘å¯¹æ•°æ®ä¾èµ–çš„LSHæ–¹æ¡ˆçš„ç ”ç©¶ï¼ˆä¾‹å¦‚[3]ï¼‰è¿˜æ²¡æœ‰åœ¨å¤§è§„æ¨¡ä¸Šè¢«è¯æ˜ã€‚æˆªè‡³ç›®å‰ï¼Œå°±æœç´¢æ—¶é—´ä¸å¬å›ç‡è€Œè¨€ï¼Œç°å®ä¸–ç•Œæ•°æ®é›†ä¸Šæœ€å¥½çš„ç®—æ³•é€šå¸¸æ˜¯åŸºäºå›¾çš„ç®—æ³•ï¼Œå¦‚HNSW[21]å’ŒNSG[13]ï¼Œå…¶ä¸­ç´¢å¼•ç®—æ³•æ„é€ äº†ä¸€ä¸ª<mark>å¯å¯¼èˆªçš„å›¾</mark>ï¼Œè¦†ç›–äº†åŸºç¡€ç‚¹ï¼Œæœç´¢è¿‡ç¨‹æ˜¯ä¸€ä¸ªæœ€ä¼˜å…ˆéå†ï¼Œå®ƒä»ä¸€ä¸ªé€‰å®šçš„ï¼ˆæˆ–éšæœºçš„ï¼‰ç‚¹å¼€å§‹ï¼Œå¹¶æ²¿ç€å›¾çš„è¾¹èµ°ï¼ŒåŒæ—¶åœ¨æ¯ä¸€æ­¥éƒ½æ›´æ¥è¿‘æŸ¥è¯¢ç‚¹ï¼Œç›´åˆ°å®ƒæ”¶æ•›åˆ°ä¸€ä¸ªå±€éƒ¨æœ€å°ç‚¹ã€‚Liç­‰äººè¿‘æœŸçš„å·¥ä½œ[20]å¯¹ANNç®—æ³•è¿›è¡Œäº†ä¼˜ç§€çš„è°ƒæŸ¥å’Œæ¯”è¾ƒã€‚</p></li><li><p>There are numerous algorithms for this problem with diverse index construction methodologies and a range of tradeoffs w.r.t indexing time, recall, and query time.</p><ul><li>å…¶å®è¿™äº›ç®—æ³•å°±æ˜¯ï¼š diverse index constructionï¼Œ tradeoff the indexing time, recall, and query time;</li></ul></li><li><p>For example, while k-d trees generate compact indices that are fast to search in low dimensions, they are typically very slow when dimension <em>d</em> exceeds about 20. On the other hand, Locality Sensitive Hashing based methods [2, 4] provide <em>near-optimal</em> guarantees on the tradeoff between index size and search time in the worst case, but they fail to exploit the distribution of the points and are outperformed by more recent graph-based methods on real-world datasets. Recent work on data-dependent LSH schemes (e.g. [3]) is yet to be proven at scale.</p><ul><li>è®²è¿°äº† kd-treeçš„ç¼ºç‚¹ç»´åº¦é—®é¢˜ å’Œ LSHçš„ç¼ºç‚¹æ²¡æœ‰å……åˆ†åˆ©ç”¨ç‚¹çš„åˆ†å¸ƒï¼šthe distrubution of the points ç©ºé—´ç‰¹æ€§ï¼Œ</li></ul></li><li><p>As of this writing, the best algorithms in terms of search time vs recall on real-world datasets are often graph-based algorithms such as HNSW [21] and NSG [13] where the indexing algorithm constructs a <em>navigable</em> graph over the base points, and the search procedure is a best-first traversal that starts at a chosen (or random) point, and walks along the edges of the graph, while getting closer to the query at each step until it converges to a local minimum. A recent work of Li et al. [20] has an excellent survey and comparison of ANN algorithms.</p><ul><li>è®²è¿°äº†åœ¨ search time vs recall è¿™ä¸¤ä¸ªçš„(not say index size) æœ‰ä¼˜åŠ¿çš„åŸºäºå›¾çš„ç®—æ³•ï¼šhnsw and nsg</li><li>ç¦»çº¿æ„å»ºé˜¶æ®µï¼šconstructs a navigable graph over the base points å¯å¯¼èˆª</li><li>åœ¨çº¿æœç´¢é˜¶æ®µï¼šand the search procedure is a best-first traversal that starts at a chosen (or random) point, and walks along the edges of the graph, while getting closer to the query at each step until it converges to a local minimum.NN-expansion;</li></ul></li><li><p>è®¸å¤šåº”ç”¨ç¨‹åºéœ€è¦åœ¨æ•°åäº¿ä¸ªæ¬§å‡ é‡Œå¾—åº¦é‡çš„ç‚¹ä¸Šè¿›è¡Œå¿«é€Ÿå‡†ç¡®çš„æœç´¢ã€‚å¦‚ä»Šå¯¹å¤§å‹æ•°æ®é›†è¿›è¡Œç´¢å¼•åŸºæœ¬ä¸Šæœ‰ä¸¤ç§ä¸»è¦çš„é«˜å±‚æ–¹æ³•ã€‚</p></li><li><p>Many applications require fast and accurate search on billions of points in Euclidean metrics. Today, there are essentially two high-level approaches to indexing large datasets.</p><ul><li>é¦–å…ˆæ˜¯ fast and accurate ï¼Œç„¶åæ˜¯ æ•°æ®é›†å¤§1bï¼Œ</li></ul></li></ul><p>â€‹</p><ul><li><p>ç¬¬ä¸€ç§æ–¹æ³•åŸºäº<mark>å€’æ’ç´¢å¼•+æ•°æ®å‹ç¼©( Inverted Index + Data Compression)</mark>ï¼ŒåŒ…æ‹¬è¯¸å¦‚ FAISS[18]å’Œ IVFOADC+G+P[8]ç­‰æ–¹æ³•ã€‚è¿™äº›æ–¹æ³•å°†æ•°æ®é›†èšç±»ä¸º M ä¸ªåˆ†åŒºï¼Œå¹¶å°†æŸ¥è¯¢ ğ‘ æœ€è¿‘çš„éƒ¨åˆ†ä¸­çš„ç‚¹åšæ¯”è¾ƒè¿›è¡Œæ¯”è¾ƒï¼Œæ¯”å¦‚ï¼Œm &lt;&lt; Måˆ†åŒºã€‚mè¿œå°äºM ä¸ªæœ€æ¥è¿‘æŸ¥è¯¢çš„èšç±»éƒ¨åˆ†ä¸­çš„ç‚¹è¿›è¡Œæ¯”è¾ƒã€‚æ­¤å¤–ï¼Œç”±äºå…¨ç²¾åº¦å‘é‡æ— æ³•è£…å…¥ä¸»å†…å­˜ï¼Œæ‰€ä»¥ä½¿ç”¨è¯¸å¦‚ä¹˜ç§¯é‡åŒ–[17]ç­‰é‡åŒ–æ–¹æ¡ˆå¯¹è¿™äº›ç‚¹è¿›è¡Œå‹ç¼©ã€‚è™½ç„¶è¿™äº›æ–¹æ¡ˆå†…å­˜å ç”¨è¾ƒå°â€”â€”åœ¨ 128 ç»´ä¸­å­˜å‚¨æ•°åäº¿ä¸ªç‚¹çš„ç´¢å¼•ä¸åˆ° 64GBâ€”â€”å¹¶ä¸”ä½¿ç”¨ GPU æˆ–å…¶ä»–ç¡¬ä»¶åŠ é€Ÿå™¨å¯ä»¥åœ¨å°äº 5 æ¯«ç§’å†…æ£€ç´¢åˆ°ç»“æœï¼Œä½†å®ƒä»¬çš„ 1-recall@1 ç›¸å½“ä½ï¼ˆçº¦ä¸º 0.5ï¼‰ï¼Œå› ä¸ºæ•°æ®å‹ç¼©æ˜¯æœ‰æŸçš„ã€‚è¿™äº›æ–¹æ³•å¯¹äºè¾ƒå¼±çš„ 1-recall@100 çš„æ¦‚å¿µä¼šæŠ¥å‘Šæ›´é«˜çš„å¬å›å€¼â€”â€”å³çœŸæ­£çš„æœ€è¿‘é‚»å­˜åœ¨äº 100 ä¸ªè¾“å‡ºå€™é€‰åˆ—è¡¨ä¸­çš„å¯èƒ½æ€§ã€‚ç„¶è€Œï¼Œåœ¨è®¸å¤šåº”ç”¨ä¸­ï¼Œè¿™ä¸ªåº¦é‡å¯èƒ½ä¸è¢«æ¥å—ã€‚</p></li><li><p>footprintï¼šå ç”¨å†…å­˜</p></li><li><p>The first approach is based on <em>Inverted Index + Data Compression</em> and includes methods such as FAISS [18] and IVFOADC+G+P [8].</p><ul><li>è¿™ä¸ªæ„Ÿè§‰å°±æ˜¯PQ çš„è®ºæ–‡ åé¢çš„ä»‹ç»çš„é‚£äº›å³ï¼šIVF+PQï¼›</li></ul></li><li><p>These methods cluster the dataset into <em>M</em> partitions, and compare the query to only the points in a few, say, <em>m &lt;&lt; M</em> partitions closest to the query.</p><ul><li>ç¬¬ä¸€æ­¥ï¼šèšç±»ï¼Œç„¶åå»ºç«‹IVFï¼Œç„¶åqueryåˆ°mä¸ª æŸ¥è¯¢éƒ¨åˆ† è¿›è¡Œ queryæ¯”è¾ƒ(å°±æ˜¯PQè®²è¿°çš„åé¢çš„éƒ¨åˆ†)</li><li>å¦‚æœä¸è¿›è¡ŒPQçš„è¯ï¼Œé‚£å°±æ˜¯æœ€æ™®é€šçš„IVFäº†</li></ul></li><li><p>Moreover, since the full-precision vectors cannot fit in main memory, the points are compressed using a quantization scheme such as <em>Product Quantization</em> [17].</p><ul><li>ä¸Šé¢å…ˆè®²è¿°ä¸€ä¸ªç®€å•çš„ivfï¼Œç„¶åè¯´ä¸èƒ½å…¨éƒ¨æ”¾å…¥åˆ°main memoryï¼Œå°±è¿›è¡ŒPQ</li></ul></li><li><p>While these schemes have a small memory footprint â€“ less than 64 GB for storing an index on billion points in 128 dimensions and can retrieve results in <em>&lt;</em> 5 ms using GPUs or other hardware accelerators, their 1-recall@1 is rather low (around 0*.*5) since the data compression is lossy.</p><ul><li>è¿™æ ·çš„è¯pqå¯¼è‡´ å†…å­˜å ç”¨å°ï¼Œç„¶ååˆæ˜¯åœ¨ main memoryæ‰€ä»¥åˆ©ç”¨ä¸Šç¡¬ä»¶åŠ é€Ÿå’ŒGPUs å¯ä»¥è¾¾åˆ°å¾ˆä½çš„æ£€ç´¢æ—¶é—´ï¼›</li><li>ä½†æ˜¯å‘¢ç”±äº æœ‰æŸcompression å¯¼è‡´recall is low</li></ul></li><li><p>These methods report higher recall values for a weaker notion of 1-recall@100 â€“ the likelihood that the true nearest neighbor is present in a list of 100 output candidates. However, this measure may not be acceptable in many applications.</p><ul><li>è¿™äº›æ–¹æ³• å¯¹äº 1-recall@100çš„æ—¶å€™ ç»“æœä¼šå¥½ï¼›ä½†æ˜¯ä¸é€‚ç”¨ï¼›ï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿ</li></ul></li><li><p>ç¬¬äºŒç§æ–¹æ³•æ˜¯å°†æ•°æ®é›†åˆ†å‰²æˆä¸ç›¸äº¤çš„åˆ†ç‰‡ï¼Œå¹¶ä¸ºæ¯ä¸ªåˆ†ç‰‡æ„å»ºä¸€ä¸ªå†…å­˜ç´¢å¼•ã€‚ç„¶è€Œï¼Œç”±äºè¿™äº›ç´¢å¼•æ—¢å­˜å‚¨ç´¢å¼•åˆå­˜å‚¨æœªå‹ç¼©çš„æ•°æ®ç‚¹ï¼Œæ‰€ä»¥å®ƒä»¬çš„å†…å­˜å ç”¨æ¯”ç¬¬ä¸€ç§æ–¹æ³•å¤§ã€‚ä¾‹å¦‚ï¼Œå¯¹äº 128 ç»´çš„ 1 äº¿ä¸ªæµ®ç‚¹å‘é‡çš„ä¸€ä¸ª NSG ç´¢å¼•ï¼Œå…¶å†…å­˜å ç”¨å¤§çº¦ä¸º 75GBÂ²ã€‚å› æ­¤ï¼Œè¦ä¸ºæ•°åäº¿ä¸ªç‚¹æä¾›ç´¢å¼•æœåŠ¡ï¼Œå°±éœ€è¦å¤šå°æœºå™¨æ¥æ‰¿è½½è¿™äº›ç´¢å¼•ã€‚æ®æŠ¥é“[13]ï¼Œåœ¨é˜¿é‡Œå·´å·´çš„ç”µå­å•†åŠ¡å¹³å°æ·˜å®ä¸­å°±é‡‡ç”¨äº†è¿™æ ·çš„æ–¹æ¡ˆï¼Œä»–ä»¬å°†åŒ…å« 20 äº¿ä¸ª 128 ç»´ç‚¹çš„æ•°æ®é›†åˆ†æˆ 32 ä¸ªåˆ†ç‰‡ï¼Œå¹¶åœ¨ä¸åŒçš„æœºå™¨ä¸Šä¸ºæ¯ä¸ªåˆ†ç‰‡æ‰¿è½½ç´¢å¼•ã€‚æŸ¥è¯¢è¢«è·¯ç”±åˆ°æ‰€æœ‰åˆ†ç‰‡ï¼Œæ‰€æœ‰åˆ†ç‰‡çš„ç»“æœè¢«æ±‡æ€»ã€‚é€šè¿‡è¿™ç§æ–¹æ³•ï¼Œä»–ä»¬æŠ¥å‘Šåœ¨å»¶è¿Ÿçº¦ä¸º 5 æ¯«ç§’æ—¶ 100-å¬å›ç‡@100 çš„å€¼ä¸º 0.98ã€‚è¯·æ³¨æ„ï¼Œå°†å…¶æ‰©å±•åˆ°æ‹¥æœ‰æ•°ç™¾äº¿ä¸ªç‚¹çš„ç½‘ç»œè§„æ¨¡æ•°æ®æ—¶ï¼Œå°†éœ€è¦æ•°åƒå°æœºå™¨ã€‚æŸ¥è¯¢æ—¶ï¼Œå°†æŸ¥è¯¢ç‚¹åŒæ—¶è·¯ç”±åˆ°æ¯ä¸€ä¸ªéƒ¨åˆ†ï¼Œåœ¨å„éƒ¨åˆ†å¹¶è¡Œæ‰§è¡ŒæŸ¥è¯¢ï¼Œæœ€åï¼Œå°†å„éƒ¨åˆ†è¿”å›çš„ç»“æœæ•´åˆåˆ°ä¸€å—é€‰å–æœ€è¿‘çš„ç‚¹ä½œä¸ºæœ€ç»ˆç»“æœã€‚è¿™ç±»æ–¹æ³•ç”±äºå°†åŸå§‹æ•°æ®è½½å…¥å†…å­˜ï¼Œå› æ­¤æœ‰å¾ˆå¤§çš„å†…å­˜å ç”¨ï¼Œè€Œä¸”ï¼Œå½“æ•°æ®è§„æ¨¡å¢å¤§æ—¶ï¼Œå°±éœ€è¦æ›´å¤šçš„æœºå™¨ï¼Œä¼˜ç‚¹æ˜¯èƒ½å¤Ÿå®ç°é«˜å¬å›ä½å»¶è¿Ÿã€‚</p></li><li><p>The second approach is to divide the dataset into disjoint <em>shards</em>, and build an in-memory index for each shard.</p><ul><li>ä¹Ÿæ˜¯å•Šï¼Œæ¯”å¦‚SIFT100Mçš„æ•°æ®ï¼Œæœ‰ä¸€ä¸ªqueryï¼Œé‚£ä¹ˆåˆ†åˆ«åœ¨10ä¸ª10Mä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œæœç´¢æœ€åç»“æœrerankçš„è¯å¥½åƒæ˜¯è·Ÿåœ¨100Mä¸Šè¿›è¡Œæœç´¢æ˜¯ä¸€æ ·çš„å§ï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿ</li></ul></li><li><p>However, since these indices store both the index and the uncompressed data points, they have a larger memory footprint than the first approach. For example, an NSG index for 100M floating-point vectors in 128 dimensions would have a memory footprint of around 75GB . Therefore, serving an index over a billion points would need several machines to host the indices.</p><ul><li>å› ä¸ºè¿™ä¸ªæ˜¯æ²¡æœ‰è¿›è¡Œå‹ç¼©çš„ï¼Œæ‰€ä»¥ SIFT100Mçš„æ•°æ® å ç”¨75GBï¼Œå› æ­¤å­˜å‚¨1Bï¼Œéœ€è¦å¤šå°æœºå™¨è¿›è¡Œæ‰¿è½½ç´¢å¼•ï¼›</li></ul></li><li><p>Such a scheme is reportedly [13] in use in Taobao, Alibabaâ€™s e-commerce platform, where they divide their dataset with 2 billion 128-dimensional points into 32 shards, and host the index for each shard on a different machine.</p><ul><li>20äº¿ä¸ªæ•°æ® åˆ†ä¸º 32å—ä¸ç›¸äº¤çš„ï¼›</li></ul></li><li><p>Queries are routed to all shards, and the results from all shards are aggregated. Using this approach, they report 100-recall@100 values of 0*.*98 with a latency of <em>âˆ¼</em> 5ms. Note that extending this to web scale data with <em>hundreds of billions</em> of points would require thousands of machines.</p><ul><li>æ•ˆæœæ„Ÿè§‰è¿˜æ˜¯å¾ˆå¥½çš„ï¼›é™¤äº†éœ€è¦æ›´å¤šçš„æœºå™¨ï¼›</li></ul></li><li><p>è¿™ä¸¤ç±»ç®—æ³•çš„å¯æ‰©å±•æ€§éƒ½å—åˆ°è¿™æ ·ä¸€ä¸ªäº‹å®çš„é™åˆ¶ï¼Œå³<mark>å®ƒä»¬æ„å»ºçš„ç´¢å¼•æ—¨åœ¨ä»ä¸»å†…å­˜ä¸­æä¾›æœåŠ¡</mark>ã€‚å°†è¿™äº›ç´¢å¼•ç§»åŠ¨åˆ°ç£ç›˜ï¼Œç”šè‡³æ˜¯å›ºæ€ç¡¬ç›˜ï¼ˆSSDsï¼‰ä¸Šï¼Œå°†ä¼šå¯¼è‡´æœç´¢å»¶è¿Ÿç¾éš¾æ€§åœ°ä¸Šå‡ä»¥åŠç›¸åº”çš„ååé‡ä¸‹é™ã€‚å…³äºéœ€è¦ä¸»å†…å­˜çš„æœç´¢çš„å½“å‰è§‚ç‚¹åæ˜ åœ¨ FAISS çš„åšå®¢æ–‡ç« [11]ä¸­ï¼šâ€œFAISS ä»…æ”¯æŒä»éšæœºå­˜å–å­˜å‚¨å™¨ï¼ˆRAMï¼‰ä¸­è¿›è¡Œæœç´¢ï¼Œå› ä¸ºç£ç›˜æ•°æ®åº“è¦æ…¢å¥½å‡ ä¸ªæ•°é‡çº§ã€‚æ˜¯çš„ï¼Œå³ä½¿æ˜¯å›ºæ€ç¡¬ç›˜ä¹Ÿæ˜¯å¦‚æ­¤ã€‚â€</p></li><li><p>The scalability of both these classes of algorithms is limited by the fact that they construct indices meant to be served from main memory.</p></li><li><p>Moving these indices to disks, even SSDs, would result in a catastrophic rise of search latency and a corresponding drop in throughput. The current wisdom on search requiring main memory is reflected in the blog post by FAISS [11]: <em>â€œFaiss supports searching</em> <em>only from RAM, as disk databases are orders of magnitude slower. Yes, even with SSDs.â€</em></p><ul><li>disks and SSDs and the throughputï¼Ÿï¼Ÿï¼Ÿ</li><li>å¦‚æœå°†indexæ”¾åˆ°è¿™é‡Œé¢å»çš„è¯ï¼Œé‚£ä¹ˆæœç´¢çš„æ—¶é—´å»¶è¿Ÿå°±ä¼šå¾ˆæ…¢ï¼Œå°±æ˜¯è¯´ å¦‚æœ æˆ‘ä»¬ä»€ä¹ˆéƒ½ä¸é¡¾çš„æŠŠè¿™äº›ç´¢å¼•æ”¾åˆ°diskçš„è¯ï¼Œé‚£ä¹ˆæˆ‘ä»¬çš„ä¸‰éƒ¨åˆ†ä¸­çš„ index sizeç›¸å½“äºåœ¨å†…å­˜æ²¡æœ‰äº†ï¼›ç„¶å recall ä¸€æ ·çš„æ–¹æ³•åº”è¯¥æ˜¯ ä¸ä¼šé™ä½çš„ï¼›ä½†æ˜¯æœ€ä¸»è¦çš„æ˜¯ æ—¶é—´ä¸Šè‚¯å®šé™ä½äº†ï¼Œç”šè‡³é™ä½äº†å‡ ä¸ªæ•°é‡çº§ï¼›ä¹Ÿå°±æ˜¯è¯´å¦‚æœæˆ‘ä»¬æƒ³è¦å»è¿›è¡Œ æŒªç§»ï¼Œé‚£ä¹ˆå°±è¦æƒ³åŠæ³• å»è§£å†³è¿™ä¸ªæ—¶é—´é—®é¢˜å» ä¸‰èµ¢ï¼›</li></ul></li></ul><h2 id="å†é‡æ–°ç»†èŠ‚çœ‹çœ‹çœ‹ä¸æ‡‚" tabindex="-1"><a class="header-anchor" href="#å†é‡æ–°ç»†èŠ‚çœ‹çœ‹çœ‹ä¸æ‡‚" aria-hidden="true">#</a> å†é‡æ–°ç»†èŠ‚çœ‹çœ‹çœ‹ä¸æ‡‚</h2><p>æŒ‘æˆ˜æ˜¯å¦‚ä½•å‡å°‘éšæœºè®¿é—® SSD çš„æ¬¡æ•°å’Œå‡å°‘å‘èµ· SSD è®¿é—®è¯·æ±‚çš„æ•°é‡ï¼Ÿï¼Ÿï¼Ÿ</p><ul><li><p>äº‹å®ä¸Šï¼Œå›ºæ€ç¡¬ç›˜é©»ç•™ç´¢å¼•çš„æœç´¢ååé‡å—åˆ°æ¯ä¸ªæŸ¥è¯¢éšæœºç£ç›˜è®¿é—®æ¬¡æ•°çš„é™åˆ¶ï¼Œè€Œå»¶è¿Ÿå—åˆ°åˆ°ç£ç›˜å¾€è¿”æ¬¡æ•°ï¼ˆæ¯æ¬¡å¾€è¿”å¯èƒ½åŒ…å«å¤šæ¬¡è¯»å–ï¼‰çš„é™åˆ¶ã€‚ä¸€ä¸ªå»‰ä»·çš„é›¶å”®çº§å›ºæ€ç¡¬ç›˜éœ€è¦å‡ ç™¾å¾®ç§’æ¥æœåŠ¡ä¸€æ¬¡éšæœºè¯»å–ï¼Œå¹¶ä¸”æ¯ç§’å¯ä»¥å¤„ç†å¤§çº¦ 30 ä¸‡æ¬¡éšæœºè¯»å–ã€‚å¦ä¸€æ–¹é¢ï¼Œå…·æœ‰å¤šé˜¶æ®µç®¡é“çš„æœç´¢åº”ç”¨ç¨‹åºï¼ˆä¾‹å¦‚ç½‘ç»œæœç´¢ï¼‰å¯¹äºæœ€è¿‘é‚»æœç´¢éœ€è¦å‡ æ¯«ç§’çš„å¹³å‡å»¶è¿Ÿã€‚å› æ­¤ï¼Œè®¾è®¡ä¸€ä¸ªé«˜æ€§èƒ½çš„å›ºæ€ç¡¬ç›˜é©»ç•™ç´¢å¼•çš„ä¸»è¦æŒ‘æˆ˜åœ¨äºå‡å°‘ï¼ˆaï¼‰éšæœºè®¿é—®å›ºæ€ç¡¬ç›˜çš„æ¬¡æ•°åˆ°å‡ åæ¬¡ï¼Œä»¥åŠï¼ˆbï¼‰åˆ°ç£ç›˜çš„å¾€è¿”è¯·æ±‚æ¬¡æ•°åˆ°åæ¬¡ä»¥ä¸‹ï¼Œæœ€å¥½æ˜¯äº”æ¬¡ã€‚å¤©çœŸåœ°å°†ä¼ ç»Ÿå†…å­˜ä¸­è¿‘ä¼¼æœ€è¿‘é‚»ç®—æ³•ç”Ÿæˆçš„ç´¢å¼•æ˜ å°„åˆ°å›ºæ€ç¡¬ç›˜ä¸Šï¼Œæ¯ä¸ªæŸ¥è¯¢ä¼šäº§ç”Ÿæ•°ç™¾æ¬¡ç£ç›˜è¯»å–ï¼Œè¿™å°†å¯¼è‡´ä¸å¯æ¥å—çš„å»¶è¿Ÿã€‚</p></li><li><p>aï¼‰<strong>éšæœºè®¿é—®å›ºæ€ç¡¬ç›˜çš„æ¬¡æ•°</strong>ï¼šè¿™ä¸ªæè¿°å…³æ³¨çš„æ˜¯SSDå¤„ç†éšæœºè¯»å–æ“ä½œçš„èƒ½åŠ›ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ&quot;æ¬¡æ•°&quot;é€šå¸¸æŒ‡çš„æ˜¯éšæœºè¯»å–æ“ä½œçš„é¢‘ç‡ï¼Œå³SSDåœ¨å•ä½æ—¶é—´å†…å¯ä»¥å¤„ç†å¤šå°‘æ¬¡éšæœºè¯»å–è¯·æ±‚ã€‚éšæœºè®¿é—®æ¬¡æ•°å¤šï¼Œæ„å‘³ç€SSDèƒ½å¤Ÿå¿«é€Ÿå“åº”å¤šä¸ªä¸è¿ç»­çš„æ•°æ®è®¿é—®è¯·æ±‚ï¼Œè¿™åœ¨éœ€è¦å¤„ç†å¤§é‡å°æ–‡ä»¶æˆ–æ•°æ®åº“æŸ¥è¯¢ç­‰åœºæ™¯ä¸­éå¸¸é‡è¦ã€‚SSDçš„éšæœºè¯»å–æ€§èƒ½é€šå¸¸ç”¨IOPSï¼ˆæ¯ç§’è¾“å…¥/è¾“å‡ºæ“ä½œæ•°ï¼‰æ¥è¡¡é‡ã€‚</p><p>bï¼‰<strong>åˆ°ç£ç›˜çš„å¾€è¿”è¯·æ±‚æ¬¡æ•°</strong>ï¼šè¿™ä¸ªæè¿°å…³æ³¨çš„æ˜¯å®Œæˆæ•°æ®è¯»å–æˆ–å†™å…¥æ“ä½œæ‰€éœ€çš„å¾€è¿”æ¬¡æ•°ï¼Œå³ä»ä¸»æœºå‘å‡ºè¯·æ±‚åˆ°SSDå®Œæˆæ“ä½œå¹¶è¿”å›ç»“æœçš„æ•´ä¸ªè¿‡ç¨‹ã€‚&quot;å¾€è¿”è¯·æ±‚æ¬¡æ•°&quot;é€šå¸¸æ¶‰åŠåˆ°æ•°æ®ä¼ è¾“çš„å»¶è¿Ÿï¼ŒåŒ…æ‹¬SSDæ§åˆ¶å™¨å¤„ç†è¯·æ±‚ã€åœ¨é—ªå­˜èŠ¯ç‰‡ä¸­æŸ¥æ‰¾æ•°æ®ã€æ•°æ®ä¼ è¾“åˆ°ä¸»æœºçš„æ—¶é—´ã€‚å¾€è¿”æ¬¡æ•°è¶Šå°‘ï¼Œæ„å‘³ç€æ•°æ®å¤„ç†çš„å»¶è¿Ÿè¶Šä½ï¼Œè¿™å¯¹äºéœ€è¦å¿«é€Ÿå“åº”æ—¶é—´çš„åº”ç”¨ï¼ˆå¦‚åœ¨çº¿äº‹åŠ¡å¤„ç†ç³»ç»Ÿï¼‰æ¥è¯´æ˜¯éå¸¸å…³é”®çš„ã€‚</p><p>ä¸¤è€…çš„åŒºåˆ«ä¸»è¦åœ¨äºï¼š</p><ul><li><strong>éšæœºè®¿é—®æ¬¡æ•°</strong>å¼ºè°ƒçš„æ˜¯SSDå¤„ç†å¤šä¸ªéšæœºä½ç½®æ•°æ®è¯·æ±‚çš„èƒ½åŠ›ï¼Œåæ˜ äº†SSDåœ¨é«˜å¹¶å‘éšæœºI/Oæ“ä½œä¸‹çš„æ€§èƒ½ã€‚</li><li><strong>å¾€è¿”è¯·æ±‚æ¬¡æ•°</strong>å¼ºè°ƒçš„æ˜¯æ¯æ¬¡æ•°æ®è¯·æ±‚ä»å‘å‡ºåˆ°å®Œæˆçš„æ•ˆç‡ï¼Œåæ˜ äº†SSDåœ¨å•ä¸ªI/Oæ“ä½œä¸­çš„å»¶è¿Ÿã€‚</li></ul></li><li><p>Indeed, the search throughput of an SSD-resident index is limited by the number of random disk accesses/query</p><ul><li>é¦–å…ˆæ˜¯SSD-indexçš„search throughputå³æœç´¢ååé‡ï¼šæ˜¯æŒ‡ å•ä½æ—¶é—´å†…èƒ½å¤Ÿå¤„ç†çš„æŸ¥è¯¢queryçš„æ•°é‡ï¼›å› ä¸ºæ¯ä¸ªæŸ¥è¯¢ç‚¹å¯èƒ½éœ€è¦çš„ éšæœºç£ç›˜è®¿é—®æ¬¡æ•°æ˜¯ä¸ä¸€æ ·çš„ï¼›QPS</li></ul></li><li><p>and latency is limited by the the number of round-trips (each round-trip can consist of multiple reads) to the disk.</p></li><li><p>An inexpensive retail-grade SSD requires a few hundred microseconds to serve a random read and can service about <em>âˆ¼</em> 300K random reads per second. On the other hand, search applications (e.g. web search) with multi-stage pipelines require mean latencies of a few milliseconds for nearest neighbor search.</p></li><li><p>Therefore, the main challenges in designing a performant SSD-resident index lie in reducing (a) the number of random SSD accesses to a few dozen, and (b) the number of round trip requests to disk to under ten, preferably five. Naively mapping indices generated by traditional in-memory ANNS algorithms to SSDs would generate several hundreds of disk reads per query, which would result in unacceptable latencies.</p></li></ul><h3 id="_1-1-our-technical-contribution" tabindex="-1"><a class="header-anchor" href="#_1-1-our-technical-contribution" aria-hidden="true">#</a> 1.1 Our technical contribution</h3><ul><li><p><mark>åŸæ–‡ç¿»è¯‘</mark></p></li><li><p>æˆ‘ä»¬æå‡ºäº†DiskANNï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæˆ‘ä»¬æ–°çš„åŸºäºå›¾çš„ç´¢å¼•ç®—æ³•Vamanaçš„SSDé©»ç•™ANNSç³»ç»Ÿï¼Œå®ƒæ¨ç¿»äº†å½“å‰çš„æ™ºæ…§å¹¶è¯æ˜äº†å³ä½¿æ˜¯å•†å“çº§SSDä¹Ÿå¯ä»¥æœ‰æ•ˆåœ°æ”¯æŒå¤§è§„æ¨¡çš„ANNSã€‚æˆ‘ä»¬å·¥ä½œçš„ä¸€äº›æœ‰è¶£æ–¹é¢åŒ…æ‹¬ï¼š</p><ul><li>DiskANNå¯ä»¥åœ¨ä¸€å°é…æœ‰64GB RAMçš„å·¥ä½œç«™ä¸Šä¸ºé«˜è¾¾æ•°åäº¿ä¸ªæ•°æ®ç‚¹çš„ç™¾ç»´æ•°æ®é›†å»ºç«‹ç´¢å¼•å¹¶æä¾›æœåŠ¡ï¼Œæä¾›95%ä»¥ä¸Šçš„1-recall@1ï¼Œå¹¶ä¸”å»¶è¿Ÿæ—¶é—´ä½äº5æ¯«ç§’ã€‚</li><li>ä¸€ç§åä¸ºVamanaçš„æ–°ç®—æ³•èƒ½ç”Ÿæˆæ¯”NSGå’ŒHNSWæ›´å°ç›´å¾„çš„å›¾ç´¢å¼•ï¼Œä½¿DiskANNèƒ½å¤Ÿå°†è¿ç»­ç¡¬ç›˜è¯»å–çš„æ•°é‡é™åˆ°æœ€ä½( sequential disk reads)ã€‚</li><li>ç”±Vamanaç”Ÿæˆçš„å›¾ä¹Ÿå¯ä»¥åœ¨å†…å­˜( in-memory)ä¸­ä½¿ç”¨ï¼Œåœ¨é‚£é‡Œå®ƒä»¬çš„æœç´¢æ€§èƒ½è¾¾åˆ°æˆ–è¶…è¿‡äº†å¦‚HNSWå’ŒNSGè¿™æ ·çš„æœ€å…ˆè¿›çš„å†…å­˜ä¸­ç®—æ³•ã€‚</li><li>å°†æ•°æ®é›†é‡å åˆ’åˆ†ä¸ºå¤šä¸ªåŒºåŸŸï¼Œåœ¨æ¯ä¸ªåŒºåŸŸä¸­å»ºç«‹å°Vamanaï¼Œç„¶åå†å½’å¹¶å¾—åˆ°ä¸€ä¸ªç´¢å¼•ï¼Œå®ƒçš„æ€§èƒ½ä¸åœ¨æ•´ä¸ªæ•°æ®é›†æ„å»ºç´¢å¼•ç›¸å½“(ä¸èƒ½å®Œå…¨è½½å…¥å†…å­˜çš„å¤§è§„æ¨¡æ•°æ®)ï¼›</li><li>æˆ‘ä»¬è¯æ˜äº†Vamanaå¯ä»¥ç»“åˆç°æˆçš„çŸ¢é‡å‹ç¼©(vector compression)æ–¹æ¡ˆï¼Œå¦‚ä¹˜ç§¯é‡åŒ–(product quantization)æ¥æ„å»ºDiskANNç³»ç»Ÿã€‚å›¾ç´¢å¼•å’Œæ•°æ®é›†çš„å…¨ç²¾åº¦å‘é‡ä¸€èµ·å­˜å‚¨åœ¨ç£ç›˜ä¸Šï¼Œè€Œå‹ç¼©çš„å‘é‡åˆ™ç¼“å­˜åœ¨å†…å­˜ä¸­ã€‚</li></ul></li><li><p>We present DiskANN, an SSD-resident ANNS system based on our new graph-based indexing algorithm called Vamana, that debunks current wisdom and establishes that even commodity SSDs can effectively support large-scale ANNS. Some interesting aspects of our work are: è¿™ä¸ªæ˜¯å°†å¤§éƒ¨åˆ†æ”¾åœ¨äº†SSDï¼Œç„¶åå¹¶ä¸”ä¸€ä¸ªæ–°çš„å¯å¯¼èˆªå›¾Vamana,å¹¶ä¸”å¯¹SSDçš„æ€§èƒ½è¦æ±‚æ²¡æœ‰å¤ªé™åˆ¶é€šè¿‡ç®—æ³•çš„è®¾ç½®ï¼Œæ¯”å¦‚å¯èƒ½å¥½çš„SSDçš„æ€§èƒ½å¥½ï¼Œå¯¼è‡´çš„searchçš„æ—¶é—´æ¶ˆè€—ä½ï¼Œä½†æ˜¯ä¸€ä¸ªæ™®é€šçš„å•†å“çº§çš„SSDä»ç„¶æ˜¯å¯ä»¥çš„ï¼›</p><ul><li>DiskANN can index and serve a billion point dataset in 100s of dimensions on a workstation with 64GB RAM, providing 95%+ 1-recall@1 with latencies of under 5 milliseconds.ä¹‹å‰çš„ç¬¬äºŒä¸ªæ–¹æ³•æ˜¯SIFT100M 75GB ï¼›è¿™é‡Œè¯´çš„æ•ˆæœå¥½ï¼›</li><li>A new algorithm called Vamana which can generate graph indices with smaller diameter than NSG and HNSW, allowing DiskANN to minimize the number of sequential disk reads.å› ä¸ºæ¯æ¬¡æŸ¥è¯¢è¦å‡å°‘è®¿é—®ç£ç›˜çš„æ¬¡æ•°ï¼Œæ‰€ä»¥æ”¹è¿›äº†ç›®å‰çš„sotaçš„å»ºç«‹å›¾çš„ç®—æ³•è¿›è¡Œæ”¹è¿›ä»¥é€‚åº”ç£ç›˜çš„ï¼›æ¯”NSGå’ŒHNSWæœ‰æ›´å°çš„ç›´å¾„ï¼ˆè·¯å¾„è·³æ•°ï¼‰ï¼Œä½¿DiskANNæœ€å°åŒ–é¡ºåºè¯»å–ç£ç›˜çš„æ¬¡æ•°ï¼›</li><li>The graphs generated by Vamana can be also be used in-memory, where their search performance matches or exceeds state-of-the-art in-memory algorithms such as HNSW and NSG.å®Œå…¨çš„å†…å­˜çš„æœç´¢æ€§èƒ½ä¹Ÿæ˜¯æ¯”è¾ƒå¥½çš„(æ›´æ”¹äº†é€‰è¾¹ç­–ç•¥)</li><li>Smaller Vamana indices for overlapping partitions of a large dataset can be easily merged into one index that provides nearly the same search performance as a single-shot index constructed for the entire dataset. This allows indexing of datasets that are otherwise too large to fit in memory.å¹¶ä¸”å¯¹äºå¤§è§„æ¨¡æ•°æ®ä¸èƒ½å¯¼å…¥åˆ°å†…å­˜çš„ï¼›è¿™ä¸ªçš„è¯å¯ä¸å¯ä»¥ç»“åˆæ·˜å®é‚£ä¸ªå…ˆåˆ’åˆ†ä¸åŒçš„æœºå™¨å‘¢ï¼Ÿï¼Ÿè¿˜æœ‰å°±æ˜¯è¿™é‡Œä¸ºä»€ä¹ˆ è¦è¿›è¡Œ é‡å å‘¢ï¼Ÿï¼Ÿå°±æ˜¯è¯´åˆ’åˆ†ç„¶å åˆå¹¶ å°±æ˜¯è¯´ç°åœ¨çš„Vamanaçš„ä»¿ç…§çš„è¿™ä¸ªåŠŸèƒ½ç›¸å¯¹äºNSGæ˜¯æ²¡æœ‰è¢«ä¸¢æ‰çš„ï¼›</li><li>We show that Vamana can be combined with off-the-shelf vector compression schemes such as product quantization to build the DiskANN system. The graph index along with the full-precision vectors of the dataset are stored on the disk, while compressed vectors are cached in memoryã€‚é€šè¿‡å‹ç¼©è¿›ä¸€æ­¥çš„å‹ç¼©å†…å­˜ï¼Œå³åœ¨main memoryçš„æ¶ˆè€—ï¼›å›¾ç´¢å¼•å’ŒåŸå§‹çš„æ•°æ®åœ¨diskä¸Šé¢ï¼Œç„¶å å‹ç¼©çš„å‘é‡åœ¨ in memoryï¼›è¿™ä¹Ÿæ˜¯ä¸ºäº†æ›´å¥½çš„å‹ç¼© ä¸»å†…å­˜ï¼›å…¶å®å¯èƒ½æ²¡æœ‰è¿™ä¸ªçš„ç»“åˆï¼Œä¹Ÿæ˜¯å¯ä»¥è¿›è¡Œå¯¹æ¯”çš„ï¼›åªä¸è¿‡å¦‚æœä½¿ç”¨äº† è¿™ä¸ª recallä»ç„¶æ²¡æœ‰ä¸‹é™çš„è¯é‚£ä¹ˆå°±æ˜¯æ›´å¥½çš„æ–¹æ¡ˆäº†ï¼›</li></ul></li></ul><h3 id="_1-2-notation" tabindex="-1"><a class="header-anchor" href="#_1-2-notation" aria-hidden="true">#</a> 1.2 Notation</h3>',12),W=e("ul",null,[e("li",null,[e("mark",null,"æ€»ç»“")]),e("li"),e("li",null,[e("mark",null,"åŸæ–‡ç¿»è¯‘")]),e("li",null,"åœ¨æœ¬æ–‡çš„å‰©ä½™éƒ¨åˆ†ï¼Œæˆ‘ä»¬ç”¨Pè¡¨ç¤ºæ•°æ®é›†ï¼Œå¹¶ä¸”|P| = nã€‚æˆ‘ä»¬è€ƒè™‘é¡¶ç‚¹å¯¹åº”äºPä¸­çš„ç‚¹ï¼Œå®ƒä»¬ä¹‹é—´å…·æœ‰è¾¹çš„æœ‰å‘å›¾ã€‚é€šè¿‡ç¨å¾®é‡è½½è¡¨ç¤ºæ³•ï¼Œæˆ‘ä»¬ç”¨G = (P, E)æ¥æŒ‡è¿™æ ·çš„å›¾ï¼ŒåŒæ—¶è®©Pä¹Ÿä»£è¡¨é¡¶ç‚¹é›†ã€‚å¯¹äºæœ‰å‘å›¾ä¸­çš„ä¸€ä¸ªç‚¹p âˆˆ Pï¼Œæˆ‘ä»¬ç”¨Nout(p)è¡¨ç¤ºè½åœ¨pä¸Šçš„å‡ºè¾¹é›†åˆã€‚æœ€åï¼Œæˆ‘ä»¬ç”¨xpè¡¨ç¤ºä¸ç‚¹på¯¹åº”çš„å‘é‡æ•°æ®ï¼Œå¹¶ä¸”ç”¨d(p, q) = ||xp âˆ’ xq||è¡¨ç¤ºä¸¤ç‚¹på’Œqä¹‹é—´çš„åº¦é‡è·ç¦»ã€‚æœ¬æ–‡ä¸­å±•ç¤ºçš„æ‰€æœ‰å®éªŒéƒ½ä½¿ç”¨äº†æ¬§å‡ é‡Œå¾—åº¦é‡( Euclidean metric)ã€‚"),e("li",null,[s("For the remainder of the paper, we let "),e("em",null,"P"),s(" denote the dataset with "),e("em",null,[s("|"),e("strong",null,"P"),s("|")]),s(" = "),e("em",null,"n"),s(". We consider directed graphs with vertices corresponding to points in "),e("em",null,"P"),s(", and edges between them. With slight notation overload, we refer to such graphs as "),e("em",null,"G"),s(" = ("),e("em",null,"P, E"),s(") by letting "),e("em",null,"P"),s(" also denote the vertex set. Given a point "),e("em",null,"p"),s(),e("em",null,"âˆˆ"),s(),e("em",null,"P"),s(" in a directed graph, we let "),e("em",null,"N"),s("out("),e("em",null,"p"),s(") to denote the set of out-edges incident on "),e("em",null,"p"),s(". Finally, we let "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msub",null,[e("mi",null,"x"),e("mi",null,"p")])]),e("annotation",{encoding:"application/x-tex"},"x_p")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.7167em","vertical-align":"-0.2861em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"x"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t vlist-t2"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.1514em"}},[e("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mathnormal mtight"},"p")])])]),e("span",{class:"vlist-s"},"â€‹")]),e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.2861em"}},[e("span")])])])])])])])]),s(" denote the vector data corresponding to "),e("em",null,"p"),s(", and let "),e("em",null,"d"),s("("),e("em",null,"p, q"),s(") = "),e("em",null,[s("||"),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msub",null,[e("mi",null,"x"),e("mi",null,"p")])]),e("annotation",{encoding:"application/x-tex"},"x_p")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.7167em","vertical-align":"-0.2861em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"x"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t vlist-t2"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.1514em"}},[e("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mathnormal mtight"},"p")])])]),e("span",{class:"vlist-s"},"â€‹")]),e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.2861em"}},[e("span")])])])])])])])]),s(" - "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msub",null,[e("mi",null,"x"),e("mi",null,"q")])]),e("annotation",{encoding:"application/x-tex"},"x_q")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.7167em","vertical-align":"-0.2861em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"x"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t vlist-t2"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.1514em"}},[e("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"q")])])]),e("span",{class:"vlist-s"},"â€‹")]),e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.2861em"}},[e("span")])])])])])])])]),s("||")]),s(" denote the metric distance between two points "),e("em",null,"p"),s(" and "),e("em",null,"q"),s(". All experiments presented in this paper used Euclidean metric. "),e("ul",null,[e("li",null,[s("è¿™é‡Œå°±æ˜¯è¯´ï¼š "),e("em",null,"G"),s(" = ("),e("em",null,"P, E"),s(") è¿™ä¸ªå›¾ï¼ŒPæ˜¯ç‚¹é›†ï¼ŒEæ˜¯è¾¹é›†ï¼Œä¸”æ˜¯æœ‰å‘è¾¹ï¼›")]),e("li",null,[e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msub",null,[e("mi",null,"N"),e("mrow",null,[e("mi",null,"o"),e("mi",null,"u"),e("mi",null,"t")])]),e("mo",{stretchy:"false"},"("),e("mi",null,"p"),e("mo",{stretchy:"false"},")")]),e("annotation",{encoding:"application/x-tex"},"N_{out} (p)")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"N"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t vlist-t2"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.2806em"}},[e("span",{style:{top:"-2.55em","margin-left":"-0.109em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mtight"},[e("span",{class:"mord mathnormal mtight"},"o"),e("span",{class:"mord mathnormal mtight"},"u"),e("span",{class:"mord mathnormal mtight"},"t")])])])]),e("span",{class:"vlist-s"},"â€‹")]),e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.15em"}},[e("span")])])])])]),e("span",{class:"mopen"},"("),e("span",{class:"mord mathnormal"},"p"),e("span",{class:"mclose"},")")])])]),s(" :è¡¨ç¤º è¯¥ç‚¹çš„ å‡ºåº¦ï¼›")]),e("li",null,[e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msub",null,[e("mi",null,"x"),e("mi",null,"p")])]),e("annotation",{encoding:"application/x-tex"},"x_p")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.7167em","vertical-align":"-0.2861em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"x"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t vlist-t2"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.1514em"}},[e("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mathnormal mtight"},"p")])])]),e("span",{class:"vlist-s"},"â€‹")]),e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.2861em"}},[e("span")])])])])])])])]),s(": è¡¨ç¤º åŸå§‹å‘é‡ï¼›")]),e("li",null,"d(p, q) :è¡¨ç¤ºè·ç¦» åœ¨ æ¬§å‡ é‡Œå¾—é‡Œé¢ï¼›")])])],-1),F=l('<h3 id="_1-3-paper-outline" tabindex="-1"><a class="header-anchor" href="#_1-3-paper-outline" aria-hidden="true">#</a> 1.3 Paper Outline</h3><ul><li><mark>åŸæ–‡ç¿»è¯‘</mark></li><li>ç¬¬2èŠ‚ä»‹ç»äº†æˆ‘ä»¬çš„æ–°å›¾ç´¢å¼•æ„å»ºç®—æ³•Vamanaï¼Œç¬¬3èŠ‚è§£é‡Šäº†DiskANNçš„æ•´ä½“ç³»ç»Ÿè®¾è®¡ã€‚ç¬¬4èŠ‚æå‡ºäº†Vamanaä¸HNSWå’ŒNSGåœ¨å†…å­˜ç´¢å¼•çš„å®è¯æ¯”è¾ƒï¼Œå¹¶å±•ç¤ºäº†DiskANNåœ¨æ™®é€šæœºå™¨ä¸Šé’ˆå¯¹åäº¿ç‚¹æ•°æ®é›†çš„æœç´¢ç‰¹æ€§ã€‚</li><li>Section 2 presents Vamana our new graph index construction algorithm and Section 3 explains the overall system design of DiskANN. Section 4 presents an empirical comparison Vamana with HNSW and NSG for in-memory indices, and also demonstrates the search characteristics of DiskANN for billion point datasets on a commodity machine.</li></ul><h2 id="no-2-the-vamana-graph-construction-algorithm" tabindex="-1"><a class="header-anchor" href="#no-2-the-vamana-graph-construction-algorithm" aria-hidden="true">#</a> No.2 The Vamana Graph Construction Algorithm</h2><ul><li><mark>åŸæ–‡ç¿»è¯‘</mark></li><li>åœ¨ä»‹ç»Vamanaçš„è¯¦ç»†ä¿¡æ¯ä¹‹å‰ï¼Œæˆ‘ä»¬é¦–å…ˆç®€è¦æ¦‚è¿°åŸºäºå›¾çš„ANNSç®—æ³•ï¼Œè¿™äº›è¯¦ç»†ä¿¡æ¯åœ¨ç®—æ³•3ä¸­ç»™å‡ºäº†è§„èŒƒã€‚</li><li>We begin with a brief overview of graph-based ANNS algorithms before presenting the details of Vamana, a specification which is given in Algorithm 3.</li></ul><h3 id="_2-1-relative-neighborhood-graphs-and-the-greedysearch-algorithm" tabindex="-1"><a class="header-anchor" href="#_2-1-relative-neighborhood-graphs-and-the-greedysearch-algorithm" aria-hidden="true">#</a> 2.1 Relative Neighborhood Graphs and the GreedySearch algorithm</h3>',5),L=e("ul",null,[e("li",null,[e("p",null,[e("mark",null,"æ€»ç»“")])]),e("li",null,[e("p",null,"Relative Neighborhood Graphs RNGï¼›")]),e("li",null,[e("p",null,"ä»¥åŠ å¯¹äº è´ªå©ªæœç´¢çš„æ—¶å€™ SNGçš„å¥½å¤„ï¼›ä»¥åŠSNGçš„æ„å»ºå’Œ è§„åˆ™ï¼›")]),e("li",null,[e("p",null,[e("mark",null,"åŸæ–‡ç¿»è¯‘")])]),e("li",null,[e("p",null,"å¤§å¤šæ•°åŸºäºå›¾çš„ANNSç®—æ³•çš„å·¥ä½œæ–¹å¼å¦‚ä¸‹ï¼šåœ¨ç´¢å¼•æ„å»ºæœŸé—´ï¼Œå®ƒä»¬æ ¹æ®æ•°æ®é›†Pçš„å‡ ä½•å±æ€§æ„å»ºå›¾G = (P, E)ã€‚åœ¨æœç´¢æ—¶ï¼Œå¯¹äºä¸€ä¸ªæŸ¥è¯¢å‘é‡xqï¼Œæœç´¢ä½¿ç”¨å¦‚ç®—æ³•1ä¸­çš„è‡ªç„¶è´ªå©ª(a natural greedy)æˆ–æœ€ä½³ä¼˜å…ˆéå†(best-first traversal)åœ¨Gä¸Šè¿›è¡Œã€‚ä»æŸä¸ªæŒ‡å®šçš„ç‚¹s âˆˆ På¼€å§‹ï¼Œå®ƒä»¬éå†å›¾å½¢ä»¥é€æ¸é è¿‘xqã€‚")]),e("li",null,[e("p",null,[s("Most graph-based ANNS algorithms work in the following manner: during index construction, they build a graph "),e("em",null,"G"),s(" = ("),e("em",null,"P, E"),s(") based on the geometric properties of the dataset "),e("em",null,"P"),s(". ç¦»çº¿æ„å»ºé˜¶æ®µ")])]),e("li",null,[e("p",null,[s("At search time, for a query vector "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msub",null,[e("mi",null,"x"),e("mi",null,"q")])]),e("annotation",{encoding:"application/x-tex"},"x_q")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.7167em","vertical-align":"-0.2861em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"x"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t vlist-t2"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.1514em"}},[e("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"q")])])]),e("span",{class:"vlist-s"},"â€‹")]),e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.2861em"}},[e("span")])])])])])])])]),s(", search employs a natural greedy or best-first traversal, such as in Algorithm 1, on "),e("em",null,"G"),s(". Starting at some designated point "),e("em",null,"s"),s(),e("em",null,"âˆˆ"),s(),e("em",null,"P"),s(", they traverse the graph to get progressively closer to "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msub",null,[e("mi",null,"x"),e("mi",null,"q")])]),e("annotation",{encoding:"application/x-tex"},"x_q")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.7167em","vertical-align":"-0.2861em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"x"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t vlist-t2"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.1514em"}},[e("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"q")])])]),e("span",{class:"vlist-s"},"â€‹")]),e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.2861em"}},[e("span")])])])])])])])]),s(".ä½¿ç”¨NN-expansionï¼›")])]),e("li",null,[e("p",null,"whileï¼šå¾—åˆ°å±€éƒ¨æœ€ä¼˜å‰ï¼›Læ˜¯å€™é€‰é˜Ÿåˆ—ï¼›Vä»…ä»…æ˜¯è®°å½•å·²ç»visited")]),e("li",null,[e("figure",null,[e("img",{src:c,alt:"algorithm1",tabindex:"0",loading:"lazy"}),e("figcaption",null,"algorithm1")])]),e("li",null,[e("p",null,"ç›®å‰å·²æœ‰å¤§é‡å·¥ä½œè‡´åŠ›äºäº†è§£å¦‚ä½•æ„é€ ç¨€ç–å›¾(sparse graphs)ï¼Œä»¥ä¾¿GreedySearch(s, xq, k, L)èƒ½å¤Ÿå¿«é€Ÿæ”¶æ•›åˆ°ä»»æ„æŸ¥è¯¢çš„ï¼ˆè¿‘ä¼¼ï¼‰æœ€è¿‘é‚»å±…ã€‚è‡³å°‘å½“æŸ¥è¯¢æ¥è¿‘æ•°æ®é›†ç‚¹æ—¶ï¼Œå‘ç”Ÿè¿™ç§æƒ…å†µçš„ä¸€ä¸ªå……åˆ†æ¡ä»¶æ˜¯æ‰€è°“çš„ç¨€ç–é‚»åŸŸå›¾ï¼ˆSNGï¼‰ï¼Œè¯¥æ¦‚å¿µåœ¨æ–‡çŒ®[5]ä¸­è¢«ä»‹ç»ã€‚åœ¨ä¸€ä¸ªSNGä¸­ï¼Œæ¯ä¸ªç‚¹pçš„å¤–éƒ¨é‚»å±…çš„ç¡®å®šå¦‚ä¸‹ï¼šåˆå§‹åŒ–ä¸€ä¸ªé›†åˆS = P \\ {p}ã€‚åªè¦S â‰  âˆ…ï¼Œå°±ä»pæ·»åŠ ä¸€æ¡æœ‰å‘è¾¹åˆ°p* ï¼Œå…¶ä¸­p*æ˜¯Sä¸­è·ç¦»pæœ€è¿‘çš„ç‚¹ï¼Œå¹¶ä¸”ä»Sä¸­ç§»é™¤æ‰€æœ‰ç‚¹p0ï¼Œä½¿å¾—d(p, p0) > d(p**, p0)ã€‚ç„¶åå¾ˆå®¹æ˜“çœ‹å‡ºï¼ŒGreedySearch(s, xp, 1, 1)ä»ä»»ä½•s âˆˆ På¼€å§‹éƒ½å°†æ”¶æ•›åˆ°æ‰€æœ‰åŸºç‚¹p âˆˆ Pçš„ç‚¹pã€‚")]),e("li",null,[e("p",null,[s("There has been much work on understanding how to construct sparse graphs for which the GreedySearch("),e("em",null,"s,"),s(),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msub",null,[e("mi",null,"x"),e("mi",null,"q")])]),e("annotation",{encoding:"application/x-tex"},"x_q")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.7167em","vertical-align":"-0.2861em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"x"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t vlist-t2"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.1514em"}},[e("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"q")])])]),e("span",{class:"vlist-s"},"â€‹")]),e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.2861em"}},[e("span")])])])])])])])]),s(", k, L) converges quickly to the (approximate) nearest neighbors for any query. ç¨€ç–å›¾æ˜¯å‹å¥½åœ°ï¼›é‚£ä¹ˆç¨€ç–å›¾çš„å¯èƒ½å®šä¹‰å¦‚ä¸‹ï¼š")])]),e("li",null,[e("p",null,[s("A sufficient condition for this to happen, at least when the queries are close to the dataset points, is the so-called "),e("em",null,"sparse neighborhood graph"),s(" (SNG), which was introduced in [5] . ã€This notion itself was inspired by a related property known as the "),e("em",null,"Relative Neighborhood Graph"),s(" (RNG) property, first defined in the 1960sã€‘æ‰€ä»¥RNG å’Œ SNGçš„å…³ç³»ï¼Ÿï¼Ÿï¼Ÿ")])]),e("li",null,[e("p",null,[s("In an SNG, the out-neighbors of each point "),e("em",null,"p"),s(" are determined as follows: initialize a set "),e("em",null,"S"),s(" = "),e("em",null,"P"),s(),e("em",null,"\\ {p}"),s(". As long as S â‰  âˆ…, add a directed edge from "),e("em",null,"p"),s(" to "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mi",null,"p"),e("mo",null,"âˆ—")]),e("annotation",{encoding:"application/x-tex"},"p*")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.6597em","vertical-align":"-0.1944em"}}),e("span",{class:"mord mathnormal"},"p"),e("span",{class:"mord"},"âˆ—")])])]),s(" , where "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mi",null,"p"),e("mo",null,"âˆ—")]),e("annotation",{encoding:"application/x-tex"},"p*")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.6597em","vertical-align":"-0.1944em"}}),e("span",{class:"mord mathnormal"},"p"),e("span",{class:"mord"},"âˆ—")])])]),s(" is the closest point to "),e("em",null,"p"),s(" from "),e("em",null,"S"),s(", and remove from "),e("em",null,"S"),s(" all points "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msup",null,[e("mi",null,"p"),e("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"â€²")])]),e("annotation",{encoding:"application/x-tex"},"p'")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.9463em","vertical-align":"-0.1944em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"p"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.7519em"}},[e("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mtight"},[e("span",{class:"mord mtight"},"â€²")])])])])])])])])])])]),s(" such that "),e("em",null,"d"),s("(p, "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msup",null,[e("mi",null,"p"),e("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"â€²")])]),e("annotation",{encoding:"application/x-tex"},"p'")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.9463em","vertical-align":"-0.1944em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"p"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.7519em"}},[e("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mtight"},[e("span",{class:"mord mtight"},"â€²")])])])])])])])])])])]),s(" ) "),e("em",null,"> d"),s("("),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mi",null,"p"),e("mo",null,"âˆ—")]),e("annotation",{encoding:"application/x-tex"},"p*")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.6597em","vertical-align":"-0.1944em"}}),e("span",{class:"mord mathnormal"},"p"),e("span",{class:"mord"},"âˆ—")])])]),s(" , "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msup",null,[e("mi",null,"p"),e("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"â€²")])]),e("annotation",{encoding:"application/x-tex"},"p'")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.9463em","vertical-align":"-0.1944em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"p"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.7519em"}},[e("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mtight"},[e("span",{class:"mord mtight"},"â€²")])])])])])])])])])])]),s(" ). It is then easy to see that GreedySearch("),e("em",null,"s,"),s(),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msub",null,[e("mi",null,"x"),e("mi",null,"p")])]),e("annotation",{encoding:"application/x-tex"},"x_p")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.7167em","vertical-align":"-0.2861em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"x"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t vlist-t2"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.1514em"}},[e("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mathnormal mtight"},"p")])])]),e("span",{class:"vlist-s"},"â€‹")]),e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.2861em"}},[e("span")])])])])])])])]),s(" 1*,* 1) starting at any "),e("em",null,"s"),s(),e("em",null,"âˆˆ"),s(),e("em",null,"P"),s(" would converge to "),e("em",null,"p"),s(" for all base points "),e("em",null,"p"),s(),e("em",null,"âˆˆ"),s(),e("em",null,"P"),s(".")]),e("ul",null,[e("li",null,"å°±æ˜¯è¯´ å…¨éƒ¨çš„æ•°æ®é›†ï¼šSï¼Œ"),e("li",null,[s("ç„¶åå°†æ¥è¿‘çš„p çš„ æœ€è¿‘é‚» æ”¾å…¥åˆ°"),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mi",null,"p"),e("mo",null,"âˆ—")]),e("annotation",{encoding:"application/x-tex"},"p*")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.6597em","vertical-align":"-0.1944em"}}),e("span",{class:"mord mathnormal"},"p"),e("span",{class:"mord"},"âˆ—")])])]),s(" ï¼›æ”¾å…¥ä¸€ä¸ª å°±å¯¹å‰©ä¸‹çš„Sä¸­çš„è¿›è¡Œæ•£åŒ–åˆ é™¤æ‰ ä¸èƒ½å½“pçš„å‡ºåº¦é‚»å±…ï¼›")]),e("li",null,"ç„¶å ä¸æ–­çš„è¿›è¡Œä¸Šä¸€æ®µçš„ï¼›è¿™æ ·çš„è¯ï¼Œè´ªå©ªæœç´¢ï¼› å°±å˜æˆäº† dfs"),e("li",null,"å°±æ˜¯è¯´ å¦‚æœ è¿›è¡Œ dfsçš„è¯ï¼Œé‚£ä¹ˆæ€ä¹ˆæ ·æ‰èƒ½å¾—åˆ° çœŸæ­£çš„ å¿«é€Ÿæ”¶æ•›åˆ°è¿™ä¸ªå‘¢ï¼Ÿ")])]),e("li",null,[e("p",null,"è™½ç„¶è¿™ç§æ„å»ºåœ¨åŸåˆ™ä¸Šæ˜¯ç†æƒ³çš„ï¼Œä½†å¯¹äºå³ä½¿æ˜¯ä¸­ç­‰è§„æ¨¡çš„æ•°æ®é›†æ¥æ„å»ºè¿™æ ·çš„å›¾ä¹Ÿæ˜¯ä¸å¯è¡Œçš„ï¼Œå› ä¸ºè¿è¡Œæ—¶é—´çº¦ä¸º O(nÂ²)ã€‚åŸºäºè¿™ç§ç›´è§‰ï¼Œå·²ç»æœ‰ä¸€ç³»åˆ—çš„å·¥ä½œæ¥è®¾è®¡æ›´å®é™…çš„ç®—æ³•ï¼Œè¿™äº›ç®—æ³•èƒ½ç”Ÿæˆå¯¹ SNG çš„è‰¯å¥½è¿‘ä¼¼[21,13]ã€‚ç„¶è€Œï¼Œç”±äºå®ƒä»¬åŸºæœ¬ä¸Šéƒ½è¯•å›¾è¿‘ä¼¼ SNG å±æ€§ï¼Œæ‰€ä»¥åœ¨æ§åˆ¶è¿™äº›ç®—æ³•è¾“å‡ºçš„å›¾çš„ç›´å¾„å’Œå¯†åº¦æ–¹é¢çµæ´»æ€§éå¸¸å°ã€‚")]),e("li",null,[e("p",null,[s("While this construction is ideal in principle, it is infeasible to construct such graphs for even moderately sized datasets, as the running time is "),e("em",null,"O"),s("("),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msup",null,[e("mi",null,"n"),e("mn",null,"2")])]),e("annotation",{encoding:"application/x-tex"},"n^2")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.8141em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"n"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.8141em"}},[e("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mtight"},"2")])])])])])])])])])]),s(" ). å¦‚æœæˆ‘ä»¬è¦å»ºç«‹ä¸€ä¸ªæ ¹æ®ä¸Šé¢çš„ç®€å•å®šä¹‰ çš„SNGï¼Œé‚£ä¹ˆå°±æ˜¯å¯¹æ¯ä¸ªç‚¹è¿›è¡Œé‚£æ ·äº†")])]),e("li",null,[e("p",null,"Building on this intuition, there have been a series of works that design more practical algorithms that generate good approximations of SNGs [21, 13]. However, since they all essentially try to approximate the SNG property, there is very little flexibility in controlling the diameter and the density of the graphs output by these algorithms."),e("ul",null,[e("li",null,"å°±æ˜¯è¯´è¿™ä¸ª diameter and the density of the graphs output /???è¿™ä¸¤ä¸ª å¾ˆé‡è¦ï¼›")])])],-1),T=e("h3",{id:"_2-2-the-robust-pruning-procedure",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_2-2-the-robust-pruning-procedure","aria-hidden":"true"},"#"),s(),e("strong",null,"2.2 The Robust Pruning Procedure")],-1),R=e("ul",null,[e("li",null,[e("p",null,[e("mark",null,"æ€»ç»“")])]),e("li",null,[e("p",null,"SNGå±æ€§çš„å›¾ è¿™ä¸ªã€‚SNGä¹Ÿå¯ä»¥å«åš RNGï¼›")]),e("li",null,[e("p",null,"åœˆå†…åªæœ‰ä¸€ä¸ªç‚¹ï¼›ç®€å•çš„é™ˆè¿°ï¼›")]),e("li",null,[e("p",null,"GreedySearchè´ªå©ªæœç´¢")]),e("li",null,[e("p",null,[e("mark",null,"åŸæ–‡ç¿»è¯‘")])]),e("li",null,[e("p",null,"å¦‚å‰é¢æ‰€æåˆ°çš„ï¼Œæ»¡è¶³SNGå±æ€§çš„å›¾éƒ½æ˜¯GreedySearchæœç´¢è¿‡ç¨‹çš„å¾ˆå¥½çš„å€™é€‰å›¾ã€‚ç„¶è€Œï¼Œè¿™äº›å›¾çš„ç›´å¾„ä¹Ÿæœ‰å¯èƒ½ç›¸å½“å¤§ã€‚ä¾‹å¦‚ï¼Œå¦‚æœç‚¹åœ¨ä¸€ç»´çº¿ä¸Šçº¿æ€§æ’åˆ—ï¼Œåˆ™æ¯ä¸ªç‚¹è¿æ¥ å…¶ä¸¤ä¸ªé‚»å±…ï¼ˆå…¶ä¸­ä¸€ä¸ªåœ¨ç«¯ç‚¹ï¼‰çš„O(n)ç›´å¾„çº¿å›¾å°±æ˜¯æ»¡è¶³SNGå±æ€§çš„å›¾ã€‚æœç´¢å­˜å‚¨åœ¨ç£ç›˜ä¸­çš„è¿™æ ·çš„å›¾ä¼šå¯¼è‡´å¯¹ç£ç›˜è¿›è¡Œå¤šæ¬¡è¿ç»­çš„è¯»å–ï¼Œä»¥è·å–ç®—æ³•1ä¸­æœç´¢è·¯å¾„ä¸Šè®¿é—®çš„é¡¶ç‚¹çš„é‚»å±…ã€‚")]),e("li",null,[e("p",null,"As mentioned earlier, graphs which satisfy the SNG property are all good candidates for the GreedySearch search procedure. However, it is possible that the diameter of the graphs can be quite large.")]),e("li",null,[e("p",null,[s("For example, if the points are linearly arranged on the real line in one dimension, the "),e("em",null,"O"),s("("),e("em",null,"n"),s(") diamater line graph, where each point connects to its two neighbors (one at the end), is the one that satisfies the SNG property. Searching such graphs stored in disks would incur many sequential reads to the disk at to fetch the neighbors of the vertices visited on the search path in Algorithm 1.")])]),e("li",null,[e("figure",null,[e("img",{src:u,alt:"vamana",tabindex:"0",loading:"lazy"}),e("figcaption",null,"vamana")])]),e("li",null,[e("p",null,"ä¸ºäº†å…‹æœè¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¸Œæœ›ç¡®ä¿æ²¿ç€æœç´¢è·¯å¾„çš„æ¯ä¸ªèŠ‚ç‚¹åˆ°æŸ¥è¯¢çš„è·ç¦»ä»¥ä¸€ä¸ªå¤§äº 1 çš„ä¹˜æ³•å› å­Î±å‡å°ï¼Œè€Œä¸ä»…ä»…æ˜¯åƒåœ¨ SNG å±æ€§ä¸­é‚£æ ·ä»…ä»…å‡å°ã€‚è€ƒè™‘æœ‰å‘å›¾ï¼Œå…¶ä¸­æ¯ä¸ªç‚¹ p çš„å‡ºè¾¹é‚»å±…æ˜¯ç”±ç®—æ³• 2 ä¸­çš„ç¨³å¥å‰ªæï¼ˆpï¼ŒVï¼ŒÎ±ï¼ŒRï¼‰è¿‡ç¨‹ç¡®å®šçš„ã€‚æ³¨æ„ï¼Œå¦‚æœæ¯ä¸ª pâˆˆP çš„å‡ºè¾¹é‚»å±…æ˜¯ç”±ç¨³å¥å‰ªæï¼ˆpï¼ŒP{p}ï¼ŒÎ±ï¼Œn-1ï¼‰ç¡®å®šçš„ï¼Œé‚£ä¹ˆä»ä»»æ„ s å¼€å§‹çš„è´ªå©ªæœç´¢ï¼ˆsï¼Œpï¼Œ1ï¼Œ1ï¼‰ï¼Œå¦‚æœÎ±ï¼1ï¼Œå°†åœ¨å¯¹æ•°çº§çš„è®¸å¤šæ­¥éª¤å†…æ”¶æ•›åˆ° pâˆˆPã€‚ç„¶è€Œï¼Œè¿™å°†å¯¼è‡´ç´¢å¼•æ„å»ºçš„è¿è¡Œæ—¶é—´çº¦ä¸º O(nÂ²)ã€‚å› æ­¤ï¼ŒåŸºäº[21,13]çš„æƒ³æ³•ï¼ŒVamanaä¸ºä¸€ä¸ªç²¾å¿ƒé€‰æ‹©çš„ã€èŠ‚ç‚¹æ•°è¿œè¿œå°‘äº n-1 çš„ V è°ƒç”¨ç¨³å¥å‰ªæï¼ˆpï¼ŒVï¼ŒÎ±ï¼ŒRï¼‰ï¼Œä»¥æ”¹è¿›ç´¢å¼•æ„å»ºæ—¶é—´ã€‚")]),e("li",null,[e("p",null,[s("To overcome this, we would like to ensure that the distance to the query decreases by a multiplicative factor of "),e("em",null,"Î± >"),s(" 1 at every node along the search path, instead of merely decreasing as in the SNG property.")])]),e("li",null,[e("p",null,[s("Consider the directed graph where the out-neighbors of every point "),e("em",null,"p"),s(" are determined by the RobustPrune("),e("em",null,"p,"),s(),e("em",null,"V"),s(", Î±, R) procedure in Algorithm 2.")])]),e("li",null,[e("p",null,[s("Note that if the out-neighbors of every "),e("em",null,"p"),s(),e("em",null,"âˆˆ"),s(),e("em",null,"P"),s(" are determined by RobustPrune("),e("em",null,"p, P"),s(),e("em",null,[s("\\ {"),e("strong",null,"p"),s("}, Î±, n")]),s(),e("em",null,"âˆ’"),s(" 1), then GreedySearch("),e("em",null,"s, p,"),s(" 1*,* 1), starting at any "),e("em",null,"s"),s(", would converge to "),e("em",null,"p"),s(),e("em",null,"âˆˆ"),s(),e("em",null,"P"),s(" in logarithmically many steps, if "),e("em",null,"Î± >"),s(" 1.")])]),e("li",null,[e("p",null,[s("However, this would result in a running time of "),e("em",null,"O"),s("("),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msup",null,[e("mi",null,"n"),e("mn",null,"2")])]),e("annotation",{encoding:"application/x-tex"},"n^2")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.8141em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"n"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.8141em"}},[e("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mtight"},"2")])])])])])])])])])]),s(" ) for index construction. Hence, building on the ideas of [21, 13], Vamana invokes RobustPrune("),e("em",null,"p,"),s(),e("em",null,"V"),s(", Î±, R) for a carefully selected "),e("em",null,"V"),s(" with far fewer than "),e("em",null,"n"),s(),e("em",null,"âˆ’"),s(" 1 nodes, to improve index construction time.")])])],-1),H=e("figure",null,[e("img",{src:d,alt:"algorithm2",tabindex:"0",loading:"lazy"}),e("figcaption",null,"algorithm2")],-1),C=e("h3",{id:"_2-3-the-vamana-indexing-algorithm",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_2-3-the-vamana-indexing-algorithm","aria-hidden":"true"},"#"),s(" 2.3 The Vamana Indexing Algorithm")],-1),B=e("ul",null,[e("li",null,[e("p",null,[e("mark",null,"æ€»ç»“")])]),e("li"),e("li",null,[e("p",null,[e("mark",null,"åŸæ–‡ç¿»è¯‘")])]),e("li",null,[e("p",null,"Vamanaä»¥è¿­ä»£çš„æ–¹å¼æ„å»ºä¸€ä¸ªæœ‰å‘å›¾ Gã€‚å›¾ G è¢«åˆå§‹åŒ–ï¼Œä½¿å¾—æ¯ä¸ªé¡¶ç‚¹æœ‰ R ä¸ªéšæœºé€‰æ‹©çš„å‡ºè¾¹é‚»å±…ã€‚è¯·æ³¨æ„ï¼Œå½“ Rï¼logn æ—¶ï¼Œå›¾æ˜¯å……åˆ†è¿æ¥çš„ï¼Œä½†éšæœºè¿æ¥å¹¶ä¸èƒ½ç¡®ä¿è´ªå©ªæœç´¢ç®—æ³•æ”¶æ•›åˆ°å¥½çš„ç»“æœã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è®© s è¡¨ç¤ºæ•°æ®é›† P çš„è´¨å¿ƒï¼Œå®ƒå°†æ˜¯æœç´¢ç®—æ³•çš„èµ·å§‹èŠ‚ç‚¹ã€‚ç„¶åè¯¥ç®—æ³•ä»¥éšæœºé¡ºåºéå† P ä¸­æ‰€æœ‰çš„ç‚¹ pï¼Œå¹¶ä¸”åœ¨æ¯ä¸€æ­¥ä¸­ï¼Œæ›´æ–°å›¾ä»¥ä½¿å…¶æ›´é€‚åˆè´ªå©ªæœç´¢ï¼ˆsï¼Œxpï¼Œ1ï¼ŒLï¼‰æ”¶æ•›åˆ° pã€‚å®é™…ä¸Šï¼Œåœ¨å¯¹åº”äºç‚¹ p çš„è¿­ä»£ä¸­ï¼ŒVamanaé¦–å…ˆåœ¨å½“å‰å›¾ G ä¸Šè¿è¡Œè´ªå©ªæœç´¢ï¼ˆsï¼Œxpï¼Œ1ï¼ŒLï¼‰ï¼Œå¹¶å°† Vp è®¾ç½®ä¸ºè´ªå©ªæœç´¢ï¼ˆsï¼Œxpï¼Œ1ï¼ŒLï¼‰è®¿é—®çš„æ‰€æœ‰ç‚¹çš„é›†åˆã€‚ç„¶åï¼Œè¯¥ç®—æ³•é€šè¿‡è¿è¡Œç¨³å¥å‰ªæï¼ˆpï¼ŒVpï¼ŒÎ±ï¼ŒRï¼‰æ¥æ›´æ–° G ä»¥ç¡®å®š p çš„æ–°å‡ºè¾¹é‚»å±…ã€‚ç„¶åï¼ŒVamanaé€šè¿‡ä¸ºæ‰€æœ‰ pâ€²âˆˆNout(p)æ·»åŠ åå‘è¾¹ï¼ˆpâ€²ï¼Œpï¼‰æ¥æ›´æ–°å›¾ Gã€‚è¿™ç¡®ä¿äº†åœ¨æœç´¢è·¯å¾„ä¸Šè®¿é—®çš„é¡¶ç‚¹å’Œ p ä¹‹é—´æœ‰è¿æ¥ï¼Œä»è€Œç¡®ä¿æ›´æ–°åçš„å›¾å°†æ›´é€‚åˆè´ªå©ªæœç´¢ï¼ˆsï¼Œxpï¼Œ1ï¼ŒLï¼‰æ”¶æ•›åˆ° pã€‚")]),e("li",null,[e("p",null,[s("Vamana constructs a directed graph "),e("em",null,"G"),s(" in an iterative manner. The graph "),e("em",null,"G"),s(" is initialized so that each vertex has "),e("em",null,"R"),s(" randomly chosen out-neighbors. Note that while the graph is well connected when "),e("em",null,"R >"),s(" log "),e("em",null,"n"),s(", random connections do not ensure convergence of the GreedySearch algorithm to good results. å…¶å®ä¸€ä¸ªå……åˆ†è¿æ¥çš„å›¾ä¹Ÿä¸ä¸€å®šèƒ½å¾—åˆ°å¥½çš„ç»“æœï¼Ÿï¼Ÿ")])]),e("li",null,[e("p",null,[s("Next, we let "),e("em",null,"s"),s(" denote the medoid of the dataset "),e("em",null,"P"),s(", which will be the starting node for the search algorithm. The algorithm then iterates through all the points in "),e("em",null,"p"),s(),e("em",null,"âˆˆ"),s(),e("em",null,"P"),s(" in a random order, and in each step, updates the graph to make it more suitable for GreedySearch("),e("em",null,"s,"),s(" x"),e("em",null,"p,"),s(" 1*, L*) to converge to "),e("em",null,"p"),s(". è´¨å¿ƒ s ç„¶åå¯¹Pä¸­çš„æ¯ä¸ªç‚¹è¿›è¡Œæœç´¢ç®—æ³•ï¼Œåœ¨è¿›è¡ŒGreedySearchçš„æ—¶å€™ï¼Œç„¶åæ›´æ–°å›¾ï¼›")])]),e("li",null,[e("p",null,[s("Indeed, in the iteration corresponding to point "),e("em",null,"p"),s(", Vamana first runs GreedySearch("),e("em",null,"s,"),s(" x"),e("em",null,"p,"),s(" 1*, L*) on the current graph "),e("em",null,"G"),s(", and sets "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msub",null,[e("mi",null,"V"),e("mi",null,"p")])]),e("annotation",{encoding:"application/x-tex"},"V_p")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.9694em","vertical-align":"-0.2861em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"V"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t vlist-t2"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.1514em"}},[e("span",{style:{top:"-2.55em","margin-left":"-0.2222em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mathnormal mtight"},"p")])])]),e("span",{class:"vlist-s"},"â€‹")]),e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.2861em"}},[e("span")])])])])])])])]),s(" to the "),e("em",null,"set of all points visited"),s(" by GreedySearch("),e("em",null,"s,"),s(" x"),e("em",null,"p,"),s(" 1*, L*). Then, the algorithm updates "),e("em",null,"G"),s(" by running RobustPrune("),e("em",null,"p,"),s(),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msub",null,[e("mi",null,"V"),e("mi",null,"p")])]),e("annotation",{encoding:"application/x-tex"},"V_p")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.9694em","vertical-align":"-0.2861em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"V"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t vlist-t2"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.1514em"}},[e("span",{style:{top:"-2.55em","margin-left":"-0.2222em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mathnormal mtight"},"p")])])]),e("span",{class:"vlist-s"},"â€‹")]),e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.2861em"}},[e("span")])])])])])])])]),s(" , Î±, R) to determine "),e("em",null,"p"),s("â€™s new out-neighbors.å½“å¯¹pç‚¹è¿›è¡Œæ›´æ–°å›¾çš„æ—¶å€™ï¼Œé¦–å…ˆ searchç„¶åæ›´æ–°å›¾ï¼›")])]),e("li",null,[e("p",null,[s("Then, Vamana updates the graph "),e("em",null,"G"),s(" by adding backward edges ("),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msup",null,[e("mi",null,"p"),e("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"â€²")])]),e("annotation",{encoding:"application/x-tex"},"p'")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.9463em","vertical-align":"-0.1944em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"p"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.7519em"}},[e("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mtight"},[e("span",{class:"mord mtight"},"â€²")])])])])])])])])])])]),s(" , p) for all "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msup",null,[e("mi",null,"p"),e("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"â€²")])]),e("annotation",{encoding:"application/x-tex"},"p'")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.9463em","vertical-align":"-0.1944em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"p"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.7519em"}},[e("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mtight"},[e("span",{class:"mord mtight"},"â€²")])])])])])])])])])])]),s(),e("em",null,"âˆˆ"),s(),e("em",null,"N"),s("out("),e("em",null,"p"),s("). This ensures that there are connections between the vertices visited on the search path and "),e("em",null,"p"),s(", thereby ensuring that the updated graph will be better suited for GreedySearch("),e("em",null,"s,"),s(" x"),e("em",null,"p,"),s(" 1*, L*) to converge to "),e("em",null,"p"),s(". è¿›è¡Œåå‘è¾¹çš„æ·»åŠ ï¼›")])]),e("li",null,[e("p",null,"ç„¶è€Œï¼Œæ·»åŠ ï¼ˆpâ€²ï¼Œpï¼‰è¿™ç§å½¢å¼çš„åå‘è¾¹å¯èƒ½ä¼šå¯¼è‡´å¯¹ pâ€²çš„åº¦çš„è¿åï¼Œå› æ­¤æ¯å½“ä»»ä½•é¡¶ç‚¹ pâ€²çš„å‡ºåº¦è¶…è¿‡åº¦é˜ˆå€¼ R æ—¶ï¼Œé€šè¿‡è¿è¡Œç¨³å¥å‰ªæï¼ˆpâ€²ï¼ŒNout(pâ€²)ï¼ŒÎ±ï¼ŒRï¼‰æ¥ä¿®æ”¹å›¾ï¼Œå…¶ä¸­ Nout(pâ€²)æ˜¯ pâ€²ç°æœ‰çš„å‡ºè¾¹é‚»å±…çš„é›†åˆã€‚éšç€ç®—æ³•çš„è¿›è¡Œï¼Œè¯¥å›¾å¯¹äºè´ªå©ªæœç´¢æ¥è¯´å˜å¾—è¶Šæ¥è¶Šå¥½ä¸”è¶Šæ¥è¶Šå¿«ã€‚æˆ‘ä»¬çš„æ•´ä½“ç®—æ³•å¯¹æ•°æ®é›†è¿›è¡Œä¸¤æ¬¡éå†ï¼Œç¬¬ä¸€æ¬¡éå†Î±=1ï¼Œç¬¬äºŒæ¬¡éå†ä½¿ç”¨ç”¨æˆ·å®šä¹‰çš„Î±â‰¥1ã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°ç¬¬äºŒæ¬¡éå†ä¼šäº§ç”Ÿæ›´å¥½çš„å›¾ï¼Œå¹¶ä¸”ä½¿ç”¨ç”¨æˆ·å®šä¹‰çš„Î±è¿›è¡Œä¸¤æ¬¡éå†ä¼šä½¿ç´¢å¼•ç®—æ³•å˜æ…¢ï¼Œå› ä¸ºç¬¬ä¸€æ¬¡éå†è®¡ç®—å‡ºçš„å›¾å…·æœ‰æ›´é«˜çš„å¹³å‡åº¦ï¼Œè¿™éœ€è¦æ›´é•¿æ—¶é—´ã€‚")]),e("li",null,[e("p",null,[s("However, adding backward edges of the form (pâ€²"),e("em",null,", p"),s(") might lead to a degree violation of pâ€² , and so whenever any vertex pâ€² has an out-degree which exceeds the degree threshold of "),e("em",null,"R"),s(", the graph is modified by running RobustPrune(pâ€²ï¼ŒNout(pâ€²)ï¼ŒÎ±ï¼ŒR) where "),e("em",null,"N"),s("out(pâ€² ) is the set of existing out neighbors of pâ€² . å½“å‡ºåº¦è¶…Rçš„æ—¶å€™ï¼Œè¿è¡ŒRobustPrune")])]),e("li",null,[e("p",null,[s("As the algorithm proceeds, the graph becomes consistently better and faster for GreedySearch. Our overall algorithm makes two passes over the dataset, the first pass with "),e("em",null,"Î±"),s(" = 1, and the second with a user-defined "),e("em",null,"Î±"),s(),e("em",null,"â‰¥"),s(" 1. We observed that a second pass results in better graphs, and that running both passes with the user-defined "),e("em",null,"Î±"),s(" makes the indexing algorithm slower as the first pass computes a graph with higher average degree which takes longer.")])])],-1),O=l('<figure><img src="'+g+'" alt="algorithm3" tabindex="0" loading="lazy"><figcaption>algorithm3</figcaption></figure><figure><img src="'+f+'" alt="figure1" tabindex="0" loading="lazy"><figcaption>figure1</figcaption></figure><h3 id="_2-4-comparison-ofvamanawith-hnsw-21-and-nsg-13" tabindex="-1"><a class="header-anchor" href="#_2-4-comparison-ofvamanawith-hnsw-21-and-nsg-13" aria-hidden="true">#</a> 2.4 Comparison ofVamanawith HNSW [21] and NSG [13]</h3><ul><li>ä»é«˜å±‚æ¬¡æ¥çœ‹ï¼ŒVamanaä¸ HNSW å’Œ NSG è¿™ä¸¤ç§éå¸¸æµè¡Œçš„è¿‘ä¼¼æœ€è¿‘é‚»æœç´¢ç®—æ³•ç›¸å½“ç›¸ä¼¼ã€‚è¿™ä¸‰ç§ç®—æ³•éƒ½å¯¹æ•°æ®é›† P è¿›è¡Œè¿­ä»£ï¼Œå¹¶ä½¿ç”¨è´ªå©ªæœç´¢GreedySearchï¼ˆsï¼Œxpï¼Œ1ï¼ŒLï¼‰å’Œç¨³å¥å‰ªæRobustPruneï¼ˆpï¼ŒVï¼ŒÎ±ï¼ŒRï¼‰çš„ç»“æœæ¥ç¡®å®š p çš„é‚»å±…ã€‚ç„¶è€Œï¼Œè¿™äº›ç®—æ³•ä¹‹é—´å­˜åœ¨ä¸€äº›é‡è¦å·®å¼‚ã€‚æœ€å…³é”®çš„æ˜¯ï¼ŒHNSW å’Œ NSG éƒ½æ²¡æœ‰å¯è°ƒèŠ‚çš„å‚æ•°Î±ï¼Œå¹¶ä¸”éšå«åœ°ä½¿ç”¨Î±=1ã€‚è¿™æ˜¯è®©Vamanaåœ¨å›¾çš„åº¦å’Œç›´å¾„ä¹‹é—´å®ç°æ›´å¥½æƒè¡¡çš„ä¸»è¦å› ç´ ã€‚æ¥ä¸‹æ¥ï¼Œè™½ç„¶ HNSW å°†å‰ªæè¿‡ç¨‹çš„å€™é€‰é›† V è®¾ç½®ä¸ºè´ªå©ªæœç´¢ï¼ˆsï¼Œpï¼Œ1ï¼ŒLï¼‰è¾“å‡ºçš„ L ä¸ªå€™é€‰çš„æœ€ç»ˆç»“æœé›†ï¼Œè€ŒVamanaå’Œ NSG è®© V æ˜¯è´ªå©ªæœç´¢ï¼ˆsï¼Œpï¼Œ1ï¼ŒLï¼‰è®¿é—®çš„æ‰€æœ‰é¡¶ç‚¹é›†ã€‚ç›´è§‚åœ°è¯´ï¼Œè¿™ä¸ªç‰¹æ€§å¸®åŠ©Vamanaå’Œ NSG æ·»åŠ è¿œç¨‹è¾¹ï¼Œè€Œ HNSW ç”±äºåªå‘é™„è¿‘ç‚¹æ·»åŠ å±€éƒ¨è¾¹ï¼Œå› æ­¤æœ‰ä¸€ä¸ªé¢å¤–çš„æ­¥éª¤ï¼Œå³åœ¨æ•°æ®é›†çš„åµŒå¥—æ ·æœ¬åºåˆ—ä¸Šæ„å»ºå›¾çš„å±‚æ¬¡ç»“æ„ã€‚ä¸‹ä¸€ä¸ªå·®å¼‚ä¸åˆå§‹å›¾æœ‰å…³ï¼šè™½ç„¶ NSG å°†èµ·å§‹å›¾è®¾ç½®ä¸ºæ•°æ®é›†ä¸Šçš„è¿‘ä¼¼ K æœ€è¿‘é‚»å›¾ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¶é—´å’Œå†…å­˜å¯†é›†å‹æ­¥éª¤ï¼Œè€Œ HNSW å’ŒVamanaæœ‰æ›´ç®€å•çš„åˆå§‹åŒ–ï¼Œå‰è€…ä»ç©ºå›¾å¼€å§‹ï¼ŒVamanaä»éšæœºå›¾å¼€å§‹ã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œä»éšæœºå›¾å¼€å§‹ä¼šæ¯”ä»ç©ºå›¾å¼€å§‹äº§ç”Ÿè´¨é‡æ›´å¥½çš„å›¾ã€‚æœ€åï¼ŒVamanaå¯¹æ•°æ®é›†è¿›è¡Œä¸¤æ¬¡éå†ï¼Œè€Œ HNSW å’Œ NSG éƒ½åªè¿›è¡Œä¸€æ¬¡éå†ï¼Œè¿™æ˜¯ç”±æˆ‘ä»¬çš„è§‚å¯Ÿç»“æœå³ç¬¬äºŒæ¬¡éå†ä¼šæé«˜å›¾çš„è´¨é‡æ‰€æ¨åŠ¨çš„ã€‚</li><li>At a high level, Vamana is rather similar to HNSW and NSG, two very popular ANNS algorithms. All three algorithms iterate over the dataset <em>P</em>, and use the results of the GreedySearch(<em>s,</em> x<em>p,</em> 1*, L*) and RobustPrune(<em>p,</em> <em>V</em>, Î±, R*) to determine <em>p</em>â€™s neighbors.</li><li>However, there are some important differences between these algorithms. Most crucially, both HNSW and NSG have no tunable parameter <em>Î±</em> and implicitly use <em>Î±</em> = 1. This is the main factor which lets Vamana achieve a better trade-off between graph degree and diameter. è¿™ä¸ªï¼Ÿï¼Ÿ graph degree and diameterï¼Ÿï¼Ÿ</li><li>Next, while HNSW sets the candidate set <em>V</em> for the pruning procedure to be the <em>final result-set of</em> <em>L</em> <em>candidates</em> output by GreedySearch(<em>s, p,</em> 1*, L*), Vamana and NSG let <em>V</em> be the entire set of vertices visited by GreedySearch(<em>s, p,</em> 1*, L*). Intuitively, this feature helps Vamana and NSG add long-range edges, while HNSW, by virtue of adding only local edges to nearby points, has an additional step of constructing a hierarchy of graphs over a nested sequence of samples of the dataset.</li><li>The next difference pertains to the initial graph: while NSG sets the starting graph to be an approximate <em>K</em>-nearest neighbor graph over the dataset, which is a time and memory intensive step, HNSW and Vamana have simpler initializations, with the former beginning with an empty graph and Vamana beginning with a random graph. We have observed that starting with a random graph results in better quality graphs than beginning with the empty graph.</li><li>Finally, Vamana makes two passes over the dataset, whereas both HNSW and NSG make only one pass, motivated by our observation that the second pass improves the graph quality.</li></ul><h2 id="_3-diskann-constructing-ssd-resident-indices" tabindex="-1"><a class="header-anchor" href="#_3-diskann-constructing-ssd-resident-indices" aria-hidden="true">#</a> 3 DiskANN: Constructing SSD-Resident Indices</h2><ul><li>æˆ‘ä»¬ç°åœ¨åˆ†ä¸¤éƒ¨åˆ†æ¥æ•´ä½“å‘ˆç° DiskANN çš„è®¾è®¡ã€‚åœ¨ç¬¬ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬è§£é‡Šç´¢å¼•æ„å»ºç®—æ³•ï¼Œåœ¨ç¬¬äºŒéƒ¨åˆ†ï¼Œæˆ‘ä»¬è§£é‡Šæœç´¢ç®—æ³•ã€‚</li><li>We now present the design of the DiskANN overall in two parts. In the first part, we explain the index construction algorithm, and in the second part, we explain the search algorithm.</li></ul><h3 id="_3-1-thediskannindex-design" tabindex="-1"><a class="header-anchor" href="#_3-1-thediskannindex-design" aria-hidden="true">#</a> 3.1 TheDiskANNIndex Design</h3>',7),E=e("ul",null,[e("li",null,[e("p",null,"é«˜å±‚çš„æƒ³æ³•å¾ˆç®€å•ï¼šåœ¨æ•°æ®é›† P ä¸Šè¿è¡ŒVamanaå¹¶å°†å¾—åˆ°çš„å›¾å­˜å‚¨åœ¨å›ºæ€ç¡¬ç›˜ï¼ˆSSDï¼‰ä¸Šã€‚åœ¨æœç´¢æ—¶ï¼Œæ¯å½“ç®—æ³• 1 éœ€è¦ä¸€ä¸ªç‚¹ p çš„å‡ºé‚»åŸŸæ—¶(å°±æ˜¯éœ€è¦ä¸€ä¸ªç‚¹pçš„é‚»å±…çš„æ—¶å€™)ï¼Œæˆ‘ä»¬åªéœ€ä» SSD ä¸­è·å–(fetch)æ­¤ä¿¡æ¯ã€‚ç„¶è€Œï¼Œ==è¯·æ³¨æ„ï¼Œä»…ä»…åœ¨ 100 ç»´ä¸­ä¸ºåäº¿ä¸ªç‚¹å­˜å‚¨å‘é‡æ•°æ®å°±ä¼šè¿œè¿œè¶…å‡ºå·¥ä½œç«™çš„éšæœºå­˜å–å­˜å‚¨å™¨ï¼ˆRAMï¼‰ï¼==è¿™å°±å¼•å‡ºäº†ä¸¤ä¸ªé—®é¢˜ï¼šæˆ‘ä»¬å¦‚ä½•åœ¨åäº¿ä¸ªç‚¹ä¸Šæ„å»ºä¸€ä¸ªå›¾ï¼Œä»¥åŠå¦‚æœæˆ‘ä»¬ç”šè‡³æ— æ³•å­˜å‚¨å‘é‡æ•°æ®ï¼Œé‚£ä¹ˆåœ¨ç®—æ³• 1 çš„æœç´¢çš„æ—¶å€™ï¼Œæˆ‘ä»¬å¦‚ä½•åœ¨æŸ¥è¯¢ç‚¹å’Œå€™é€‰åˆ—è¡¨ä¸­çš„ç‚¹ä¹‹é—´è¿›è¡Œè·ç¦»æ¯”è¾ƒï¼Ÿ")]),e("li",null,[e("p",null,[s("The high-level idea is simple: run Vamana on a dataset "),e("em",null,"P"),s(" and store the resulting graph on an SSD. At search time, whenever Algorithm 1 requires the out-neighbors of a point "),e("em",null,"p"),s(", we simply fetch this information from the SSD. ä»”ç»†æƒ³ä¸‹Vamanaçš„è¿‡ç¨‹ï¼Œ")])]),e("li",null,[e("p",null,[s("However, note that "),e("em",null,"just storing the vector data for a billion points in"),s(" 100 "),e("em",null,"dimensions would far exceed the RAM on a workstation!")])]),e("li",null,[e("p",null,"This raises two questions: how do we build a graph over a billion points, ï¼Ÿç¬¬ä¸€ä¸ªé—®é¢˜ï¼Ÿ")]),e("li",null,[e("p",null,"and how do we do distance comparisons between the query point and points in our candidate list at search time in Algorithm 1, if we cannot even store the vector data?ç¬¬äºŒä¸ªé—®é¢˜ï¼›")]),e("li",null,[e("p",null,"è§£å†³ç¬¬ä¸€ä¸ªé—®é¢˜çš„ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨åƒ k-means è¿™æ ·çš„èšç±»æŠ€æœ¯å°†æ•°æ®åˆ†å‰²æˆå¤šä¸ªè¾ƒå°çš„åˆ†ç‰‡ï¼Œä¸ºæ¯ä¸ªåˆ†ç‰‡æ„å»ºä¸€ä¸ªå•ç‹¬çš„ç´¢å¼•ï¼Œå¹¶åœ¨æœç´¢æ—¶ä»…å°†æŸ¥è¯¢è·¯ç”±åˆ°å°‘æ•°å‡ ä¸ªåˆ†ç‰‡ã€‚ç„¶è€Œï¼Œå› ä¸ºæŸ¥è¯¢éœ€è¦è¢«è·¯ç”±åˆ°å¤šä¸ªåˆ†ç‰‡ã€‚è¿™æ ·çš„æ–¹æ³•ä¼šé­å—æœç´¢å»¶è¿Ÿå¢åŠ å’Œååé‡é™ä½çš„é—®é¢˜ã€‚")]),e("li",null,[e("p",null,[s("One way to address the first question would be to partition the data into "),e("em",null,"multiple smaller shards"),s(" using clustering techniques like "),e("em",null,"k"),s("-means, build a separate index for each shard, and route the query only to a few shards at search time. However, such an approach would suffer from increased search latency and reduced throughput since the query needs to be routed to several shards.")])]),e("li",null,[e("p",null,"äº‹åçœ‹æ¥ï¼Œ==æˆ‘ä»¬çš„æƒ³æ³•å¾ˆç®€å•ï¼šä¸å…¶åœ¨æœç´¢æ—¶å°†æŸ¥è¯¢è·¯ç”±åˆ°å¤šä¸ªåˆ†ç‰‡ï¼Œä¸å¦‚å¦‚æœæˆ‘ä»¬å°†æ¯ä¸ªåŸºæœ¬ç‚¹å‘é€åˆ°å¤šä¸ªé™„è¿‘çš„ä¸­å¿ƒä»¥è·å¾—é‡å çš„ç°‡å‘¢ï¼Ÿï¼ˆè¿™ä¸ªè¦å¥½å¥½çš„ç†è§£ä»¥ä¸‹ï¼‰==å®é™…ä¸Šï¼Œæˆ‘ä»¬é¦–å…ˆä½¿ç”¨ k-means å°†åäº¿ä¸ªç‚¹çš„æ•°æ®é›†åˆ’åˆ†ä¸º k ä¸ªç°‡ï¼ˆæ¯”å¦‚è¯´ k = 40ï¼‰ï¼Œç„¶åå°†æ¯ä¸ªåŸºæœ¬ç‚¹(base point)åˆ†é…ç»™ ll- ä¸ªæœ€æ¥è¿‘çš„ä¸­å¿ƒï¼ˆé€šå¸¸ ll= 2 å°±è¶³å¤Ÿäº†ï¼‰ã€‚ç„¶åï¼Œæˆ‘ä»¬ä¸ºåˆ†é…ç»™æ¯ä¸ªç°‡çš„ç‚¹æ„å»ºVamanaç´¢å¼•ï¼ˆç°åœ¨æ¯ä¸ªç°‡å¤§çº¦åªæœ‰ N * ll / k ä¸ªç‚¹ï¼Œå› æ­¤å¯ä»¥åœ¨å†…å­˜ä¸­è¿›è¡Œç´¢å¼•ï¼‰ï¼Œæœ€åé€šè¿‡ç®€å•åœ°åˆå¹¶è¾¹å°†æ‰€æœ‰ä¸åŒçš„å›¾åˆå¹¶æˆä¸€ä¸ªå•ä¸€çš„å›¾ã€‚æ ¹æ®ç»éªŒï¼Œäº‹å®è¯æ˜ä¸åŒç°‡çš„é‡å æ€§è´¨ä¸ºè´ªå©ªæœç´¢ç®—æ³•æä¾›äº†è¶³å¤Ÿçš„è¿æ¥æ€§ï¼Œå³ä½¿æŸ¥è¯¢çš„æœ€è¿‘é‚»å®é™…ä¸Šåœ¨å¤šä¸ªåˆ†ç‰‡ä¸­åˆ†è£‚ã€‚æˆ‘ä»¬æƒ³æŒ‡å‡ºçš„æ˜¯ï¼Œä¹‹å‰å·²ç»æœ‰æ—©æœŸçš„å·¥ä½œ[9,22]é€šè¿‡åˆå¹¶å‡ ä¸ªè¾ƒå°çš„ã€é‡å çš„ç´¢å¼•æ¥ä¸ºå¤§å‹æ•°æ®é›†æ„å»ºç´¢å¼•ã€‚ç„¶è€Œï¼Œä»–ä»¬æ„å»ºé‡å ç°‡çš„æƒ³æ³•æ˜¯ä¸åŒçš„ï¼Œéœ€è¦å¯¹è¿™äº›ä¸åŒæŠ€æœ¯è¿›è¡Œæ›´è¯¦ç»†çš„æ¯”è¾ƒã€‚")]),e("li",null,[e("p",null,[s("Our idea is simple in hindsight: "),e("em",null,"instead of routing the query to multiple shards at search time, what"),s(),e("em",null,"if we send each base point to multiple nearby centers to obtain overlapping clusters?")])]),e("li",null,[e("p",null,[s("Indeed, we first partition a billion point dataset into "),e("em",null,"k"),s(" clusters (with "),e("em",null,"k"),s(" = 40, say) using "),e("em",null,"k"),s("-means, and then assign each base point to the "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msup",null,[e("mi",null,"l"),e("mo",null,"âˆ—")])]),e("annotation",{encoding:"application/x-tex"},"l^*")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.6944em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.6887em"}},[e("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mbin mtight"},"âˆ—")])])])])])])])])])]),s("-closest centers (typically "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msup",null,[e("mi",null,"l"),e("mo",null,"âˆ—")])]),e("annotation",{encoding:"application/x-tex"},"l^*")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.6944em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.6887em"}},[e("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mbin mtight"},"âˆ—")])])])])])])])])])]),s(" = 2 suffices). We then build Vamana indices for the points assigned to each of the clusters (which would now only have about $ N l^* /k$ points and thus can be indexed in-memory), and finally merge all the different graphs into a single graph by taking a simple union of edges. é‚£ä¹ˆè¿™ä¸ªåˆå¹¶æ˜¯åœ¨å“ªé‡Œè¿›è¡Œçš„å‘¢ï¼Ÿï¼Ÿï¼Ÿ")])]),e("li",null,[e("p",null,"Empirically, it turns out that the overlapping nature of the different clusters provides sufficient connectivity for the GreedySearch algorithm to succeed even if the queryâ€™s nearest neighbors are actually split between multiple shards. We would like to remark that there have been earlier works [9, 22] which construct indices for large datasets by merging several smaller, overlapping indices. However, their ideas for constructing the overlapping clusters are different, and a more detailed comparison of these different techniques needs to be done.")]),e("li",null,[e("p",null,"æˆ‘ä»¬è§£å†³ç¬¬äºŒä¸ªé—®é¢˜çš„ä¸‹ä¸€ä¸ªè‡ªç„¶æƒ³æ³•æ˜¯åœ¨ä¸»å†…å­˜ä¸­ä¸ºæ¯ä¸ªæ•°æ®åº“ç‚¹ pâˆˆP å­˜å‚¨å‹ç¼©å‘é‡ Ìƒxpï¼ŒåŒæ—¶åœ¨å›ºæ€ç¡¬ç›˜ä¸Šå­˜å‚¨è¯¥å›¾ã€‚æˆ‘ä»¬ä½¿ç”¨ä¸€ç§ç§°ä¸ºä¹˜ç§¯é‡åŒ–[17]4 çš„æµè¡Œå‹ç¼©æ–¹æ¡ˆï¼Œå®ƒå°†æ•°æ®ç‚¹å’ŒæŸ¥è¯¢ç‚¹ç¼–ç æˆçŸ­ä»£ç ï¼ˆä¾‹å¦‚ï¼Œæ¯ä¸ªæ•°æ®ç‚¹ 32 å­—èŠ‚ï¼‰ï¼Œå¯ä»¥åœ¨ç®—æ³• 1 ä¸­æŸ¥è¯¢æ—¶æœ‰æ•ˆåœ°è·å¾—è¿‘ä¼¼è·ç¦» d( Ìƒxp,xq)ã€‚æˆ‘ä»¬æƒ³æŒ‡å‡ºçš„æ˜¯ï¼ŒVamanaåœ¨æ„å»ºå›¾ç´¢å¼•æ—¶ä½¿ç”¨å…¨ç²¾åº¦åæ ‡ï¼Œå› æ­¤èƒ½å¤Ÿæœ‰æ•ˆåœ°å¼•å¯¼æœç´¢æœå‘å›¾çš„æ­£ç¡®åŒºåŸŸï¼Œå°½ç®¡æˆ‘ä»¬åœ¨æŸ¥è¯¢æ—¶ä»…ä½¿ç”¨å‹ç¼©æ•°æ®ã€‚")]),e("li",null,[e("p",null,[s("Our next and natural idea to address the second question is to store "),e("em",null,"compressed vectors"),s(),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mover",{accent:"true"},[e("msub",null,[e("mi",null,"x"),e("mi",null,"p")]),e("mo",{stretchy:"true"},"â€¾")])]),e("annotation",{encoding:"application/x-tex"},"\\overline{x_p}")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.9167em","vertical-align":"-0.2861em"}}),e("span",{class:"mord overline"},[e("span",{class:"vlist-t vlist-t2"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.6306em"}},[e("span",{style:{top:"-3em"}},[e("span",{class:"pstrut",style:{height:"3em"}}),e("span",{class:"mord"},[e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"x"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t vlist-t2"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.1514em"}},[e("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mathnormal mtight"},"p")])])]),e("span",{class:"vlist-s"},"â€‹")]),e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.2861em"}},[e("span")])])])])])])]),e("span",{style:{top:"-3.5506em"}},[e("span",{class:"pstrut",style:{height:"3em"}}),e("span",{class:"overline-line",style:{"border-bottom-width":"0.04em"}})])]),e("span",{class:"vlist-s"},"â€‹")]),e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.2861em"}},[e("span")])])])])])])]),s(" for every database point "),e("em",null,"p"),s(),e("em",null,"âˆˆ"),s(),e("em",null,"P"),s(" in main memory, along with storing the graph on the SSD. We use a popular compression scheme known as "),e("em",null,"Product Quantization"),s("[17], which encodes the data and query points into short "),e("em",null,"codes"),s(" (e.g., 32 bytes per data point) that can be used to efficiently obtain approximate distances "),e("em",null,"d"),s("("),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mover",{accent:"true"},[e("msub",null,[e("mi",null,"x"),e("mi",null,"p")]),e("mo",{stretchy:"true"},"â€¾")])]),e("annotation",{encoding:"application/x-tex"},"\\overline{x_p}")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.9167em","vertical-align":"-0.2861em"}}),e("span",{class:"mord overline"},[e("span",{class:"vlist-t vlist-t2"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.6306em"}},[e("span",{style:{top:"-3em"}},[e("span",{class:"pstrut",style:{height:"3em"}}),e("span",{class:"mord"},[e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"x"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t vlist-t2"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.1514em"}},[e("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mathnormal mtight"},"p")])])]),e("span",{class:"vlist-s"},"â€‹")]),e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.2861em"}},[e("span")])])])])])])]),e("span",{style:{top:"-3.5506em"}},[e("span",{class:"pstrut",style:{height:"3em"}}),e("span",{class:"overline-line",style:{"border-bottom-width":"0.04em"}})])]),e("span",{class:"vlist-s"},"â€‹")]),e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.2861em"}},[e("span")])])])])])])]),s(" , "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msub",null,[e("mi",null,"x"),e("mi",null,"q")])]),e("annotation",{encoding:"application/x-tex"},"x_q")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.7167em","vertical-align":"-0.2861em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"x"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t vlist-t2"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.1514em"}},[e("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"q")])])]),e("span",{class:"vlist-s"},"â€‹")]),e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.2861em"}},[e("span")])])])])])])])]),s(") at query time in Algorithm 1.")])]),e("li",null,[e("p",null,[s("We would like to remark that Vamana uses "),e("em",null,"full"),s(),e("em",null,"precision coordinates"),s(" when building the graph index, and hence is able to efficiently guide the search towards the right region of the graph, although we use only the compressed data at search time.")]),e("ul",null,[e("li",null,"ä¹Ÿå°±æ˜¯è¯´åœ¨æ„å»ºå›¾çš„è¿‡ç¨‹ä¸­çš„ æ¶‰åŠåˆ° searchçš„æ—¶å€™ ä¹Ÿæ˜¯è¿™æ ·çš„ä½¿ç”¨pqï¼Œç„¶åå†è¿›è¡Œrerankçš„æ—¶å€™ä½¿ç”¨å…¨ç²¾åº¦ï¼Ÿ")])])],-1),K=l('<h3 id="_3-2-diskannindex-layout" tabindex="-1"><a class="header-anchor" href="#_3-2-diskannindex-layout" aria-hidden="true">#</a> 3.2 DiskANNIndex Layout</h3><ul><li>æˆ‘ä»¬å°†æ‰€æœ‰æ•°æ®ç‚¹çš„å‹ç¼©å‘é‡å­˜å‚¨åœ¨å†…å­˜ä¸­ï¼Œå¹¶å°†å›¾å’Œå…¨ç²¾åº¦å‘é‡ä¸€èµ·å­˜å‚¨åœ¨å›ºæ€ç¡¬ç›˜ä¸ŠSSDã€‚åœ¨ç£ç›˜ä¸Šï¼Œå¯¹äºæ¯ä¸ªç‚¹iï¼Œæˆ‘ä»¬éƒ½ä¼šå­˜å‚¨å…¶å…¨ç²¾åº¦å‘é‡xiï¼Œä»¥åŠå…¶â‰¤R ä¸ªé‚»å±…çš„èº«ä»½ä¿¡æ¯ã€‚å¦‚æœèŠ‚ç‚¹çš„åº¦æ•°degreeå°äº Rï¼Œæˆ‘ä»¬å°±ç”¨0å¡«å……ï¼Œè¿™æ ·è®¡ç®—ä»»æ„ç‚¹i å¯¹åº”çš„æ•°æ®åœ¨ç£ç›˜ä¸­çš„åç§»é‡å°±éå¸¸ç®€å•ï¼Œä¸éœ€è¦åœ¨å†…å­˜ä¸­å­˜å‚¨åç§»é‡äº†ã€‚æˆ‘ä»¬å°†åœ¨ä¸‹ä¸€èŠ‚è§£é‡Šå­˜å‚¨å…¨ç²¾åº¦åæ ‡çš„å¿…è¦æ€§ã€‚</li><li>We store the compressed vectors of all the data points in memory, and store the graph along with the full-precision vectors on the SSD. On the disk, for each point <em>i</em>, we store its full precision vector x<em>i</em> followed by the identities of its <em>â‰¤</em> <em>R</em> neighbors.</li><li>If the degree of a node is smaller than <em>R</em>, we pad with zeros, so that computing the offset within the disk of the data corresponding to any point <em>i</em> is a simple calculation, and does not require storing the offsets in memory. We will explain the need to store full-precision coordinates in the following section.</li></ul><h3 id="_3-3-diskann-beam-search" tabindex="-1"><a class="header-anchor" href="#_3-3-diskann-beam-search" aria-hidden="true">#</a> 3.3 DiskANN Beam Search</h3>',3),Q=e("ul",null,[e("li",null,"æœç´¢ç»™å®šæŸ¥è¯¢ xq çš„é‚»å±…çš„è‡ªç„¶æ–¹æ³•æ˜¯è¿è¡Œç®—æ³• 1ï¼Œæ ¹æ®éœ€è¦ä» SSD è·å–é‚»å±…ä¿¡æ¯ Nout(pâˆ—)ã€‚å¯ä»¥ä½¿ç”¨å‹ç¼©çŸ¢é‡è¿›è¡Œè·ç¦»è®¡ç®—ï¼Œä»¥ç¡®å®šä»ç£ç›˜è¯»å–çš„æœ€ä½³é¡¶ç‚¹ï¼ˆå’Œé‚»åŸŸï¼‰ã€‚ è¿™æ ·åšè™½ç„¶åˆç†ï¼Œä½†éœ€è¦å¤šæ¬¡å¾€è¿”å›ºæ€ç¡¬ç›˜ï¼ˆè€—æ—¶æ•°ç™¾å¾®ç§’ï¼‰ï¼Œä»è€Œå¯¼è‡´æ›´é«˜çš„å»¶è¿Ÿã€‚ ä¸ºäº†åœ¨ä¸å¢åŠ è¿‡å¤šè®¡ç®—é‡ï¼ˆè·ç¦»è®¡ç®—ï¼‰çš„æƒ…å†µä¸‹å‡å°‘åˆ° SSD çš„å¾€è¿”æ¬¡æ•°ï¼ˆä¾æ¬¡è·å–é‚»åŸŸï¼‰ï¼Œæˆ‘ä»¬ä¼šä¸€æ¬¡æ€§è·å– L ï¼ˆæˆ– Vï¼‰ä¸­æœ€æ¥è¿‘ç‚¹çš„å°‘é‡é‚»åŸŸ Wï¼ˆæ¯”å¦‚ 4ï¼Œ8ï¼‰ï¼Œå¹¶å°† L æ›´æ–°ä¸º L ä¸­çš„å‰ L ä¸ªå€™é€‰ç‚¹ä»¥åŠåœ¨æ­¤æ­¥éª¤ä¸­è·å–çš„æ‰€æœ‰é‚»åŸŸã€‚è¯·æ³¨æ„ï¼Œä»å›ºæ€ç¡¬ç›˜ä¸­è·å–å°‘é‡éšæœºæ‰‡åŒºæ‰€éœ€çš„æ—¶é—´ä¸è·å–ä¸€ä¸ªæ‰‡åŒºæ‰€éœ€çš„æ—¶é—´å‡ ä¹ç›¸åŒã€‚æˆ‘ä»¬å°†è¿™ç§æ”¹è¿›çš„æœç´¢ç®—æ³•ç§°ä¸ºBeamSearchã€‚å¦‚æœW = 1ï¼Œè¿™ä¸ªæœç´¢ç±»ä¼¼äºæ­£å¸¸çš„è´ªå©ªæœç´¢ã€‚æ³¨æ„ï¼Œå¦‚æœWå¤ªå¤§ï¼Œæ¯”å¦‚16æˆ–æ›´å¤šï¼Œé‚£ä¹ˆè®¡ç®—å’ŒSSDå¸¦å®½éƒ½å¯èƒ½è¢«æµªè´¹ã€‚"),e("li",null,[s("A natural way to search for neighbors of a given query x"),e("em",null,"q"),s(" would be to run Algorithm 1, fetching the neighborhood information "),e("em",null,"N"),s("out("),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msup",null,[e("mi",null,"p"),e("mo",null,"âˆ—")])]),e("annotation",{encoding:"application/x-tex"},"p^*")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.8831em","vertical-align":"-0.1944em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"p"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.6887em"}},[e("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mbin mtight"},"âˆ—")])])])])])])])])])]),s(" ) from the SSD as needed. Distance calculations to guide the best vertices (and neighborhoods) to read from disk can be done using the compressed vectors. å½“è¿›è¡Œsearchçš„æ—¶å€™ï¼Œæ‰¾åˆ°äº†"),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msup",null,[e("mi",null,"p"),e("mo",null,"âˆ—")])]),e("annotation",{encoding:"application/x-tex"},"p^*")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.8831em","vertical-align":"-0.1944em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"p"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.6887em"}},[e("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mbin mtight"},"âˆ—")])])])])])])])])])]),s(" é‚£ä¹ˆéœ€è¦å¾—åˆ°"),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msup",null,[e("mi",null,"p"),e("mo",null,"âˆ—")])]),e("annotation",{encoding:"application/x-tex"},"p^*")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.8831em","vertical-align":"-0.1944em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"p"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.6887em"}},[e("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mbin mtight"},"âˆ—")])])])])])])])])])]),s("çš„é‚»å±…ï¼Œç„¶åå°±åˆ°ssdä¸­å»æ‘˜å–ï¼Œå¯ä»¥å¾—åˆ°"),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msup",null,[e("mi",null,"p"),e("mo",null,"âˆ—")])]),e("annotation",{encoding:"application/x-tex"},"p^*")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.8831em","vertical-align":"-0.1944em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal"},"p"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.6887em"}},[e("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mbin mtight"},"âˆ—")])])])])])])])])])]),s("çš„å…¨ç²¾åº¦å‘é‡å’Œ å…¶é‚»å±…index ä½†æ˜¯å¹¶æ²¡æœ‰å…¶é‚»å±…çš„vectorï¼Œæ‰€ä»¥ä½¿ç”¨å­˜åœ¨ä¸»å­˜ä¸­çš„codes")]),e("li",null,[s("While reasonable, this requires many rountrips to SSD (which take few hundred microseconds) resulting in higher latencies. To reduce the number of round triprs to SSD (to fetch neighborhoods sequentially) without increasing compute (distance calculations) excessively, we fetch the neighborhoods of a small number, "),e("em",null,"W"),s(" (say 4*,* 8), of the closest points in "),e("em",null,"L \\ V"),s(" in one shot, and update "),e("em",null,"L"),s(" to be the top "),e("em",null,"L"),s(" candidates in "),e("em",null,"L"),s(" along with all the neighbors retrieved in this step.")]),e("li",null,[s("Note that fetching a small number of random sectors from an SSD takes almost the same time as one sector. We refer to this modified search algorithm as BeamSearch. If "),e("em",null,"W"),s(" = 1, this search resembles normal greedy search. Note that if "),e("em",null,"W"),s(" is too large, say 16 or more, then both compute and SSD bandwidth could be wasted.è¿™ä¸ªçš„æ„æ€ æ˜¯æŒ‡ å†å¯¹å€™é€‰é˜Ÿåˆ—é‡Œé¢çš„ç‚¹è¿›è¡Œè·å–çš„æ—¶å€™å—ï¼Ÿï¼Ÿï¼Ÿ")])],-1),U=l('<figure><img src="'+w+'" alt="figure2" tabindex="0" loading="lazy"><figcaption>figure2</figcaption></figure><figure><img src="'+b+'" alt="figure3" tabindex="0" loading="lazy"><figcaption>figure3</figcaption></figure><ul><li>è™½ç„¶åŸºäº NAND é—ªå­˜çš„å›ºæ€ç¡¬ç›˜æ¯ç§’å¯æä¾› 500K+ éšæœºè¯»å–ï¼Œä½†è¦è·å¾—æœ€å¤§è¯»å–ååé‡ï¼Œæ‰€æœ‰ I/O è¯·æ±‚é˜Ÿåˆ—éƒ½å¿…é¡»è¾¾åˆ°é¥±å’ŒçŠ¶æ€ã€‚ç„¶è€Œï¼Œåœ¨é˜Ÿåˆ—ç§¯å‹çš„æƒ…å†µä¸‹ä»¥å³°å€¼ååé‡è¿è¡Œï¼Œä¼šå¯¼è‡´ç£ç›˜è¯»å–å»¶è¿Ÿè¶…è¿‡ä¸€æ¯«ç§’ã€‚å› æ­¤ï¼Œæœ‰å¿…è¦ä»¥è¾ƒä½çš„è´Ÿè½½ç‡è¿è¡Œå›ºæ€ç¡¬ç›˜ï¼Œä»¥è·å¾—è¾ƒä½çš„æœç´¢å»¶è¿Ÿã€‚æˆ‘ä»¬å‘ç°ï¼Œä»¥è¾ƒä½çš„æ³¢æŸå®½åº¦ï¼ˆå¦‚ W = 2ã€4ã€8ï¼‰è¿è¡Œï¼Œå¯ä»¥åœ¨å»¶è¿Ÿå’Œååé‡ä¹‹é—´å–å¾—è‰¯å¥½çš„å¹³è¡¡ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå›ºæ€ç¡¬ç›˜çš„è´Ÿè½½ç‡åœ¨ 30 - 40% ä¹‹é—´ï¼Œè¿è¡Œæœç´¢ç®—æ³•çš„æ¯ä¸ªçº¿ç¨‹åœ¨ I/O ä¸­èŠ±è´¹çš„æŸ¥è¯¢å¤„ç†æ—¶é—´åœ¨ 40 - 50% ä¹‹é—´ã€‚</li><li>Although NAND-flash based SSDs can serve 500K+ random reads per second, extracting mimaxmum read throughput requires saturating all I/O request queues. However, operating at peak throughput with backlogged queues results in disk read latencies of over a millisecond. Therefore, it is necessary to operate the SSD at a lower load factor to obtain low search latency. We have found that operating at low beam widths (e.g., <em>W</em> = 2*,* 4*,* 8) can strike a good balance between latency and throughput.</li><li>In this setting, the load factor on the SSD is between 30 <em>âˆ’</em> 40% and each thread running our search algorithm spends between 40 <em>âˆ’</em> 50% of the query processing time in I/O.</li></ul><h3 id="_3-4-diskanncaching-frequently-visited-vertices" tabindex="-1"><a class="header-anchor" href="#_3-4-diskanncaching-frequently-visited-vertices" aria-hidden="true">#</a> 3.4 DiskANNCaching Frequently Visited Vertices</h3><ul><li>ä¸ºäº†è¿›ä¸€æ­¥å‡å°‘æ¯ä¸ªæŸ¥è¯¢çš„ç£ç›˜è®¿é—®æ¬¡æ•°ï¼Œæˆ‘ä»¬åœ¨åŠ¨æ€éšæœºå­˜å–å­˜å‚¨å™¨ï¼ˆDRAMï¼‰ä¸­ç¼“å­˜ä¸ä¸€éƒ¨åˆ†é¡¶ç‚¹ç›¸å…³çš„æ•°æ®ï¼Œè¦ä¹ˆåŸºäºå·²çŸ¥çš„æŸ¥è¯¢åˆ†å¸ƒï¼Œè¦ä¹ˆç®€å•åœ°é€šè¿‡ç¼“å­˜æ‰€æœ‰è·ç¦»èµ·å§‹ç‚¹ä¸º C=3 æˆ– 4 æ­¥çš„é¡¶ç‚¹ã€‚ç”±äºç´¢å¼•å›¾ä¸­è·ç¦» C å¤„çš„èŠ‚ç‚¹æ•°é‡éšç€ C å‘ˆæŒ‡æ•°å¢é•¿ï¼Œè¾ƒå¤§çš„ C å€¼ä¼šå¯¼è‡´è¿‡å¤§çš„å†…å­˜å ç”¨ã€‚</li><li>To further reduce the number of disk accesses per query, we cache the data associated with a subset of vertices in DRAM, either based on a known query distribution, or simply by caching all vertices that are <em>C</em> = 3 or 4 hops from the starting point <em>s</em>.</li><li>Since the number of nodes in the index graph at distance <em>C</em> grows exponentially with <em>C</em>, larger values of <em>C</em> incur excessively large memory footprint.</li></ul><h3 id="_3-5-diskannimplicit-re-ranking-using-full-precision-vectors" tabindex="-1"><a class="header-anchor" href="#_3-5-diskannimplicit-re-ranking-using-full-precision-vectors" aria-hidden="true">#</a> 3.5 DiskANNImplicit Re-Ranking Using Full-Precision Vectors</h3><ul><li>ç”±äºä¹˜ç§¯é‡åŒ–æ˜¯ä¸€ç§æœ‰æŸå‹ç¼©æ–¹æ³•ï¼Œä½¿ç”¨åŸºäºä¹˜ç§¯é‡åŒ–çš„è¿‘ä¼¼è·ç¦»è®¡ç®—å‡ºçš„ä¸æŸ¥è¯¢æœ€æ¥è¿‘çš„ k ä¸ªå€™é€‰è€…ä¸ä½¿ç”¨å®é™…è·ç¦»è®¡ç®—å‡ºçš„ä¹‹é—´å­˜åœ¨å·®å¼‚ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸ºæ¯ä¸ªç‚¹åœ¨ç£ç›˜ä¸Šå…¶é‚»åŸŸæ—è¾¹å­˜å‚¨çš„å…¨ç²¾åº¦åæ ‡ã€‚å®é™…ä¸Šï¼Œå½“æˆ‘ä»¬åœ¨æœç´¢è¿‡ç¨‹ä¸­æ£€ç´¢ä¸€ä¸ªç‚¹çš„é‚»åŸŸæ—¶ï¼Œæˆ‘ä»¬ä¹Ÿä¼šæ£€ç´¢è¯¥ç‚¹çš„å…¨åæ ‡ï¼Œè€Œä¸ä¼šäº§ç”Ÿé¢å¤–çš„ç£ç›˜è¯»å–ã€‚è¿™æ˜¯å› ä¸ºï¼Œå°† 4KB å¯¹é½çš„ç£ç›˜åœ°å€è¯»å…¥å†…å­˜å¹¶ä¸æ¯”è¯»å– 512B æ›´æ˜‚è´µï¼Œå¹¶ä¸”ä¸€ä¸ªé¡¶ç‚¹çš„é‚»åŸŸï¼ˆå¯¹äº 128 åº¦çš„å›¾ä¸º 4*128 å­—èŠ‚é•¿ï¼‰å’Œå…¨ç²¾åº¦åæ ‡å¯ä»¥å­˜å‚¨åœ¨åŒä¸€ä¸ªç£ç›˜æ‰‡åŒºä¸Šã€‚å› æ­¤ï¼Œå½“BeamSearcåŠ è½½æœç´¢å‰æ²¿çš„é‚»åŸŸæ—¶ï¼Œå®ƒä¹Ÿå¯ä»¥ç¼“å­˜æœç´¢è¿‡ç¨‹ä¸­è®¿é—®çš„æ‰€æœ‰èŠ‚ç‚¹çš„å…¨ç²¾åº¦åæ ‡ï¼Œè€Œæ— éœ€å¯¹å›ºæ€ç¡¬ç›˜è¿›è¡Œé¢å¤–çš„è¯»å–ã€‚è¿™ä½¿å¾—æˆ‘ä»¬èƒ½å¤Ÿæ ¹æ®å…¨ç²¾åº¦å‘é‡è¿”å›å‰ k ä¸ªå€™é€‰è€…ã€‚ä¸æˆ‘ä»¬çš„å·¥ä½œæ— å…³ï¼Œåœ¨å›ºæ€ç¡¬ç›˜ä¸Šè·å–å’Œé‡æ–°æ’åºå­˜å‚¨çš„å…¨ç²¾åº¦åæ ‡çš„æƒ³æ³•ä¹Ÿåœ¨[24]ä¸­ä½¿ç”¨ï¼Œä½†è¯¥ç®—æ³•ä¸€æ¬¡æ€§è·å–æ‰€æœ‰å‘é‡è¿›è¡Œé‡æ–°æ’åºï¼Œè¿™å°†å¯¼è‡´ä¸€æ¬¡æ€§è¿›è¡Œæ•°ç™¾æ¬¡éšæœºç£ç›˜è®¿é—®ï¼Œåè¿‡æ¥åˆä¼šå¯¹ååé‡å’Œå»¶è¿Ÿäº§ç”Ÿä¸åˆ©å½±å“ã€‚æˆ‘ä»¬åœ¨ç¬¬ 4.3 èŠ‚ä¸­æä¾›äº†æ›´è¯¦ç»†çš„è§£é‡Šã€‚åœ¨æˆ‘ä»¬çš„æƒ…å†µä¸‹ï¼Œå…¨ç²¾åº¦åæ ‡åŸºæœ¬ä¸Šæ˜¯é™„å¸¦åœ¨æ‰©å±•é‚»åŸŸçš„æˆæœ¬ä¸Šã€‚</li><li>Since Product Quantization is a lossy compression method, there is a discrepancy between the closest <em>k</em> candidates to the query computed using PQ-based approximate distances and using the actual distances. To bridge this gap, we use <em>full-precision coordinates</em> stored for each point next to its neighborhood on the disk.</li><li>In fact, when we retrieve the neighborhood of a point during search, we also retrieve the full coordinates of the point without incurring extra disk reads. This is because, reading 4<em>KB</em>-aligned disk address into memory is no more expensive than reading 512<em>B</em>, and the neighborhood of a vertex (4 * 128 bytes long for degree 128 graphs) and full-precision coordinates can be stored on the same disk sector.</li><li>Hence, as BeamSearch loads neighborhoods of the search frontier, it can also cache full-precision coordinates of all the nodes visited during the search process, using no extra reads to the SSD. This allows us to return the top <em>k</em> candidates based on the full precision vectors. Independent of our work, the idea of fetching and re-ranking full-precision coordinates stored on the SSD is also used in [24], but the algorithm fetches all the vectors to re-rank in one shot, which would result in hundreds of random disk accesses all in one shot, in turn adversely affecting throughput and latency. We provide a more detailed explanation in Section 4.3. In our case, full precision coordinates <em>essentially piggyback</em> on the cost of expanding the neighborhoods.</li></ul><h2 id="_4-evaluation" tabindex="-1"><a class="header-anchor" href="#_4-evaluation" aria-hidden="true">#</a> 4 Evaluation</h2><ul><li><p>ç°åœ¨æˆ‘ä»¬å°†Vamanaä¸å…¶ä»–ç”¨äºè¿‘ä¼¼æœ€è¿‘é‚»æœç´¢çš„ç›¸å…³ç®—æ³•è¿›è¡Œæ¯”è¾ƒã€‚é¦–å…ˆï¼Œå¯¹äºå†…å­˜ä¸­æœç´¢ï¼Œæˆ‘ä»¬å°†æˆ‘ä»¬çš„ç®—æ³•ä¸ NSG[13]å’Œ HNSW[21]è¿›è¡Œæ¯”è¾ƒï¼Œå®ƒä»¬åœ¨å¤§å¤šæ•°å…¬å…±åŸºå‡†æ•°æ®é›†ä¸Šæä¾›äº†åŒç±»æœ€ä½³çš„å»¶è¿Ÿä¸å¬å›ç‡æƒè¡¡ã€‚æ¥ä¸‹æ¥ï¼Œå¯¹äºæ•°åäº¿ç‚¹çš„å¤§å‹æ•°æ®é›†ï¼Œæˆ‘ä»¬å°† DiskANN ä¸åŸºäºå‹ç¼©çš„æŠ€æœ¯å¦‚ FAISS[18]å’Œ IVF-OADC+G+P[8]è¿›è¡Œæ¯”è¾ƒã€‚</p></li><li><p>We now compare Vamana with other relevant algorithms for approximate nearest neighbor search. First, for in-memory search, we compare our algorithm with NSG [13] and HNSW [21], which offer best-in-class latency vs recall on most public benchmark datasets.</p></li><li><p>Next, for large billion point datasets, we compare DiskANN with compression based techniques such as FAISS [18] and IVF-OADC+G+P [8].</p></li><li><p>We use the following two machines for all experiments.</p><ul><li>z840ï¼šä¸€æ¬¾è£¸é‡‘å±ä¸­ç«¯å·¥ä½œç«™ï¼Œé…å¤‡åŒè‡³å¼º E5-2620v4 å¤„ç†å™¨ï¼ˆ16 æ ¸ï¼‰ã€64GB DDR4 å†…å­˜ä»¥åŠä¸¤å—ä¸‰æ˜Ÿ 960 EVO 1TB å›ºæ€ç¡¬ç›˜ï¼Œé‡‡ç”¨ RAID-0 é…ç½®ã€‚</li><li>M64-32msï¼šä¸€å°å…·æœ‰åŒè‡³å¼º E7-8890v3sï¼ˆ32 ä¸ªè™šæ‹Ÿ CPUï¼‰å’Œ 1792GB DDR3 å†…å­˜çš„è™šæ‹Ÿæœºï¼Œæˆ‘ä»¬ç”¨å®ƒæ¥ä¸ºåäº¿ç‚¹æ•°æ®é›†æ„å»ºä¸€æ¬¡æ€§çš„å†…å­˜ç´¢å¼•ã€‚</li></ul></li></ul><h3 id="_4-1-comparison-of-hnsw-nsg-and-vamanafor-in-memory-search-performance" tabindex="-1"><a class="header-anchor" href="#_4-1-comparison-of-hnsw-nsg-and-vamanafor-in-memory-search-performance" aria-hidden="true">#</a> 4.1 Comparison of HNSW, NSG and Vamanafor In-Memory Search Performance</h3>',10),X=e("ul",null,[e("li",null,[e("p",null,"æˆ‘ä»¬åœ¨ä¸‰ä¸ªå¸¸ç”¨çš„å…¬å…±åŸºå‡†ä¸Šæ¯”è¾ƒäº†Vamanaä¸ HNSW å’Œ NSGï¼šSIFT1Mï¼ˆ128 ç»´ï¼‰å’Œ GIST1Mï¼ˆ960 ç»´ï¼‰ï¼Œè¿™ä¸¤ä¸ªéƒ½æ˜¯å›¾åƒæè¿°ç¬¦çš„ç™¾ä¸‡ç‚¹æ•°æ®é›†[1]ï¼Œä»¥åŠ DEEP1Mï¼ˆ96 ç»´ï¼‰ï¼Œè¿™æ˜¯ DEEP1B çš„ä¸€ä¸ªéšæœºçš„ä¸€ç™¾ä¸‡å¤§å°æ ·æœ¬ï¼ŒDEEP1B æ˜¯ä¸€ä¸ªæœºå™¨å­¦ä¹ å¾—åˆ°çš„åäº¿ä¸ªå‘é‡çš„é›†åˆ[6]ã€‚å¯¹äºæ‰€æœ‰è¿™ä¸‰ç§ç®—æ³•ï¼Œæˆ‘ä»¬è¿›è¡Œäº†å‚æ•°æ‰«æï¼Œå¹¶ä¸ºæœ€ä½³å¬å›ç‡ä¸å»¶è¿Ÿçš„æƒè¡¡é€‰æ‹©äº†æ¥è¿‘æœ€ä¼˜çš„å‚æ•°é€‰æ‹©ã€‚æ‰€æœ‰ HNSW ç´¢å¼•éƒ½æ˜¯ä½¿ç”¨ M=128ï¼ŒefC=512 æ„å»ºçš„ï¼Œè€ŒVamanaç´¢å¼•ä½¿ç”¨ R=70ï¼ŒL=75ï¼ŒÎ±=1.2ã€‚å¯¹äº SIFT1M å’Œ GIST1M ä¸Šçš„ NSGï¼Œç”±äºå…¶å‡ºè‰²çš„æ€§èƒ½ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä»–ä»¬å­˜å‚¨åº“ä¸­åˆ—å‡ºçš„å‚æ•° 5ï¼Œå¯¹äº DEEP1Mï¼Œæˆ‘ä»¬ä½¿ç”¨ R=60ï¼ŒL=70ï¼ŒC=500ã€‚æ­¤å¤–ï¼Œç”±äºè¿™é¡¹å·¥ä½œçš„ä¸»è¦é‡ç‚¹æ˜¯åŸºäºå›ºæ€ç¡¬ç›˜çš„æœç´¢ï¼Œæˆ‘ä»¬æ²¡æœ‰å®ç°æˆ‘ä»¬è‡ªå·±çš„å†…å­˜ä¸­æœç´¢ç®—æ³•æ¥æµ‹è¯•Vamanaã€‚ç›¸åï¼Œæˆ‘ä»¬åªæ˜¯åœ¨Vamanaç”Ÿæˆçš„ç´¢å¼•ä¸Šä½¿ç”¨äº† NSG å­˜å‚¨åº“ä¸­ä¼˜åŒ–åçš„æœç´¢ç®—æ³•çš„å®ç°ã€‚ä»å›¾ 3 ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸€ä¸ªæ˜æ˜¾çš„è¶‹åŠ¿â€”â€”åœ¨æ‰€æœ‰æƒ…å†µä¸‹ï¼ŒNSG å’ŒVamanaçš„æ€§èƒ½éƒ½ä¼˜äº HNSWï¼Œå¹¶ä¸”åœ¨ 960 ç»´çš„ GIST1M æ•°æ®é›†ä¸Šï¼ŒVamanaçš„æ€§èƒ½ä¼˜äº NSG å’Œ HNSW ä¸¤è€…ã€‚æ­¤å¤–ï¼Œåœ¨æ‰€æœ‰ä¸‰ä¸ªå®éªŒä¸­ï¼ŒVamanaçš„ç´¢å¼•æ„å»ºæ—¶é—´éƒ½ä¼˜äº HNSW å’Œ NSGã€‚ä¾‹å¦‚ï¼Œåœ¨ z840 ä¸Šå¯¹ DEEP1M è¿›è¡Œç´¢å¼•æ„å»ºæ—¶ï¼ŒVamanaã€HNSW å’Œ NSG6 çš„æ€»ç´¢å¼•æ„å»ºæ—¶é—´åˆ†åˆ«ä¸º 129 ç§’ã€219 ç§’å’Œ 480 ç§’ã€‚ä»è¿™äº›å®éªŒä¸­ï¼Œæˆ‘ä»¬å¾—å‡ºç»“è®ºï¼ŒVamanaåœ¨ä»ä¸åŒæ¥æºè·å¾—çš„æ•°ç™¾ç»´å’Œæ•°åƒç»´æ•°æ®é›†ä¸Šä¸å½“å‰æœ€å¥½çš„è¿‘ä¼¼æœ€è¿‘é‚»æ–¹æ³•ç›¸åŒ¹é…ï¼Œæœ‰æ—¶ç”šè‡³è¡¨ç°æ›´ä¼˜ã€‚")]),e("li",null,[e("p",null,"We compared Vamana with HNSW and NSG on three commonly used public benchmarks: SIFT1M (128-dimensions) and GIST1M (960-dimensions), both of which are million point datasets of image descriptors [1], and DEEP1M (96-dimensions), a random one million size sample of DEEP1B, a machine-learned set of one billion vectors [6].")]),e("li",null,[e("p",null,"For all three algorithms, we did a parameter sweep and selected near-optimal choice of parameters for the best recall vs latency trade-off.")]),e("li",null,[e("p",null,[s("All HNSW indices were constructed using "),e("em",null,"M"),s(" = 128, "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mi",null,"e"),e("msub",null,[e("mi",null,"f"),e("mi",null,"C")])]),e("annotation",{encoding:"application/x-tex"},"ef_C")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.8889em","vertical-align":"-0.1944em"}}),e("span",{class:"mord mathnormal"},"e"),e("span",{class:"mord"},[e("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t vlist-t2"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.3283em"}},[e("span",{style:{top:"-2.55em","margin-left":"-0.1076em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.07153em"}},"C")])])]),e("span",{class:"vlist-s"},"â€‹")]),e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.15em"}},[e("span")])])])])])])])]),s(" = 512, while Vamana indices used "),e("em",null,"R"),s(" = 70*, L* = 75*, Î±* = 1*."),e("em",null,[s("2. For NSG on SIFT1M and GIST1M, we use the parameters listed on their repository due to their excellent performance, and used "),e("em",null,"R"),s(" = 60")]),s(", L* = 70*, C* = 500 for DEEP1M.")])]),e("li",null,[e("p",null,"Moreover, since the main focus of this work is on the SSD-based search, we did not implement our own in-mmeory search"),e("p",null,"algorithm to test Vamana. Instead, we simply used the implementation of the optimized search algorithm on the NSG repository, on the indices generated by Vamana. è¿™é‡Œå°±æ˜¯è¯´åœ¨æµ‹è¯•vamanaçš„æ—¶å€™åœ¨å¯¹æ¯”å†…å­˜çš„ç®—æ³•çš„æ—¶å€™ï¼Œå…¶å»ºå›¾çš„æ—¶å€™ä»¥åŠæœç´¢çš„æ—¶å€™æ¶‰åŠåˆ°çš„searchéƒ½æ˜¯ç”¨åˆ°çš„nsgçš„ï¼Œå¹¶ä¸”å¯èƒ½å»ºå›¾çš„æ—¶å€™å°±æ˜¯ä½¿ç”¨äº† é€‰è¾¹ç­–ç•¥ä¸ä¸€æ ·ï¼›")]),e("li",null,[e("p",null,"From Figure 3, we can see one clear trend â€“ NSG and Vamana out-perform HNSW in all instances, and on the 960-dimensional"),e("p",null,"GIST1M dataset, Vamana outperforms both NSG and HNSW. Moreover, the indexing time of Vamana was better than both HNSW and NSG in all three experiments.")]),e("li",null,[e("p",null,"For example, when indexing DEEP1M on z840, the total index construction times were 129s, 219s, and 480s for Vamana, HNSW"),e("p",null,"and NSG6 respectively. From these experiments, we conclude that Vamana matches, and sometimes outperforms, the current best ANNS methods on both hundred and thousand-dimensional datasets obtained from different sources.")])],-1),Z=l('<h3 id="_4-2-comparison-of-hnsw-nsg-andvamanafor-number-of-hops" tabindex="-1"><a class="header-anchor" href="#_4-2-comparison-of-hnsw-nsg-andvamanafor-number-of-hops" aria-hidden="true">#</a> 4.2 Comparison of HNSW, NSG andVamanafor Number of Hops</h3><ul><li>Vamanaæ¯”å…¶ä»–åŸºäºå›¾çš„ç®—æ³•æ›´é€‚åˆåŸºäºå›ºæ€ç¡¬ç›˜çš„æœåŠ¡ï¼Œå› ä¸ºä¸ HNSW å’Œ NSG ç›¸æ¯”ï¼Œåœ¨å¤§å‹æ•°æ®é›†ä¸­ï¼Œå®ƒä¸ºäº†ä½¿æœç´¢æ”¶æ•›è€Œè¿›è¡Œçš„è·³æ•°è¦å°‘ 2 åˆ° 3 å€ã€‚æ‰€è°“è·³æ•°ï¼Œæˆ‘ä»¬æŒ‡çš„æ˜¯åœ¨æœç´¢å…³é”®è·¯å¾„ä¸Šè¿›è¡Œç£ç›˜è¯»å–çš„è½®æ•°ã€‚åœ¨BeamSearchä¸­ï¼Œå®ƒæ˜ å°„ä¸ºé€šè¿‡è¿›è¡Œ W æ¬¡å¹¶è¡Œç£ç›˜è¯»å–æ¥æ‰©å±•æœç´¢å‰æ²¿çš„æ¬¡æ•°ã€‚è·³æ•°å¾ˆé‡è¦ï¼Œå› ä¸ºå®ƒç›´æ¥å½±å“æœç´¢å»¶è¿Ÿã€‚å¯¹äº HNSWï¼Œæˆ‘ä»¬å‡è®¾é™¤äº†åŸºç¡€å±‚ä¹‹å¤–çš„æ‰€æœ‰å±‚ä¸­çš„èŠ‚ç‚¹éƒ½ç¼“å­˜åœ¨åŠ¨æ€éšæœºå­˜å–å­˜å‚¨å™¨ï¼ˆDRAMï¼‰ä¸­ï¼Œå¹¶ä¸”åªè®¡ç®—åŸºç¡€å±‚å›¾ä¸Šçš„è·³æ•°ã€‚å¯¹äº NSG å’ŒVamanaç´¢å¼•ï¼Œæˆ‘ä»¬å‡è®¾å›´ç»•å¯¼èˆªèŠ‚ç‚¹çš„å‰ 3 å±‚å¹¿åº¦ä¼˜å…ˆæœç´¢ï¼ˆBFSï¼‰çº§åˆ«å¯ä»¥ç¼“å­˜åœ¨ DRAM ä¸­ã€‚åœ¨å›¾ 2(c)ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡æ”¹å˜æœ€å¤§å›¾åº¦æ•°æ¥æ¯”è¾ƒè¾¾åˆ°ç›®æ ‡ 5-recall@5ä¸º 98%æ‰€éœ€çš„è·³æ•°ã€‚æˆ‘ä»¬æ³¨æ„åˆ° HNSW å’Œ NSG éƒ½æœ‰åœæ»è¶‹åŠ¿ï¼Œè€ŒVamanaéšç€æœ€å¤§åº¦æ•°å’ŒÎ±çš„å¢åŠ ï¼Œè·³æ•°å‡å°‘ã€‚ä½¿ç”¨è¾ƒå¤§çš„ R å’ŒÎ±å€¼ä¼šç”±äºå®ƒä»¬èƒ½å¤Ÿæ·»åŠ æ›´å¤šè¿œç¨‹è¾¹è€Œå¯¼è‡´è·³æ•°å‡å°‘ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æ¨æ–­Vamanaåœ¨Î±&gt;1 æ—¶æ¯”å…¶ä»–åŸºäºå›¾çš„æ–¹æ³•èƒ½æ›´å¥½åœ°åˆ©ç”¨å›ºæ€ç¡¬ç›˜æä¾›çš„é«˜å®¹é‡ã€‚</li><li>Vamana is more suitable for SSD-based serving than other graph-based algorithms as it makes 2 <em>âˆ’</em> 3 times fewer hops for search to converge on large datasets compared to HNSW and NSG.</li><li>By hops, we refer to the number of rounds of disk reads on the critical path of the search. In BeamSearch, it maps to the number of times the search frontier is expanded by making <em>W</em> parallel disk reads. The number of hops is important as it directly affects search latency. For HNSW, we assume nodes in all levels excluding the base level are cached in DRAM and only count the number of hops on base-level graph.</li><li>For NSG and Vamana indices, we assume that the first 3 BFS levels around the navigating node(s) can be cached in DRAM. We compare the number of hops required to achieve a target 5-recall@5 of 98% by varying the maximum graph degrees in Figure 2(c). We notice a stagnation trend for both HNSW and NSG, while Vamana shows a reduction in number of hops with increasing max degree and <em>Î±</em>. Using large values of <em>R</em> and <em>Î±</em> result in fewer hops due to their ability to add more long-range edges. We thus infer that Vamana with <em>Î± &gt;</em> 1 makes better use of the high capacity offered by SSDs than other graph-based methods.</li></ul><h3 id="_4-3-comparison-on-billion-scale-datasets-one-shotvamanavs-merged-vamana" tabindex="-1"><a class="header-anchor" href="#_4-3-comparison-on-billion-scale-datasets-one-shotvamanavs-merged-vamana" aria-hidden="true">#</a> 4.3 Comparison on Billion-Scale Datasets: One-ShotVamanavs Merged Vamana</h3>',3),j=e("ul",null,[e("li",null,[e("p",null,"å¯¹äºæˆ‘ä»¬æ¥ä¸‹æ¥çš„ä¸€ç»„å®éªŒï¼Œæˆ‘ä»¬å°†è¯„ä¼°é‡ç‚¹æ”¾åœ¨æ‹¥æœ‰ 10^9 ä¸ªç‚¹çš„ ANN_SIFT1B[1]å¤§å‹æ•°æ®é›†ä¸Šï¼Œè¯¥æ•°æ®é›†æ˜¯ 128 ä¸ªæ— ç¬¦å· 8 ä½æ•´æ•°ç±»å‹çš„ SIFT å›¾åƒæè¿°ç¬¦ã€‚ä¸ºäº†å±•ç¤ºåœ¨ç¬¬ 3 èŠ‚ä¸­æè¿°çš„åˆå¹¶Vamanaæ–¹æ¡ˆçš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨æˆ‘ä»¬çš„Vamanaæ„å»ºäº†ä¸¤ä¸ªç´¢å¼•ã€‚ç¬¬ä¸€ä¸ªæ˜¯åœ¨æ•´ä¸ªåäº¿ç‚¹æ•°æ®é›†ä¸Šå…·æœ‰ L=50ã€R=128ã€Î±=1.2 çš„å•ä¸€ç´¢å¼•ã€‚è¿™ä¸ªè¿‡ç¨‹åœ¨ M64-32ms ä¸Šå¤§çº¦éœ€è¦ 2 å¤©ï¼Œå³°å€¼å†…å­˜ä½¿ç”¨é‡çº¦ä¸º 1100GBï¼Œå¹¶ç”Ÿæˆäº†ä¸€ä¸ªå¹³å‡åº¦æ•°ä¸º 113.9 çš„ç´¢å¼•ã€‚ç¬¬äºŒä¸ªæ˜¯åˆå¹¶ç´¢å¼•ï¼Œå…¶æ„å»ºæ–¹å¼å¦‚ä¸‹ï¼š(1)ä½¿ç”¨ k -meansèšç±»å°†æ•°æ®é›†åˆ’åˆ†ä¸º k=40 ä¸ªåˆ†ç‰‡ï¼Œ(2)å°†æ•°æ®é›†ä¸­çš„æ¯ä¸ªç‚¹å‘é€åˆ°è·ç¦»æœ€è¿‘çš„ 2 ä¸ªåˆ†ç‰‡ï¼Œ(3)ä¸ºæ¯ä¸ªåˆ†ç‰‡æ„å»ºå…·æœ‰ L=50ã€R=64ã€Î±=1.2 çš„ç´¢å¼•ï¼Œ(4)åˆå¹¶æ‰€æœ‰å›¾çš„è¾¹é›†ã€‚ç»“æœæ˜¯ä¸€ä¸ª 348GB çš„ç´¢å¼•ï¼Œå¹³å‡åº¦æ•°ä¸º 92.1ã€‚è¿™äº›ç´¢å¼•æ˜¯åœ¨ z840 ä¸Šæ„å»ºçš„ï¼Œæ•´ä¸ªè¿‡ç¨‹å¤§çº¦éœ€è¦ 5 å¤©ï¼Œå†…å­˜ä½¿ç”¨é‡åœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­ä¿æŒåœ¨ 64GB ä»¥ä¸‹ã€‚åˆ†ç‰‡å’Œåˆå¹¶é€Ÿåº¦å¾ˆå¿«ï¼Œå¹¶ä¸”å¯ä»¥åœ¨åŒä¸€å°æœºå™¨ä¸Šä»ç£ç›˜è¿›è¡Œã€‚")]),e("li",null,[e("p",null,[s("For our next set of experiments, we focus our evaluations on the "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mn",null,"1"),e("msup",null,[e("mn",null,"0"),e("mn",null,"9")])]),e("annotation",{encoding:"application/x-tex"},"10^9")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.8141em"}}),e("span",{class:"mord"},"1"),e("span",{class:"mord"},[e("span",{class:"mord"},"0"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.8141em"}},[e("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mtight"},"9")])])])])])])])])])]),s(" point ANN_SIFT1B [1] "),e("em",null,"bigann"),s(" dataset of SIFT image descriptors of 128 uint8s. To demonstrate the effectiveness of the merged Vamana scheme described in Section 3, we built two indices using our Vamana.")])]),e("li",null,[e("p",null,[s("The first is a "),e("strong",null,"single"),s(),e("strong",null,"index"),s(" with "),e("em",null,"L"),s(" = 50*, R* = 128*, Î±* = 1*."),e("em",null,[s("2 on the full billion-point dataset. This procedure takes about 2 days on M64-32 with a peak memory usage at "),e("em",null,"â‰ˆ"),s("1100GB, and generates an index with an average degree of 113")]),s(".*9.")])]),e("li",null,[e("p",null,[s("The second is the "),e("strong",null,"merged"),s(" index, which is constructed as follows:")]),e("ul",null,[e("li",null,[s("(1) partition the dataset into "),e("em",null,"k"),s(" = 40 shards using k-means clustering,")]),e("li",null,[s("(2) send each point in the dataset to the "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msup",null,[e("mi",null,"l"),e("mo",null,"âˆ—")])]),e("annotation",{encoding:"application/x-tex"},"l^*")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.6944em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.6887em"}},[e("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mbin mtight"},"âˆ—")])])])])])])])])])]),s("= 2closest shards,")]),e("li",null,[s("(3) build indices for each shard with "),e("em",null,"L"),s(" = 50*, R* = 64*, Î±* = 1*.*2, and")]),e("li",null,"(4) merge the edge sets of all the graphs. The result is a 348GB index with an average degree of 92*.*1. The indices were built on z480 and took about 5 days with memory usage remaining under 64GB for the entire process. Sharding and merging are fast and can be done on the same machine from the disk.")])]),e("li",null,[e("p",null,[s("åœ¨å›¾ 2(a)ä¸­ï¼Œæˆ‘ä»¬é’ˆå¯¹è¿™ä¸¤ç§é…ç½®æ¯”è¾ƒäº†1-recall@1 ä¸å»¶è¿Ÿä»¥åŠ 10,000 ä¸ªæŸ¥è¯¢å¤§å‹æ•°æ®é›†ã€‚ä»è¿™ä¸ªå®éªŒæˆ‘ä»¬å¾—å‡ºä»¥ä¸‹ç»“è®ºã€‚(a)å•ä¸€ç´¢å¼•çš„æ€§èƒ½ä¼˜äºåˆå¹¶ç´¢å¼•ï¼Œå› ä¸ºåˆå¹¶ç´¢å¼•è¦éå†æ›´å¤šé“¾æ¥æ‰èƒ½åˆ°è¾¾ç›¸åŒçš„é‚»åŸŸï¼Œä»è€Œå¢åŠ äº†æœç´¢å»¶è¿Ÿã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºåˆå¹¶ç´¢å¼•ä¸­æ¯ä¸ªèŠ‚ç‚¹çš„å…¥è¾¹å’Œå‡ºè¾¹è¢«é™åˆ¶åœ¨å¤§çº¦æ‰€æœ‰ç‚¹çš„"),e("code",null,"l/k=5%ã€‚(b)å¯¹äºåäº¿è§„æ¨¡çš„ k-æœ€è¿‘é‚»ç´¢å¼•ç¼–åˆ¶å’ŒæœåŠ¡å•ä¸ªèŠ‚ç‚¹ï¼Œåˆå¹¶ç´¢å¼•ä»ç„¶æ˜¯ä¸€ä¸ªéå¸¸å¥½çš„é€‰æ‹©ï¼Œå®ƒè½»æ¾è¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œå¹¶ä¸”ä¸å•ä¸€ç´¢å¼•ç›¸æ¯”ï¼Œåœ¨ç›®æ ‡å¬å›ç‡æ–¹é¢æ‰€éœ€çš„é¢å¤–å»¶è¿Ÿä¸è¶…è¿‡ 20%ã€‚å¦ä¸€æ–¹é¢ï¼Œå•ä¸€ç´¢å¼•åœ¨å»¶è¿Ÿå°äº 5 æ¯«ç§’çš„æƒ…å†µä¸‹å®ç°äº†æ–°çš„æœ€å…ˆè¿›çš„ 1 å¬å›ç‡@1 ä¸º 98.68%ã€‚åˆå¹¶ç´¢å¼•å¯¹äº DEEP1B æ•°æ®é›†ä¹Ÿæ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ã€‚å›¾ 2(b)å±•ç¤ºäº†åœ¨ z840 æœºå™¨ä¸Šä½¿ç”¨ k=40 ä¸ªåˆ†ç‰‡å’Œ"),s("l=2 æ„å»ºçš„ DEEP1B æ•°æ®é›†çš„åˆå¹¶ DiskANN ç´¢å¼•çš„å¬å›ç‡ä¸å»¶è¿Ÿæ›²çº¿ã€‚")])]),e("li",null,[e("p",null,[s("We compare 1-recall@1 vs latency with the 10,000 query "),e("em",null,"bigann"),s(" dataset for both configurations in Figure 2(a). From this experiment we conclude the following.")]),e("ul",null,[e("li",null,[s("(a) The "),e("strong",null,"single"),s(" index outperforms the "),e("strong",null,"merged"),s(" index, which traverses more links to reach the same neighborhood, thus increasing search latency. This could possibly be because the in- and out-edges of each node in the "),e("strong",null,"merged"),s(" index are limited to about "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msup",null,[e("mi",null,"l"),e("mo",null,"âˆ—")]),e("mi",{mathvariant:"normal"},"/"),e("mi",null,"k")]),e("annotation",{encoding:"application/x-tex"},"l^* / k")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.6887em"}},[e("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mbin mtight"},"âˆ—")])])])])])])]),e("span",{class:"mord"},"/"),e("span",{class:"mord mathnormal",style:{"margin-right":"0.03148em"}},"k")])])]),s(" = 5% of all points.")]),e("li",null,[s("(b) The "),e("strong",null,"merged"),s(" index is still a very good choice for billion scale k-ANN indexing and serving single-node, easily outperforming the existing state-of-the-art methods and requires no more than 20% extra latency for a target recall when compared to the "),e("strong",null,"single"),s(" index. The "),e("strong",null,"single"),s(" index, on the other hand, achieves a new state-of-the-art 1-recall@1 of 98*.*68% with <5 milliseconds latency. The merged index is also a good choice for the DEEP1B dataset. Figure 2(b) shows the recall vs latency curve of the merged DiskANN index for the DEEP1B dataset built using "),e("em",null,"k"),s(" = 40 shards and "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msup",null,[e("mi",null,"l"),e("mo",null,"âˆ—")])]),e("annotation",{encoding:"application/x-tex"},"l^*")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.6944em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.6887em"}},[e("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mbin mtight"},"âˆ—")])])])])])])])])])]),s("= 2 on the z480 machine.")])])])],-1),$=e("h3",{id:"_4-4-comparison-on-billion-scale-datasets-diskann-vs-ivf-based-methods",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_4-4-comparison-on-billion-scale-datasets-diskann-vs-ivf-based-methods","aria-hidden":"true"},"#"),s(" 4.4 Comparison on Billion-Scale Datasets: DiskANN vs IVF-based Methods")],-1),Y=e("ul",null,[e("li",null,[e("p",null,"æˆ‘ä»¬æœ€åçš„æ¯”è¾ƒæ˜¯FAISS[18]å’ŒIVFOADC+G+P[7]ï¼Œè¿™æ˜¯ä¸¤ç§æœ€è¿‘åœ¨å•ä¸ªèŠ‚ç‚¹ä¸Šæ„å»ºåäº¿ä¸ªç‚¹æŒ‡æ•°çš„æ–¹æ³•ã€‚è¿™ä¸¤ç§æ–¹æ³•éƒ½åˆ©ç”¨å€’ç½®ç´¢å¼•å’ŒåŸºäºäº§å“é‡åŒ–(PQ)çš„å‹ç¼©æ–¹æ¡ˆæ¥å¼€å‘å…·æœ‰ä½å†…å­˜å ç”¨çš„ç´¢å¼•ï¼Œå¯ä»¥æœåŠ¡äºå…·æœ‰é«˜ååé‡å’Œè‰¯å¥½çš„1-recall@100çš„æŸ¥è¯¢ã€‚æˆ‘ä»¬å°†DiskANNä¸ä»…IVFOADC+G+Pè¿›è¡Œæ¯”è¾ƒï¼Œå› ä¸º[7]å¯¹IVFOADC+G+Pçš„å¬å›ç‡ä¼˜äºFAISSï¼Œè€Œä¸”ï¼Œæ­¤å¤–ï¼Œä½¿ç”¨ FAISS è¿›è¡Œåäº¿è§„æ¨¡çš„ç´¢å¼•éœ€è¦ GPUï¼Œè€ŒæŸäº›å¹³å°å¯èƒ½æ²¡æœ‰ GPUã€‚")]),e("li",null,[e("p",null,"Our final comparisons are with FAISS[18] and IVFOADC+G+P[7], two recent approaches to constructing billion point indices on a single node. Both methods utilize Inverted Indexing and Product Quantization-based compression schemes to develop indices with low-memory footprint that can serve queries with high-throughput and good 1-recall@100. We compare DiskANN with only IVFOADC+G+P since [7] demonstrates superior recall for IVFOADC+G+P over FAISS, and moreover, billion-scale indexing using FAISS requires GPUs that might not be available in some platforms.")]),e("li",null,[e("p",null,"IVFOADC+G+P ä½¿ç”¨ HNSW ä½œä¸ºè·¯ç”±å±‚æ¥è·å¾—ä¸€å°ç»„ç°‡ï¼Œè¿™äº›ç°‡ä½¿ç”¨ä¸€ç§æ–°é¢–çš„åˆ†ç»„å’Œä¿®å‰ªç­–ç•¥è¿›ä¸€æ­¥ç»†åŒ–ã€‚ä½¿ç”¨ä»–ä»¬çš„å¼€æºä»£ç ï¼Œæˆ‘ä»¬åœ¨ SIFT1B åŸºç¡€æ•°æ®é›†ä¸Šæ„å»ºå…·æœ‰ 16 å­—èŠ‚å’Œ 32 å­—èŠ‚ OPQ ç æœ¬çš„ç´¢å¼•ã€‚å›¾ 2(a)ä¸­çš„ IVFOADC+G+P-16 å’Œ IVFOADC+G+P-32 æ›²çº¿ä»£è¡¨è¿™ä¸¤ç§é…ç½®ã€‚è™½ç„¶ IVFOADC+G+P-16 åœ¨ 1-recall@1è¾¾åˆ° 37.04%æ—¶è¶‹äºå¹³ç¨³ï¼Œä½†è¾ƒå¤§çš„ IVFOADC+G+P-32 ç´¢å¼•åœ¨ 1-recall@1 è¾¾åˆ° 62.74%ã€‚åœ¨ä¸ IVFOADC+G+P-32 ç›¸åŒçš„å†…å­˜å ç”¨æƒ…å†µä¸‹ï¼ŒDiskANN åœ¨å®Œç¾çš„1-recall@1 è¾¾åˆ° 100%æ—¶è¾¾åˆ°é¥±å’Œï¼ŒåŒæ—¶åœ¨ä¸åˆ° 3.5 æ¯«ç§’å†…æä¾›è¶…è¿‡ 95%çš„ 1-recall@1ã€‚å› æ­¤ï¼ŒDiskANN åœ¨ä¸åŸºäºå‹ç¼©çš„æ–¹æ³•åŒ¹é…å†…å­˜å ç”¨çš„åŒæ—¶ï¼Œèƒ½å¤Ÿåœ¨ç›¸åŒå»¶è¿Ÿä¸‹å®ç°æ˜¾è‘—æ›´é«˜çš„å¬å›ç‡ã€‚åŸºäºå‹ç¼©çš„æ–¹æ³•ç”±äºå¯¹åæ ‡è¿›è¡Œæœ‰æŸå‹ç¼©å¯¼è‡´ç²¾åº¦æŸå¤±ï¼Œä»è€Œå¯¼è‡´è·ç¦»è®¡ç®—ç•¥æœ‰ä¸å‡†ç¡®ï¼Œå› æ­¤æä¾›è¾ƒä½çš„å¬å›ç‡ã€‚")]),e("li",null,[e("p",null,[s("IVFOADC+G+P uses HNSW as a "),e("em",null,"routing"),s(" layer to obtain a small set of clusters that are further refined using a novel grouping and pruning strategy. Using their open-source code, we build indices with 16 and 32-byte OPQ code-books on the SIFT1B base set. IVFOADC+G+P-16 and IVFOADC+G+P-32 curves in 2(a) represent the two configurations.")])]),e("li",null,[e("p",null,[s("While IVFOADC+G+P-16 plateaus at 1-recall@1 of 37*."),e("em",null,"04%, the larger IVFOADC+G+P-32 indices reach 1-recall@1 at 62"),s("."),e("em",null,"74%. With the same memory footprint as IVFOADC+G+P-32, DiskANN saturates at a perfect 1-recall@1 of 100%, while providing 1-recall@1 of above 95% in under 3"),s(".*5ms. Thus DiskANN, while matching the memory footprint of compression-based methods, can achieve significantly higher recall at the same latency. Compression-based methods provide low recall due to loss of precision from lossy")]),e("p",null,"compression of coordinates which results in slightly inaccurate distance calculations.")]),e("li",null,[e("p",null,"Zoom[24]æ˜¯ä¸€ç§åŸºäºå‹ç¼©çš„æ–¹æ³•ï¼Œä¸ IVFOADC+G+P ç±»ä¼¼ï¼Œå®ƒåˆ©ç”¨å‹ç¼©å‘é‡æ¥ç¡®å®šè¿‘ä¼¼çš„æœ€è¿‘çš„ K'ï¼ˆK'ï¼Kï¼‰ä¸ªå€™é€‰è€…ï¼Œç„¶åé€šè¿‡ä»ç£ç›˜è·å–å…¨ç²¾åº¦åæ ‡å¯¹å®ƒä»¬è¿›è¡Œé‡æ–°æ’åºï¼Œä»¥è¾“å‡ºæœ€ç»ˆçš„ K ä¸ªå€™é€‰è€…é›†åˆã€‚ç„¶è€Œï¼ŒZoom å­˜åœ¨ä¸¤ä¸ªç¼ºç‚¹ï¼šï¼ˆaï¼‰å®ƒé€šè¿‡åŒæ—¶è¿›è¡Œéšæœºç£ç›˜è¯»å–æ¥è·å–æ‰€æœ‰çš„ K'ï¼ˆå³ä½¿ K=1ï¼Œé€šå¸¸ä¹Ÿæ¥è¿‘ä¸€ç™¾ä¸ªï¼‰å…¨ç²¾åº¦å‘é‡ï¼Œè¿™ä¼šå½±å“å»¶è¿Ÿå’Œååé‡ï¼›ï¼ˆbï¼‰å®ƒéœ€è¦ä½¿ç”¨æˆç™¾ä¸Šåƒä¸ªè´¨å¿ƒè¿›è¡Œæ˜‚è´µçš„ k-meansèšç±»æ¥æ„å»ºåŸºäº HNSW çš„è·¯ç”±å±‚ã€‚ä¾‹å¦‚ï¼Œ[24]ä¸­æè¿°çš„åœ¨ 1000 ä¸‡åŸºç¡€æ•°æ®é›†ä¸Šçš„èšç±»æ­¥éª¤ä½¿ç”¨äº† 20 ä¸‡ä¸ªè´¨å¿ƒï¼Œå¹¶ä¸”å¯èƒ½ä¸å®¹æ˜“æ‰©å±•åˆ°æ•°åäº¿ä¸ªç‚¹çš„æ•°æ®é›†ã€‚")]),e("li",null,[e("p",null,[s("Zoom[24] is a compression-based method, similar to IVFOADC+G+P, that identifies the approximate nearest "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msup",null,[e("mi",null,"K"),e("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"â€²")])]),e("annotation",{encoding:"application/x-tex"},"K'")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.7519em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"K"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.7519em"}},[e("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mtight"},[e("span",{class:"mord mtight"},"â€²")])])])])])])])])])])]),s(),e("em",null,"> K"),s(" candidates using the compressed vectors, and re-ranks them by fetching the full precision coordinates from the disk to output the final set of "),e("em",null,"K"),s(" candidates. However, Zoom suffers from two drawbacks:")]),e("ul",null,[e("li",null,[s("(a) it fetches all the "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("msup",null,[e("mi",null,"K"),e("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"â€²")])]),e("annotation",{encoding:"application/x-tex"},"K'")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.7519em"}}),e("span",{class:"mord"},[e("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"K"),e("span",{class:"msupsub"},[e("span",{class:"vlist-t"},[e("span",{class:"vlist-r"},[e("span",{class:"vlist",style:{height:"0.7519em"}},[e("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[e("span",{class:"pstrut",style:{height:"2.7em"}}),e("span",{class:"sizing reset-size6 size3 mtight"},[e("span",{class:"mord mtight"},[e("span",{class:"mord mtight"},"â€²")])])])])])])])])])])]),s(" (often close to hundred even if "),e("em",null,"K"),s(" = 1) full-precision vectors using simultaneous random disk reads, which would affect latency and throughput, and")]),e("li",null,[s("(b) it requires expensive "),e("em",null,"k"),s("-means clustering using hundreds of thousands of centroids to build the HNSW-based routing layer. For example, the clustering step described in [24] utilizes 200K centroids on 10M base set, and might not scale easily to billion-point datasets.")])])])],-1),J=l('<h2 id="_5-conclusion" tabindex="-1"><a class="header-anchor" href="#_5-conclusion" aria-hidden="true">#</a> 5 Conclusion</h2><ul><li><p>ä»…ä»…ä½¿ç”¨äº†64GBä¸»å­˜ å°±è¿›è¡Œäº† 10äº¿ç‚¹çš„ index</p></li><li><p>æˆ‘ä»¬æå‡ºå¹¶è¯„ä¼°äº†ä¸€ç§æ–°çš„åŸºäºå›¾çš„ç´¢å¼•ç®—æ³•ï¼Œç§°ä¸ºVamanaï¼Œå…¶ç´¢å¼•å¯ä¸ç›®å‰æœ€å…ˆè¿›(state-of-the-art)çš„å†…å­˜çš„(in-memory)æœç´¢æ–¹æ³•åœ¨é«˜å¬å›ç‡ç›¸åª²ç¾ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ¼”ç¤ºäº†åœ¨ä»…ä½¿ç”¨64GBä¸»å­˜çš„10äº¿ç‚¹æ•°æ®é›†ä¸Šæ„å»ºä¸€ä¸ªé«˜è´¨é‡çš„SSDé©»ç•™ç´¢å¼•DiskANNã€‚æˆ‘ä»¬è¯¦ç»†ä»‹ç»å¹¶æ¿€åŠ±äº†ç®—æ³•çš„æ”¹è¿›ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿä½¿ç”¨å»‰ä»·çš„é›¶å”®çº§SSDï¼Œä»¥å‡ æ¯«ç§’çš„å»¶è¿Ÿä¸ºè¿™äº›æŒ‡æ•°æä¾›æœåŠ¡ã€‚é€šè¿‡å°†åŸºäºå›¾çš„æ–¹æ³•çš„é«˜å¬å›ç‡ã€ä½å»¶è¿Ÿç‰¹æ€§ä¸åŸºäºå‹ç¼©çš„æ–¹æ³•çš„å†…å­˜æ•ˆç‡å’Œå¯ä¼¸ç¼©æ€§ç‰¹æ€§ç›¸ç»“åˆï¼Œæˆ‘ä»¬å»ºç«‹äº†æ–°çš„æœ€å…ˆè¿›çš„ç´¢å¼•æ„å»ºå’ŒæœåŠ¡çš„åäº¿ç‚¹æ•°æ®é›†ã€‚</p></li><li><p>We presented and evaluated a new graph-based indexing algorithm called Vamana for ANNS whose indices are comparable to the current state-of-the-art methods for in-memory search in high recall regimes. In addition, we demonstrated the construction of a high-quality SSD-resident index DiskANN on a billion point dataset using only 64GB of main memory.</p><ul><li>10äº¿çº§åˆ«çš„æ•°æ®ä»…ä»…ä½¿ç”¨äº† 64GBï¼›</li></ul></li><li><p>We detailed and motivated the algorithmic improvements that enabled us to serve these indices using inexpensive retail-grade SSDs with latencies of few milliseconds. By combining the high-recall, low-latency properties of graph-based methods with the memory efficiency and scalability properties of compression-based methods, we established the new state-of-the-art for indexing and serving billion point datasets.</p></li></ul>',2);function ee(se,ae){const i=r("ExternalLinkIcon"),t=r("router-link");return m(),h("div",null,[y,x,p(" more "),e("div",S,[k,e("ul",null,[N,_,G,e("li",null,[e("p",null,[s("codeï¼š "),e("a",M,[s("https://github.com/microsoft/DiskANN"),a(i)])])]),D,e("li",null,[e("p",null,[e("a",A,[s("https://www.zhihu.com/search?type=content&q=diskANN"),a(i)])])]),e("li",null,[e("p",null,[e("a",V,[s("https://blog.csdn.net/whenever5225/article/details/106863674"),a(i)])])]),e("li",null,[e("p",null,[e("a",z,[s("https://blog.csdn.net/weixin_44839084/article/details/119217569"),a(i)])])]),e("li",null,[e("p",null,[e("a",P,[s("https://blog.csdn.net/weixin_44839084/article/details/129679691"),a(i)])])])])]),e("nav",q,[e("ul",null,[e("li",null,[a(t,{to:"#no-0-abstract"},{default:n(()=>[s("No.0 Abstract")]),_:1})]),e("li",null,[a(t,{to:"#no-1-introduction"},{default:n(()=>[s("No.1 Introduction")]),_:1})]),e("li",null,[a(t,{to:"#å†é‡æ–°ç»†èŠ‚çœ‹çœ‹çœ‹ä¸æ‡‚"},{default:n(()=>[s("å†é‡æ–°ç»†èŠ‚çœ‹çœ‹çœ‹ä¸æ‡‚")]),_:1}),e("ul",null,[e("li",null,[a(t,{to:"#_1-1-our-technical-contribution"},{default:n(()=>[s("1.1 Our technical contribution")]),_:1})]),e("li",null,[a(t,{to:"#_1-2-notation"},{default:n(()=>[s("1.2 Notation")]),_:1})]),e("li",null,[a(t,{to:"#_1-3-paper-outline"},{default:n(()=>[s("1.3 Paper Outline")]),_:1})])])]),e("li",null,[a(t,{to:"#no-2-the-vamana-graph-construction-algorithm"},{default:n(()=>[s("No.2 The Vamana Graph Construction Algorithm")]),_:1}),e("ul",null,[e("li",null,[a(t,{to:"#_2-1-relative-neighborhood-graphs-and-the-greedysearch-algorithm"},{default:n(()=>[s("2.1 Relative Neighborhood Graphs and the GreedySearch algorithm")]),_:1})]),e("li",null,[a(t,{to:"#_2-2-the-robust-pruning-procedure"},{default:n(()=>[s("2.2 The Robust Pruning Procedure")]),_:1})]),e("li",null,[a(t,{to:"#_2-3-the-vamana-indexing-algorithm"},{default:n(()=>[s("2.3 The Vamana Indexing Algorithm")]),_:1})]),e("li",null,[a(t,{to:"#_2-4-comparison-ofvamanawith-hnsw-21-and-nsg-13"},{default:n(()=>[s("2.4 Comparison ofVamanawith HNSW [21] and NSG [13]")]),_:1})])])]),e("li",null,[a(t,{to:"#_3-diskann-constructing-ssd-resident-indices"},{default:n(()=>[s("3 DiskANN: Constructing SSD-Resident Indices")]),_:1}),e("ul",null,[e("li",null,[a(t,{to:"#_3-1-thediskannindex-design"},{default:n(()=>[s("3.1 TheDiskANNIndex Design")]),_:1})]),e("li",null,[a(t,{to:"#_3-2-diskannindex-layout"},{default:n(()=>[s("3.2 DiskANNIndex Layout")]),_:1})]),e("li",null,[a(t,{to:"#_3-3-diskann-beam-search"},{default:n(()=>[s("3.3 DiskANN Beam Search")]),_:1})]),e("li",null,[a(t,{to:"#_3-4-diskanncaching-frequently-visited-vertices"},{default:n(()=>[s("3.4 DiskANNCaching Frequently Visited Vertices")]),_:1})]),e("li",null,[a(t,{to:"#_3-5-diskannimplicit-re-ranking-using-full-precision-vectors"},{default:n(()=>[s("3.5 DiskANNImplicit Re-Ranking Using Full-Precision Vectors")]),_:1})])])]),e("li",null,[a(t,{to:"#_4-evaluation"},{default:n(()=>[s("4 Evaluation")]),_:1}),e("ul",null,[e("li",null,[a(t,{to:"#_4-1-comparison-of-hnsw-nsg-and-vamanafor-in-memory-search-performance"},{default:n(()=>[s("4.1 Comparison of HNSW, NSG and Vamanafor In-Memory Search Performance")]),_:1})]),e("li",null,[a(t,{to:"#_4-2-comparison-of-hnsw-nsg-andvamanafor-number-of-hops"},{default:n(()=>[s("4.2 Comparison of HNSW, NSG andVamanafor Number of Hops")]),_:1})]),e("li",null,[a(t,{to:"#_4-3-comparison-on-billion-scale-datasets-one-shotvamanavs-merged-vamana"},{default:n(()=>[s("4.3 Comparison on Billion-Scale Datasets: One-ShotVamanavs Merged Vamana")]),_:1})]),e("li",null,[a(t,{to:"#_4-4-comparison-on-billion-scale-datasets-diskann-vs-ivf-based-methods"},{default:n(()=>[s("4.4 Comparison on Billion-Scale Datasets: DiskANN vs IVF-based Methods")]),_:1})])])]),e("li",null,[a(t,{to:"#_5-conclusion"},{default:n(()=>[s("5 Conclusion")]),_:1})])])]),I,W,F,L,T,R,H,C,B,O,E,K,Q,U,X,Z,j,$,Y,J])}const le=o(v,[["render",ee],["__file","diskann.html.vue"]]);export{le as default};
