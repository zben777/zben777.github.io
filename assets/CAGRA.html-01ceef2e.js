import{_ as l}from"./plugin-vue_export-helper-c27b6911.js";import{r,o,c as m,d as h,a as s,e as t,w as n,b as a,f as i}from"./app-2a2d189a.js";const p="/assets/figure1-0c97ab14.png",c="/assets/figure2-f4f7a3cb.png",d="/assets/table1-3ed9ae18.png",g="/assets/figure3-b5d0dcf1.png",u="/assets/figure4-93ace720.png",f="/assets/figure5-515ff85a.png",y={},b=s("h1",{id:"l-cagra",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#l-cagra","aria-hidden":"true"},"#"),a(" L-CAGRA")],-1),v=s("p",null,"L-CAGRA",-1),w=s("div",{class:"hint-container info"},[s("p",{class:"hint-container-title"},"相关信息"),s("ul",null,[s("li",null,"可能这里要有一些 关于 其它的对于这篇文章的解读"),s("li",null,"我们需要一些链接？"),s("li",null,"paper:"),s("li",null,"code：")])],-1),x={class:"table-of-contents"},A=i('<h2 id="abstract" tabindex="-1"><a class="header-anchor" href="#abstract" aria-hidden="true">#</a> Abstract</h2><ul><li><p>critical</p></li><li><p><strong>however, only a few studies have explored</strong> <strong>harnessing the power of GPUs and multi-core processors despite</strong> <strong>the widespread use of massively parallel and general-purpose</strong> <strong>computing.</strong> 然而，尽管大规模并行和通用计算得到了广泛应用，但只有少数研究探索了利用 GPU 和多核处理器的力量。</p></li><li><p><strong>In graph construction time,</strong> <strong>our method, CAGRA, is</strong> 2*.<em>2 <em>∼</em> 27</em>×* <strong>faster than HNSW, which is</strong> <strong>one of the CPU SOTA implementations.</strong></p></li></ul><h2 id="i-introduction-ok" tabindex="-1"><a class="header-anchor" href="#i-introduction-ok" aria-hidden="true">#</a> I. INTRODUCTION==ok</h2><ul><li><p>The graph-based method for ANNS relies on a <em>proximity</em> <em>graph</em>, or a graph that represents the similarity relationships among data points within a dataset.</p></li><li><p>Graph-based methods involve two primary steps: constructing a proximity graph from a dataset and traversing it to find the <em>k</em> closest nodes to the input query.</p></li><li><p>The question of determining the optimal proximity graph structure is not easily answered theoretically.</p></li><li><p>researchers have focused on optimizing the graph’s efficiency and structure heuristically and empirically.</p></li></ul><br><ul><li>When it comes to implementing graph-based ANNS methods, few studies have introduced high-performance implementations optimized for data-center servers capable of harnessing the massive parallelism offered by GPUs. 在实现基于图的近似最近邻搜索方法时，很少有研究引入针对数据中心服务器进行优化的高性能实现，而这些服务器能够利用 GPU 提供的大规模并行性。</li><li>One notable implementation is SONG [31], which stands as the first graph search implementation on GPUs, using various optimization techniques. These techniques include employing the open addressing hash table and performing multi-query searches within a warp.</li><li>Similarly, GANNS is a GPU-friendly graph search and construction method tailored for NSW, HNSW, and <em>k</em> nearest neighbor graphs on GPUs [30]. This approach further advances the efficiency of graph-based ANNS on GPU architectures by modifying data structures for GPUs and reducing their operation time.</li><li>Additionally, Groh et al. present GGNN, a fast graph construction and search method designed explicitly for GPUs [8]. Their work also improves the overall performance of ANNS on GPUs by improving data structures for GPUs and utilizing fast shared memory.</li><li>Some studies have pointed out and managed the issue that graph construction can be time-consuming by using the advantage that a proximity graph can be reused once it is constructed. Unfortunately, there still remains a critical challenge in efficiently designing proximity graphs that are well-suited for GPU architectures in both construction and search. Despite the progress made in using GPUs for graph-based ANNS, most existing studies focus on adapting or optimizing existing graphs for GPU utilization rather than specifically designing proximity graphs from the ground up to fully leverage the GPU’s capabilities in both graph construction and subsequent search operations.一些研究已经指出并解决了图构建可能很耗时的问题，利用了一旦构建了邻近图就可以重复使用的优势。不幸的是，在高效设计既适用于图构建又适用于搜索的、适合 GPU 架构的邻近图方面仍然存在关键挑战。尽管在将 GPU 用于基于图的近似最近邻搜索方面取得了进展，但大多数现有研究都集中在调整或优化现有图以用于 GPU，而不是从一开始就专门设计能够在图构建和后续搜索操作中充分利用 GPU 能力的邻近图。</li></ul><br><ul><li><p>This paper proposes</p><ul><li>1: a proximity graph suitable for parallel computing in graph construction and query search and</li><li>2: a fast ANNS graph construction and search implementation, <strong>CAGRA</strong> (Cuda Anns GRAph-based), optimized for NVIDIA GPU. Our graph is search implementation-centric and designed to increase the efficiency of a massively parallel computing device, like the GPU, rather than theoretical graph quality.</li></ul></li><li><p>The summary of our contributions is as follows:</p><ul><li>We propose a proximity graph for ANNS and its construction method suitable for massively[大规模] parallel computing. This method reduces the memory footprint and usage, which can be the performance bottleneck in the graph optimization process, by avoiding exact similarity computation.</li><li>We provide a search implementation optimized for GPU, which is designed to gain high throughput in both single and large-batch queries. We harness software warp splitting and forgettable hash table management to utilize the GPU resource efficiently.</li><li>We demonstrate that CAGRA achieves a higher performance in graph construction and query than the state-of-the-art graph-based ANNS implementations for CPU and GPU. In graph construction time, CAGRA is 2*.<em>2 <em>∼</em> 27</em>×* faster than HNSW. In large-batch query throughput in the 90% to 95% recall range, CAGRA is 33 <em>∼</em> 77<em>×</em> faster than HNSW and is 3*.<em>8 <em>∼</em> 8</em>.<em>8</em>×* faster than the SOTA implementations for GPU. For a single query, CAGRA is 3*.<em>4 <em>∼</em> 53</em>×* faster than HNSW at 95% recall.</li></ul></li></ul><h2 id="ii-background-ok" tabindex="-1"><a class="header-anchor" href="#ii-background-ok" aria-hidden="true">#</a> II. BACKGROUND==ok</h2><h3 id="a-approximate-nearest-neighbor-search" tabindex="-1"><a class="header-anchor" href="#a-approximate-nearest-neighbor-search" aria-hidden="true">#</a> <em>A. Approximate Nearest Neighbor search</em></h3><p>wu</p><h3 id="b-cuda" tabindex="-1"><a class="header-anchor" href="#b-cuda" aria-hidden="true">#</a> <em>B. CUDA</em></h3><ul><li>图形处理器（GPU）近年来已被广泛用于通用计算，而它最初是严格为图形处理而开发的。英伟达提出并一直在开发 CUDA，它使我们能够利用 GPU 的高性能计算能力进行通用计算。虽然 GPU 比中央处理器（CPU）具有更高的并行性和内存带宽，但我们必须能够从算法中抽象出并行性并将其映射到 GPU 的架构上，以利用其高性能。因此，并非所有应用程序都能仅通过使用 GPU 获得更高的性能。</li><li><em>1) Thread hierarchy:</em> In the NVIDIA GPU thread hierarchy, 32 threads in a group called “warp” execute the same instruction simultaneously. On the other hand, different instructions are not executed in a warp in parallel, leading to a performance degradation called “warp divergence”. A group of up to 32 warps composes a CTA (Cooperative Thread Array), or thread block, and can use shared memory to share the same memory space on a GPU streaming multiprocessor (SM). The SM is like a core in a multi-core CPU, and since there are many SMs on recent GPUs, we can launch and operate multiple CTAs at a time.</li><li><em>2) Memory hierarchy:</em> In the memory hierarchy of the GPU, the device memory has the largest size, and all threads can access the same memory space. Shared memory, on the other hand, is a local memory used within each CTA and all the threads in the CTA share the memory space. While the size of shared memory is much smaller than the device memory, it has lower latency and higher bandwidth. Registers are local data storage for each thread and have lower latency than the shared memory. Although each thread can only access its own registers, one thread can send data on a register to another thread in the same warp using “warp shuffle” instructions without passing data through shared or device memory.</li></ul><h3 id="c-related-work" tabindex="-1"><a class="header-anchor" href="#c-related-work" aria-hidden="true">#</a> <em>C. Related work</em></h3><ul><li><em>1) SONG:</em> SONG is the first graph-based ANN implementation for GPU proposed by Zhao <em>et al.</em> [31]. Unlike CAGRA, this method does not contribute a faster graph construction technique and relies on other methods like NSW [18], NSG [7], and DPG [15]. SONG proposes a dataset and several optimizations for the GPU, in which they use open address hash table, bounded priority queue, and dynamic allocation reduction. They have achieved 10–180<em>×</em> speed up on the GPU compared to single-threaded HNSW on CPU.</li><li><em>2) GGNN:</em> GGNN is a GPU-friendly implementation of graph-based ANNS proposed by Groh <em>et al.</em> [8] that, like CAGRA, provides both a high-throughput search implementation and a fast graph construction technique that can utilize high parallelism. GGNN was demonstrated to outperform SONG in multi-batch searches.</li><li><em>3) GANNS:</em> GANNS is also a GPU-accelerated graph construction and search method proposed by Yu <em>et al.</em> [30]. They propose a GPU-based NSW graph construction method and show that both the proximity graph construction and search performance are better than SONG.</li><li>Unfortunately, between GGNN and GANNS, it is unclear which is the state-of-the-art graph-based ANNS GPU implementation since there is no study on comparison between them. In addition, all of the above GPU implementations are focused on applications with a large number of queries. To the best of our knowledge, no GPU implementation outperforms the CPU implementation for applications with small queries. In this paper, we will show that CAGRA outperforms both the CPU and GPU in proximity graph construction and search.不幸的是，在（GGNN）和（GANNS）之间，目前尚不清楚哪个是基于图的近似最近邻搜索的最先进的 GPU 实现，因为目前还没有对它们进行比较的研究。此外，上述所有的 GPU 实现都集中在具有大量查询的应用上。据我们所知，对于具有少量查询的应用，没有一种 GPU 实现能超越 CPU 实现。在本文中，我们将展示在邻近图构建和搜索方面（CAGRA）在性能上超越了 CPU 和 GPU。</li></ul><h2 id="iii-cagra-graph" tabindex="-1"><a class="header-anchor" href="#iii-cagra-graph" aria-hidden="true">#</a> III. CAGRA GRAPH</h2><ul><li>The CAGRA graph has the following features:</li><li><mark><strong>Fixed out-degree</strong> (<em>d</em>)</mark></li><li>By fixing the out-degree, we can utilize the massive parallelism of GPU effectively. Most graph-based ANNS algorithms build and utilize non-fixed out-degree graphs. In single-thread execution on a CPU, a non-fixed degree for each node has an advantage in that we can reduce the less important distance computation by keeping only essential edge connections. However, in the case of GPU, too small a degree doesn’t fully saturate the computing resources allocated to each CTA, leading to lower hardware utilization. Rather, it is better to expand the search space using all the available compute resources, as it won’t increase the overall compute time. Another advantage is that fixing the degree allows more uniform computation, thus creating less load imbalance during the parallel graph traversal phase, which would lead to low hardware utilization. We set the degree depending on the dataset and required recall and throughput.</li><li><mark><strong>Directional</strong></mark> . Since the out-degree is fixed, the graph is naturally directional.</li><li><mark><strong>No hierarchy</strong></mark>. HNSW, for instance, employs a hierarchical graph to determine the initial nodes on the bottom layer. However, in the case of GPU, we can obtain compatible initial nodes by randomly picking some nodes and comparing their distances to the query, thus employing the high parallelism and memory bandwidth of GPU. The detail of the search algorithm is in Sec. IV.</li></ul><br><ul><li>Two main steps are involved in the construction of the CAGRA graph: <ul><li><ol><li>building a <em>k</em>-NN graph and</li><li>optimizing it to enhance recall and throughput.</li></ol></li></ul></li><li>We chose <em>k</em>-NN graph as the base graph because the fixed out-degree graph is well suited for efficient GPU operations, and we can rapidly build it using nearest neighbors descent (NN-descent) [27] even on the GPU [26]. The following section outlines the heuristic graph optimization approach and its parallel computation algorithm.</li></ul><h3 id="a-graph-optimization" tabindex="-1"><a class="header-anchor" href="#a-graph-optimization" aria-hidden="true">#</a> <em>A. Graph optimization</em></h3><ul><li>The primary objective of CAGRA graph optimization is to enhance reachability among a large number of nodes. Reachability is characterized by two properties: <ul><li><ol><li>whether we can traverse from any arbitrary node to another arbitrary node and</li><li><ol start="2"><li>the number of nodes we can traverse from one node within a specified number of path traversals.</li></ol></li></ol></li></ul></li></ul><br><ul><li>To assess property 1), we measure the number of strongly connected components (CC) in the graph. The number of CC is determined as follows:</li><li>There is no guarantee that the base kNN graph is not disconnected [19], and the weak CC represents the number of subgraphs in the graph. Additionally, in the case of a directional edge graph, there may be scenarios where traversal from one node to another is not possible, even if the graph is not entirely disconnected. A graph is considered strongly connected when an arbitrary node in the graph can reach any other node. The number of strong CC is the count of node groups in the graph, where each group forms a strongly connected subgraph. A smaller number of strong CC are preferred because a larger number of CC can lead to more unreachable nodes starting from a search start node.</li></ul><br>',24),z=s("ul",null,[s("li",null,[a("To assess property 2), we utilize the average 2-hop node count ("),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"N"),s("mrow",null,[s("mn",null,"2"),s("mi",null,"h"),s("mi",null,"o"),s("mi",null,"p")])])]),s("annotation",{encoding:"application/x-tex"},"N_{2hop}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.9694em","vertical-align":"-0.2861em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"N"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.109em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2"),s("span",{class:"mord mathnormal mtight"},"h"),s("span",{class:"mord mathnormal mtight"},"o"),s("span",{class:"mord mathnormal mtight"},"p")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])])])])]),a(") for all nodes in the graph as the metric. The 2-hop node count of a given node is defined as the number of nodes that can be reached in two traversals from the node. Its maximum value is determined as "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msubsup",null,[s("mi",null,"N"),s("mrow",null,[s("mn",null,"2"),s("mi",null,"h"),s("mi",null,"o"),s("mi",null,"p")]),s("mrow",null,[s("mi",null,"m"),s("mi",null,"a"),s("mi",null,"x")])]),s("mo",null,"="),s("mi",null,"d"),s("mo",null,"+"),s("msup",null,[s("mi",null,"d"),s("mn",null,"2")])]),s("annotation",{encoding:"application/x-tex"},"N_{2hop}^{max} = d + d^{2}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1025em","vertical-align":"-0.4192em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"N"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6644em"}},[s("span",{style:{top:"-2.4169em","margin-left":"-0.109em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2"),s("span",{class:"mord mathnormal mtight"},"h"),s("span",{class:"mord mathnormal mtight"},"o"),s("span",{class:"mord mathnormal mtight"},"p")])])]),s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"ma"),s("span",{class:"mord mathnormal mtight"},"x")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.4192em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7778em","vertical-align":"-0.0833em"}}),s("span",{class:"mord mathnormal"},"d"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8141em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"d"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])])])])]),a(" where "),s("em",null,"d"),a(" is the degree of the graph. A higher average 2-hop node count indicates that more nodes can be explored during specific search iteration steps.")])],-1),G=i('<br><ul><li>In the CAGRA graph optimization, two key techniques are employed on the initial kNN graph: <strong>reordering</strong> and <strong>reverse edge addition</strong>. Reordering is a technique that reorders each edge of the initial kNN graph in an order that increases the diversity of the graph, rather than in the order of its length, and has the primary effect of increasing 2-hop node counts. Reverse edge addition is a technique often used in other graph based ANN implementations and improves node reachability while reducing strong CC values.</li></ul><h3 id="b-graph-construction-and-optimization-algorithm" tabindex="-1"><a class="header-anchor" href="#b-graph-construction-and-optimization-algorithm" aria-hidden="true">#</a> <em>B. Graph construction and optimization algorithm</em></h3><ul><li>The CAGRA graph is a directed graph where the degree, <em>d</em>, of all nodes is the same. The construction of the graph consists of two stages: 1) construction of an initial graph and 2) optimization, as shown in Fig. 1.</li><li><img src="'+p+'" alt="figure1" tabindex="0" loading="lazy"><figcaption>figure1</figcaption></li></ul><br>',5),N=s("ul",null,[s("li",null,[s("em",null,"1) Initial graph construction:"),a(" We construct a "),s("em",null,"k"),a("-NN graph as an initial graph where the degree of each node is "),s("em",null,"k"),a(" = "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"d"),s("mrow",null,[s("mi",null,"i"),s("mi",null,"n"),s("mi",null,"i"),s("mi",null,"t")])])]),s("annotation",{encoding:"application/x-tex"},"d_{init}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8444em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"d"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"ini"),s("span",{class:"mord mathnormal mtight"},"t")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a(".")]),s("li",null,[a("We use NN-Descent [5] to construct the graph and will typically set "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"d"),s("mrow",null,[s("mi",null,"i"),s("mi",null,"n"),s("mi",null,"i"),s("mi",null,"t")])])]),s("annotation",{encoding:"application/x-tex"},"d_{init}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8444em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"d"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"ini"),s("span",{class:"mord mathnormal mtight"},"t")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a(" to be 2"),s("em",null,"d"),a(" or 3"),s("em",null,"d"),a(", where "),s("em",null,"d"),a(" is the degree of the final CAGRA graph. As a final step in this process, we sort the connected node list of each node in ascending order based on distance from the source node. This sorting operation can be efficiently executed in parallel using GPUs since no dependency exists in the computation for each individual node list. We assume that the initial "),s("em",null,"k"),a("-NN graph has sufficient connectivity among nodes. And the goal of the CAGRA graph optimization is to reduce the degree of the graph to reduce the size while preserving the reachability.")])],-1),k=s("br",null,null,-1),C=s("ul",null,[s("li",null,[s("em",null,"2) Graph optimization:"),a(" The optimization process involves two steps: 1) reordering edges, and 2) adding reverse edges. It takes the initial graph as input and produces the CAGRA graph as output. This process offers notable advantages: i) it no longer requires the dataset or distance computation, and ii) it allows for many computations to be executed in parallel without complex dependencies.")])],-1),_=s("br",null,null,-1),U=s("ul",null,[s("li",null,[s("p",null,[a("In the reordering edges step, we determine the significance of an edge, "),s("strong",null,"rank"),a(", to prune the edges at the end of the entire optimization. Existing pruning algorithms prune an edge from one node to another if it can be bypassed using another route (detourable route) that satisfies certain criteria. For instance, in NGT [9], it defines the detourable route from "),s("em",null,"X"),a(" to "),s("em",null,"Y"),a(" as a pair of two edges as follows:")]),s("ul",null,[s("li",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"e"),s("mrow",null,[s("mi",null,"X"),s("mo",null,"−"),s("mo",null,">"),s("mi",null,"Z")])]),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"e"),s("mrow",null,[s("mi",null,"Z"),s("mo",null,"−"),s("mo",null,">"),s("mi",null,"Y")])]),s("mo",{stretchy:"false"},")"),s("mi",null,"s"),s("mi",{mathvariant:"normal"},"."),s("mi",null,"t"),s("mi",{mathvariant:"normal"},"."),s("mi",null,"m"),s("mi",null,"a"),s("mi",null,"x"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"w"),s("mrow",null,[s("mi",null,"X"),s("mo",null,"−"),s("mo",null,">"),s("mi",null,"Z")])]),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"w"),s("mrow",null,[s("mi",null,"Z"),s("mo",null,"−"),s("mo",null,">"),s("mi",null,"Y")])]),s("mo",{stretchy:"false"},")"),s("mo",null,"<"),s("msub",null,[s("mi",null,"w"),s("mrow",null,[s("mi",null,"X"),s("mo",null,"−"),s("mo",null,">"),s("mi",null,"Y")])]),s("mo",{separator:"true"},","),s("mo",{stretchy:"false"},"("),s("mn",null,"3"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"(e_{X->Z}, e_{Z->Y})s.t. max(w_{X->Z},w_{Z->Y}) < w_{X->Y}, (3)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"mord mtight"},"−"),s("span",{class:"mrel mtight"},">"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.07153em"}},"Z")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.07153em"}},"Z"),s("span",{class:"mord mtight"},"−"),s("span",{class:"mrel mtight"},">"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.22222em"}},"Y")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])]),s("span",{class:"mclose"},")"),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mord"},"."),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord"},"."),s("span",{class:"mord mathnormal"},"ma"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0269em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"mord mtight"},"−"),s("span",{class:"mrel mtight"},">"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.07153em"}},"Z")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0269em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.07153em"}},"Z"),s("span",{class:"mord mtight"},"−"),s("span",{class:"mrel mtight"},">"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.22222em"}},"Y")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])]),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"<"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0269em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"mord mtight"},"−"),s("span",{class:"mrel mtight"},">"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.22222em"}},"Y")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"3"),s("span",{class:"mclose"},")")])])])])])]),s("li",null,[s("p",null,[a("where "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"e"),s("mrow",null,[s("msub",null,[s("mi",{mathvariant:"normal"},"."),s("mo",null,">")]),s("mi",{mathvariant:"normal"},".")])])]),s("annotation",{encoding:"application/x-tex"},"e_{._>.}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7002em","vertical-align":"-0.2697em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.0195em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"."),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2421em"}},[s("span",{style:{top:"-2.357em","margin-left":"0em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mrel mtight"},">")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1709em"}},[s("span")])])])])]),s("span",{class:"mord mtight"},".")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2697em"}},[s("span")])])])])])])])]),a(" and "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"w"),s("mrow",null,[s("msub",null,[s("mi",{mathvariant:"normal"},"."),s("mo",null,">")]),s("mi",{mathvariant:"normal"},".")])])]),s("annotation",{encoding:"application/x-tex"},"w_{._>.}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7002em","vertical-align":"-0.2697em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.0195em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0269em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"."),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2421em"}},[s("span",{style:{top:"-2.357em","margin-left":"0em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mrel mtight"},">")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1709em"}},[s("span")])])])])]),s("span",{class:"mord mtight"},".")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2697em"}},[s("span")])])])])])])])]),a(" denote a directed edge between two nodes and the distance, respectively, and "),s("em",null,"Z"),a(" is a node with a direct connection from "),s("em",null,"X"),a(" and a direct connection to "),s("em",null,"Y"),a(" . Based on this pruning, we consider two reordering techniques, "),s("strong",null,"distance-based"),a(" and "),s("strong",null,"rank-based"),a(" reordering, and adopt rank based in the CAGRA graph optimization. 一个基于距离的，一个可能没有基于距离的；")])])],-1),P=s("br",null,null,-1),R=s("ul",null,[s("li",null,"In distance-based reordering, we first count the number of detourable routes for each edge and reorder the node list by the counts in ascending. A fewer number of detourable routes for an edge indicates that this edge is more important to keep the 2-hop node counts. Then, we set the position of an edge in the node list as a rank of the edge, which is an indicator of the importance of the edge. The computation of distance based reordering has high parallelism since we can count the detourable routes for each edge in parallel. 在基于距离的重排序中，我们首先计算每条边的可绕行路线的数量，并按照数量升序对节点列表进行重排序。一条边的可绕行路线数量越少，表明这条边对于保持两跳节点数量更为重要。然后，我们将一条边在节点列表中的位置设置为该边的等级，这是边的重要性的一个指标。基于距离的重排序的计算具有高度的并行性，因为我们可以并行地计算每条边的可绕行路线的数量。"),s("li",null,[a("However, we need to compute the distances on the fly during the operation or make a distance table before the operation, making this method impractical for a large dataset. In the former case, we need "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"N"),s("mtext",null,"✖"),s("mi",{mathvariant:"normal"},"®"),s("msub",null,[s("mi",null,"d"),s("mrow",null,[s("mi",null,"i"),s("mi",null,"n"),s("mi",null,"i"),s("mi",null,"t")])]),s("mtext",null,"✖"),s("mi",{mathvariant:"normal"},"®"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"d"),s("mrow",null,[s("mi",null,"i"),s("mi",null,"n"),s("mi",null,"i"),s("mi",null,"t")])]),s("mo",null,"−"),s("mn",null,"1"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"N ✖️ d_{init} ✖️ (d_{init} - 1)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1389em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"N"),s("span",{class:"mord"},"✖"),s("span",{class:"mord accent"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8889em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal sizing reset-size6 size3",style:{"margin-right":"0.00773em"}},"R")])]),s("span",{style:{top:"-3.1944em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body accent-full",style:{left:"0em",top:".2em"}},[s("span",{class:"mord"},"◯")])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"d"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"ini"),s("span",{class:"mord mathnormal mtight"},"t")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mord"},"✖"),s("span",{class:"mord accent"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8889em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal sizing reset-size6 size3",style:{"margin-right":"0.00773em"}},"R")])]),s("span",{style:{top:"-3.1944em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body accent-full",style:{left:"0em",top:".2em"}},[s("span",{class:"mord"},"◯")])])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"d"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"ini"),s("span",{class:"mord mathnormal mtight"},"t")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},"1"),s("span",{class:"mclose"},")")])])]),a(" distance computations, and in the latter case, we need a distance table with "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"N"),s("mtext",null,"✖"),s("mi",{mathvariant:"normal"},"®"),s("msub",null,[s("mi",null,"d"),s("mrow",null,[s("mi",null,"i"),s("mi",null,"n"),s("mi",null,"i"),s("mi",null,"t")])])]),s("annotation",{encoding:"application/x-tex"},"N ✖️ d_{init}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0389em","vertical-align":"-0.15em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"N"),s("span",{class:"mord"},"✖"),s("span",{class:"mord accent"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8889em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal sizing reset-size6 size3",style:{"margin-right":"0.00773em"}},"R")])]),s("span",{style:{top:"-3.1944em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body accent-full",style:{left:"0em",top:".2em"}},[s("span",{class:"mord"},"◯")])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"d"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"ini"),s("span",{class:"mord mathnormal mtight"},"t")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a(" entries on memory, where "),s("em",null,"N"),a(" is the size of the dataset. 然而，我们需要在操作期间即时计算距离，或者在操作之前制作一个距离表，这使得这种方法对于大型数据集不切实际。在前一种情况下，我们需要进行"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"N"),s("mo",null,"×"),s("msub",null,[s("mi",null,"d"),s("mrow",null,[s("mi",null,"i"),s("mi",null,"n"),s("mi",null,"i"),s("mi",null,"t")])]),s("mo",null,"×"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"d"),s("mrow",null,[s("mi",null,"i"),s("mi",null,"n"),s("mi",null,"i"),s("mi",null,"t")])]),s("mo",null,"−"),s("mn",null,"1"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"N\\times d_{init}\\times(d_{init}-1)")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7667em","vertical-align":"-0.0833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"N"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"×"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8444em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"d"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"ini"),s("span",{class:"mord mathnormal mtight"},"t")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"×"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"d"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"ini"),s("span",{class:"mord mathnormal mtight"},"t")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},"1"),s("span",{class:"mclose"},")")])])]),a("次距离计算；在后一种情况下，我们需要一个在内存中有"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"N"),s("mo",null,"×"),s("msub",null,[s("mi",null,"d"),s("mrow",null,[s("mi",null,"i"),s("mi",null,"n"),s("mi",null,"i"),s("mi",null,"t")])])]),s("annotation",{encoding:"application/x-tex"},"N\\times d_{init}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7667em","vertical-align":"-0.0833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"N"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"×"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8444em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"d"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"ini"),s("span",{class:"mord mathnormal mtight"},"t")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a("个条目的距离表，其中"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"N")]),s("annotation",{encoding:"application/x-tex"},"N")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"N")])])]),a("是数据集的大小。")])],-1),T=i('<br><ul><li>We set the position of the edge in the neighbor node list, which is sorted by distance at the end of the initial graph construction, as the initial rank, similar to distance-based reordering. Then, we reorder the edges in the same way as distance-based reordering, but we use the initial rank instead of the distance, as shown in Fig. 2. In other words, we approximate the distance by the initial rank. This approximation allows us not to compute the impractical amount of distance computations and not to store the large size of the distance table in memory. We set the order index of a node as the rank, the same as distance-based. We adopt rank-based reordering in the CAGRA graph optimization and only keep top <em>d</em> neighbors for each node (pruning).</li><li><img src="'+c+'" alt="figure2" tabindex="0" loading="lazy"><figcaption>figure2</figcaption></li></ul><br><ul><li><p>After reordering, we create a reversed graph where all edges have opposite directions of the reordered and pruned graph. Since the number of incoming edges per node, or in-degree, is not fixed in the reordered graph, the degree of each node in the reversed graph is also not fixed. However, we set the upper bound of the degree to <em>d</em> because of an attribute of the next operation. And we make the reversed graph so that the reversed edges are sorted by the rank in the pruned graph in ascending order. It means “<em>Someone who considers you are</em> <em>more important is also more important to you</em>”.</p></li><li><p>Finally, we merge the pruned graph and reversed graph. In this process, we basically take *d/*2 children for each parent node from each graph and interleave them. When the number of children for a parent node in the reversed edge graph is fewer than *d/*2, we compensate them by taking from the pruned graph.</p></li></ul><h3 id="c-evaluation-of-the-cagra-graph-and-optimization" tabindex="-1"><a class="header-anchor" href="#c-evaluation-of-the-cagra-graph-and-optimization" aria-hidden="true">#</a> <em>C. Evaluation of the CAGRA graph and optimization</em></h3><ul><li><mark><strong>Q-A1</strong></mark> How much do the CC and 2-hop node counts improve with the CAGRA graph optimization?</li><li><mark><strong>Q-A2</strong></mark> How fast is rank-based reordering compared to distance-based?</li><li><mark><strong>Q-A3</strong></mark> Does rank-based reordering have compatible recall with distance-based?</li><li>We use the datasets in Table I. All experiments are conducted on a computer with AMD EPYC 7742 CPU (64 cores) and NVIDIA A100 (80GB) GPU, and we put both the dataset and graph on the device memory of the GPU.</li><li><img src="'+d+'" alt="table1" tabindex="0" loading="lazy"><figcaption>table1</figcaption></li></ul><br><ul><li><mark><em>1)</em> <strong>Q-A1:</strong></mark></li><li><em>Connected components and 2-hop node count:</em> In the CAGRA graph construction, two optimizations are performed on the initial <em>k</em>-NN graph: reordering and reverse edge addition. Then, <em>how much effect does each optimization</em> <em>have?</em> To evaluate this, we have compared the properties of a standard <em>k</em>-NN graph, a partially optimized CAGRA graph (using only one optimization), and a fully optimized CAGRA graph (using both optimizations).</li><li>The results of the 2-hop node count and the strong CC experiments are shown in Fig. 3. In the case of the 2-hop node count, we observe that both optimizations increase the average 2-hop count, and the effect of the reordering is more significant compared to the reverse edge addition. The results also show that reverse edge addition significantly affects the strong CC more than reordering.</li><li><img src="'+g+'" alt="figure3" tabindex="0" loading="lazy"><figcaption>figure3</figcaption></li></ul><br><ul><li><mark><em>2)</em> <strong>Q-A2:</strong></mark></li><li><em>The reordering method’s advantage on compute</em> <em>time:</em> In the reordering optimization, we avoid the distance computation altogether, reducing the computational overhead, and leading to faster optimization. So then, <em>how does that</em> <em>improve the total optimization time?</em> We have measured the optimization time, as shown in Fig. 4. The rank-based CAGRA optimization is faster than the distance-based for all datasets by as much as 1*.<em>9</em>×*. Furthermore, while we were still able to perform the rank-based optimization, we experienced an out-of-memory error that prevented us from performing the distance-based optimization on DEEP-100. These results show that rank-based optimization is faster than distance-based and supports larger datasets.</li><li><img src="'+u+'" alt="figure4" tabindex="0" loading="lazy"><figcaption>figure4</figcaption></li></ul><br><ul><li><mark><em>3)</em> <strong>Q-A3:</strong></mark></li><li><em>Seach performance comparison to distance-based</em> <em>optimization:</em> The recall that a graph can potentially achieve and the number of iterations to obtain a specific recall will vary by the graph construction methods, including the reordering distance criteria in the CAGRA graph optimization. In CAGRA, we reduce the graph optimization time, avoiding distance computation and instead using the initial rank as the distance criteria. So then, <em>does the CAGRA graph have</em> <em>the compatible search performance compared to distance</em> based optimization?* To answer this question, we have tested both rank-based and distance-based reordering during CAGRA graph optimization and measured the throughput and recall of a query search process using the graph, as shown in Fig.5 This confirms the recall-throughput balance is almost the same while the rank-based graph construction time is shorter, as demonstrated in Q-A2.</li><li><img src="'+f+'" alt="figure5" tabindex="0" loading="lazy"><figcaption>figure5</figcaption></li></ul><h2 id="iv-cagra-search" tabindex="-1"><a class="header-anchor" href="#iv-cagra-search" aria-hidden="true">#</a> IV. CAGRA SEARCH</h2>',13);function S(I,M){const e=r("router-link");return o(),m("div",null,[b,v,h(" more "),w,s("nav",x,[s("ul",null,[s("li",null,[t(e,{to:"#abstract"},{default:n(()=>[a("Abstract")]),_:1})]),s("li",null,[t(e,{to:"#i-introduction-ok"},{default:n(()=>[a("I. INTRODUCTION==ok")]),_:1})]),s("li",null,[t(e,{to:"#ii-background-ok"},{default:n(()=>[a("II. BACKGROUND==ok")]),_:1}),s("ul",null,[s("li",null,[t(e,{to:"#a-approximate-nearest-neighbor-search"},{default:n(()=>[a("A. Approximate Nearest Neighbor search")]),_:1})]),s("li",null,[t(e,{to:"#b-cuda"},{default:n(()=>[a("B. CUDA")]),_:1})]),s("li",null,[t(e,{to:"#c-related-work"},{default:n(()=>[a("C. Related work")]),_:1})])])]),s("li",null,[t(e,{to:"#iii-cagra-graph"},{default:n(()=>[a("III. CAGRA GRAPH")]),_:1}),s("ul",null,[s("li",null,[t(e,{to:"#a-graph-optimization"},{default:n(()=>[a("A. Graph optimization")]),_:1})]),s("li",null,[t(e,{to:"#b-graph-construction-and-optimization-algorithm"},{default:n(()=>[a("B. Graph construction and optimization algorithm")]),_:1})]),s("li",null,[t(e,{to:"#c-evaluation-of-the-cagra-graph-and-optimization"},{default:n(()=>[a("C. Evaluation of the CAGRA graph and optimization")]),_:1})])])]),s("li",null,[t(e,{to:"#iv-cagra-search"},{default:n(()=>[a("IV. CAGRA SEARCH")]),_:1})])])]),A,z,G,N,k,C,_,U,P,R,T])}const D=l(y,[["render",S],["__file","CAGRA.html.vue"]]);export{D as default};
