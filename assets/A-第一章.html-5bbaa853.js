import{_ as u}from"./plugin-vue_export-helper-c27b6911.js";import{r as p,o as d,c as b,d as m,a as l,e as a,w as i,b as n,f as t}from"./app-2a2d189a.js";const U="/assets/figure1-1-390d63bf.png",k="/assets/figure1-2-fb17ba43.png",h="/assets/figure1-3-488dc808.png",g="/assets/figure1-4-3d149fd9.png",P="/assets/figure1-5-11c03828.png",v="/assets/figure1-6-25997a15.png",f="/assets/figure1-7-2586b38d.png",_="/assets/figure1-8-d5871cdd.png",C="/assets/figure1-9-fa0178d2.png",A="/assets/table1-1-74001998.png",G="/assets/table1-2-64944bad.png",D="/assets/figure1-10-4c340953.png",I="/assets/figure1-11-4e000cc0.png",y="/assets/figure1-12-b8711152.png",x="/assets/figure1-13-ad8ea7bb.png",w="/assets/figure1-14-acd35998.png",H="/assets/figure1-15-fb6aa587.png",M="/assets/figure1-16-f81f5f53.png",N={},S=l("h1",{id:"a-第一章节",tabindex:"-1"},[l("a",{class:"header-anchor",href:"#a-第一章节","aria-hidden":"true"},"#"),n(" A-第一章节")],-1),T=l("p",null,"A-第一章节",-1),W={class:"table-of-contents"},E=t('<h2 id="简单介绍主要是基础" tabindex="-1"><a class="header-anchor" href="#简单介绍主要是基础" aria-hidden="true">#</a> 简单介绍主要是基础</h2><div class="hint-container info"><p class="hint-container-title">说明</p><p>主要是各种搜索找的学习；</p><p>主题：CUDA核心GPU编程</p><p>前置条件：</p><ul><li>应具备C++编程知识</li><li>需理解内存管理，如malloc和free</li><li>理解STL及其模板机制</li><li>需配置NVIDIA显卡，型号需为900系列或更高</li><li>所用扩展要求版本为11或更新</li><li>编译器版本不低于11</li><li>CMake版本需在3.18以上</li></ul></div><div class="hint-container info"><p class="hint-container-title">问题</p><ul><li><p>1-在一个典型的系统中会有成千上万的线程排队等待工作。如果GPU必须等待一组线程执行结束，那么它只要调用另一组线程执行其他任务即可。</p></li><li><p>这个一组线程是指？</p></li><li><p>2-现代的NVIDIA GPU在每个多处理器上最多可以并发支持1536个同时活跃的线程。有16个多处理器的GPU，可以并发支持超过24000个同时活跃的线程。</p></li><li><p>这个是指 每个SM可以并发支持1536个同时活跃的线程？？然后 16 个 SM？这个可以看看目前GPU4090的那个可执行程序</p></li></ul></div><h2 id="第1章-heterogeneous-parallel-computing-with-cuda" tabindex="-1"><a class="header-anchor" href="#第1章-heterogeneous-parallel-computing-with-cuda" aria-hidden="true">#</a> 第1章 Heterogeneous Parallel Computing with CUDA</h2><ul><li><p><mark>基于CUDA的异构并行计算</mark></p></li><li><p><mark>WHAT’S IN THIS CHAPTER?</mark></p></li><li><p>了解异构计算架构</p></li><li><p>认识并行程序设计的范例转换</p></li><li><p>掌握 GPU 编程的基本要素</p></li><li><p>了解 CPU 和 GPU 编程的区别</p></li><li><p>随着新科技和处理方法的普及，高性能计算（HPC）领域也在不断变化，而HPC的定<br> 义也随之产生了相应的变化。一般来说，它涉及多个处理器或计算机的使用，以高吞吐量<br> 和高效率来完成一个复杂的任务。HPC不仅可以认为是一个计算架构，还可以认为是包括<br> 硬件系统、软件工具、编程平台及并行编程范例的一组元素列表(包含了基本所涉及的)。</p></li><li><p>在过去的十几年中，高性能计算取得了极大的发展，尤其是GPU-CPU异构架构的出<br> 现，直接导致了在并行程序设计中一个基本的范例转变。将从本章开始学习异构并行程序<br> 设计。（因为之前基本都是CPU上的多线程进行并行计算）</p></li><li><p><mark>异构架构</mark></p></li><li><p>异构架构（Heterogeneous Architecture）是一种计算系统设计，其中包含了不同类型的处理器或计算单元，这些单元具有不同的架构、指令集或专长，旨在协同工作以优化计算性能、能效或适应<mark>特定的计算任务</mark>。</p></li></ul><h2 id="_1-1-并行计算" tabindex="-1"><a class="header-anchor" href="#_1-1-并行计算" aria-hidden="true">#</a> 1.1 并行计算</h2><ul><li><p><mark>1.1 PARALLEL COMPUTING</mark></p></li><li><p>在过去的几十年间，人们对并行计算产生了越来越多的兴趣。并行计算的主要目标是<br> 提高运算速度。</p></li><li><p>从纯粹的计算视角来看，并行计算可以被定义为计算的一种形式，在这种形式下，计<br> 算机可以同时进行许多运算，计算原则是一个大的问题往往可以被划分为很多可以同时解<br> 决的小问题。</p></li><li><p>从程序员的角度来说，一个很自然的疑问，就是如何将并发计算映射到计算机上。假<br> 设你有许多计算资源，并行计算可以被定义为同时使用许多计算资源（核心或计算机）来<br> 执行并发计算，一个大的问题可以被分解成多个小问题，然后在不同的计算资源上并行处<br> 理这些小问题。并行计算的软件和硬件层面是紧密联系的。事实上，并行计算通常涉及两<br> 个不同的计算技术领域。</p><ul><li>Computer architecture (hardware aspect)计算机架构（硬件方面）</li><li>Parallel programming (software aspect)并行程序设计（软件方面）</li></ul></li><li><p>所以就是说硬件提供计算机架构，然后程序员本身去编程软件方面的并行程序设计？</p></li><li><p>计算机架构关注的是在结构级别上支持并行性，而并行编程设计关注的是充分使用计<br> 算机架构的计算能力来并发地解决问题。为了在软件中实现并行执行，硬件必须提供一个<br> 支持并行执行多进程或多线程的平台。</p></li><li><p>大多数现代处理器都应用了哈佛体系结构（Harvard architecture），如图1-1所示，它主要由3个部分组成。</p><ul><li>Memory (instruction memory and data memory)内存（指令内存和数据内存）</li><li>Central processing unit (control unit and arithmetic logic unit)中央处理单元（控制单元和算术逻辑单元）</li><li>Input/Output interfaces输入/输出接口</li></ul></li></ul><figure><img src="'+U+'" alt="figure1-1" tabindex="0" loading="lazy"><figcaption>figure1-1</figcaption></figure><ul><li><p>高性能计算的关键部分是中央处理单元（CPU），通常被称为计算机的核心。在早期<br> 的计算机中，一个芯片上只有一个CPU，这种结构被称为单核处理器。现在，芯片设计的<br> 趋势是将多个核心集成到一个单一的处理器上，以在体系结构级别支持并行性，这种形式<br> 通常被称为多核处理器。因此，并行程序设计可以看作是将一个问题的计算分配给可用的<br> 核心以实现并行的过程。</p></li><li><p>当实现一段串行算法时，你可能不需要为了编写一个程序而特意去理解计算机架构的<br> 细节。但是，当在多核计算机上执行算法时，对于程序员来说，了解基本的计算机架构的<br> 特点就显得非常重要了。要编写一个既正确又高效的并行程序需要对多核体系结构有一个<br> 基本的认识。</p></li><li><p>下文将介绍并行计算的一些基本概念，以及这些概念与 CUDA 编程设计的关系。</p></li></ul><h3 id="_1-1-1-串行编程和并行编程" tabindex="-1"><a class="header-anchor" href="#_1-1-1-串行编程和并行编程" aria-hidden="true">#</a> 1.1.1 串行编程和并行编程</h3><p>Sequential and Parallel Programming</p><ul><li><p>顺序编程 和 并行编程</p></li><li><p>当用计算机程序解决一个问题时，我们会很自然地把这个问题划分成许多的运算块，<br> 每一个运算块执行一个指定的任务，如图1-2所示。这样的程序叫作串行程序。<br><img src="'+k+'" alt="figure1-2" loading="lazy"></p></li><li><p>有两种方法可以区分两个计算单元之间的关系：有些是有执行次序的，所以必须串行<br> 执行；其他的没有执行次序的约束，则可以并发执行。所有包含并发执行任务的程序都是<br> 并行程序。如图1-3所示，一个并行程序中可能会有一些串行部分。<br><img src="'+h+'" alt="figure1-3" loading="lazy"></p></li><li><p>从程序员的角度来看，一个程序应包含两个基本的组成部分：指令和数据。当一个计<br> 算问题被划分成许多小的计算单元后，每个计算单元都是一个任务。在一个任务中，单独<br> 的指令负责处理输入和调用一个函数并产生输出。当一个指令处理前一个指令产生的数据<br> 时，就有了数据相关性的概念。因此，你可以区分任何两个任务之间的依赖关系，如果一<br> 个任务处理的是另一个任务的输出，那么它们就是相关的，否则就是独立的。</p></li><li><p>在并行算法的实现中，分析数据的相关性是最基本的内容，因为相关性是限制并行性<br> 的一个主要因素，而且在现代编程环境下，为了提高应用程序的运行速度，理解这些是很<br> 有必要的。在大多数情况下，具有依赖关系的任务之间的独立的关系链为并行化提供了很<br> 好的机会。</p></li><li><p><mark>数据依懒性的分析</mark></p></li><li><p>对于数据依赖性的分析 是 进行 设计 并行程序的 一项基本技能。</p></li></ul><h3 id="_1-1-2-并行性" tabindex="-1"><a class="header-anchor" href="#_1-1-2-并行性" aria-hidden="true">#</a> 1.1.2 并行性</h3><ul><li><p>如今，并行性的应用非常广泛，在编程领域，并行编程设计正在成为主流。多层次的<br> 并行性设计是架构设计的驱动力。在应用程序中有两种基本的并行类型。</p><ul><li>Task parallelism任务并行</li><li>Data parallelism数据并行</li></ul></li><li><p>当许多任务或函数可以独立地、大规模地并行执行时，这就是任务并行。任务并行的<br> 重点在于利用多核系统对任务进行分配。</p></li><li><p>当可以同时处理许多数据时，这就是数据并行。数据并行的重点在于利用多核系统对<br> 数据进行分配。</p></li><li><p>CUDA编程非常适合解决数据并行计算的问题。本书的重点便是如何使用CUDA编程<br> 解决数据并行问题。许多处理大数据集的应用可以使用数据并行模型来提高计算单元的速<br> 度。<mark>数据并行处理可以将数据映射给并行线程</mark>。</p></li><li><p>数据并行程序设计的第一步是把数据依据线程进行划分，以使每个线程处理一部分数<br> 据。通常来说，有两种方法可以对数据进行划分：块划分（block partitioning）和周期划分（cyclic partitioning）。</p><ul><li>在块划分中，一组连续的数据被分到一个块内。每个数据块以任意次序被安排给一个线程，线程通常在同一时间只处理一个数据块。</li><li>在周期划分中，更少的数据被分到一个块内。相邻的线程处理相邻的数据块，每个线程可以处理多个数据块。为一个待处理的线程选择一个新的块，就意味着要跳过和现有线程一样多的数据块。</li></ul></li><li><p>图1-4所示为对一维数据进行划分的两个例子。在块划分中，每个线程仅需处理数据<br> 的一部分，而在周期划分中，每个线程要处理数据的多个部分。图1-5所示为对二维数据<br> 进行划分的3个例子：沿y轴的块划分，沿x轴和y轴的块划分，以及沿x轴的周期划分。<br> 其余的划分方式为沿x轴的块划分，沿x轴和y轴的周期划分，以及沿y轴的周期划分留作练习。</p></li></ul><figure><img src="'+g+'" alt="figure1-4" tabindex="0" loading="lazy"><figcaption>figure1-4</figcaption></figure><figure><img src="'+P+'" alt="figure1-5" tabindex="0" loading="lazy"><figcaption>figure1-5</figcaption></figure><ul><li>通常，数据是在一维空间中存储的。即便是多维逻辑数据，仍然要被映射到一维物理<br> 地址空间中。如何在线程中分配数据不仅与数据的物理储存方式密切相关，并且与每个线<br> 程的执行次序也有很大关系。<mark>组织线程的方式对程序的性能有很大的影响</mark>。</li></ul><br><ul><li><mark>数据划分</mark></li><li>对数据划分有两种基本的方法：<br> 块划分：每个线程作用于一部分数据，通常这些数据具有相同大小。<br> 周期划分：每个线程作用于数据的多部分。</li><li>这个的话感觉像是归约的两种不同方式的那个？</li><li>程序性能通常对块的大小比较敏感。块划分与周期划分中划分方式的选择与计算机架构有密切关系。具体实例详见本书其他章节。</li></ul><h3 id="_1-1-3-计算机架构" tabindex="-1"><a class="header-anchor" href="#_1-1-3-计算机架构" aria-hidden="true">#</a> 1.1.3 计算机架构</h3><ul><li><p>有多种不同的方法可以对计算机架构进行分类。一个广泛使用的分类方法是弗林分类法（Flynn’s Taxonomy），<br> 它根据指令和数据进入CPU的方式，将计算机架构分为4种不同的类型（如图1-6所示）。<br> 单指令单数据（SISD）<br> 单指令多数据（SIMD）<br> 多指令单数据（MISD）<br> 多指令多数据（MIMD）<br><img src="'+v+'" alt="figure1-6" loading="lazy"></p></li><li><p>SISD指的是传统计算机：一种串行架构。在这种计算机上只有一个核心。在任何时<br> 间点上只有一个指令流在处理一个数据流。</p></li><li><p>SIMD是一种并行架构类型。在这种计算机上有多个核心。在任何时间点上所有的核<br> 心只有一个指令流处理不同的数据流。向量机是一种典型的SIMD类型的计算机，现在大<br> 多数计算机都采用了SIMD架构。SIMD最大的优势或许就是，在CPU上编写代码时，程序<br> 员可以继续按串行逻辑思考但对并行数据操作实现并行加速，而其他细节则由编译器来负责。</p></li><li><p>MISD类架构比较少见，在这种架构中，每个核心通过使用多个指令流处理同一个数据流。</p></li><li><p>MIMD是一种并行架构，在这种架构中，多个核心使用多个指令流来异步处理多个数<br> 据流，从而实现空间上的并行性。许多MIMD架构还包括SIMD执行的子组件。</p></li><li><p>可以思考下SIMT与上面的本质区别？？？？</p></li></ul><br><ul><li><p>为了实现以下目的，在架构层次上已经取得了许多进展。</p><ul><li>降低延迟</li><li>提高带宽</li><li>提高吞吐量</li></ul></li><li><p>延迟是一个操作从开始到完成所需要的时间，常用微秒来表示。带宽是单位时间内可<br> 处理的数据量，通常表示为MB/s或GB/s。吞吐量是单位时间内成功处理的运算数量，通<br> 常表示为gflops（即每秒十亿次的浮点运算数量），特别是在重点使用浮点计算的科学计<br> 算领域经常用到。延迟用来衡量完成一次操作的时间，而吞吐量用来衡量在给定的单位时<br> 间内处理的操作量。</p></li><li><p>计算机架构也能根据内存组织方式进行进一步划分，一般可以分成下面两种类型。</p><ul><li>分布式内存的多节点系统</li><li>共享内存的多处理器系统</li></ul></li><li><p>在多节点系统中，大型计算引擎是由许多网络连接的处理器构成的。每个处理器有自<br> 己的本地内存，而且处理器之间可以通过网络进行通信。图1-7所示为一个典型的分布式<br> 内存的多节点系统，这种系统常被称作集群.</p></li></ul><figure><img src="'+f+'" alt="figure1-7" tabindex="0" loading="lazy"><figcaption>figure1-7</figcaption></figure><ul><li>多处理器架构的大小通常是从双处理器到几十个或几百个处理器之间。这些处理器要<br> 么是与同一个物理内存相关联（如图1-8所示），要么共用一个低延迟的链路（ PCI-Express或PCIe）。尽管共享内存意味着共享地址空间，但并不意味着它就是一个独立的物理内存。这样的多处理器不仅包括由多个核心组成的单片机系统，即所谓的多核系统，而且还包括由多个芯片组成的计算机系统，其中每一个芯片都可能是多核的。目前，多核架构已经永久地取代了单核架构。</li></ul><figure><img src="'+_+'" alt="figure1-8" tabindex="0" loading="lazy"><figcaption>figure1-8</figcaption></figure><ul><li><p>“众核”（many-core）通常是指有很多核心（几十或几百个）的多核架构。近年来，<br> 计算机架构正在从多核转向众核。</p></li><li><p>GPU代表了一种众核架构，几乎包括了前文描述的所有并行结构：多线程、<br> MIMD（多指令多数据）、SIMD（单指令多数据），以及指令级并行。NVIDIA公司称这<br> 种架构为SIMT（单指令多线程）。</p></li><li><p>GPU和CPU的来源并不相同。历史上，GPU是图形加速器。直到最近，GPU才演化成<br> 一个强大的、多用途的、完全可编程的，以及任务和数据并行的处理器，它非常适合解决<br> 大规模的并行计算问题。</p></li><li><p><mark>GPU核心和CPU核心</mark></p></li><li><p>尽管可以使用多核和众核来区分CPU和GPU的架构，但这两种核心是完全不同的。</p></li><li><p>CPU核心比较重，用来处理非常复杂的控制逻辑，以优化串行程序执行。</p></li><li><p>GPU核心较轻，用于优化具有简单控制逻辑的数据并行任务，注重并行程序的吞吐量。</p></li></ul><h2 id="_1-2-异构计算" tabindex="-1"><a class="header-anchor" href="#_1-2-异构计算" aria-hidden="true">#</a> 1.2 异构计算</h2><ul><li><p>异构计算</p></li><li><p>最初，计算机只包含用来运行编程任务的中央处理器（CPU）。近年来，高性能计算<br> 领域中的主流计算机不断添加了其他处理元素，其中最主要的就是GPU。GPU最初是被设<br> 计用来专门处理并行图形计算问题的，随着时间的推移，GPU已经成了更强大且更广义的<br> 处理器，在执行大规模并行计算中有着优越的性能和很高的效率。</p></li><li><p>CPU和GPU是两个独立的处理器，它们通过单个计算节点中的PCI-Express总线相连。<br> 在这种典型的架构中，GPU指的是离散的设备从同构系统到异构系统的转变是高性能计算<br> 史上的一个里程碑。同构计算使用的是同一架构下的一个或多个处理器来执行一个应用。<br> 而异构计算则使用一个处理器架构来执行一个应用，为任务选择适合它的架构，使其最终<br> 对性能有所改进。</p></li><li><p>尽管异构系统比传统的高性能计算系统有更大的优势，但目前对这种系统的有效利用<br> 受限于增加应用程序设计的复杂性。而且最近得到广泛关注的并行计算也因包含异构资源<br> 而增加了复杂性。</p></li><li><p>如果你刚开始接触并行编程，那么这些性能的改进和异构架构中可用的软件工具将对<br> 你以后的编程有很大帮助。如果你已经是一个很好的并行编程程序员了，那么适应并行异<br> 构架构的并行编程是很简单的。</p></li></ul><h3 id="_1-2-1-异构架构" tabindex="-1"><a class="header-anchor" href="#_1-2-1-异构架构" aria-hidden="true">#</a> 1.2.1 异构架构</h3><ul><li>一个典型的异构计算节点包括两个多核CPU插槽和两个或更多个的<mark>众核GPU</mark>。GPU不<br> 是一个独立运行的平台而是CPU的协处理器。因此，GPU必须通过PCIe总线与基于CPU的<br> 主机相连来进行操作，如图1-9所示。这就是为什么CPU所在的位置被称作主机端而GPU<br> 所在的位置被称作设备端。</li></ul><figure><img src="'+C+'" alt="figure1-9" tabindex="0" loading="lazy"><figcaption>figure1-9</figcaption></figure><ul><li><p>一个异构应用包括两个部分。</p><ul><li>Host code主机代码</li><li>Device code设备代码</li></ul></li><li><p>主机代码在CPU上运行，设备代码在GPU上运行。异构平台上执行的应用通常由CPU初始化。<br> 在设备端加载计算密集型任务之前，CPU代码负责管理设备端的环境、代码和数据。</p></li><li><p>在计算密集型应用中，往往有很多并行数据的程序段。GPU就是用来提高这些并行数<br> 据的执行速度的。当使用CPU上的一个与其物理上分离开的硬件组件来提高应用中的计算<br> 密集部分的执行速度时，这个组件就成为了一个硬件加速器。GPU可以说是最为常见的硬<br> 件加速器。</p></li><li><p>以下产品应用了NVIDIA公司的GPU计算平台。</p></li><li><p>Tegra</p></li><li><p>GeForce</p></li><li><p>Quadro</p></li><li><p>Tesla</p></li><li><p>Tegra系列产品是专为移动和嵌入式设备而设计的，如平板电脑和手机，GeForce面向<br> 图形用户，Quadro用于专业绘图设计，Tesla用于大规模的并行计算。Fermi是Tesla系列产品中的一种，用作GPU加速器，近来在高性能计算中获得了广泛应用。NVIDIA于2010年<br> 发布的Fermi架构是世界上第一款完整的GPU计算架构。Fermi GPU加速器的出现让许多领<br> 域的高性能计算有了新的发展，如地震资料处理、生化模拟、天气和气候建模、信号处<br> 理、计算金融、计算机辅助工程、计算流体力学和数据分析等。Fermi之后的新一代GPU<br> 计算架构Kepler，于2012年秋季发布，其处理能力相比以往的GPU有很大提升，并且提供<br> 了新的方法来优化和提高GPU并行工作的执行，有望将高性能计算提升到新的高度。<br> Tegra K1包含一个Kepler GPU，并能满足GPU在嵌入式应用中的一切要求。</p></li></ul><br><ul><li>以下是描述GPU容量的两个重要特征。 <ul><li>CUDA核心数量</li><li>内存大小(显存)</li></ul></li><li>相应的，有两种不同的指标来评估GPU的性能。 <ul><li>峰值计算性能</li><li>内存带宽</li></ul></li><li>峰值计算性能是用来评估计算容量的一个指标，通常定义为每秒能处理的单精度或双精度浮点运算的数量。峰值性能通常用GFlops（每秒十亿次浮点运算）或TFlops（每秒万亿次浮点运算）来表示。</li><li>内存带宽是从内存中读取或写入数据的比率。内存带宽通常用<br> GB/s表示。表1-1所示为Fermi架构和Kepler架构的一些性能指标。①单精度浮点性能的峰值。</li><li>本书中的大多数示例程序均可在Fermi和Kepler两种GPU上运行。一些示例需要在只包<br> 含Kepler GPU中特殊的架构上运行。<br><img src="'+A+'" alt="table1-1" loading="lazy"></li></ul><br><ul><li><mark>计算能力</mark></li><li>NVIDIA使用一个术语“计算能力”（compute capability）来描述整个Tesla系列的GPU加速器的硬件版本。表1-2给出了Tesla产品的各个版本及其计算能力。</li><li>具有相同主版本号的设备具有相同的核心架构。<br> 主版本NO.3是Kepler类架构<br> 主版本NO.2是Fermi类架构。<br> 主版本NO.1是Tesla类架构。</li><li>NVIDIA发布的第一版GPU包含了与整个Tesla GPU加速器系列相同的名称“Tesla”。</li><li>本书中的所有示例都需要版本2以上的计算能力。<br><img src="'+G+'" alt="table1-2" loading="lazy"></li></ul><h3 id="_1-2-2-异构计算范例" tabindex="-1"><a class="header-anchor" href="#_1-2-2-异构计算范例" aria-hidden="true">#</a> 1.2.2 异构计算范例</h3><ul><li>GPU计算并不是要取代CPU计算。对于特定的程序来说，每种计算方法都有它自己的<br> 优点。CPU计算适合处理控制密集型任务，GPU计算适合处理包含数据并行的计算密集型<br> 任务。GPU与CPU结合后，能有效提高大规模计算问题的处理速度与性能。CPU针对动态<br> 工作负载进行了优化，这些动态工作负载是由短序列的计算操作和不可预测的控制流程标<br> 记的；而GPU在其他领域内的目的是：处理由计算任务主导的且带有简单控制流的工作负<br> 载。如图1-10所示，可以从两个方面来区分CPU和GPU应用的范围。</li></ul><figure><img src="'+D+'" alt="figure1-10" tabindex="0" loading="lazy"><figcaption>figure1-10</figcaption></figure><ul><li><p><mark>并行级</mark></p></li><li><p><mark>数据规模</mark></p></li><li><p>如果一个问题有较小的数据规模、复杂的控制逻辑和/或很少的并行性，那么最好选<br> 择CPU处理该问题，因为它有处理复杂逻辑和指令级并行性的能力。相反，如果该问题包含较大规模的待处理数据并表现出大量的数据并行性，那么使用GPU是最好的选择。因为<br> GPU中有大量可编程的核心，可以支持大规模多线程运算，而且相比CPU有较大的峰值带宽。</p></li><li><p>因为CPU和GPU的功能互补性导致了CPU＋GPU的异构并行计算架构的发展，这两种<br> 处理器的类型能使应用程序获得最佳的运行效果。因此，为获得最佳性能，你可以同时使<br> 用CPU和GPU来执行你的应用程序，在CPU上执行串行部分或任务并行部分，在GPU上执<br> 行数据密集型并行部分，如图1-11所示。</p></li><li><p>这种代码的编写方式能保证GPU与CPU相辅相成，从而使CPU＋GPU系统的计算能力<br> 得以充分利用。为了支持使用CPU＋GPU异构系统架构来执行应用程序，NVIDIA设计了<br> 一个被称为CUDA的编程模型。这个新的编程模型是本书将要介绍的重点。<br><img src="'+I+'" alt="figure1-11" loading="lazy"></p></li></ul><br><ul><li><p><mark>CPU线程与GPU线程</mark></p></li><li><p>CPU上的线程通常是重量级的实体。操作系统必须交替线程使用启用或关闭CPU执行<br> 通道以提供多线程处理功能。上下文的切换缓慢且开销大。</p></li><li><p><mark>GPU上的线程是高度轻量级的。在一个典型的系统中会有成千上万的线程排队等待工<br> 作。如果GPU必须等待一组线程执行结束，那么它只要调用另一组线程执行其他任务即可。</mark></p></li><li><p>上面这句话要好好理解一下了；<mark>一组线程？</mark></p></li><li><p>CPU的核被设计用来尽可能减少一个或两个线程运行时间的延迟，而GPU的核是用来<br> 处理大量并发的、轻量级的线程，以最大限度地提高吞吐量。</p></li><li><p>现在，四核CPU上可以同时运行16个线程，如果CPU支持超线程可支持多至32个线程。</p></li><li><p>现代的NVIDIA GPU在每个多处理器上最多可以并发支持1536个同时活跃的线程。有<br> 16个多处理器的GPU，可以并发支持超过24000个同时活跃的线程。</p></li><li><p>这个是指 每个SM可以并发支持1536个同时活跃的线程？？</p></li><li><p>然后 16 个 SM？</p></li></ul><h3 id="_1-2-3-cuda-一种异构计算平台" tabindex="-1"><a class="header-anchor" href="#_1-2-3-cuda-一种异构计算平台" aria-hidden="true">#</a> 1.2.3 CUDA：一种异构计算平台</h3><ul><li><p>CUDA是一种通用的并行计算平台和编程模型，它利用NVIDIA GPU中的并行计算引<br> 擎能更有效地解决复杂的计算问题。通过使用CUDA，你可以像在CPU上那样，通过GPU<br> 来进行计算。</p></li><li><p>CUDA平台可以通过CUDA加速库、编译器指令、应用编程接口以及行业标准程序语<br> 言的扩展（包括C、C++、Fortran、Python，如图1-12所示）来使用。<br> 本书重点介绍CUDAC的编程。</p></li><li><p>CUDA C是标准ANSI C语言的一个扩展，它带有的少数语言扩展功能使异构编程成为<br> 可能，同时也能通过API来管理设备、内存和其他任务。CUDA还是一个可扩展的编程模<br> 型，它使程序能对有不同数量核的GPU明显地扩展其并行性，同时对熟悉C编程语言的程<br> 序员来说也比较容易上手。</p></li></ul><figure><img src="'+y+'" alt="figure1-12" tabindex="0" loading="lazy"><figcaption>figure1-12</figcaption></figure><ul><li>CUDA提供了两层API来管理GPU设备和组织线程，如图1-13所示。</li></ul><figure><img src="'+x+'" alt="figure1-13" tabindex="0" loading="lazy"><figcaption>figure1-13</figcaption></figure><ul><li><p><mark>CUDA驱动API</mark></p></li><li><p><mark>CUDA运行时API</mark></p></li><li><p>驱动API是一种低级API，它相对来说较难编程，但是它对于在GPU设备使用上提供了<br> 更多的控制。运行时API是一个高级API，它在驱动API的上层实现。每个运行时API函数<br> 都被分解为更多传给驱动API的基本运算。</p></li><li><p><mark>运行时API与驱动API</mark></p></li><li><p>运行时API和驱动API之间没有明显的性能差异。在设备端，内核是如何使用内存以<br> 及你是如何组织线程的，对性能有更显著的影响。</p></li><li><p>这两种API是相互排斥的，你必须使用两者之一，从两者中混合函数调用是不可能<br> 的。本书中所有例子都使用运行时API。</p></li><li><p>一个CUDA程序包含了以下两个部分的混合。</p><ul><li>在CPU上运行的主机代码</li><li>在GPU上运行的设备代码</li></ul></li><li><p>NVIDIA的CUDA nvcc编译器在编译过程中将设备代码从主机代码中分离出来。如图1-<br> 14所示，主机代码是标准的C代码，使用C编译器进行编译。设备代码，也就是核函数，<br> 是用扩展的带有标记数据并行函数关键字的CUDA C语言编写的。设备代码通过nvcc进行<br> 编译。在链接阶段，在内核程序调用和显示GPU设备操作中添加CUDA运行时库。</p></li></ul><figure><img src="'+w+'" alt="figure1-14" tabindex="0" loading="lazy"><figcaption>figure1-14</figcaption></figure><ul><li>CUDA nvcc编译器是以广泛使用LLVM开源编译系统为基础的。在GPU加速器的支持<br> 下，通过使用CUDA编译器SDK，你可以创建或扩展编程语言，如图1-15所示。</li></ul><figure><img src="'+H+'" alt="figure1-15" tabindex="0" loading="lazy"><figcaption>figure1-15</figcaption></figure>',52),V=l("br",null,null,-1),z=l("br",null,null,-1),F=l("br",null,null,-1),B={href:"http://deve-loper.nvidia.com/cuda-toolkit%EF%BC%89%EF%BC%8C",target:"_blank",rel:"noopener noreferrer"},R=l("br",null,null,-1),L=l("br",null,null,-1),K=l("img",{src:M,alt:"figure1-16",loading:"lazy"},null,-1),q=t('<h2 id="_1-3-用gpu输出hello-world" tabindex="-1"><a class="header-anchor" href="#_1-3-用gpu输出hello-world" aria-hidden="true">#</a> 1.3 用GPU输出Hello World</h2><ul><li><p>学习一门新编程语言的最好方法就是使用这门新语言编写程序。在本节中，您将编写第一个在 GPU 上运行的内核代码(kernel code)。第一个程序对所有语言都是一样的： 打印字符串 &quot;Hello World&quot;。</p></li><li><p>如果这是您第一次使用 CUDA，您可能需要在 Linux 系统上使用以下命令检查 CUDA 编译器是否安装正确：$ which nvcc 就像在Linux 上使用 which 命令检查 gcc 是否安装正确一样。</p></li><li><p>典型的回答是：/usr/local/cuda/bin/nvcc or /usr/bin/nvcc</p></li></ul><br><ul><li><p>您还需要检查机器是否安装了 GPU 加速卡。您可以在 Linux 系统上使用以下命令进行检查：$ ls -l /dev/nv*</p></li><li><p>命令 ls -l /dev/nv* 是在类Unix系统（如Linux）中使用的一个shell命令，用于列出与NVIDIA GPU相关的设备文件。</p></li><li><p>在这个例子中，你安装了两个GPU卡（不同的用户配置可能有所不同，因此显示结果会有所差异）。</p></li><li><p>设备上的回答： /dev/nvram<br> crw-rw-rw- 1 root root 195, 0 Jul 3 13:44 /dev/nvidia0<br> crw-rw-rw- 1 root root 195, 1 Jul 3 13:44 /dev/nvidia1<br> crw-rw-rw- 1 root root 195, 255 Jul 3 13:44 /dev/nvidiactl<br> crw-rw---- 1 root root 10, 144 Jul 3 13:39 /dev/nvram</p></li></ul><br><ul><li><p>Now you are ready to write your first CUDA C code. To write a CUDA C program, you need to:</p><ul><li>1：创建一个源代码文件(source code file)，文件名扩展名为 .cu。</li><li>2: 使用 CUDA nvcc 编译器编译程序。</li><li>3: 从命令行运行可执行文件(command line)，其中包含可在 GPU 上执行的内核代码。</li></ul></li><li><p>下面是程序展示：可点击进行展开查看</p></li></ul>',6),O={class:"hint-container details"},$=l("summary",null,"Click me to view the code!",-1),J=l("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[l("pre",{class:"language-cpp"},[l("code",null,[l("span",{class:"token macro property"},[l("span",{class:"token directive-hash"},"#"),l("span",{class:"token directive keyword"},"include"),n(),l("span",{class:"token string"},"<stdio.h>")]),n(`
`),l("span",{class:"token keyword"},"int"),n(),l("span",{class:"token function"},"main"),l("span",{class:"token punctuation"},"("),l("span",{class:"token keyword"},"void"),l("span",{class:"token punctuation"},")"),n(`
`),l("span",{class:"token punctuation"},"{"),n(`
    `),l("span",{class:"token function"},"printf"),l("span",{class:"token punctuation"},"("),l("span",{class:"token string"},'"Hello World from CPU!\\n"'),l("span",{class:"token punctuation"},")"),l("span",{class:"token punctuation"},";"),n(`
    `),l("span",{class:"token keyword"},"return"),n(),l("span",{class:"token number"},"0"),l("span",{class:"token punctuation"},";"),n(`
`),l("span",{class:"token punctuation"},"}"),n(`
`)])]),l("div",{class:"line-numbers","aria-hidden":"true"},[l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"})])],-1),Q=l("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[l("pre",{class:"language-cpp"},[l("code",null,[l("span",{class:"token macro property"},[l("span",{class:"token directive-hash"},"#"),l("span",{class:"token directive keyword"},"include"),n(),l("span",{class:"token string"},"<stdio.h>")]),n(`
`),l("span",{class:"token keyword"},"int"),n(),l("span",{class:"token function"},"main"),l("span",{class:"token punctuation"},"("),l("span",{class:"token keyword"},"void"),l("span",{class:"token punctuation"},")"),n(`
`),l("span",{class:"token punctuation"},"{"),n(`
    `),l("span",{class:"token function"},"printf"),l("span",{class:"token punctuation"},"("),l("span",{class:"token string"},'"Hello World from CPU!\\n"'),l("span",{class:"token punctuation"},")"),l("span",{class:"token punctuation"},";"),n(`
    `),l("span",{class:"token keyword"},"return"),n(),l("span",{class:"token number"},"0"),l("span",{class:"token punctuation"},";"),n(`
`),l("span",{class:"token punctuation"},"}"),n(`
`)])]),l("div",{class:"line-numbers","aria-hidden":"true"},[l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"})])],-1),j=l("div",{class:"language-markdown line-numbers-mode","data-ext":"md"},[l("pre",{class:"language-markdown"},[l("code",null,[l("span",{class:"token list punctuation"},"-"),n(` 将代码保存到文件 hello.cu 中，然后使用 nvcc 进行编译。CUDA nvcc 编译器的语义与 gcc 和其他编译器类似。
`),l("span",{class:"token list punctuation"},"-"),n(` $ nvcc hello.cu -o hello
`),l("span",{class:"token list punctuation"},"-"),n(` 如果你运行可执行文件hello，将会输出：
Hello World from CPU!
`)])]),l("div",{class:"line-numbers","aria-hidden":"true"},[l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"})])],-1),X=l("li",null,[l("p",null,"接下来，编写一个内核函数，命名为helloFromGPU，用它来输出字符串“Hello World from GPU！”。")],-1),Y=l("li",null,[l("p",null,[n("修饰符__global__告诉编译器这个函数将会从CPU中调用，然后在GPU上执行。用下面的代码启动内核函数。"),l("code",null,"hello_from_gpu<<<1,10>>>();")])],-1),Z=l("li",null,[l("p",null,[n("三重尖括号意味着从主线程到设备端代码的调用。一个内核函数通过一组线程来执"),l("br"),n(" 行，所有线程执行相同的代码。三重尖括号里面的参数是执行配置，用来说明使用多少线"),l("br"),n(" 程来执行内核函数。在这个例子中，有10个GPU线程被调用。综上所述，得到代码清单1-1所示的程序。")])],-1),ll=l("li",null,[l("p",null,"函数 cudaDeviceReset() 将明确销毁并清理当前进程中与当前设备相关(the current device in the current process)的所有资源(resources)。在 nvcc 命令行中使用 -arch sm_20 开关编译代码，如下所示：")],-1),nl={href:"http://hello.cu",target:"_blank",rel:"noopener noreferrer"},il={class:"hint-container details"},al=l("summary",null,"Click me to view the code!",-1),el=l("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[l("pre",{class:"language-cpp"},[l("code",null,[l("span",{class:"token macro property"},[l("span",{class:"token directive-hash"},"#"),l("span",{class:"token directive keyword"},"include"),l("span",{class:"token string"},"<stdio.h>")]),n(`

__global__ `),l("span",{class:"token keyword"},"void"),n(),l("span",{class:"token function"},"hello_from_gpu"),l("span",{class:"token punctuation"},"("),l("span",{class:"token punctuation"},")"),n(`
`),l("span",{class:"token punctuation"},"{"),n(`
    `),l("span",{class:"token function"},"printf"),l("span",{class:"token punctuation"},"("),l("span",{class:"token string"},'"hello from the gpu\\n"'),l("span",{class:"token punctuation"},")"),l("span",{class:"token punctuation"},";"),n(`
`),l("span",{class:"token punctuation"},"}"),n(`
`),l("span",{class:"token keyword"},"int"),n(),l("span",{class:"token function"},"main"),l("span",{class:"token punctuation"},"("),l("span",{class:"token keyword"},"void"),l("span",{class:"token punctuation"},")"),l("span",{class:"token punctuation"},"{"),n(`

    `),l("span",{class:"token comment"},"// hello from cpu"),n(`
    `),l("span",{class:"token function"},"printf"),l("span",{class:"token punctuation"},"("),l("span",{class:"token string"},'"hello from the cpu\\n"'),l("span",{class:"token punctuation"},")"),l("span",{class:"token punctuation"},";"),n(`


    hello_from_gpu`),l("span",{class:"token operator"},"<<"),l("span",{class:"token operator"},"<"),l("span",{class:"token number"},"1"),l("span",{class:"token punctuation"},","),l("span",{class:"token number"},"10"),l("span",{class:"token operator"},">>"),l("span",{class:"token operator"},">"),l("span",{class:"token punctuation"},"("),l("span",{class:"token punctuation"},")"),l("span",{class:"token punctuation"},";"),n(`
    `),l("span",{class:"token function"},"cudaDeviceReset"),l("span",{class:"token punctuation"},"("),l("span",{class:"token punctuation"},")"),l("span",{class:"token punctuation"},";"),n(`
    `),l("span",{class:"token keyword"},"return"),n(),l("span",{class:"token number"},"0"),l("span",{class:"token punctuation"},";"),n(`
`),l("span",{class:"token punctuation"},"}"),n(`
`)])]),l("div",{class:"line-numbers","aria-hidden":"true"},[l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"})])],-1),sl=l("div",{class:"language-markdown line-numbers-mode","data-ext":"md"},[l("pre",{class:"language-markdown"},[l("code",null,[n(`$ nvcc -arch sm_20 hello.cu -o hello

`),l("span",{class:"token list punctuation"},"-"),n(" 开关 "),l("span",{class:"token code-snippet code keyword"},"`-arch sm_20`"),n(`  会使编译器生成 Fermi架构的设备代码。运行可执行文件，
`),l("span",{class:"token list punctuation"},"-"),n(` 它将中打印 10 个 "Hello World from GPU!"字符串从每个线程，如下所示。
\`\`\`cu
$ ./hello
Hello World from CPU!
Hello World from GPU!
Hello World from GPU!
Hello World from GPU!
Hello World from GPU!
Hello World from GPU!
Hello World from GPU!
Hello World from GPU!
Hello World from GPU!
Hello World from GPU!
Hello World from GPU!

`)])]),l("div",{class:"line-numbers","aria-hidden":"true"},[l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"}),l("div",{class:"line-number"})])],-1),rl=t('<ul><li><p><mark>CUDA PROGRAM STRUCTURE CUDA程序结构</mark></p></li><li><p>A typical CUDA program structure consists of five main steps:</p></li><li><p>1、Allocate GPU memories. 申请GPU内存</p></li><li><p>2、Copy data from CPU memory to GPU memory. 将数据从主机复制到设备</p></li><li><p>3、Invoke the CUDA kernel to perform program-specifi c computation.调用 CUDA 内核执行程序特定计算</p></li><li><p>4、Copy data back from GPU memory to CPU memory.将数据从 GPU 内存拷贝回 CPU 内存。</p></li><li><p>5、Destroy GPU memories。销毁 GPU 内存</p></li><li><p><mark>一个典型的CUDA编程结构包括5个主要步骤</mark><br> 1.分配GPU内存。<br> 2.从CPU内存中拷贝数据到GPU内存。<br> 3.调用CUDA内核函数来完成程序指定的运算。<br> 4.将数据从GPU拷回CPU内存。<br> 5.释放GPU内存空间。</p></li><li><p>在hello.cu中，你只看到了第三步：调用内核。本书其他部分的示例代码是完全按照<br> CUDA编程结构来编写的。</p></li></ul><h2 id="_1-4-使用cudac编程难吗" tabindex="-1"><a class="header-anchor" href="#_1-4-使用cudac编程难吗" aria-hidden="true">#</a> 1.4 使用CUDAC编程难吗</h2><ul><li><p>CPU编程和GPU编程的主要区别是程序员对GPU架构的熟悉程度。用并行思维进行思<br> 考并对GPU架构有了基本的了解，会使你编写规模达到成百上千个核的并行程序，如同写<br> 串行程序一样简单。</p></li><li><p>如果你想编写一个像并行程序一样高效的代码，那么你需要对CPU架构有基本的了<br> 解。例如，数据局部性在并行编程中是一个非常重要的概念。数据局部性指的是数据重<br> 用，以降低内存访问的延迟。</p></li><li><p>数据局部性有两种基本类型。时间局部性是指在相对较短的<br> 时间段内数据和/或资源的重用。空间局部性是指在相对较接近的存储空间内数据元素的<br> 重用。</p></li><li><p>现代的CPU架构使用大容量缓存来优化具有良好空间局部性和时间局部性的应用程<br> 序。设计高效利用CPU缓存的算法是程序员的工作。程序员必须处理低层的缓存优化，但<br> 由于线程在底层架构中的安排是透明的，所以这一点程序员是没有办法优化的。</p></li><li><p>CUDA中有内存层次和线程层次的概念，使用如下结构，有助于你对线程执行进行更<br> 高层次的控制和调度：</p><ul><li>内存层次结构</li><li>线程层次结构</li></ul></li><li><p>例如，在CUDA编程模型中使用的共享内存（一个特殊的内存）。共享内存可以视为<br> 一个被软件管理的高速缓存，通过为主内存节省带宽来大幅度提高运行速度。有了共享内<br> 存，你可以直接控制代码的数据局部性。</p></li><li><p>当用ANSI C语言编写一个并行程序时，你需要使用pthreads或者OpenMP来显式地组织<br> 线程，这两项技术使得在大多数处理器架构以及操作系统中支持并行编程。当用CUDA C<br> 编写程序时，实际上你只编写了被单个线程调用的一小段串行代码。GPU处理这个内核函<br> 数，然后通过启动成千上万个线程来实现并行化，所有的线程都执行相同的计算。CUDA<br> 编程模型提供了一个层次化地组织线程的方法，它直接影响到线程在GPU上的执行顺序。<br> 因为CUDA C是C语言的扩展，通常可以直接将C程序移植到CUDA C程序中。概念上，剥<br> 离代码中的循环后产生CUDA C实现的内核代码。</p></li><li><p>CUDA抽象了硬件细节，且不需要将应用程序映射到传统图形API上。CUDA核中有3<br> 个关键抽象：线程组的层次结构，内存的层次结构以及障碍同步。这3个抽象是最小的一<br> 组语言扩展。随着CUDA版本的更新，NVIDIA正在对并行编程进行不断简化。尽管一些<br> 人仍然认为CUDA的概念比较低级，但如果稍稍提高抽象级，对你控制应用程序和平台之<br> 间的互动关系来说会增加很大难度。如果那样的话，不管你掌握了多少底层架构的知识，<br> 你的应用程序的性能都将超出控制。</p></li><li><p>因此，你的目标应是学习GPU架构的基础及掌握CUDA开发工具和环境。</p></li></ul><br><ul><li><mark>CUDA开发环境</mark></li><li>NVIDIA为C和C++开发人员提供了综合的开发环境以创建GPU加速应用程序，包括以下几种。<br> NVIDIA Nsight集成开发环境<br> CUDA-GDB命令行调试器<br> 用于性能分析的可视化和命令行分析器<br> CUDA-MEMCHECK内存分析器<br> GPU设备管理工具</li><li>当你熟悉这些工具的使用之后，你会发现使用CUDA C语言进行编程是非常简单高效的</li></ul><h2 id="_1-5-总结" tabindex="-1"><a class="header-anchor" href="#_1-5-总结" aria-hidden="true">#</a> 1.5 总结</h2><ul><li><p>随着计算机架构和并行编程模型的发展，逐渐有了现在所用的异构系统。CUDA平台<br> 帮助提高了异构架构的性能和程序员的工作效率。</p></li><li><p>CPU＋GPU的异构系统在高性能计算领域已经成为主流。这种变化使并行设计范例有<br> 了根本性转变：在GPU上执行数据并行工作，而在CPU上执行串行和任务并行工作</p></li><li><p>作为完整的GPU计算架构，Fermi和Kepler GPU加速器让许多领域的高性能计算水平<br> 有了提高。在阅读和理解本书中这些概念后，你会发现，在异构系统中编写一个具有成百<br> 上千个核的CUDA程序就像编写一个串行程序那样简单。</p></li></ul><h2 id="_1-6-习题" tabindex="-1"><a class="header-anchor" href="#_1-6-习题" aria-hidden="true">#</a> 1.6 习题</h2>',8),tl=t("<li><p>1.参考图1-5，分析以下几种数据划分形式：<br> （1）对于二维数据，沿x轴进行块划分<br> （2）对于二维数据，沿y轴进行周期划分<br> （3）对于三维数据，沿z轴进行周期划分</p></li><li><p>2.从hello.cu中移除cudaDeviceReset函数，然后编译运行，看看会发生什么。<br><code>如果去掉了cudaDeviceReset，本地实验仅仅 是 输出改变了，仅仅输出了第一行的Hello World from CPU!</code></p></li><li><p>3.用cudaDeviceSynchronize函数来替换hello.cu中的cudaDeviceReset函数，然后编译运行，看看会发生什么。<br><code>结果一样；</code><br><code>但是应该理解 两个函数 的 区别 以及 具体的作用的过程底层、cudaDeviceReset 将会等待这些内核执行完成。</code></p></li><li><p>4.参考1.3节，从编译器命令行中移除设备架构标志，然后按照下面的方式进行编译，<br> 看看会发生什么。<code>nvcc hello.cu -o hello</code></p></li>",4),ol={href:"http://docs.nvidia.com/cuda/index.html%EF%BC%89%E3%80%82%E5%9F%BA%E4%BA%8E%E2%80%9CCUDA%E7%BC%96%E8%AF%91%E5%99%A8%E9%A9%B1",target:"_blank",rel:"noopener noreferrer"},pl=l("br",null,null,-1),cl=l("li",null,[l("p",null,[n("6.为执行核函数的每个线程提供了一个唯一的线程ID，通过内置变量threadIdx.x可以"),l("br"),n(" 在内核中对线程进行访问。在hello.cu中修改核函数的线程索引，使输出如下："),l("br"),n(" $ ./hello"),l("br"),n(" Hello World from CPU!"),l("br"),n(" Hello World from GPU thread 5!")])],-1),ul=t(`<div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span><span class="token string">&lt;stdio.h&gt;</span></span>


__global__ <span class="token keyword">void</span> <span class="token function">hello_from_gpu</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">{</span>   
    <span class="token keyword">int</span> idx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
    <span class="token keyword">if</span><span class="token punctuation">(</span>idx <span class="token operator">==</span> <span class="token number">5</span><span class="token punctuation">)</span>
    <span class="token punctuation">{</span>
        <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">&quot;hello from the gpu thread %d\\n&quot;</span><span class="token punctuation">,</span>idx<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
    
<span class="token punctuation">}</span>
<span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span><span class="token punctuation">{</span>

    <span class="token comment">// hello from cpu</span>
    <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">&quot;hello from the cpu\\n&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


    hello_from_gpu<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">//cudaDeviceReset();</span>
    <span class="token function">cudaDeviceSynchronize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,1);function dl(bl,ml){const e=p("router-link"),o=p("ExternalLinkIcon"),c=p("CodeTabs");return d(),b("div",null,[S,T,m(" more "),l("nav",W,[l("ul",null,[l("li",null,[a(e,{to:"#简单介绍主要是基础"},{default:i(()=>[n("简单介绍主要是基础")]),_:1})]),l("li",null,[a(e,{to:"#第1章-heterogeneous-parallel-computing-with-cuda"},{default:i(()=>[n("第1章 Heterogeneous Parallel Computing with CUDA")]),_:1})]),l("li",null,[a(e,{to:"#_1-1-并行计算"},{default:i(()=>[n("1.1 并行计算")]),_:1}),l("ul",null,[l("li",null,[a(e,{to:"#_1-1-1-串行编程和并行编程"},{default:i(()=>[n("1.1.1 串行编程和并行编程")]),_:1})]),l("li",null,[a(e,{to:"#_1-1-2-并行性"},{default:i(()=>[n("1.1.2 并行性")]),_:1})]),l("li",null,[a(e,{to:"#_1-1-3-计算机架构"},{default:i(()=>[n("1.1.3 计算机架构")]),_:1})])])]),l("li",null,[a(e,{to:"#_1-2-异构计算"},{default:i(()=>[n("1.2 异构计算")]),_:1}),l("ul",null,[l("li",null,[a(e,{to:"#_1-2-1-异构架构"},{default:i(()=>[n("1.2.1 异构架构")]),_:1})]),l("li",null,[a(e,{to:"#_1-2-2-异构计算范例"},{default:i(()=>[n("1.2.2 异构计算范例")]),_:1})]),l("li",null,[a(e,{to:"#_1-2-3-cuda-一种异构计算平台"},{default:i(()=>[n("1.2.3 CUDA：一种异构计算平台")]),_:1})])])]),l("li",null,[a(e,{to:"#_1-3-用gpu输出hello-world"},{default:i(()=>[n("1.3 用GPU输出Hello World")]),_:1})]),l("li",null,[a(e,{to:"#_1-4-使用cudac编程难吗"},{default:i(()=>[n("1.4 使用CUDAC编程难吗")]),_:1})]),l("li",null,[a(e,{to:"#_1-5-总结"},{default:i(()=>[n("1.5 总结")]),_:1})]),l("li",null,[a(e,{to:"#_1-6-习题"},{default:i(()=>[n("1.6 习题")]),_:1})])])]),E,l("ul",null,[l("li",null,[n("CUDA平台也是支持多样化并行计算生态系统的基础，如图1-16所示。现在，随着越"),V,n(" 来越多的公司可以提供全球性的工具、服务和解决方案，CUDA生态系统迅速成长。如果"),z,n(" 你想在GPU上建立你的应用程序，强化GPU性能的最简单方法是使用CUDA工具包"),F,n(" （"),l("a",B,[n("http://deve-loper.nvidia.com/cuda-toolkit），"),a(o)]),R,n(" 它为C和C++开发人员提供了一个综合的开发环境。CUDA工具包包括编译器、数学库，以及调试和优化应用程序性能的工具。同时提供了代码样例、编程指南、用户手册、API参考文档和其他帮助你入门的文档。"),L,K])]),q,l("details",O,[$,a(c,{id:"955",data:[{id:"CPP"},{id:"CUDA"},{id:"编译运行"}],"tab-id":"shell"},{title0:i(({value:s,isActive:r})=>[n("CPP")]),title1:i(({value:s,isActive:r})=>[n("CUDA")]),title2:i(({value:s,isActive:r})=>[n("编译运行")]),tab0:i(({value:s,isActive:r})=>[J]),tab1:i(({value:s,isActive:r})=>[Q]),tab2:i(({value:s,isActive:r})=>[j]),_:1})]),l("ul",null,[X,Y,Z,ll,l("li",null,[l("p",null,[n("$ nvcc -arch sm_20 "),l("a",nl,[n("hello.cu"),a(o)]),n(" -o hello")])])]),l("details",il,[al,a(c,{id:"995",data:[{id:"CUDA"},{id:"编译运行"}],"tab-id":"shell"},{title0:i(({value:s,isActive:r})=>[n("CUDA")]),title1:i(({value:s,isActive:r})=>[n("编译运行")]),tab0:i(({value:s,isActive:r})=>[el]),tab1:i(({value:s,isActive:r})=>[sl]),_:1})]),rl,l("ul",null,[tl,l("li",null,[l("p",null,[n("5.参阅CUDA在线文档（"),l("a",ol,[n("http://docs.nvidia.com/cuda/index.html）。基于“CUDA编译器驱"),a(o)]),pl,n(" 动NVCC”一节，谈谈nvcc对带有哪些后缀的文件支持编译？")])]),cl]),ul])}const hl=u(N,[["render",dl],["__file","A-第一章.html.vue"]]);export{hl as default};
