import{_ as u}from"./plugin-vue_export-helper-c27b6911.js";import{r as i,o as r,c as k,d,a as n,e,w as a,b as s,f as c}from"./app-2a2d189a.js";const m="/assets/figure5-1-e6d8ddba.png",b="/assets/figure5-2-4cb3a37c.png",v="/assets/figure5-3-195ec0e0.png",_="/assets/figure5-4-64da09e1.png",h="/assets/figure5-5-27aa6ba8.png",y="/assets/figure5-6-b1434b15.png",x="/assets/figure5-7-e089eed6.png",g="/assets/figure5-8-cff38cb6.png",f="/assets/figure5-9-d61ce29d.png",w="/assets/figure5-10-d9ba2152.png",I="/assets/figure5-11-4c46a49d.png",D="/assets/figure5-12-2404fd34.png",S="/assets/figure5-13-e1b76790.png",R="/assets/figure5-14-5e4b35e1.png",M="/assets/table5-1-6517db27.png",C="/assets/table5-2-04e93fbf.png",B="/assets/figure5-15-fa42e7f0.png",A="/assets/figure5-16-ff314418.png",K="/assets/table5-3-1d55f831.png",U="/assets/table5-4-e4e22254.png",G="/assets/figure5-17-ca3877ce.png",T="/assets/table5-5-3ec8561e.png",P="/assets/table5-6-a17c4b88.png",q="/assets/table5-7-3d2c2f90.png",z="/assets/figure5-18-194024e7.png",X="/assets/figure5-19-a69eb8a1.png",E="/assets/figure5-20-fa3c12b6.png",Y="/assets/figure5-21-79686bc6.png",N="/assets/figure5-22-fb39d213.png",F="/assets/figure5-23-3ca6bd5e.png",L={},$=n("h1",{id:"e-第五章",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#e-第五章","aria-hidden":"true"},"#"),s(" E-第五章")],-1),W=n("p",null,"E-第五章",-1),V={class:"table-of-contents"},O=c('<h2 id="简单介绍主要是基础" tabindex="-1"><a class="header-anchor" href="#简单介绍主要是基础" aria-hidden="true">#</a> 简单介绍主要是基础</h2><div class="hint-container info"><p class="hint-container-title">说明</p><p>主要是各种搜索找的学习；</p><p>主题：CUDA核心GPU编程</p><p>前置条件：</p><ul><li>应具备C++编程知识</li><li>需理解内存管理，如malloc和free</li><li>理解STL及其模板机制</li><li>需配置NVIDIA显卡，型号需为900系列或更高</li><li>所用扩展要求版本为11或更新</li><li>编译器版本不低于11</li><li>CMake版本需在3.18以上</li></ul></div><h2 id="第5章-共享内存和常量内存" tabindex="-1"><a class="header-anchor" href="#第5章-共享内存和常量内存" aria-hidden="true">#</a> 第5章 共享内存和常量内存</h2><ul><li><p>本章内容：<br> ·了解数据在共享内存中是如何被安排的<br> ·掌握从二维共享内存到线性全局内存的索引转换<br> ·解决不同访问模式中存储体中的冲突<br> ·在共享内存中缓存数据以减少对全局内存的访问<br> ·使用共享内存避免非合并全局内存的访问<br> ·理解常量缓存和只读缓存之间的差异<br> ·使用线程束洗牌指令编程</p></li><li><p>在前面的章节中，已经介绍了几种全局内存的访问模式。通过安排全局内存访问模式<br> （它们是合并的），我们学会了如何实现良好的性能并且避免了浪费事务。未对齐的内存<br> 访问是没有问题的，因为现代的GPU硬件都有一级缓存，但在跨全局内存的非合并内存访<br> 问，仍然会导致带宽利用率不会达到最佳标准。根据算法性质和相应的访问模式，非合并<br> 访问可能是无法避免的。然而，在许多情况下，使用共享内存来提高全局内存合并访问是<br> 有可能的。共享内存是许多高性能计算应用程序的关键驱动力。</p></li><li><p>在本章中，你将学习如何使用共享内存进行编程、数据在共享内存中如何被存储、数<br> 据元素是怎样使用不同的访问模式被映射到内存存储体中的。还将掌握使用共享内存提高<br> 核函数性能的方法。</p></li></ul><h2 id="_5-1-cuda共享内存概述" tabindex="-1"><a class="header-anchor" href="#_5-1-cuda共享内存概述" aria-hidden="true">#</a> 5.1 CUDA共享内存概述</h2><ul><li><p>GPU中有两种类型的内存：<br> ·板载内存<br> ·片上内存</p></li><li><p>全局内存是较大的板载内存，具有相对较高的延迟。共享内存是较小的片上内存，具<br> 有相对较低的延迟，并且共享内存可以提供比全局内存高得多的带宽。可以把它当作一个<br> 可编程管理的缓存。共享内存通常的用途有：<br> ·块内线程通信的通道<br> ·用于全局内存数据的可编程管理的缓存<br> ·高速暂存存储器，用于转换数据以优化全局内存访问模式</p></li><li><p>在本章中，将通过两个例子学习共享内存编程：归约核函数、矩阵转置核函数。</p></li></ul><h3 id="_5-1-1-共享内存" tabindex="-1"><a class="header-anchor" href="#_5-1-1-共享内存" aria-hidden="true">#</a> 5.1.1 共享内存</h3><ul><li><p>共享内存（shared memory，SMEM）是GPU的一个关键部件。物理上，每个SM都有<br> 一个小的低延迟内存池，这个内存池被当前正在该SM上执行的线程块中的所有线程所共<br> 享。共享内存使同一个线程块中的线程能够互相协作，便于重用片上数据，并可以大大降<br> 低核函数所需的全局内存带宽。由于共享内存中的内容是由应用程序显式管理的，所以它<br> 通常被描述为可编程管理的缓存。</p></li><li><p>Fermi和Kepler GPU具有相似的内存层次结构，不同的是Kepler包括一个额外的编译器<br> 导向缓存，它用于只读数据。如图5-1所示，全局内存的所有加载和存储请求都要经过二<br> 级缓存，这是SM单元之间数据统一的基本点。注意，相较于二级缓存和全局内存，共享<br> 内存和一级缓存在物理上更接近SM。因此，共享内存相较于全局内存而言，延迟要低大<br> 约20～30倍，而带宽高其大约10倍。<br><img src="'+m+'" alt="figure5-1" loading="lazy"></p></li><li><p>当每个线程块开始执行时，会分配给它一定数量的共享内存。这个共享内存的地址空<br> 间被线程块中所有的线程共享。它的内容和创建时所在的线程块具有相同生命周期。每个<br> 线程束发出共享内存访问请求。在理想的情况下，每个被线程束共享内存访问的请求在一<br> 个事务中完成。最坏的情况下，每个共享内存的请求在32个不同的事务中顺序执行。如果<br> 多个线程访问共享内存中的同一个字，一个线程读取该字后，通过多播把它发送给其他线<br> 程。在以下几节中将介绍避免多事务共享内存请求的更多细节。</p></li><li><p>共享内存被SM中的所有常驻线程块划分，因此，共享内存是限制设备并行性的关键<br> 资源。一个核函数使用的共享内存越多，处于并发活跃状态的线程块就越少。</p></li></ul><br><ul><li><p><mark>可编程管理的缓存</mark></p></li><li><p>在C语言中，循环转换是一种常用的缓存优化方法。通过重新安排迭代顺序，循环转<br> 换可以在循环遍历的过程中提高缓存局部性。在算法层面上，在考虑缓存大小的同时，需<br> 要手动调整循环，以实现更好的空间局部性。缓存对程序而言是透明的，编译器可以处理<br> 所有的数据移动。我们不能控制缓存的释放。</p></li><li><p>共享内存是一个可编程管理的缓存。当数据移动到共享内存中以及数据被释放时，我<br> 们对它有充分的控制权。由于在CUDA中允许手动管理共享内存，所以通过在数据布局上<br> 提供更多的细粒度控制和改善片上数据的移动，使得对应用程序代码进行优化变得更简单<br> 了。</p></li></ul><h3 id="_5-1-2-共享内存分配" tabindex="-1"><a class="header-anchor" href="#_5-1-2-共享内存分配" aria-hidden="true">#</a> 5.1.2 共享内存分配</h3><ul><li><p>有多种方法可以用来分配或声明由应用程序请求所决定的共享内存变量。可以静态或<br> 动态地分配共享内存变量。在CUDA的源代码文件中，共享内存可以被声明为一个本地的<br> CUDA核函数或是一个全局的CUDA核函数。CUDA支持一维、二维和三维共享内存数组<br> 的声明。</p></li><li><p>共享内存变量用下列修饰符进行声明：<br><code>__shared__</code></p></li><li><p>下面的代码段静态声明了一个共享内存的二维浮点数组。如果在核函数中进行声明，<br> 那么这个变量的作用域就局限在该内核中。如果在文件的任何核函数外进行声明，那么这<br> 个变量的作用域对所有核函数来说都是全局的。<br><code>__shared__ float tile[size_y][size_x];</code></p></li><li><p>如果共享内存的大小在编译时是未知的，那么可以用extern关键字声明一个未知大小<br> 的数组。例如，下面的代码段声明了共享内存中一个未知大小的一维整型数组。这个声明<br> 可以在某个核函数的内部或所有核函数的外部进行。<br><code>extern __shared__ int tile[];</code></p></li><li><p>因为这个数组的大小在编译时是未知的，所以在每个核函数被调用时，需要动态分配<br> 共享内存，将所需的大小按字节数作为三重括号内的第三个参数，如下所示：<br><code>kernel&lt;&lt;&lt;grid, block, isize * sizeof(int)&gt;&gt;&gt;(...)</code></p></li><li><p>请注意，只能动态声明一维数组</p></li></ul><h3 id="_5-1-3-共享内存存储体和访问模式" tabindex="-1"><a class="header-anchor" href="#_5-1-3-共享内存存储体和访问模式" aria-hidden="true">#</a> 5.1.3 共享内存存储体和访问模式</h3><ul><li>优化内存性能时要度量的两个关键属性是：延迟和带宽。第4章解释了由不同的全局<br> 内存访问模式引起的延迟和带宽对核函数性能的影响。共享内存可以用来隐藏全局内存延<br> 迟和带宽对性能的影响。要想充分理解这些资源，了解共享内存是如何被安排的，对其将<br> 会有所帮助。</li></ul><br><ul><li><mark>5.1.3.1 内存存储体</mark></li><li>为了获得高内存带宽，共享内存被分为32个同样大小的内存模型，它们被称为存储<br> 体，它们可以被同时访问。有32个存储体是因为在一个线程束中有32个线程。共享内存是<br> 一个一维地址空间。根据GPU的计算能力，共享内存的地址在不同模式下会映射到不同的<br> 存储体中（稍后详述）。如果通过线程束发布共享内存加载或存储操作，且在每个存储体<br> 上只访问不多于一个的内存地址，那么该操作可由一个内存事务来完成。否则，该操作由<br> 多个内存事务来完成，这样就降低了内存带宽的利用率。</li></ul><br><ul><li><p><mark>5.1.3.2 存储体冲突</mark></p></li><li><p>在共享内存中当多个地址请求落在相同的内存存储体中时，就会发生存储体冲突，这<br> 会导致请求被重复执行。硬件会将存储体冲突的请求分割到尽可能多的独立的无冲突事务<br> 中，有效带宽的降低是由一个等同于所需的独立内存事务数量的因素导致的。</p></li><li><p>当线程束发出共享内存请求时，有以下3种典型的模式：<br> ·并行访问：多个地址访问多个存储体<br> ·串行访问：多个地址访问同一个存储体<br> ·广播访问：单一地址读取单一存储体</p></li><li><p>并行访问是最常见的模式，它是被一个线程束访问的多个地址落在多个存储体中。这<br> 种模式意味着，如果不是所有的地址，那么至少有一些地址可以在一个单一的内存事务中<br> 被服务。最佳情况是，当每个地址都位于一个单独的存储体中时，执行无冲突的共享内存<br> 访问。</p></li><li><p>串行访问是最坏的模式，当多个地址属于同一个存储体时，必须以串行的方式进行请<br> 求。如果线程束中32个线程全都访问同一存储体中不同的内存地址，那么将需要32个内存<br> 事务，并且满足这些访问所消耗的时间是单一请求的32倍。</p></li><li><p>在广播访问的情况下，线程束中所有的线程都读取同一存储体中相同的地址。若一个<br> 内存事务被执行，那么被访问的字就会被广播到所有请求的线程中。虽然一个单一的内存<br> 事务只需要一个广播访问，但是因为只有一小部分字节被读取，所以带宽利用率很差。</p></li><li><p>图5-2显示了最优的并行访问模式。每个线程访问一个32位字。因为每个线程访问不<br> 同存储体中的地址，所以没有存储体冲突。图5-3显示了不规则的随机访问模式。因为每<br> 个线程访问不同的存储体，所以也没有存储体冲突。图5-4显示了另一种不规则的访问模<br> 式，在这里几个线程访问同一存储体。对于这样一个请求，会产生两种可能的行为：<br> ·如果线程访问同一个存储体中相同的地址，广播访问无冲突<br> ·如果线程访问同一个存储体中不同的地址，会发生存储体冲突<br><img src="'+b+'" alt="figure5-2" loading="lazy"></p><figure><img src="'+v+'" alt="figure5-3" tabindex="0" loading="lazy"><figcaption>figure5-3</figcaption></figure><figure><img src="'+_+'" alt="figure5-4" tabindex="0" loading="lazy"><figcaption>figure5-4</figcaption></figure></li></ul><br><ul><li><p><mark>5.1.3.3 访问模式</mark></p></li><li><p>共享内存存储体的宽度规定了共享内存地址与共享内存存储体的对应关系。内存存储<br> 体的宽度随设备计算能力的不同而变化。有两种不同的存储体宽度：<br> ·计算能力2.x的设备中为4字节（32位）<br> ·计算能力3.x的设备中为8字节（64位）</p></li><li><p>对于Fermi设备，存储体的宽度是32位并且有32个存储体。每个存储体在每两个时钟<br> 周期内都有32位的带宽。连续的32位字映射到连续的存储体中。因此，从共享内存地址到<br> 存储体索引的映射可以按如下公式进行计算：<br> 存储体索引＝（字节地址÷4字节/存储体）%32存储体</p></li><li><p>字节地址除以4转换为一个4字节字索引，然后进行模32操作，将4字节字索引转换为<br> 存储体索引。图5-5所示的上部显示了在Fermi设备中从字节地址到字索引的映射。下部显<br> 示了从字索引到存储体索引的映射。注意，存储体成员线束相差32个字。邻近的字被分到<br> 不同的存储体中，以最大限度地提高线程束中可能的并发访问数量。</p></li><li><p>当来自相同线程束中的两个线程访问相同的地址时，不会发生存储体冲突。在这种情<br> 况下，对于读访问，这个字被广播到请求的线程中；对于写访问，这个字只能由其中一个<br> 线程写入，执行这个写入操作的线程是不确定的。</p></li></ul><figure><img src="'+h+'" alt="figure5-5" tabindex="0" loading="lazy"><figcaption>figure5-5</figcaption></figure><ul><li><p>对于Kepler设备，共享内存有32个存储体，它们有以下两种地址模式：<br> ·64位模式<br> ·32位模式</p></li><li><p>在64位模式下，连续的64位字映射到连续的存储体中。在每时钟周期内每个存储体都<br> 有64位的带宽。从共享内存地址到存储体索引的映射可以按以下公式进行计算：<br> 存储体索引＝（字节地址÷8字节/存储体）%32存储体</p></li><li><p>如果两个线程访问同一个64位字中的任何子字，从线程束发出的共享内存请求就不会<br> 产生存储体冲突，因为满足这两个请求只需要一个64位的读操作。因此，在相同的访问模<br> 式下，相对于Fermi架构，在Kepler架构上，64位模式总是产生相同或更少的存储体冲<br> 突。</p></li><li><p>在32位模式下，连续的32位字映射到连续的存储体中。然而，因为Kepler在每个时钟<br> 周期内都有64位带宽，在同一存储体中访问两个32位字并不总意味重操作。在单一的时钟<br> 周期内读64位并只将32位请求传输给每个线程，这是有可能的。图5-6显示了在32位模式<br> 下从字节地址到存储体索引的映射。上部的图是字节地址和4字节字索引标记的共享内<br> 存。下部的图显示了从4字节字索引到存储体索引的映射。虽然word 0和word 32都在bank<br> 0中，但是在相同的内存请求中读取这两个字不会产生存储体冲突。</p></li><li><p>图5-7显示了在64位模式下无冲突访问的一种情况，在这种情况下，每个线程访问不<br> 同的存储体。图5-8显示了在64位模式下无冲突访问的另一种情况，在这种情况下，两个<br> 线程访问相同存储体中的字和相同的8字节字。图5-9展示了一个双向存储体冲突，在这种<br> 情况下，两个线程访问同一个存储体，但地址落在两个不同的8字节字中。图5-10展示了<br> 一个三向存储体冲突，在这种情况下，3个线程访问相同的存储体，并且地址落在3个不同<br> 的8字节字中。</p></li></ul><figure><img src="'+y+'" alt="figure5-6" tabindex="0" loading="lazy"><figcaption>figure5-6</figcaption></figure><figure><img src="'+x+'" alt="figure5-7" tabindex="0" loading="lazy"><figcaption>figure5-7</figcaption></figure><figure><img src="'+g+'" alt="figure5-8" tabindex="0" loading="lazy"><figcaption>figure5-8</figcaption></figure><figure><img src="'+f+'" alt="figure5-9" tabindex="0" loading="lazy"><figcaption>figure5-9</figcaption></figure><figure><img src="'+w+'" alt="figure5-10" tabindex="0" loading="lazy"><figcaption>figure5-10</figcaption></figure><br><ul><li><p><mark>5.1.3.4 内存填充</mark></p></li><li><p>内存填充是避免存储体冲突的一种方法。图5-11所示为通过一个简单的例子来说明内<br> 存填充。假设只有5个共享内存存储体。如果所有线程访问bank 0的不同地址，那么会发<br> 生一个五向的存储体冲突。解决这种存储体冲突的一个方法是在每N个元素之后添加一个<br> 字，这里的N是存储体的数量。这就改变了从字到存储体的映射，如图5-11的右侧所示。</p></li><li><p>由于填充，之前所有属于bank 0的字，现在被传播到了不同的存储体中。</p></li><li><p>填充的内存不能用于数据存储。其唯一的作用是移动数据元素，以便将原来属于同一<br> 个存储体中的数据分散到不同存储体中。这样，线程块可用的总的共享内存的数量将减<br> 少。填充之后，还需要重新计算数组索引以确保能访问到正确的数据元素。</p></li><li><p>虽然Fermi和Kepler都有32个存储体，但它们的存储体宽度不同。在这些不同的架构<br> 上填充共享内存时，必须要小心。Fermi架构中的某些内存填充模式可能会导致Kepler中<br> 的存储体冲突。<br><img src="'+I+`" alt="figure5-11" loading="lazy"></p></li></ul><br><ul><li><p><mark>5.1.3.5 访问模式配置</mark></p></li><li><p>之前提到过，Kepler设备支持4字节和8字节的共享内存访问模式。默认是4字节模<br> 式。可采用以下的CUDA运行时API函数查询访问模式：<br><code>cudaError_t cudaDeviceGetSharedMemConfig(cudaSharedMemConfig *pConfig);</code></p></li><li><p>结果返回到pConfig中。返回的存储体配置可以是下列值中的一个：<br><code>cudaSharedMemBankSizeFourByte </code><br><code>cudaSharedMemBankSizeEightByte</code></p></li><li><p>在可配置共享内存存储体的设备上，可以使用以下功能设置一个新的存储体大小：<br><code>cudaError_t cudaDeviceSetSharedMemConfig(cudaSharedMemConfig config);</code></p></li><li><p>支持的存储体配置为：<br><code>cudaSharedMemBankSizeDefault </code><br><code>cudaSharedMemBankSizeFourByte</code><br><code>cudaSharedMemBankSizeEightByte</code></p></li><li><p>在不同的核函数启动之间更改共享内存配置可能需要一个隐式的设备同步点。更改共<br> 享内存存储体的大小不会增加共享内存的使用量，也不会影响核函数的占用率，但它对性<br> 能可能有重大影响。一个大的存储体可能为共享内存访问产生更高的带宽，但是可能会导<br> 致更多的存储体冲突，这取决于应用程序中共享内存的访问模式。</p></li></ul><h3 id="_5-1-4-配置共享内存量" tabindex="-1"><a class="header-anchor" href="#_5-1-4-配置共享内存量" aria-hidden="true">#</a> 5.1.4 配置共享内存量</h3><ul><li><p>每个SM都有64 KB的片上内存。共享内存和一级缓存共享该硬件资源。CUDA为配置<br> 一级缓存和共享内存的大小提供了两种方法：<br> ·按设备进行配置<br> ·按核函数进行配置</p></li><li><p>使用下述的运行时函数，可以为在设备上启动的核函数配置一级缓存和共享内存的大小：<br><code>cudaError_t cudaDeviceSetCacheConfig(cudaFuncCache cacheConfig);</code></p></li><li><p>参数cacheConfig指明，在当前的CUDA设备上，片上内存是如何在一级缓存和共享内<br> 存间进行划分的。所支持的缓存配置参数如下所示：<br><code>cudaFuncCachePreferNone: no preference(default)</code><br><code>cudaFuncCachePreferShared: prefer 48KB shared memory and 16 KB L1 cache</code><br><code>cudaFuncCachePreferL1: prefer 48KB L1 cache and 16 KB shared memory</code><br><code>cudaFuncCachePreferEqual: prefer 32KB L1 cache and 32 KB shared memory</code></p></li><li><p>哪种模式更好，这取决于在核函数中使用了多少共享内存。典型情况如下：<br> ·当核函数使用较多的共享内存时，倾向于更多的共享内存<br> ·当核函数使用更多的寄存器时，倾向于更多的一级缓存</p></li><li><p>如果核函数使用了大量的共享内存，那么配置48 KB的共享内存能实现较高的占用率<br> 和更好的性能。另一方面，如果核函数仅使用了少量的共享内存，那么应该为一级缓存配<br> 置cacheConfig参数为48 KB。对Kepler设备而言，一级缓存用于寄存器溢出。指定-Xptxas￾v选项给nvcc，<br> 可以知道核函数使用了多少寄存器。当内核使用的寄存器数量超过了硬件<br> 限制所允许的数量时，应该为寄存器溢出配置一个更大的一级缓存。对Fermi设备而言，<br> 本地内存用于溢出寄存器，但本地内存的加载可能被缓存在一级缓存中。在这种情况下，<br> 大的一级缓存可能也是有益的。</p></li><li><p>CUDA运行时会尽可能使用请求设备的片上内存配置，但如果需要执行一个核函数，<br> 它可自由地选择不同的配置。每个核函数的配置可以覆盖设备范围的设置，也可以使用以<br> 下运行时函数进行设置：<br><code>cudaError_t cudaFuncSetCacheConfig(const void* func, enum cudaFuncCacheca cheConfig);</code></p></li><li><p>核函数使用的这种配置是由核函数指针func指定的。启动一个不同优先级的内核比启<br> 动有最近优先级设置的内核更可能会导致隐式设备同步。对于每个核，只需调用一次这个<br> 函数。每个核函数启动时，片上内存中的配置不需要重新设定。</p></li><li><p>虽然一级缓存和共享内存位于相同的片上硬件中，但在某些方面它们却不太相同。共<br> 享内存是通过32个存储体进行访问的，而一级缓存则是通过缓存行进行访问的。使用共享<br> 内存，对存储内容和存放位置有完全的控制权，而使用一级缓存，数据删除工作是由硬件<br> 完成的。</p></li></ul><br><ul><li><p><mark>GPU缓存与CPU缓存</mark></p></li><li><p>一般情况下，GPU缓存的行为比CPU缓存的行为更难以理解。GPU使用不同的启发式<br> 算法删除数据。在GPU上，数百个线程共享相同的一级缓存，数千个线程共享相同的二级<br> 缓存。因此，数据删除在GPU上可能会发生得更频繁而且更不可预知。使用GPU共享内存<br> 不仅可以显式管理数据而且还可以保证SM的局部性。</p></li></ul><h3 id="_5-1-5-同步" tabindex="-1"><a class="header-anchor" href="#_5-1-5-同步" aria-hidden="true">#</a> 5.1.5 同步</h3><ul><li><p>并行线程间的同步是所有并行计算语言的重要机制。正如它名字所暗示的，共享内存<br> 可以同时被线程块中的多个线程访问。当不同步的多个线程修改同一个共享内存地址时，<br> 将导致线程内的冲突。CUDA提供了几个运行时函数来执行块内同步。同步的两个基本方<br> 法如下所示：<br> ·障碍<br> ·内存栅栏</p></li><li><p>在障碍中，所有调用的线程等待其余调用的线程到达障碍点。在内存栅栏中，所有调<br> 用的线程必须等到全部内存修改对其余调用线程可见时才能继续执行。然而，在学习<br> CUDA的块内障碍点和内存栅栏之前，理解CUDA采用的弱排序内存模型是十分重要的。</p></li></ul><br><ul><li><p><mark>5.1.5.1 弱排序内存模型</mark></p></li><li><p>现代的内存架构有一个宽松的内存模型。这意味着，内存访问不一定按照它们在程序<br> 中出现的顺序进行执行。CUDA采用弱排序内存模型从而优化了更多激进的编译器。</p></li><li><p>GPU线程在不同内存（如共享内存、全局内存、锁页主机内存或对等设备的内存）中<br> 写入数据的顺序，不一定和这些数据在源代码中访问的顺序相同。一个线程的写入顺序对<br> 其他线程可见时，它可能和写操作被执行的实际顺序不一致。</p></li><li><p>如果指令之间是相互独立的，线程从不同内存中读取数据的顺序和读指令在程序中出<br> 现的顺序不一定相同。</p></li><li><p>为了显式地强制程序以一个确切的顺序执行，必须在应用程序代码中插入内存栅栏和<br> 障碍。这是保证与其他线程共享资源的核函数行为正确的唯一途径。</p></li></ul><br><ul><li><p><mark>5.1.5.2 显式障碍</mark></p></li><li><p>在CUDA中，障碍只能在同一线程块的线程间执行。在核函数中，可以通过调用下面<br> 的函数来指定一个障碍点：<br><code>void __syncthreads();</code></p></li><li><p>__syncthreads作为一个障碍点来发挥作用，它要求块中的线程必须等待直到所有线程<br> 都到达该点。__syncthreads还确保在障碍点之前，被这些线程访问的所有全局和共享内存<br> 对同一块中的所有线程都可见。</p></li><li><p>__syncthreads用于协调同一块中线程间的通信。当块中的某些线程访问共享内存或全<br> 局内存中的同一地址时，会有潜在问题（写后读、读后写、写后写），这将导致在那些内<br> 存位置产生未定义的应用程序行为和未定义的状态。可以通过利用冲突访问间的同步线程<br> 来避免这种情况。</p></li><li><p>在条件代码中使用__syncthreads时，必须要特别小心。如果一个条件能保证对整个线<br> 程块进行同等评估，则它是调用__syncthreads的唯一有效条件。否则执行很可能会挂起或<br> 产生意想不到的问题。例如，下面的代码可能会导致块中的线程无限期地等待对方，因为<br> 块中的所有线程没有达到相同的障碍点。</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">if</span> <span class="token punctuation">(</span>threadID <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> 
<span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>
    <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>如果不允许跨线程块同步，线程块可能会以任何顺序、并行、串行的顺序在任何SM<br> 上执行。线程块执行的独立性质使得CUDA编程在任意数量的核心中都是可扩展的。如果<br> 一个CUDA核函数要求跨线程块全局同步，那么通过在同步点分割核函数并执行多个内核<br> 启动可能会达到预期的效果。因为每个连续的内核启动必须等待之前的内核启动完成，所<br> 以这会产生一个隐式全局障碍。</li></ul><br><ul><li><p><mark>5.1.5.3 内存栅栏</mark></p></li><li><p>内存栅栏的功能可确保栅栏前的任何内存写操作对栅栏后的其他线程都是可见的。根<br> 据所需范围，有3种内存栅栏：块、网格或系统。</p></li><li><p>通过以下固有函数可以在线程块内创建内存栅栏：<br><code>void __threadfence_block();</code></p></li><li><p>__threadfence_block保证了栅栏前被调用线程产生的对共享内存和全局内存的所有写<br> 操作对栅栏后同一块中的其他线程都是可见的。回想一下，内存栅栏不执行任何线程同<br> 步，所以对于一个块中的所有线程来说，没有必要实际执行这个指令。</p></li><li><p>使用下面的固有函数来创建网格级内存栅栏：<br><code>void __threadfence();</code></p></li><li><p>__threadfence挂起调用的线程，直到全局内存中的所有写操作对相同网格内的所有线<br> 程都是可见的。</p></li><li><p>使用下面的函数可以跨系统（包括主机和设备）设置内存栅栏：<br><code>void __threadfence_system();</code></p></li><li><p>__threadfence_system挂起调用的线程，以确保该线程对全局内存、锁页主机内存和其<br> 他设备内存中的所有写操作对全部设备中的线程和主机线程是可见的。</p></li></ul><br><ul><li><mark>5.1.5.4 Volatile修饰符</mark></li><li>在全局或共享内存中使用volatile修饰符声明一个变量，可以防止编译器优化，编译<br> 器优化可能会将数据暂时缓存在寄存器或本地内存中。当使用volatile修饰符时，编译器<br> 假定任何其他线程在任何时间都可以更改或使用该变量的值。因此，这个变量的任何引用<br> 都会直接被编译到全局内存读指令或全局内存写指令中，它们都会忽略缓存。</li></ul><br><ul><li><p><mark>共享内存与全局内存</mark></p></li><li><p>GPU全局内存常驻在设备内存（DRAM）上，它比GPU的共享内存访问慢得多。相较<br> 于DRAM，共享内存有以下几个特点：<br> ·DRAM比其高20～30倍的延迟<br> ·比DRAM大10倍的带宽</p></li><li><p>共享内存的访问粒度也比较小。而DRAM的访问粒度可以是32个字节或128个字节，<br> 共享内存的访问粒度如下：<br> ·Fermi架构：4字节存储体宽<br> ·Kepler架构：8字节存储体宽</p></li></ul><h2 id="_5-2-共享内存的数据布局" tabindex="-1"><a class="header-anchor" href="#_5-2-共享内存的数据布局" aria-hidden="true">#</a> 5.2 共享内存的数据布局</h2><ul><li>为了全面了解如何有效地使用共享内存，本节将使用共享内存研究几个简单的例子，<br> 其中包括下列主题：<br> ·方阵与矩阵数组<br> ·行主序与列主序访问<br> ·静态与动态共享内存的声明<br> ·文件范围与内核范围的共享内存<br> ·内存填充与无内存填充<br> 当使用共享内存设计核函数时，重点应放在以下两个概念上：<br> ·跨内存存储体映射数据元素<br> ·从线程索引到共享内存偏移的映射</li><li>当这些概念了然于心时，就可以设计一个高效的核函数了，它可以避免存储体冲突，<br> 并充分利用共享内存的优势。</li></ul><h3 id="_5-2-1-方形共享内存" tabindex="-1"><a class="header-anchor" href="#_5-2-1-方形共享内存" aria-hidden="true">#</a> 5.2.1 方形共享内存</h3><ul><li><p>使用共享内存可以直接缓存具有方形维度的全局数据。方形矩阵的简单维度可以很容<br> 易从二维线程索引中计算出一维内存偏移。图5-12显示了一个共享内存块，它在每个维度<br> 有32个元素，且按行主序进行存储。上部的图显示了一维数据布局的实际排列，下部的图<br> 显示了带有4字节数据元素和存储体映射的二维共享内存逻辑视图。</p></li><li><p>使用下面的语句静态声明一个二维共享内存变量：<br><code>__shared__ int tile[N][N];</code></p></li></ul><figure><img src="`+D+`" alt="figure5-12" tabindex="0" loading="lazy"><figcaption>figure5-12</figcaption></figure><ul><li><p>因为这个共享内存块是方形的，所以可以选择一个二维线程块访问它，在x或者y维度<br> 上通过相邻线程访问邻近元素：<br><code>tile[threadIdx.y][threadIdx.x]</code><br><code>tile[threadIdx.x][threadIdx.y]</code></p></li><li><p>在这些访问方法中哪个有可能表现得更好？这就需要注意线程与共享内存存储体的映<br> 射关系。回想一下，在同一个线程束中若有访问独立存储体的线程，则它是最优的。相同<br> 线程束中的线程可由连续的threadIdx.x值来确定。属于不同存储体的共享内存元素也可以<br> 通过字偏移进行连续存储。因此，最好是有访问共享内存连续位置的线程，且该线程带有<br> 连续的threadIdx.x值。由此，可以得出结论，第一存取模式（块[threadIdx.y][threadIdx.x]）<br> 将比第二存取模式（块[threadIdx.x][threadIdx.y]）呈现出更好的性能和更少的存储体冲<br> 突，因为邻近线程在最内层数组维度上访问相邻的阵列单元。</p></li></ul><br><ul><li><p><mark>5.2.1.1 行主序访问和列主序访问</mark></p></li><li><p>考虑一个例子，在例子中网格有一个二维线程块，块中每个维度包含32个可用的线<br> 程。可以使用下面的宏来定义块维度：<br><code>#define BDIMX 32</code><br><code>#define BDIMY 32</code></p></li><li><p>还可以使用下面的宏来定义核函数的执行配置：<br><code>dim3 block (BDIMX, BDIMY);</code><br><code>dim3 grid (1,1);</code></p></li><li><p>核函数有两个简单操作：<br> ·将全局线程索引按行主序写入到一个二维共享内存数组中<br> ·从共享内存中按行主序读取这些值并将它们存储到全局内存中</p></li><li><p>首先，可以用如下方法静态声明一个二维共享内存数组：<br><code>__shared__ int tile[BDIMY][BDIMX];</code></p></li><li><p>接下来，需要为每个线程计算全局线程索引，它是根据其二维线程ID进行计算的。因<br> 为只有一个线程块将被启动，该索引转换可以被简化为：<br><code>unsigned int idx = threadIdx.y * blockDim.x + threadIdx.x;</code></p></li><li><p>在本节的例子中，idx用于模拟从输入矩阵中读取值。基于线程全局ID的写入位置，<br> 存储idx的值到输出数组，将允许可视化核函数的访问模式。</p></li><li><p>将全局线程索引按行主序顺序写入共享内存块，可以按如下方式进行：<br><code>tile[threadIdx.y][threadIdx.x] = idx;</code></p></li><li><p>一旦达到同步点（使用syncthreads函数），所有线程必须将存储的数据送到共享内存<br> 块中，这样就可以按行主序从共享内存给全局内存赋值，如下所示：<br><code>out[idx] = tile[threadIdx.y][threadIdx.x];</code></p></li><li><p>核函数的代码如下：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>The kernel code is as follows<span class="token operator">:</span>
__global__ <span class="token keyword">void</span> <span class="token function">setRowReadRow</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token operator">*</span>out<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token comment">// static shared memory</span>
 __shared__ <span class="token keyword">int</span> tile<span class="token punctuation">[</span>BDIMY<span class="token punctuation">]</span><span class="token punctuation">[</span>BDIMX<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token comment">// mapping from thread index to global memory index</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> idx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>y <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 <span class="token comment">// shared memory store operation</span>
 tile<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">]</span><span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span> <span class="token operator">=</span> idx<span class="token punctuation">;</span>
 <span class="token comment">// wait for all threads to complete</span>
 <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// shared memory load operation</span>
 out<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> tile<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">]</span><span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span> <span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>到目前为止，在内核中有3个内存操作：<br> ·共享内存的存储操作<br> ·共享内存的加载操作<br> ·全局内存的存储操作</p></li><li><p>因为相同线程束中的线程有连续的threadIdx.x值，并且可以使用threadIdx.x索引共享内<br> 存数组tile的最内层维度，所以核函数无存储体冲突。</p></li><li><p>另一方面，如果在将数据分配给共享内存块时交换threadIdx.y和threadIdx.x，线程束的<br> 内存将会按列主序访问。每个共享内存的加载和存储将导致Fermi装置中有32路存储体冲<br> 突，导致Kepler装置中有16路存储体冲突</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">setColReadCol</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token operator">*</span>out<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token comment">// static shared memory</span>
 __shared__ <span class="token keyword">int</span> tile<span class="token punctuation">[</span>BDIMX<span class="token punctuation">]</span><span class="token punctuation">[</span>BDIMY<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token comment">// mapping from thread index to global memory index</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> idx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>y <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 <span class="token comment">// shared memory store operation</span>
 tile<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">]</span> <span class="token operator">=</span> idx<span class="token punctuation">;</span>
 <span class="token comment">// wait for all threads to complete</span>
 <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// shared memory load operation</span>
 out<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> tile<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>测试这些内核的性能之前，需要准备全局内存。我们鼓励你自己编写主函数。这个示<br> 例的代码和本节所有的核函数示例代码也可从Wrox.com上的checkSmemSquare.cu中查到。<br> 使用以下命令将它编译到名为smemSquare的可执行文件中：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>$ nvcc checkSmemSquare<span class="token punctuation">.</span>cu –o smemSquare

首先，使用以下命令计算运行时间：
$ nvprof <span class="token punctuation">.</span><span class="token operator">/</span>smemSquare

在Tesla K40c上，具有<span class="token number">4</span>字节共享内存访问模式的结果如下所示。它们清楚地展示了按
行访问共享内存可以提高性能，因为相邻线程引用相邻字。
<span class="token punctuation">.</span><span class="token operator">/</span>smemSquare at device <span class="token number">0</span> of Tesla K40c with Bank Mode<span class="token operator">:</span><span class="token number">4</span><span class="token operator">-</span>byte
<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span> <span class="token function">grid</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token function">block</span> <span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span>
<span class="token function">Time</span><span class="token punctuation">(</span><span class="token operator">%</span><span class="token punctuation">)</span> Time Calls Avg Min Max Name 
 <span class="token number">13.25</span><span class="token operator">%</span> <span class="token number">2.6880u</span>s <span class="token number">1</span> <span class="token number">2.6880u</span>s <span class="token number">2.6880u</span>s <span class="token number">2.6880u</span>s <span class="token function">setColReadCol</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span>
 <span class="token number">11.36</span><span class="token operator">%</span> <span class="token number">2.3040u</span>s <span class="token number">1</span> <span class="token number">2.3040u</span>s <span class="token number">2.3040u</span>s <span class="token number">2.3040u</span>s <span class="token function">setRowReadRow</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span>

接下来，在两种核函数中使用以下nvprof指标以检查存储体冲突：
shared_load_transactions_per_request 
shared_store_transactions_per_request

nvprof的结果如下。这些结果表明，在setRowReadRow核函数中，线程束的存储和加
载请求由一个事务完成，而相同的请求在setColReadCol核函数中由<span class="token number">16</span>个事务完成。这证
实了在Kepler设备上，当使用<span class="token number">8</span>字节共享内存存储体时，核函数会有<span class="token number">16</span>路存储体冲突。
Kernel<span class="token operator">:</span><span class="token function">setColReadCol</span> <span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span>
 <span class="token number">1</span> shared_load_transactions_per_request <span class="token number">16.000000</span> 
 <span class="token number">1</span> shared_store_transactions_per_request <span class="token number">16.000000</span> 
Kernel<span class="token operator">:</span><span class="token function">setRowReadRow</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span>
 <span class="token number">1</span> shared_load_transactions_per_request <span class="token number">1.000000</span> 
 <span class="token number">1</span> shared_store_transactions_per_request <span class="token number">1.000000</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><br><ul><li><p><mark>5.2.1.2 按行主序写和按列主序读</mark></p></li><li><p>下面的核函数实现了共享内存中按行主序写入和按列主序读取。按行主序写入共享内<br> 存是将线程索引的最内层维度作为二维共享内存块的列索引实现的（等同于最后一个例<br> 子）：<br><code>tile[threadIdx.y][threadIdx.x] = idx;</code></p></li><li><p>按列主序在共享内存块中给全局内存赋值，这是在引用共享内存时交换两个线程索引实现的：<br><code>out[idx] = tile[threadIdx.x][threadIdx.y];</code></p></li><li><p>图5-13显示了两个内存操作，它们使用了简化的五存储体共享内存实现。<br><img src="`+S+`" alt="figure5-13" loading="lazy"></p></li><li><p>内核代码如下：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">setRowReadCol</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token operator">*</span>out<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token comment">// static shared memory</span>
 __shared__ <span class="token keyword">int</span> tile<span class="token punctuation">[</span>BDIMY<span class="token punctuation">]</span><span class="token punctuation">[</span>BDIMX<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token comment">// mapping from thread index to global memory index</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> idx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>y <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 <span class="token comment">// shared memory store operation</span>
 tile<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">]</span><span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span> <span class="token operator">=</span> idx<span class="token punctuation">;</span>
 <span class="token comment">// wait for all threads to complete</span>
 <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// shared memory load operation</span>
 out<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> tile<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

用nvprof检查该内核的内存事务后，将会报告下列指标：
Kernel<span class="token operator">:</span><span class="token function">setRowReadCol</span> <span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span>
 <span class="token number">1</span> shared_load_transactions_per_request <span class="token number">16.000000</span> 
 <span class="token number">1</span> shared_store_transactions_per_request <span class="token number">1.000000</span>


存储操作是无冲突的，但是加载操作显示有<span class="token number">16</span>路冲突。
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><br><ul><li><p><mark>5.2.1.3 动态共享内存</mark></p></li><li><p>可以动态声明共享内存，从而实现这些相同的核函数。可以在核函数外声明动态共享<br> 内存，使它的作用域为整个文件，也可以在核函数内声明动态共享内存，将其作用域限制<br> 在该内核之中。动态共享内存必须被声明为一个未定大小的一维数组，因此，需要基于二<br> 维线程索引来计算内存访问索引。因为要在这个核函数中按行主序写入，按列主序读取，<br> 所以需要保留以下两个索引：<br> ·row_idx：根据二维线程索引计算出的一维行主序内存偏移量<br> ·col_idx：根据二维线程索引计算出的一维列主序内存偏移量</p></li><li><p>使用已经计算出的row_idx，按行主序写入共享内存，如下所示：<br><code>tile[row_idx] = row_idx;</code></p></li><li><p>在共享内存块被填满之后，使用适当的同步，然后按列主序将其读出并分配到全局内<br> 存中，如下所示：<br><code>out[row_idx] = tile[col_idx];</code></p></li><li><p>因为out数组存储在全局内存中，并且线程按行主序被安排在一个线程块内，所以为<br> 了确保合并存储，需要通过线程坐标按行主序对out数组写入。该核函数的代码如下：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">setRowReadColDyn</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token operator">*</span>out<span class="token punctuation">)</span> <span class="token punctuation">{</span> 
 <span class="token comment">// dynamic shared memory</span>
 <span class="token keyword">extern</span> __shared__ <span class="token keyword">int</span> tile<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token comment">// mapping from thread index to global memory index</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> row_idx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>y <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> col_idx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>y <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">;</span>
 <span class="token comment">// shared memory store operation</span>
 tile<span class="token punctuation">[</span>row_idx<span class="token punctuation">]</span> <span class="token operator">=</span> row_idx<span class="token punctuation">;</span>
 <span class="token comment">// wait for all threads to complete</span>
 <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// shared memory load operation</span>
 out<span class="token punctuation">[</span>row_idx<span class="token punctuation">]</span> <span class="token operator">=</span> tile<span class="token punctuation">[</span>col_idx<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>在启动内核时，必须指定共享内存的大小，如下所示：<br><code>setRowReadColDyn&lt;&lt;&lt;grid, block, BDIMX * BDIMY * sizeof(int)&gt;&gt;&gt;(d_C);</code></p></li><li><p>这个内核在checkSmemSquare.cu中也可以使用。试着用nvprof检查setRowReadCol-Dyn<br> 核函数的内存事务。如下所示：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>Kernel<span class="token operator">:</span> <span class="token function">setRowReadColDyn</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span>
 <span class="token number">1</span> shared_load_transactions_per_request <span class="token number">16.000000</span> 
 <span class="token number">1</span> shared_store_transactions_per_request <span class="token number">1.000000</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>这些结果和前面setRowReadCol例子中的结果相同，但是它却使用了由一维数组索引<br> 计算出的动态声明的共享内存。写操作是无冲突的，然而读操作报告了16路冲突。</li></ul><br><ul><li><p><mark>5.2.1.4 填充静态声明的共享内存</mark></p></li><li><p>正如本章5.1.3.4节所描述的，填充数组是避免存储体冲突的一种方法。填充静态声明<br> 的共享内存很简单。只需简单地将一列添加到二维共享内存分配中，代码如下所示：<br><code>__shared__ int tile[BDIMY][BDIMX];</code></p></li><li><p>下面的核函数是setRowReadCol核函数的修改版，setRowReadCol按列主序读取时报告<br> 了16路冲突。通过在每行添加一个元素，列元素便分布在了不同的存储体中，因此读和写<br> 操作都是无冲突的。</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">setRowReadColPad</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token operator">*</span>out<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token comment">// static shared memory</span>
 __shared__ <span class="token keyword">int</span> tile<span class="token punctuation">[</span>BDIMY<span class="token punctuation">]</span><span class="token punctuation">[</span>BDIMX<span class="token operator">+</span>IPAD<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token comment">// mapping from thread index to global memory offset</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> idx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>y <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 <span class="token comment">// shared memory store operation</span>
 tile<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">]</span><span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span> <span class="token operator">=</span> idx<span class="token punctuation">;</span>
 <span class="token comment">// wait for all threads to complete</span>
 <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// shared memory load operation</span>
 out<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> tile<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>



用nvprof检查这个核函数的内存事务。结果如下所示：
Kernel<span class="token operator">:</span> <span class="token function">setRowReadColPad</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span>
 <span class="token number">1</span> shared_load_transactions_per_request <span class="token number">1.000000</span> 
 <span class="token number">1</span> shared_store_transactions_per_request <span class="token number">1.000000</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>对于Fermi设备，需要增加一列来解决存储体冲突；对于Kepler设备，并非总是如<br> 此。在Kepler设备中，每行需要填充的数据元素数量取决于二维共享内存的大小。因此，<br> 在Kepler设备中需要进行更多的测试，以便为64位访问模式确定合适的填充数量元素。</li></ul><br><ul><li><p><mark>5.2.1.5 填充动态声明的共享内存</mark></p></li><li><p>填充动态声明的共享内存数组更加复杂。当执行从二维线程索引到一维内存索引的索<br> 引转换时，对于每一行必须跳过一个填充的内存空间，代码如下：<br><code>unsigned int row_idx = threadIdx.y * (blockDim.x + 1) + threadIdx.x;</code><br><code>unsigned int col_idx = threadIdx.x * (blockDim.x + 1) + threadIdx.y;</code></p></li><li><p>图5-14显示了这些内存索引计算，这些计算使用了一个简化的五存储体共享内存实现。<br><img src="`+R+`" alt="figure5-14" loading="lazy"></p></li><li><p>因为在以下核函数中用于存储数据的全局内存小于填充的共享内存，所以需要3个索<br> 引：一个索引用于按照行主序写入共享内存，一个索引用于按照列主序读取共享内存，一<br> 个索引用于未填充的全局内存的合并访问，代码如下所示：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">setRowReadColDynPad</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token operator">*</span>out<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token comment">// dynamic shared memory</span>
 <span class="token keyword">extern</span> __shared__ <span class="token keyword">int</span> tile<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token comment">// mapping from thread index to global memory index</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> row_idx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>y <span class="token operator">*</span> <span class="token punctuation">(</span>blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> IPAD<span class="token punctuation">)</span> <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> col_idx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> <span class="token punctuation">(</span>blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> IPAD<span class="token punctuation">)</span> <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">;</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> g_idx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>y <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 <span class="token comment">// shared memory store operation</span>
 tile<span class="token punctuation">[</span>row_idx<span class="token punctuation">]</span> <span class="token operator">=</span> g_idx<span class="token punctuation">;</span>
 <span class="token comment">// wait for all threads to complete</span>
 <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// shared memory load operation</span>
 out<span class="token punctuation">[</span>g_idx<span class="token punctuation">]</span> <span class="token operator">=</span> tile<span class="token punctuation">[</span>col_idx<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token operator">-</span> 在启动核函数时应指定填充共享内存的大小，代码如下：
setRowReadColDynPad<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span>grid<span class="token punctuation">,</span> block<span class="token punctuation">,</span> <span class="token punctuation">(</span>BDIMX <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> BDIMY <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>d_C<span class="token punctuation">)</span><span class="token punctuation">;</span>

用nvprof检查这个核函数的内存事务。在K40上的结果报告如下：
Kernel<span class="token operator">:</span> <span class="token function">setRowReadColDynPad</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span>
 <span class="token number">1</span> shared_load_transactions_per_request <span class="token number">1.000000</span> 
 <span class="token number">1</span> shared_store_transactions_per_request <span class="token number">1.000000</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>请注意，这些结果和填充静态声明的共享内存是一致的，所以这两种类型的共享内存<br> 可以被有效地填充。</li></ul><br><ul><li><mark>5.2.1.6 方形共享内存内核性能的比较</mark></li><li>到目前为止，从所有执行过的内核运行时间可以看出：<br> ·使用填充的内核可提高性能，因为它减少了存储体冲突<br> ·带有动态声明共享内存的内核增加了少量的消耗</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>$ nvprof <span class="token punctuation">.</span><span class="token operator">/</span>smemSquare 
<span class="token punctuation">.</span><span class="token operator">/</span>smemSquare at device <span class="token number">0</span><span class="token operator">:</span> Tesla K40c with Bank Mode<span class="token operator">:</span><span class="token number">4</span><span class="token operator">-</span>Byte 
<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span> <span class="token function">grid</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token function">block</span> <span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span>
<span class="token function">Time</span><span class="token punctuation">(</span><span class="token operator">%</span><span class="token punctuation">)</span> Time Calls Avg Min Max Name
 <span class="token number">5.32</span><span class="token operator">%</span> <span class="token number">3.6160u</span>s <span class="token number">1</span> <span class="token number">3.6160u</span>s <span class="token number">3.6160u</span>s <span class="token number">3.6160u</span>s <span class="token function">setColReadCol</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span>
 <span class="token number">4.57</span><span class="token operator">%</span> <span class="token number">3.1040u</span>s <span class="token number">1</span> <span class="token number">3.1040u</span>s <span class="token number">3.1040u</span>s <span class="token number">3.1040u</span>s <span class="token function">setRowReadColDyn</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span>
 <span class="token number">4.24</span><span class="token operator">%</span> <span class="token number">2.8800u</span>s <span class="token number">1</span> <span class="token number">2.8800u</span>s <span class="token number">2.8800u</span>s <span class="token number">2.8800u</span>s <span class="token function">setColReadRow</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span>
 <span class="token number">3.81</span><span class="token operator">%</span> <span class="token number">2.5920u</span>s <span class="token number">1</span> <span class="token number">2.5920u</span>s <span class="token number">2.5920u</span>s <span class="token number">2.5920u</span>s <span class="token function">setRowReadCol</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span>
 <span class="token number">3.20</span><span class="token operator">%</span> <span class="token number">2.1760u</span>s <span class="token number">1</span> <span class="token number">2.1760u</span>s <span class="token number">2.1760u</span>s <span class="token number">2.1760u</span>s <span class="token function">setRowReadColDynPad</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span>
 <span class="token number">3.15</span><span class="token operator">%</span> <span class="token number">2.1440u</span>s <span class="token number">1</span> <span class="token number">2.1440u</span>s <span class="token number">2.1440u</span>s <span class="token number">2.1440u</span>s <span class="token function">setRowReadRow</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span>
 <span class="token number">3.15</span><span class="token operator">%</span> <span class="token number">2.1440u</span>s <span class="token number">1</span> <span class="token number">2.1440u</span>s <span class="token number">2.1440u</span>s <span class="token number">2.1440u</span>s <span class="token function">setRowReadColPad</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>要想显示每个内核产生的二维矩阵的内容，首先要将共享内存块的维度减少到4，使<br> 其可以更简单地可视化：<br><code>#define BDIMX 4</code><br><code>#define BDIMY 4</code></p></li><li><p>然后，编译并运行下面的命令以列出所有核函数的输出。从这个结果可以看到，如果<br> 读和写操作使用不同的顺序（例如，读操作使用行主序，而写操作使用列主序），那么核<br> 函数会产生转置矩阵。这些简单的核函数为更复杂的转置算法奠定了基础。</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>$<span class="token punctuation">.</span><span class="token operator">/</span>smemSquare <span class="token number">1</span>
<span class="token punctuation">.</span><span class="token operator">/</span>smemSquare at device <span class="token number">0</span><span class="token operator">:</span> Tesla K40c with Bank Mode<span class="token operator">:</span><span class="token number">4</span><span class="token operator">-</span>Byte <span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span> <span class="token function">grid</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token function">block</span> 
<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span>
set col read col <span class="token operator">:</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">2</span> <span class="token number">3</span> <span class="token number">4</span> <span class="token number">5</span> <span class="token number">6</span> <span class="token number">7</span> <span class="token number">8</span> <span class="token number">9</span> <span class="token number">10</span> <span class="token number">11</span> <span class="token number">12</span> <span class="token number">13</span> <span class="token number">14</span> <span class="token number">15</span>
set row read row <span class="token operator">:</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">2</span> <span class="token number">3</span> <span class="token number">4</span> <span class="token number">5</span> <span class="token number">6</span> <span class="token number">7</span> <span class="token number">8</span> <span class="token number">9</span> <span class="token number">10</span> <span class="token number">11</span> <span class="token number">12</span> <span class="token number">13</span> <span class="token number">14</span> <span class="token number">15</span>
set col read row <span class="token operator">:</span> <span class="token number">0</span> <span class="token number">4</span> <span class="token number">8</span> <span class="token number">12</span> <span class="token number">1</span> <span class="token number">5</span> <span class="token number">9</span> <span class="token number">13</span> <span class="token number">2</span> <span class="token number">6</span> <span class="token number">10</span> <span class="token number">14</span> <span class="token number">3</span> <span class="token number">7</span> <span class="token number">11</span> <span class="token number">15</span>
set row read col <span class="token operator">:</span> <span class="token number">0</span> <span class="token number">4</span> <span class="token number">8</span> <span class="token number">12</span> <span class="token number">1</span> <span class="token number">5</span> <span class="token number">9</span> <span class="token number">13</span> <span class="token number">2</span> <span class="token number">6</span> <span class="token number">10</span> <span class="token number">14</span> <span class="token number">3</span> <span class="token number">7</span> <span class="token number">11</span> <span class="token number">15</span>
set row read col Dynamic <span class="token operator">:</span> <span class="token number">0</span> <span class="token number">4</span> <span class="token number">8</span> <span class="token number">12</span> <span class="token number">1</span> <span class="token number">5</span> <span class="token number">9</span> <span class="token number">13</span> <span class="token number">2</span> <span class="token number">6</span> <span class="token number">10</span> <span class="token number">14</span> <span class="token number">3</span> <span class="token number">7</span> <span class="token number">11</span> <span class="token number">15</span>
set row read col Padding <span class="token operator">:</span> <span class="token number">0</span> <span class="token number">4</span> <span class="token number">8</span> <span class="token number">12</span> <span class="token number">1</span> <span class="token number">5</span> <span class="token number">9</span> <span class="token number">13</span> <span class="token number">2</span> <span class="token number">6</span> <span class="token number">10</span> <span class="token number">14</span> <span class="token number">3</span> <span class="token number">7</span> <span class="token number">11</span> <span class="token number">15</span>
set row read col Dyn Pad <span class="token operator">:</span> <span class="token number">0</span> <span class="token number">4</span> <span class="token number">8</span> <span class="token number">12</span> <span class="token number">1</span> <span class="token number">5</span> <span class="token number">9</span> <span class="token number">13</span> <span class="token number">2</span> <span class="token number">6</span> <span class="token number">10</span> <span class="token number">14</span> <span class="token number">3</span> <span class="token number">7</span> <span class="token number">11</span> <span class="token number">15</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_5-2-2-矩形共享内存" tabindex="-1"><a class="header-anchor" href="#_5-2-2-矩形共享内存" aria-hidden="true">#</a> 5.2.2 矩形共享内存</h3><ul><li><p>矩形共享内存是一个更普遍的二维共享内存，在矩形共享内存中数组的行与列的数量不相等。<br><code>__shared__ int tile[Row][Col];</code></p></li><li><p>当执行一个转置操作时，不能像在方形共享内存中一样，只是通过简单地转换来引用<br> 矩形数组的线程坐标。当使用矩形共享内存时，这样做会导致内存访问冲突。需要基于矩<br> 阵维度重新计算访问索引，以重新实现之前描述的核函数。</p></li><li><p>一般情况下，需要测试一个矩形共享内存数组，其每行有32个元素，每列有16个元<br> 素。在下面的宏中定义了维度：<br><code>#define BDIMX 32</code><br><code>#define BDIMY 16</code></p></li><li><p>矩形共享内存块被分配如下：<br><code>__shared__ int tile[BDIMY][BDIMX];</code></p></li><li><p>为了简单起见，内核将被启动为只有一个网格和一个二维线程块，该线程块的大小与<br> 矩形共享内存数组相同，代码如下：<br><code>dim3 block (BDIMX,BDIMY);</code><br><code>dim3 grid (1,1);</code></p></li></ul><br><ul><li><p><mark>5.2.2.1 行主序访问与列主序访问</mark></p></li><li><p>将要测试的前两个核函数也在方形（共享内存）情况下使用：<br><code>__global__ void setRowReadRow(int *out);</code><br><code>__global__ void setColReadCol(int *out);</code></p></li><li><p>需要注意每个内核中矩形共享内存数组的声明。在setRowReadRow核函数中，共享内<br> 存数组tile的最内层维度的长度被设置为同二维线程块最内层维度相同的长度：<br><code>__shared__ int tile[BDIMY][BDIMX];</code></p></li><li><p>在setColReadCol内核中，共享内存数组tile的最内层维度的长度被设置为同二维线程<br> 块最外层维度相同的长度：<br><code>__shared__ int tile[BDIMX][BDIMY];</code></p></li><li><p>从Wrox.com上可以下载checkSmemRectangle.cu文件，里面有这个例子的代码。编译它<br> 并用下面的nvprof指标检查存储体冲突的结果：<br><code>shared_load_transactions_per_request</code><br><code>shared_store_transactions_per_request</code></p></li><li><p>在K40上的结果显示如下：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>Kernel<span class="token operator">:</span><span class="token function">setRowReadRow</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span>
 <span class="token number">1</span> shared_load_transactions_per_request <span class="token number">1.000000</span>
 <span class="token number">1</span> shared_store_transactions_per_request <span class="token number">1.000000</span>
Kernel<span class="token operator">:</span><span class="token function">setColReadCol</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span>
 <span class="token number">1</span> shared_load_transactions_per_request <span class="token number">8.000000</span>
 <span class="token number">1</span> shared_store_transactions_per_request <span class="token number">8.000000</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>共享内存的存储和加载请求，由setRowReadRow核函数中的一个事务完成。同样的请<br> 求在setColReadCol函数中由8个事务完成。Kepler K40的存储体宽度是8个字，一列16个4<br> 字节的数据元素被安排到8个存储体中，如图5-6所示，因此，该操作有一个8路冲突。</li></ul><br><ul><li><p><mark>5.2.2.2 行主序写操作和列主序读操作</mark></p></li><li><p>在本节中，将实现一个核函数，该核函数使用一个矩形共享内存数组，按行主序写入<br> 共享内存，并按列主序读取共享内存。这个内核在现实的应用程序中是可用的。它使用共<br> 享内存执行矩阵转置，通过最大化低延迟的加载和存储来提高性能，并合并全局内存访<br> 问。</p></li><li><p>二维共享内存块被声明如下：<br><code>__shared__ int tile[BDIMY][BDIMX];</code></p></li><li><p>内核有3个内存操作：<br> ·写入每个线程束的共享内存行，以避免存储体冲突<br> ·读取每个线程束中的共享内存列，以完成矩阵转置<br> ·使用合并访问写入每个线程束的全局内存行</p></li><li><p>计算出正确的共享和全局内存访问的步骤如下所示。首先，将当前线程的二维线程索<br> 引转换为一维全局线程ID：<br><code>unsigned int idx = threadIdx.y * blockDim.x + threadIdx.x;</code></p></li><li><p>这个一维行主序的映射可以确保全局内存访问是合并的。因为输出的全局内存中的数<br> 据元素是转置过的，所以需要计算转置矩阵中的新坐标，代码如下所示：<br><code>unsigned int irow = idx / blockDim.y;</code><br><code>unsigned int icol = idx % blockDim.y;</code></p></li><li><p>通过将全局线程ID存储到二维共享内存块中来初始化共享内存块，如下：<br><code>tile[threadIdx.y][threadIdx.x] = idx;</code></p></li><li><p>此时，共享内存中的数据是从0到BDIMX×BDIMY-1线性存储的。由于每个线程束对<br> 共享内存执行了行主序写入，因此在写操作期间没有存储体冲突。</p></li><li><p>现在，可以使用之前计算出的坐标访问转置过的共享内存数据。通过交换过的irow和<br> icol访问共享内存，可以用一维线程ID向全局内存写入转置数据。如下面的代码所示，线<br> 程束从共享内存的一列中读取数据元素，并对全局内存执行合并写入操作。<br><code>out[idx] = tile[icol][irow];</code></p></li><li><p>完整的核函数代码如下所示：</p></li></ul>`,92),H={class:"hint-container details"},j=n("summary",null,"Click me to view the code!",-1),J=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s("__global__ "),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"setRowReadCol"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("out"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token comment"},"// static shared memory"),s(`
 __shared__ `),n("span",{class:"token keyword"},"int"),s(" tile"),n("span",{class:"token punctuation"},"["),s("BDIMY"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},"["),s("BDIMX"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// mapping from 2D thread index to linear memory"),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" idx "),n("span",{class:"token operator"},"="),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("y "),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"+"),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// convert idx to transposed coordinate (row, col)"),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" irow "),n("span",{class:"token operator"},"="),s(" idx "),n("span",{class:"token operator"},"/"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("y"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" icol "),n("span",{class:"token operator"},"="),s(" idx "),n("span",{class:"token operator"},"%"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("y"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// shared memory store operation"),s(`
 tile`),n("span",{class:"token punctuation"},"["),s("threadIdx"),n("span",{class:"token punctuation"},"."),s("y"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},"["),s("threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" idx"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// wait for all threads to complete"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// shared memory load operation"),s(`
 out`),n("span",{class:"token punctuation"},"["),s("idx"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" tile"),n("span",{class:"token punctuation"},"["),s("icol"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},"["),s("irow"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
`),n("span",{class:"token punctuation"},"}"),s(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),Q=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s(`当使用nvprof检查内存事务时，报告如下：
Kernel`),n("span",{class:"token operator"},":"),n("span",{class:"token function"},"setRowReadCol"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),s(`
 `),n("span",{class:"token number"},"1"),s(" shared_load_transactions_per_request "),n("span",{class:"token number"},"8.000000"),s(`
 `),n("span",{class:"token number"},"1"),s(" shared_store_transactions_per_request "),n("span",{class:"token number"},"1.000000"),s(`

该存储操作是无冲突的，加载操作报告了一个`),n("span",{class:"token number"},"8"),s(`路冲突。用下面的命令输出生成矩阵的内容：
$ `),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s("smemRectangle "),n("span",{class:"token number"},"1"),s(`

请注意，全局内存中的所有数据元素都被转置了。
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),Z=c(`<br><ul><li><p><mark>5.2.2.3 动态声明的共享内存</mark></p></li><li><p>因为动态共享内存只能被声明为一维数组，当按照行写入和按照列读取时，将二维线<br> 程坐标转换为一维共享内存索引需要一个新的索引：<br><code>unsigned int col_idx = icol * blockDim.x + irow;</code></p></li><li><p>因为icol对应于线程块中最内层的维度，所以这种转换以列主序访问共享内存，这会<br> 导致存储体冲突。核函数的代码如下：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">setRowReadColDyn</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token operator">*</span>out<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token comment">// dynamic shared memory</span>
 <span class="token keyword">extern</span> __shared__ <span class="token keyword">int</span> tile<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token comment">// mapping from thread index to global memory index</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> idx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>y <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
c05<span class="token punctuation">.</span>indd <span class="token number">08</span><span class="token operator">/</span><span class="token number">19</span><span class="token operator">/</span><span class="token number">2014</span> Page <span class="token number">228</span>
Checking the Data Layout of Shared Memory ❘ <span class="token number">229</span>
 <span class="token comment">// convert idx to transposed (row, col)</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> irow <span class="token operator">=</span> idx <span class="token operator">/</span> blockDim<span class="token punctuation">.</span>y<span class="token punctuation">;</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> icol <span class="token operator">=</span> idx <span class="token operator">%</span> blockDim<span class="token punctuation">.</span>y<span class="token punctuation">;</span>
 <span class="token comment">// convert back to smem idx to access the transposed element</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> col_idx <span class="token operator">=</span> icol <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> irow<span class="token punctuation">;</span>
 <span class="token comment">// shared memory store operation</span>
 tile<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> idx<span class="token punctuation">;</span>
 <span class="token comment">// wait for all threads to complete</span>
 <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// shared memory load operation</span>
 out<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> tile<span class="token punctuation">[</span>col_idx<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>作为内核启动的一部分，共享内存的大小必须被指定：<br><code>setRowReadColDyn&lt;&lt;&lt;grid, block, BDIMX * BDIMY * sizeof(int)&gt;&gt;&gt;(d_C);</code></p></li><li><p>用nvprof检查共享内存的事务时，报告如下：<br><code>Kernel: setRowReadColDyn(int*)</code><br><code>1 shared_load_transactions_per_request 8.000000</code><br><code>1 shared_store_transactions_per_request 1.000000</code></p></li><li><p>写操作是无冲突的，然而读操作报告了一个8路冲突。动态分配共享内存不会影响存储体冲突。</p></li></ul><br><ul><li><p><mark>5.2.2.4 填充静态声明的共享内存</mark></p></li><li><p>对于矩形共享内存，还可以使用共享内存填充来解决存储体冲突。然而，对于Kepler<br> 设备，必须计算出需要多少填充元素。为了便于编程，使用宏来定义每一行添加的填充列<br> 的数量：<code>#define NPAD 2</code></p></li><li><p>填充的静态共享内存被声明如下：<code>__shared__ int tile[BDIMY][BDIMX + NPAD];</code></p></li><li><p>除添加了共享内存的填充以外，setRowReadColPad核函数与setRowReadCol核函数是<br> 相同的：</p></li></ul>`,6),nn={class:"hint-container details"},sn=n("summary",null,"Click me to view the code!",-1),an=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s("__global__ "),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"setRowReadColPad"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("out"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token comment"},"// static shared memory"),s(`
 __shared__ `),n("span",{class:"token keyword"},"int"),s(" tile"),n("span",{class:"token punctuation"},"["),s("BDIMY"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},"["),s("BDIMX"),n("span",{class:"token operator"},"+"),s("IPAD"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// mapping from 2D thread index to linear memory "),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" idx "),n("span",{class:"token operator"},"="),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("y "),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"+"),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// convert idx to transposed (row, col)"),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" irow "),n("span",{class:"token operator"},"="),s(" idx "),n("span",{class:"token operator"},"/"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("y"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" icol "),n("span",{class:"token operator"},"="),s(" idx "),n("span",{class:"token operator"},"%"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("y"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// shared memory store operation"),s(`
 tile`),n("span",{class:"token punctuation"},"["),s("threadIdx"),n("span",{class:"token punctuation"},"."),s("y"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},"["),s("threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" idx"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// wait for all threads to complete"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// shared memory load operation"),s(`
 out`),n("span",{class:"token punctuation"},"["),s("idx"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" tile"),n("span",{class:"token punctuation"},"["),s("icol"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},"["),s("irow"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token punctuation"},";"),s(`
`),n("span",{class:"token punctuation"},"}"),s(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),en=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s(`用nvprof检查内存事务，结果报告如下：
Kernel`),n("span",{class:"token operator"},":"),s(),n("span",{class:"token function"},"setRowReadColPad"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),s(`
 `),n("span",{class:"token number"},"1"),s(" shared_load_transactions_per_request "),n("span",{class:"token number"},"1.000000"),s(` 
 `),n("span",{class:"token number"},"1"),s(" shared_store_transactions_per_request "),n("span",{class:"token number"},"1.000000"),s(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),tn=c(`<ul><li>在前面的宏中若将填充数据元素的数量从2改到1，则nvprof报告有两个事务完成共享<br> 内存的加载操作，即发生一个双向存储体冲突。鼓励你用不同数值的NPAD进行试验，分<br> 析得到的结果并解释它。</li></ul><h4 id="_5-2-2-5-填充动态声明的共享内存" tabindex="-1"><a class="header-anchor" href="#_5-2-2-5-填充动态声明的共享内存" aria-hidden="true">#</a> 5.2.2.5 填充动态声明的共享内存</h4><ul><li><p>填充技术还可以应用于动态共享内存的内核中，该内核使用矩形共享内存区域。因为<br> 填充的共享内存和全局内存大小会有所不同，所以在内核中每个线程必须保留3个索引：<br> ·row_idx：填充共享内存的行主序索引。使用该索引，线程束可以访问单一的矩阵行<br> ·col_idx：填充共享内存的列主序索引。使用该索引，线程束可以访问单一的矩阵列<br> ·g_idx：线性全局内存索引。使用该索引，线程束可以对全局内存进行合并访问</p></li><li><p>这些索引是用以下代码计算出来的：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code> <span class="token comment">// mapping from thread index to global memory index</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> g_idx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>y <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 <span class="token comment">// convert idx to transposed (row, col)</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> irow <span class="token operator">=</span> g_idx <span class="token operator">/</span> blockDim<span class="token punctuation">.</span>y<span class="token punctuation">;</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> icol <span class="token operator">=</span> g_idx <span class="token operator">%</span> blockDim<span class="token punctuation">.</span>y<span class="token punctuation">;</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> row_idx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>y <span class="token operator">*</span> <span class="token punctuation">(</span>blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> IPAD<span class="token punctuation">)</span> <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 <span class="token comment">// convert back to smem idx to access the transposed element</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> col_idx <span class="token operator">=</span> icol <span class="token operator">*</span> <span class="token punctuation">(</span>blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> IPAD<span class="token punctuation">)</span> <span class="token operator">+</span> irow<span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>完整的内核代码如下所示：</li></ul>`,5),pn={class:"hint-container details"},on=n("summary",null,"Click me to view the code!",-1),cn=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s("__global__ "),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"setRowReadColDynPad"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("out"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token comment"},"// dynamic shared memory"),s(`
 `),n("span",{class:"token keyword"},"extern"),s(" __shared__ "),n("span",{class:"token keyword"},"int"),s(" tile"),n("span",{class:"token punctuation"},"["),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// mapping from thread index to global memory index"),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" g_idx "),n("span",{class:"token operator"},"="),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("y "),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"+"),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// convert idx to transposed (row, col)"),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" irow "),n("span",{class:"token operator"},"="),s(" g_idx "),n("span",{class:"token operator"},"/"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("y"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" icol "),n("span",{class:"token operator"},"="),s(" g_idx "),n("span",{class:"token operator"},"%"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("y"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" row_idx "),n("span",{class:"token operator"},"="),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("y "),n("span",{class:"token operator"},"*"),s(),n("span",{class:"token punctuation"},"("),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"+"),s(" IPAD"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"+"),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// convert back to smem idx to access the transposed element"),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" col_idx "),n("span",{class:"token operator"},"="),s(" icol "),n("span",{class:"token operator"},"*"),s(),n("span",{class:"token punctuation"},"("),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"+"),s(" IPAD"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"+"),s(" irow"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// shared memory store operation"),s(`
 tile`),n("span",{class:"token punctuation"},"["),s("row_idx"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" g_idx"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// wait for all threads to complete"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// shared memory load operation"),s(`
 out`),n("span",{class:"token punctuation"},"["),s("g_idx"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" tile"),n("span",{class:"token punctuation"},"["),s("col_idx"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
`),n("span",{class:"token punctuation"},"}"),s(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),ln=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s(`可以通过减少每个请求的事务来测试共享内存填充的情况。报告如下：
Kernel`),n("span",{class:"token operator"},":"),s(),n("span",{class:"token function"},"setRowReadColDynPad"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},")"),s(`
 `),n("span",{class:"token number"},"1"),s(" shared_load_transactions_per_request "),n("span",{class:"token number"},"1.000000"),s(`
 `),n("span",{class:"token number"},"1"),s(" shared_store_transactions_per_request "),n("span",{class:"token number"},"1.000000"),s(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),un=c(`<h4 id="_5-2-2-6-矩形共享内存内核性能的比较" tabindex="-1"><a class="header-anchor" href="#_5-2-2-6-矩形共享内存内核性能的比较" aria-hidden="true">#</a> 5.2.2.6 矩形共享内存内核性能的比较</h4><ul><li>运行以下命令，计算在本节中使用矩形数组实现的所有核函数的运行时间。在一般情<br> 况下，核函数使用共享内存填充消除存储体冲突以提高性能，使用动态共享内存的核函数<br> 会显示有少量的消耗</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>$ nvprof <span class="token punctuation">.</span><span class="token operator">/</span>smemRectangle 
<span class="token punctuation">.</span><span class="token operator">/</span>smemRectangle at device <span class="token number">0</span><span class="token operator">:</span> Tesla K40c with Bank Mode<span class="token operator">:</span><span class="token number">4</span><span class="token operator">-</span>Byte 
<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span> <span class="token function">grid</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token function">block</span> <span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span>
<span class="token function">Time</span><span class="token punctuation">(</span><span class="token operator">%</span><span class="token punctuation">)</span> Time Calls Avg Min Max Name
 <span class="token number">5.35</span><span class="token operator">%</span> <span class="token number">2.4000u</span>s <span class="token number">1</span> <span class="token number">2.4000u</span>s <span class="token number">2.4000u</span>s <span class="token number">2.4000u</span>s <span class="token function">setRowReadColDyn</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span>
 <span class="token number">4.99</span><span class="token operator">%</span> <span class="token number">2.2400u</span>s <span class="token number">1</span> <span class="token number">2.2400u</span>s <span class="token number">2.2400u</span>s <span class="token number">2.2400u</span>s <span class="token function">setRowReadColDynPad</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span>
 <span class="token number">4.85</span><span class="token operator">%</span> <span class="token number">2.1760u</span>s <span class="token number">1</span> <span class="token number">2.1760u</span>s <span class="token number">2.1760u</span>s <span class="token number">2.1760u</span>s <span class="token function">setRowReadCol</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span>
 <span class="token number">4.71</span><span class="token operator">%</span> <span class="token number">2.1120u</span>s <span class="token number">1</span> <span class="token number">2.1120u</span>s <span class="token number">2.1120u</span>s <span class="token number">2.1120u</span>s <span class="token function">setRowReadColPad</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span>
 <span class="token number">4.07</span><span class="token operator">%</span> <span class="token number">1.8240u</span>s <span class="token number">1</span> <span class="token number">1.8240u</span>s <span class="token number">1.8240u</span>s <span class="token number">1.8240u</span>s <span class="token function">setRowReadRow</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>要想显示所有内核产生的内容，需将矩形共享内存数组的维度重新定义为一个非常小<br> 的数，如下所示：<br><code>#define BDIMX 8</code><br><code>#define BDIMY 2</code></p></li><li><p>然后，编译和运行以下命令，列出由所有核函数生成的二维矩阵的内容。第一个核函<br> 数产生原始矩阵，所有其他的核函数使用矩形共享内存数组进行转置操作。</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>
$ <span class="token punctuation">.</span><span class="token operator">/</span>smemRectangle <span class="token number">1</span>
<span class="token punctuation">.</span><span class="token operator">/</span>smemRectangle at device <span class="token number">0</span><span class="token operator">:</span> Tesla K40c with Bank Mode<span class="token operator">:</span><span class="token number">4</span><span class="token operator">-</span>Byte <span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span> <span class="token function">grid</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token function">block</span> 
<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span>
setRowReadRow <span class="token operator">:</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">2</span> <span class="token number">3</span> <span class="token number">4</span> <span class="token number">5</span> <span class="token number">6</span> <span class="token number">7</span> <span class="token number">8</span> <span class="token number">9</span> <span class="token number">10</span> <span class="token number">11</span> <span class="token number">12</span> <span class="token number">13</span> <span class="token number">14</span> <span class="token number">15</span>
setRowReadCol <span class="token operator">:</span> <span class="token number">0</span> <span class="token number">8</span> <span class="token number">1</span> <span class="token number">9</span> <span class="token number">2</span> <span class="token number">10</span> <span class="token number">3</span> <span class="token number">11</span> <span class="token number">4</span> <span class="token number">12</span> <span class="token number">5</span> <span class="token number">13</span> <span class="token number">6</span> <span class="token number">14</span> <span class="token number">7</span> <span class="token number">15</span>
setRowReadColDyn <span class="token operator">:</span> <span class="token number">0</span> <span class="token number">8</span> <span class="token number">1</span> <span class="token number">9</span> <span class="token number">2</span> <span class="token number">10</span> <span class="token number">3</span> <span class="token number">11</span> <span class="token number">4</span> <span class="token number">12</span> <span class="token number">5</span> <span class="token number">13</span> <span class="token number">6</span> <span class="token number">14</span> <span class="token number">7</span> <span class="token number">15</span>
setRowReadColPad <span class="token operator">:</span> <span class="token number">0</span> <span class="token number">8</span> <span class="token number">1</span> <span class="token number">9</span> <span class="token number">2</span> <span class="token number">10</span> <span class="token number">3</span> <span class="token number">11</span> <span class="token number">4</span> <span class="token number">12</span> <span class="token number">5</span> <span class="token number">13</span> <span class="token number">6</span> <span class="token number">14</span> <span class="token number">7</span> <span class="token number">15</span>
setRowReadColDynPad <span class="token operator">:</span> <span class="token number">0</span> <span class="token number">8</span> <span class="token number">1</span> <span class="token number">9</span> <span class="token number">2</span> <span class="token number">10</span> <span class="token number">3</span> <span class="token number">11</span> <span class="token number">4</span> <span class="token number">12</span> <span class="token number">5</span> <span class="token number">13</span> <span class="token number">6</span> <span class="token number">14</span> <span class="token number">7</span> <span class="token number">15</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_5-3-减少全局内存访问" tabindex="-1"><a class="header-anchor" href="#_5-3-减少全局内存访问" aria-hidden="true">#</a> 5.3 减少全局内存访问</h2><ul><li><p>使用共享内存的主要原因之一是要缓存片上的数据，从而减少核函数中全局内存访问<br> 的次数。第3章介绍了使用全局内存的并行归约核函数，并集中解释了以下几个问题：<br> ·如何重新安排数据访问模式以避免线程束分化<br> ·如何展开循环以保证有足够的操作使指令和内存带宽饱和</p></li><li><p>在本节中，将重新使用这些并行归约核函数，但是这里使用共享内存作为可编程管理<br> 缓存以减少全局内存的访问.</p></li></ul><h3 id="_5-3-1-使用共享内存的并行归约" tabindex="-1"><a class="header-anchor" href="#_5-3-1-使用共享内存的并行归约" aria-hidden="true">#</a> 5.3.1 使用共享内存的并行归约</h3><ul><li>下面的reduceGmem核函数将被用作基准性能的起点，在第3章中介绍过该函数。实现<br> 并行归约只使用全局内存，输入元素的内循环是完全展开的。以下的核函数代码可以在<br> Wrox.com上的reduceInteger.cu文件中找到。</li></ul>`,9),rn={class:"hint-container details"},kn=n("summary",null,"Click me to view the code!",-1),dn=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s("__global__ "),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"reduceGmem"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("g_idata"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("g_odata"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" n"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token comment"},"// set thread ID"),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" tid "),n("span",{class:"token operator"},"="),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("idata "),n("span",{class:"token operator"},"="),s(" g_idata "),n("span",{class:"token operator"},"+"),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// boundary check "),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" idx "),n("span",{class:"token operator"},"="),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"+"),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("idx "),n("span",{class:"token operator"},">="),s(" n"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token keyword"},"return"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// in-place reduction in global memory"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},">="),s(),n("span",{class:"token number"},"1024"),s(),n("span",{class:"token operator"},"&&"),s(" tid "),n("span",{class:"token operator"},"<"),s(),n("span",{class:"token number"},"512"),n("span",{class:"token punctuation"},")"),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"512"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},">="),s(),n("span",{class:"token number"},"512"),s(),n("span",{class:"token operator"},"&&"),s(" tid "),n("span",{class:"token operator"},"<"),s(),n("span",{class:"token number"},"256"),n("span",{class:"token punctuation"},")"),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"256"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},">="),s(),n("span",{class:"token number"},"256"),s(),n("span",{class:"token operator"},"&&"),s(" tid "),n("span",{class:"token operator"},"<"),s(),n("span",{class:"token number"},"128"),n("span",{class:"token punctuation"},")"),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"128"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},">="),s(),n("span",{class:"token number"},"128"),s(),n("span",{class:"token operator"},"&&"),s(" tid "),n("span",{class:"token operator"},"<"),s(),n("span",{class:"token number"},"64"),n("span",{class:"token punctuation"},")"),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"64"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// unrolling warp"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("tid "),n("span",{class:"token operator"},"<"),s(),n("span",{class:"token number"},"32"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token keyword"},"volatile"),s(),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("vsmem "),n("span",{class:"token operator"},"="),s(" idata"),n("span",{class:"token punctuation"},";"),s(`
 vsmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vsmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"32"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 vsmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vsmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"16"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 vsmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vsmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"8"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 vsmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vsmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"4"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 vsmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vsmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"2"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 vsmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vsmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token comment"},"// write result for this block to global mem"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("tid "),n("span",{class:"token operator"},"=="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s(" g_odata"),n("span",{class:"token punctuation"},"["),s("blockIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" idata"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
`),n("span",{class:"token punctuation"},"}"),s(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),mn=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s("yarn add "),n("span",{class:"token operator"},"-"),s("D vuepress"),n("span",{class:"token operator"},"-"),s("theme"),n("span",{class:"token operator"},"-"),s(`hope
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"})])],-1),bn=c(`<ul><li><p>这个核函数有4个主要部分。首先，计算数据块的偏移量，该数据块属于线程块，与<br> 全局输入有关。<code>int *idata = g_idata + blockIdx.x * blockDim.x;</code></p></li><li><p>接下来，核函数执行一个使用全局内存的原地归约，将其归约到32个元素：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code> <span class="token comment">// in-place reduction in global memory</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>blockDim<span class="token punctuation">.</span>x <span class="token operator">&gt;=</span> <span class="token number">1024</span> <span class="token operator">&amp;&amp;</span> tid <span class="token operator">&lt;</span> <span class="token number">512</span><span class="token punctuation">)</span> idata<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> idata<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>blockDim<span class="token punctuation">.</span>x <span class="token operator">&gt;=</span> <span class="token number">512</span> <span class="token operator">&amp;&amp;</span> tid <span class="token operator">&lt;</span> <span class="token number">256</span><span class="token punctuation">)</span> idata<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> idata<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>blockDim<span class="token punctuation">.</span>x <span class="token operator">&gt;=</span> <span class="token number">256</span> <span class="token operator">&amp;&amp;</span> tid <span class="token operator">&lt;</span> <span class="token number">128</span><span class="token punctuation">)</span> idata<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> idata<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>blockDim<span class="token punctuation">.</span>x <span class="token operator">&gt;=</span> <span class="token number">128</span> <span class="token operator">&amp;&amp;</span> tid <span class="token operator">&lt;</span> <span class="token number">64</span><span class="token punctuation">)</span> idata<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> idata<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>然后，核函数执行原地归约，这个过程仅使用每个线程块的第一个线程束。注意在循<br> 环展开的部分，volatile修饰符用来确保当线程束在锁步中执行时，只有最新数值能被读取。</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">volatile</span> <span class="token keyword">int</span> <span class="token operator">*</span>vsmem <span class="token operator">=</span> idata<span class="token punctuation">;</span>
vsmem<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> vsmem<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
vsmem<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> vsmem<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">16</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
vsmem<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> vsmem<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
vsmem<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> vsmem<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
vsmem<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> vsmem<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
vsmem<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> vsmem<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>最后，分配给该线程块的输入数据块总数被写回到全局内存中：<code>if (tid == 0) g_odata[blockIdx.x] = idata[0];</code></p></li><li><p>在所有的测试中，使用以下语句，数组的长度将被设置为16M，这相当于减少了整型<br> 的数目。<code>int size = 1&lt;&lt;24;</code></p></li><li><p>使用下述的宏，将块大小设置为恒定的128个线程：<code>#define DIM 128</code></p></li><li><p>现在，用以下命令编译文件：<code>$ nvcc reduceInteger.cu –o reduce</code></p></li><li><p>使用nvprof计算这个仅使用全局内存的归约核函数的运行时间：<code>$ nvprof ./reduce</code></p></li><li><p>使用Tesla k40c的基准结果总结如下：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>reduce at device <span class="token number">0</span><span class="token operator">:</span> Tesla K40c with array size <span class="token number">16777216</span> grid <span class="token number">131072</span> block <span class="token number">128</span>
<span class="token function">Time</span><span class="token punctuation">(</span><span class="token operator">%</span><span class="token punctuation">)</span> Time Calls Avg Min Max Name
 <span class="token number">2.01</span><span class="token operator">%</span> <span class="token number">2.1206</span>ms <span class="token number">1</span> <span class="token number">2.1206</span>ms <span class="token number">2.1206</span>ms <span class="token number">2.1206</span>ms <span class="token function">reduceGmem</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><br><ul><li>接下来测试下面的原地归约核函数reduceSmem，它增加了带有共享内存的全局内存<br> 操作。这个核函数和原来的reduceGmem核函数几乎相同。然而，reduceSmem函数没有使<br> 用全局内存中的输入数组子集来执行原地归约，而是使用了共享内存数组smem。smem被<br> 声明为与每个线程块具有相同的维度。</li></ul>`,8),vn={class:"hint-container details"},_n=n("summary",null,"Click me to view the code!",-1),hn=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s("__shared__ "),n("span",{class:"token keyword"},"int"),s(" smem"),n("span",{class:"token punctuation"},"["),s("DIM"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
`),n("span",{class:"token comment"},"//每个线程块都用它的全局输入数据块来初始化smem数组："),s(`
smem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
`),n("span",{class:"token function"},"syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
然后，原地归约是使用共享内存（smem）被执行的，而不是全局内存（idata）。
reduce`),n("span",{class:"token operator"},"-"),s(`Smem核函数的代码如下：

__global__ `),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"reduceSmem"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("g_idata"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("g_odata"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" n"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 __shared__ `),n("span",{class:"token keyword"},"int"),s(" smem"),n("span",{class:"token punctuation"},"["),s("DIM"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// set thread ID"),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" tid "),n("span",{class:"token operator"},"="),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// boundary check"),s(`
`),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" idx "),n("span",{class:"token operator"},"="),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"+"),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("idx "),n("span",{class:"token operator"},">="),s(" n"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token keyword"},"return"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// convert global data pointer to the local pointer of this block"),s(`
 `),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("idata "),n("span",{class:"token operator"},"="),s(" g_idata "),n("span",{class:"token operator"},"+"),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"*"),s(" blockDim"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// set to smem by each threads"),s(`
 smem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" idata"),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// in-place reduction in shared memory"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},">="),s(),n("span",{class:"token number"},"1024"),s(),n("span",{class:"token operator"},"&&"),s(" tid "),n("span",{class:"token operator"},"<"),s(),n("span",{class:"token number"},"512"),n("span",{class:"token punctuation"},")"),s(" smem"),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" smem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"512"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},">="),s(),n("span",{class:"token number"},"512"),s(),n("span",{class:"token operator"},"&&"),s(" tid "),n("span",{class:"token operator"},"<"),s(),n("span",{class:"token number"},"256"),n("span",{class:"token punctuation"},")"),s(" smem"),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" smem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"256"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},">="),s(),n("span",{class:"token number"},"256"),s(),n("span",{class:"token operator"},"&&"),s(" tid "),n("span",{class:"token operator"},"<"),s(),n("span",{class:"token number"},"128"),n("span",{class:"token punctuation"},")"),s(" smem"),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" smem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"128"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},">="),s(),n("span",{class:"token number"},"128"),s(),n("span",{class:"token operator"},"&&"),s(" tid "),n("span",{class:"token operator"},"<"),s(),n("span",{class:"token number"},"64"),n("span",{class:"token punctuation"},")"),s(" smem"),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" smem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"64"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// unrolling warp"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("tid "),n("span",{class:"token operator"},"<"),s(),n("span",{class:"token number"},"32"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token keyword"},"volatile"),s(),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("vsmem "),n("span",{class:"token operator"},"="),s(" smem"),n("span",{class:"token punctuation"},";"),s(`
 vsmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vsmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"32"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 vsmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vsmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"16"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 vsmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vsmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"8"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 vsmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vsmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"4"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 vsmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vsmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"2"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 vsmem`),n("span",{class:"token punctuation"},"["),s("tid"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"+="),s(" vsmem"),n("span",{class:"token punctuation"},"["),s("tid "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 `),n("span",{class:"token comment"},"// write result for this block to global mem"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("tid "),n("span",{class:"token operator"},"=="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s(" g_odata"),n("span",{class:"token punctuation"},"["),s("blockIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" smem"),n("span",{class:"token punctuation"},"["),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
`),n("span",{class:"token punctuation"},"}"),s(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),yn=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[n("span",{class:"token comment"},"//用nvprof为两个核函数（有共享内存和没有共享内存的）计算运行时间："),s(`
$ nvprof `),n("span",{class:"token punctuation"},"."),n("span",{class:"token operator"},"/"),s(`reduce

使用Tesla K40c的结果总结如下：
reduce at device `),n("span",{class:"token number"},"0"),n("span",{class:"token operator"},":"),s(" Tesla K40c with array size "),n("span",{class:"token number"},"16777216"),s(" grid "),n("span",{class:"token number"},"131072"),s(" block "),n("span",{class:"token number"},"128"),s(`
`),n("span",{class:"token function"},"Time"),n("span",{class:"token punctuation"},"("),n("span",{class:"token operator"},"%"),n("span",{class:"token punctuation"},")"),s(` Time Calls Avg Min Max Name
 `),n("span",{class:"token number"},"2.01"),n("span",{class:"token operator"},"%"),s(),n("span",{class:"token number"},"2.1206"),s("ms "),n("span",{class:"token number"},"1"),s(),n("span",{class:"token number"},"2.1206"),s("ms "),n("span",{class:"token number"},"2.1206"),s("ms "),n("span",{class:"token number"},"2.1206"),s("ms "),n("span",{class:"token function"},"reduceGmem"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),s(`
 `),n("span",{class:"token number"},"1.10"),n("span",{class:"token operator"},"%"),s(),n("span",{class:"token number"},"1.1536"),s("ms "),n("span",{class:"token number"},"1"),s(),n("span",{class:"token number"},"1.1536"),s("ms "),n("span",{class:"token number"},"1.1536"),s("ms "),n("span",{class:"token number"},"1.1536"),s("ms "),n("span",{class:"token function"},"reduceSmem"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),s(`

使用共享内存的核函数比只使用全局内存的核函数快了`),n("span",{class:"token number"},"1.84"),s(`倍。下一步，使用下列指
标测试全局内存加载和存储事务，看一下共享内存是如何很好地减少全局内存访问的：
gld_transactions`),n("span",{class:"token operator"},":"),s(` Number of global memory load transactions
gst_transactions`),n("span",{class:"token operator"},":"),s(` Number of global memory store transactions

结果总结如下：

Device `),n("span",{class:"token string"},'"Tesla K40c (0)"'),s(`
 Kernel`),n("span",{class:"token operator"},":"),s(),n("span",{class:"token function"},"reduceSmem"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"int"),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),n("span",{class:"token punctuation"},")"),s(`
 `),n("span",{class:"token number"},"1"),s(" Global Load Transactions "),n("span",{class:"token number"},"524288"),s(` 
 `),n("span",{class:"token number"},"1"),s(" Global Store Transactions "),n("span",{class:"token number"},"131072"),s(` 
 Kernel`),n("span",{class:"token operator"},":"),s(),n("span",{class:"token function"},"reduceGmem"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"int"),n("span",{class:"token operator"},"*"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),n("span",{class:"token punctuation"},")"),s(`
 `),n("span",{class:"token number"},"1"),s(" Global Load Transactions "),n("span",{class:"token number"},"2883584"),s(` 
 `),n("span",{class:"token number"},"1"),s(" Global Store Transactions "),n("span",{class:"token number"},"1179648"),s(`

从这个结果可以看出，使用共享内存明显减少了全局内存访问。
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),xn=c(`<h3 id="_5-3-2-使用展开的并行归约" tabindex="-1"><a class="header-anchor" href="#_5-3-2-使用展开的并行归约" aria-hidden="true">#</a> 5.3.2 使用展开的并行归约</h3><ul><li><p>在前面的核函数中，每个线程块处理一个数据块。在第3章中，可以通过一次运行多<br> 个I/O操作，展开线程块来提高内核性能。以下内核展开了4个线程块，即每个线程处理来<br> 自于4个数据块的数据元素。通过展开，以下优势是可预期的：<br> ·通过在每个线程中提供更多的并行I/O，增加全局内存的吞吐量<br> ·全局内存存储事务减少了1/4<br> ·整体内核性能的提升</p></li><li><p>核函数的代码如下：</p></li></ul><details class="hint-container details"><summary>Click me to view the code!</summary><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">reduceSmemUnroll</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token operator">*</span>g_idata<span class="token punctuation">,</span> <span class="token keyword">int</span> <span class="token operator">*</span>g_odata<span class="token punctuation">,</span> <span class="token keyword">unsigned</span> <span class="token keyword">int</span> n<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token comment">// static shared memory</span>
 __shared__ <span class="token keyword">int</span> smem<span class="token punctuation">[</span>DIM<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token comment">// set thread ID</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> tid <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 <span class="token comment">// global index, 4 blocks of input data processed at a time</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> idx <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">*</span> <span class="token number">4</span> <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 <span class="token comment">// unrolling 4 blocks</span>
 <span class="token keyword">int</span> tmpSum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
 <span class="token comment">// boundary check</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>idx <span class="token operator">+</span> <span class="token number">3</span> <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">&lt;=</span> n<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token keyword">int</span> a1 <span class="token operator">=</span> g_idata<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token keyword">int</span> a2 <span class="token operator">=</span> g_idata<span class="token punctuation">[</span>idx <span class="token operator">+</span> blockDim<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token keyword">int</span> a3 <span class="token operator">=</span> g_idata<span class="token punctuation">[</span>idx <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token keyword">int</span> a4 <span class="token operator">=</span> g_idata<span class="token punctuation">[</span>idx <span class="token operator">+</span> <span class="token number">3</span> <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">;</span>
 tmpSum <span class="token operator">=</span> a1 <span class="token operator">+</span> a2 <span class="token operator">+</span> a3 <span class="token operator">+</span> a4<span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 
 smem<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">=</span> tmpSum<span class="token punctuation">;</span>
 <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// in-place reduction in shared memory</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>blockDim<span class="token punctuation">.</span>x <span class="token operator">&gt;=</span> <span class="token number">1024</span> <span class="token operator">&amp;&amp;</span> tid <span class="token operator">&lt;</span> <span class="token number">512</span><span class="token punctuation">)</span> smem<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> smem<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>blockDim<span class="token punctuation">.</span>x <span class="token operator">&gt;=</span> <span class="token number">512</span> <span class="token operator">&amp;&amp;</span> tid <span class="token operator">&lt;</span> <span class="token number">256</span><span class="token punctuation">)</span> smem<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> smem<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>blockDim<span class="token punctuation">.</span>x <span class="token operator">&gt;=</span> <span class="token number">256</span> <span class="token operator">&amp;&amp;</span> tid <span class="token operator">&lt;</span> <span class="token number">128</span><span class="token punctuation">)</span> smem<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> smem<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>blockDim<span class="token punctuation">.</span>x <span class="token operator">&gt;=</span> <span class="token number">128</span> <span class="token operator">&amp;&amp;</span> tid <span class="token operator">&lt;</span> <span class="token number">64</span><span class="token punctuation">)</span> smem<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> smem<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// unrolling warp</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>tid <span class="token operator">&lt;</span> <span class="token number">32</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token keyword">volatile</span> <span class="token keyword">int</span> <span class="token operator">*</span>vsmem <span class="token operator">=</span> smem<span class="token punctuation">;</span>
 vsmem<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> vsmem<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
 vsmem<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> vsmem<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">16</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
 vsmem<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> vsmem<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
 vsmem<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> vsmem<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
 vsmem<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> vsmem<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
 vsmem<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> vsmem<span class="token punctuation">[</span>tid <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 <span class="token comment">// write result for this block to global mem</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>tid <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> g_odata<span class="token punctuation">[</span>blockIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span> <span class="token operator">=</span> smem<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><ul><li><p>要使每个线程处理4个数据元素，第一步是基于每个线程的线程块和线程索引，重新<br> 计算全局输入数据的偏移：<br><code>unsigned int idx = blockIdx.x * blockDim.x * 4 + threadIdx.x;</code></p></li><li><p>因为每个线程读取4个数据元素，所以每个线程的处理起点现在被偏移为就好像是线<br> 程块的4倍。利用这个新的偏移，每个线程读取4个数据元素，然后将其添加到局部变量<br> tmpSum中。然后，tmpSum用于初始化共享内存，而不是直接从全局内存进行初始化。</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">int</span> tmpSum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span>idx <span class="token operator">+</span> <span class="token number">3</span> <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">&lt;=</span> n<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token keyword">int</span> a1 <span class="token operator">=</span> g_idata<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token keyword">int</span> a2 <span class="token operator">=</span> g_idata<span class="token punctuation">[</span>idx <span class="token operator">+</span> blockDim<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token keyword">int</span> a3 <span class="token operator">=</span> g_idata<span class="token punctuation">[</span>idx <span class="token operator">+</span><span class="token number">2</span> <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token keyword">int</span> a4 <span class="token operator">=</span> g_idata<span class="token punctuation">[</span>idx <span class="token operator">+</span><span class="token number">3</span> <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">;</span>
 tmpSum <span class="token operator">=</span> a1 <span class="token operator">+</span> a2 <span class="token operator">+</span> a3 <span class="token operator">+</span> a4<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>在这个展开下，全局内存加载事务的数量在核函数中没有变化，但是全局内存存储事<br> 务的数量减少了1/4。此外，一次运行4个全局加载运算，GPU在并发调度时有了更大的灵<br> 活性，可能会产生更好的全局内存利用率。</p></li><li><p>该核函数的网格维度必须被减少到每个线程执行工作量的1/4：<br><code>reduceGmemUnroll&lt;&lt;&lt;grid.x / 4, block&gt;&gt;&gt;(d_idata, d_odata, size);</code></p></li><li><p>有了这些变化，使用nvprof检查运行时间。被4展开的共享内存核函数（reduceSmemUnroll），比示例系统中的上个共享内存核函数（reduceSmem）快了2.76倍。结果概括如下：</p></li></ul><details class="hint-container details"><summary>Click me to view the code!</summary><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>reduce at device <span class="token number">0</span><span class="token operator">:</span> Tesla K40c with array size <span class="token number">16777216</span> grid <span class="token number">131072</span> block <span class="token number">128</span>
<span class="token function">Time</span><span class="token punctuation">(</span><span class="token operator">%</span><span class="token punctuation">)</span> Time Calls Avg Min Max Name
 <span class="token number">1.10</span><span class="token operator">%</span> <span class="token number">1.1536</span>ms <span class="token number">1</span> <span class="token number">1.1536</span>ms <span class="token number">1.1536</span>ms <span class="token number">1.1536</span>ms <span class="token function">reduceSmem</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
 <span class="token number">0.40</span><span class="token operator">%</span> <span class="token number">418.27u</span>s <span class="token number">1</span> <span class="token number">418.27u</span>s <span class="token number">418.27u</span>s <span class="token number">418.27u</span>s <span class="token function">reduceSmemUnroll</span><span class="token punctuation">(</span><span class="token punctuation">)</span>


使用nvprof检查全局内存事务也是有趣的。同reduceSeme函数相比，reduceSmem<span class="token operator">-</span>
Unroll函数中存储事务的数量减少了<span class="token number">1</span><span class="token operator">/</span><span class="token number">4</span>，然而加载事务的数量保持不变，结果如下所示：
Kernel<span class="token operator">:</span> <span class="token function">reduceSmem</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">unsigned</span> <span class="token keyword">int</span><span class="token punctuation">)</span>
 <span class="token number">1</span> Global Load Transactions <span class="token number">524288</span> 
 <span class="token number">1</span> Global Store Transactions <span class="token number">131072</span> 
Kernel<span class="token operator">:</span> <span class="token function">reduceSmemUnroll</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">unsigned</span> <span class="token keyword">int</span><span class="token punctuation">)</span>
 <span class="token number">1</span> Global Load Transactions <span class="token number">524288</span> 
 <span class="token number">1</span> Global Store Transactions <span class="token number">32768</span>


最后，检查全局内存吞吐量。加载吞吐量增加了<span class="token number">2.57</span>倍而存储吞吐量下降了<span class="token number">1.56</span>倍。
加载吞吐量的增加归因于大量的同时加载请求。存储吞吐量的下降是因为较少的存储请求
使总线达到了饱和。结果总结如下：

Kernel<span class="token operator">:</span> <span class="token function">reduceSmem</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">unsigned</span> <span class="token keyword">int</span><span class="token punctuation">)</span>
 <span class="token number">1</span> Requested Global Load Throughput <span class="token number">63.537</span>GB<span class="token operator">/</span>s 
 <span class="token number">1</span> Requested Global Store Throughput <span class="token number">496.38</span> MB<span class="token operator">/</span>s 
Kernel<span class="token operator">:</span> <span class="token function">reduceSmemUnroll</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">unsigned</span> <span class="token keyword">int</span><span class="token punctuation">)</span>
 <span class="token number">1</span> Requested Global Load Throughput <span class="token number">162.57</span> GB<span class="token operator">/</span>s 
 <span class="token number">1</span> Requested Global Store Throughput <span class="token number">317.53</span> MB<span class="token operator">/</span>s
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><h3 id="_5-3-3-使用动态共享内存的并行归约" tabindex="-1"><a class="header-anchor" href="#_5-3-3-使用动态共享内存的并行归约" aria-hidden="true">#</a> 5.3.3 使用动态共享内存的并行归约</h3><ul><li><p>并行归约核函数还可以使用动态共享内存来执行，通过以下声明，<br> 在reduceSmemUnroll中用动态共享内存取代静态共享内存：<code>extern __shared__ int smem[];</code></p></li><li><p>启动核函数时，必须指定待动态分配的共享内存数量：<br><code>reduceSmemUnrollDyn&lt;&lt;&lt;grid.x / 4, block, DIM * sizeof(int)&gt;&gt;&gt;(d_idata, d_odata, size);</code></p></li><li><p>如果用nvprof计算核函数的运行时间，那么会发现用动态分配共享内存实现的核函数<br> 和用静态分配共享内存实现的核函数之间没有显著的差异。</p></li></ul><h3 id="_5-3-4-有效带宽" tabindex="-1"><a class="header-anchor" href="#_5-3-4-有效带宽" aria-hidden="true">#</a> 5.3.4 有效带宽</h3><ul><li><p>由于归约核函数是受内存带宽约束的，所以评估它们时所使用的适当的性能指标是有<br> 效带宽。有效带宽是在核函数的完整执行时间内I/O的数量（以字节为单位）。对于内存<br> 约束的应用程序，有效带宽是一个估算实际带宽利用率的很好的指标。它可以表示为：</p><ul><li>有效带宽＝（读字节＋写字节）÷（运行时间×109）GB/s</li></ul></li><li><p>表5-1总结了每个核函数已取得的有效带宽。显然，可以通过展开块来获得有效带宽<br> 的显著改进。这样做使每个线程在运行中同时有多个请求，这会导致内存总线高饱和。<br><img src="`+M+`" alt="table5-1" loading="lazy"></p></li></ul><h2 id="_5-4-合并的全局内存访问" tabindex="-1"><a class="header-anchor" href="#_5-4-合并的全局内存访问" aria-hidden="true">#</a> 5.4 合并的全局内存访问</h2><ul><li><p>使用共享内存也能帮助避免对未合并的全局内存的访问。矩阵转置就是一个典型的例<br> 子：读操作被自然合并，但写操作是按照交叉访问的。第4章中已表明，交叉访问是全局<br> 内存中最糟糕的访问模式，因为它浪费总线带宽。在共享内存的帮助下，可以先在共享内<br> 存中进行转置操作，然后再对全局内存进行合并写操作。</p></li><li><p>在本章前面的部分，测试了一个矩阵转置核函数，该核函数使用单个线程块对共享内<br> 存中的矩阵行进行写入，并读取共享内存中的矩阵列。在本节中，将扩展该核函数，具体<br> 方法是使用多个线程块对基于交叉的全局内存访问重新排序到合并访问。</p></li></ul><h3 id="_5-4-1-基准转置内核" tabindex="-1"><a class="header-anchor" href="#_5-4-1-基准转置内核" aria-hidden="true">#</a> 5.4.1 基准转置内核</h3><ul><li>作为基准，下面的核函数是一个仅使用全局内存的矩阵转置的朴素实现。</li></ul><details class="hint-container details"><summary>Click me to view the code!</summary><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">naiveGmem</span><span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span>out<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>in<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">int</span> nx<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">int</span> ny<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token comment">// matrix coordinate (ix,iy)</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> ix <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> iy <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>y <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>y <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">;</span>
 <span class="token comment">// transpose with boundary test</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>ix <span class="token operator">&lt;</span> nx <span class="token operator">&amp;&amp;</span> iy <span class="token operator">&lt;</span> ny<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 out<span class="token punctuation">[</span>ix<span class="token operator">*</span>ny<span class="token operator">+</span>iy<span class="token punctuation">]</span><span class="token operator">=</span> in<span class="token punctuation">[</span>iy<span class="token operator">*</span>nx<span class="token operator">+</span>ix<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><ul><li><p>因为ix是这个核函数二维线程配置的最内层维度，全局内存读操作在线程束内是被合<br> 并的，而全局内存写操作在相邻线程间是交叉访问的。naiveGmem核函数的性能是一个下<br> 界，本节中涵盖的逐步优化将再次被测量。</p></li><li><p>以执行合并访问为目的的更改写操作会生成副本内核。因为读写操作将被合并，但仍<br> 执行相同数量的I/O，所以copyGmem函数将成为一个性能近似的上界：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">copyGmem</span><span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span>out<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>in<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">int</span> nx<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">int</span> ny<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token comment">// matrix coordinate (ix,iy)</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> ix <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> iy <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>y <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>y <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">;</span>
 <span class="token comment">// transpose with boundary test</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>ix <span class="token operator">&lt;</span> nx <span class="token operator">&amp;&amp;</span> iy <span class="token operator">&lt;</span> ny<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 out<span class="token punctuation">[</span>iy <span class="token operator">*</span> nx <span class="token operator">+</span> ix<span class="token punctuation">]</span> <span class="token operator">=</span> in<span class="token punctuation">[</span>iy <span class="token operator">*</span> nx <span class="token operator">+</span> ix<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>这个部分的核函数和主机代码可以在Wrox.com上的transposeRectangle.cu中找到。对于<br> 这些测试，矩阵大小被设置为4096×4096，并且还会用到一个维度为32×16的二维线程块。</p></li><li><p>在Tesla M2090和Tesla K40c上，copyGmem和naiveGmem核函数的结果总结如表5-2所示。<br><img src="`+C+`" alt="table5-2" loading="lazy"></p></li><li><p>副本内核比朴素内核快了将近3倍。由于朴素内核写入全局内存，使其带有了4096个<br> 元素的跨度，所以一个单一线程束的存储内存操作是由32个全局内存事务完成的。可以使<br> 用以下nvprof指标来确认这一点：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>gld_transactions_per_request<span class="token operator">:</span> average number of transactions per load request 
gst_transactions_per_request<span class="token operator">:</span> average number of transactions per store request
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>这些nvprof指标计算了加载和存储全局内存请求的平均事务的次数。在Tesla K40c上<br> 的结果如下所示，它表明对全局内存的存储请求在naiveGmem核函数中重复了32次。</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>Device <span class="token string">&quot;Tesla K40c (0)&quot;</span> Metrics Transactions
Kernel<span class="token operator">:</span><span class="token function">copyGmem</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">)</span>
 <span class="token number">1</span> gld_transactions_per_request <span class="token number">1.000000</span> 
 <span class="token number">1</span> gst_transactions_per_request <span class="token number">1.000000</span> 
Kernel<span class="token operator">:</span><span class="token function">naiveGmem</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">)</span>
 <span class="token number">1</span> gld_transactions_per_request <span class="token number">1.000000</span> 
 <span class="token number">1</span> gst_transactions_per_request <span class="token number">32.000000</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_5-4-2-使用共享内存的矩阵转置" tabindex="-1"><a class="header-anchor" href="#_5-4-2-使用共享内存的矩阵转置" aria-hidden="true">#</a> 5.4.2 使用共享内存的矩阵转置</h3><ul><li>为了避免交叉全局内存访问，可以使用二维共享内存来缓存原始矩阵的数据。从二维<br> 共享内存中读取的一列可以被转移到转置矩阵行中，它被存储在全局内存中。虽然朴素实<br> 现将导致共享内存存储体冲突，但这个结果将比非合并的全局内存访问好得多。图5-15显<br> 示了在矩阵转置中是如何使用共享内存的。</li></ul><figure><img src="`+B+`" alt="figure5-15" tabindex="0" loading="lazy"><figcaption>figure5-15</figcaption></figure><ul><li>下面的核函数实现了使用共享内存的矩阵转置。它可以被看作是前面的章节中所讨论<br> 的setRowReadCol函数的扩展。这两个核函数之间的差别在于setRowReadCol使用一个线程<br> 块处理输入矩阵的单块转置，而transposeSmem扩展了转置操作，使用了多个线程块和多<br> 个数据块。</li></ul><details class="hint-container details"><summary>Click me to view the code!</summary><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">transposeSmem</span><span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span>out<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>in<span class="token punctuation">,</span> <span class="token keyword">int</span> nx<span class="token punctuation">,</span> <span class="token keyword">int</span> ny<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token comment">// static shared memory</span>
 __shared__ <span class="token keyword">float</span> tile<span class="token punctuation">[</span>BDIMY<span class="token punctuation">]</span><span class="token punctuation">[</span>BDIMX<span class="token punctuation">]</span><span class="token punctuation">;</span>
 
 <span class="token comment">// coordinate in original matrix</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> ix<span class="token punctuation">,</span>iy<span class="token punctuation">,</span>ti<span class="token punctuation">,</span>to<span class="token punctuation">;</span>
 ix <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span>blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 iy <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>y <span class="token operator">*</span>blockDim<span class="token punctuation">.</span>y <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">;</span>
 
 <span class="token comment">// linear global memory index for original matrix</span>
 ti <span class="token operator">=</span> iy<span class="token operator">*</span>nx <span class="token operator">+</span> ix<span class="token punctuation">;</span>
 <span class="token comment">// thread index in transposed block</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> bidx<span class="token punctuation">,</span>irow<span class="token punctuation">,</span>icol<span class="token punctuation">;</span>
 bidx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>y<span class="token operator">*</span>blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 irow <span class="token operator">=</span> bidx<span class="token operator">/</span>blockDim<span class="token punctuation">.</span>y<span class="token punctuation">;</span>
 icol <span class="token operator">=</span> bidx<span class="token operator">%</span>blockDim<span class="token punctuation">.</span>y<span class="token punctuation">;</span>
 
 <span class="token comment">// coordinate in transposed matrix</span>
 ix <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>y <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>y <span class="token operator">+</span> icol<span class="token punctuation">;</span>
 iy <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> irow<span class="token punctuation">;</span>
 <span class="token comment">// linear global memory index for transposed matrix</span>
 to <span class="token operator">=</span> iy<span class="token operator">*</span>ny <span class="token operator">+</span> ix<span class="token punctuation">;</span>
 <span class="token comment">// transpose with boundary test</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>ix <span class="token operator">&lt;</span> nx <span class="token operator">&amp;&amp;</span> iy <span class="token operator">&lt;</span> ny<span class="token punctuation">)</span>
 <span class="token punctuation">{</span>
 <span class="token comment">// load data from global memory to shared memory</span>
 tile<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">]</span><span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span> <span class="token operator">=</span> in<span class="token punctuation">[</span>ti<span class="token punctuation">]</span><span class="token punctuation">;</span>
 
 <span class="token comment">// thread synchronization</span>
 <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 
 <span class="token comment">// store data to global memory from shared memory </span>
 out<span class="token punctuation">[</span>to<span class="token punctuation">]</span> <span class="token operator">=</span> tile<span class="token punctuation">[</span>icol<span class="token punctuation">]</span><span class="token punctuation">[</span>irow<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><ul><li><p>kerneltransposeSmem函数可被分解为以下几个步骤：<br> 1.线程束执行合并读取一行，该行存储在全局内存中的原始矩阵块中。<br> 2.然后，该线程束按行主序将该数据写入共享内存中，因此，这个写操作没有存储体冲突。<br> 3.因为线程块的读/写操作是同步的，所以会有一个填满全局内存数据的二维共享内存数组。<br> 4.该线程束从二维共享内存数组中读取一列。由于共享内存没有被填充，所以会发生存储体冲突。<br> 5.然后该线程束执行数据的合并写入操作，将其写入到全局内存的转置矩阵中的某行。</p></li><li><p>对于每一个线程，若要想从全局内存和共享内存中取得正确的数据，都必须计算多个<br> 索引。对于一个给定的线程，首先要基于其线程索引和块索引计算其原始矩阵坐标，如下：<br><code>ix = blockIdx.x * blockDim.x + threadIdx.x;</code><br><code>iy = blockIdx.y * blockDim.y + threadIdx.y;</code></p></li><li><p>然后可以计算出全局内存的索引：<code>ti = iy * nx + ix;</code></p></li><li><p>因为ix是沿着线程块的最内层维度，包含32个线程的线程束可以用ti对全局内存进行合并读取。<br> 同样，转置矩阵的坐标计算公式如下所示：<br><code>ix = blockIdx.y * blockDim.y + icol;</code><br><code>iy = blockIdx.x * blockDim.x + irow;</code></p></li><li><p>与原始矩阵中线程的坐标计算相比，它有两个主要的差异。</p></li><li><p>首先，转置矩阵中块的偏移交换了blockDim和blockIdx的使用：线程配置的x维度被用<br> 来计算转置矩阵的列坐标，y维度被用来计算行坐标。</p></li><li><p>此外，两个新的变量icol和irow被引入以代替threadIdx。这些变量是相应转置块的索引：<br><code>bidx = threadIdx.y * blockDim.x + threadIdx.x;</code><br><code>irow = bidx / blockDim.y;</code><br><code>icol = bidx % blockDim.y;</code></p></li><li><p>然后，用于存储转置矩阵的全局内存索引可以根据下式进行计算：<code>to = iy * ny + ix;</code></p></li><li><p>利用计算出的偏移量，线程中的线程束可以从全局内存中连续读取，并对二维共享内<br> 存数组tile的行进行写入，如下所示：<code>tile[threadIdx.y][threadIdx.x] = in[ti];</code></p></li><li><p>全局内存的读操作是合并的，同时共享内存存储体中的写操作没有冲突。所以线程中<br> 的线程束可以从共享内存tile中读取一列，并连续写入到全局内存中：<br><code>out[to] = tile[icol][irow];</code></p></li><li><p>全局内存的写入是合并的，但是从共享内存读取会导致存储体冲突，因为每个线程束<br> 沿tile中的一列读取数据。在本节的稍后部分将使用共享内存填充来解决存储体冲突问<br> 题。图5-16显示了索引的计算。<br><img src="`+A+'" alt="figure5-16" loading="lazy"></p></li><li><p>使用共享内存提高了转置内核的性能，如表5-3所示。<br><img src="'+K+`" alt="table5-3" loading="lazy"></p></li><li><p>使用nvprof报告transposeSmem函数中每个请求执行的全局内存事务数量：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>Device <span class="token string">&quot;Tesla K40c (0)&quot;</span> Metrics Transactions
Kernel<span class="token operator">:</span> <span class="token function">transposeSmem</span> <span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">)</span>
 <span class="token number">1</span> gld_transactions_per_request <span class="token number">1.000000</span> 
 <span class="token number">1</span> gst_transactions_per_request <span class="token number">2.000000</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>全局内存存储的重复数量从32减少到2。由于转置块中的块宽为16，所以线程束前半<br> 部分的写操作和线程束后半部分的写操作间隔了4080；因此，线程束的写入全局内存请求<br> 是由两个事务完成的。将线程块大小更改到32×32会把重复次数减少到1。然而，32×16的<br> 线程块配置比32×32的启动配置显示出了更多的并行性。稍后将调查哪个优化会更有利。</p></li><li><p>以下是在Tesla K40上每个共享内存加载和存储请求的共享内存事务的计算结果。</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>Device <span class="token string">&quot;Tesla K40c (0)&quot;</span> Metrics Transactions
Kernel<span class="token operator">:</span> <span class="token function">transposeSmem</span> <span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">)</span>
 <span class="token number">1</span> shared_load_transactions_per_request <span class="token number">8.000000</span> 
 <span class="token number">1</span> shared_store_transactions_per_request <span class="token number">1.000000</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>显然，读取二维共享内存数组中的一列会产生存储体冲突。在Tesla M2090上运行这<br> 个核函数会产生16个事务的重复。在Fermi GPU上，访问存储体宽度为4字节的一列会导致<br> 16路冲突，因为每一列有16个数据元素并且长度为均4字节。然而，Tesla K40有宽度为8<br> 字节的存储体，这会使存储体冲突减少一半。</li></ul><h3 id="_5-4-3-使用填充共享内存的矩阵转置" tabindex="-1"><a class="header-anchor" href="#_5-4-3-使用填充共享内存的矩阵转置" aria-hidden="true">#</a> 5.4.3 使用填充共享内存的矩阵转置</h3><ul><li><p>通过给二维共享内存数组tile中的每一行添加列填充，可以将原矩阵相同列中的数据<br> 元素均匀地划分到共享内存存储体中。需要填充的列数取决于设备的计算能力和线程块的<br> 大小。对于一个大小为32×16的线程块被测试内核来说，在Tesla K40中必须增加两列填<br> 充，在Tesla M2090中必须增加一列填充。在Tesla K40中，下面的语句声明了填充的共享<br> 内存： <code>__shared__ float tile[BDIMY][BDIMX + 2];</code></p></li><li><p>此外，对tile的存储和加载必须被转化以对每行中的额外两列负责。填充列会提供额<br> 外的加速，如表5-4所示。<br><img src="`+U+`" alt="table5-4" loading="lazy"></p></li><li><p>下面是在Tesla K40上每个请求的共享内存事务的计算结果。在共享内存数组中添加<br> 列填充消除了所有的存储体冲突。</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>Device <span class="token string">&quot;Tesla K40c (0)&quot;</span> Metrics Transactions
Kernel<span class="token operator">:</span> <span class="token function">transposeSmemPad</span> <span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">)</span>
 <span class="token number">1</span> shared_load_transactions_per_request <span class="token number">1.000000</span> 
 <span class="token number">1</span> shared_store_transactions_per_request <span class="token number">1.000000</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_5-4-4-使用展开的矩阵转置" tabindex="-1"><a class="header-anchor" href="#_5-4-4-使用展开的矩阵转置" aria-hidden="true">#</a> 5.4.4 使用展开的矩阵转置</h3><ul><li>下面的核函数展开两个数据块的同时处理：每个线程现在转置了被一个数据块跨越的<br> 两个数据元素。这种转化的目标是通过创造更多的同时加载和存储以提高设备内存带宽利<br> 用率。</li></ul><details class="hint-container details"><summary>Click me to view the code!</summary><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">transposeSmemUnrollPad</span><span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span>out<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>in<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">int</span> nx<span class="token punctuation">,</span> 
 <span class="token keyword">const</span> <span class="token keyword">int</span> ny<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token comment">// static 1D shared memory with padding</span>
 __shared__ <span class="token keyword">float</span> tile<span class="token punctuation">[</span>BDIMY<span class="token operator">*</span><span class="token punctuation">(</span>BDIMX<span class="token operator">*</span><span class="token number">2</span><span class="token operator">+</span>IPAD<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token comment">// coordinate in original matrix</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> ix <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">*</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> iy <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>y <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>y <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">;</span>
 <span class="token comment">// linear global memory index for original matrix</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> ti <span class="token operator">=</span> iy<span class="token operator">*</span>nx <span class="token operator">+</span> ix<span class="token punctuation">;</span>
 <span class="token comment">// thread index in transposed block</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> bidx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>y <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> irow <span class="token operator">=</span> bidx <span class="token operator">/</span> blockDim<span class="token punctuation">.</span>y<span class="token punctuation">;</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> icol <span class="token operator">=</span> bidx <span class="token operator">%</span> blockDim<span class="token punctuation">.</span>y<span class="token punctuation">;</span>
 <span class="token comment">// coordinate in transposed matrix</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> ix2 <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>y <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>y <span class="token operator">+</span> icol<span class="token punctuation">;</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> iy2 <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">*</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> irow<span class="token punctuation">;</span>
 <span class="token comment">// linear global memory index for transposed matrix</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> to <span class="token operator">=</span> iy2<span class="token operator">*</span>ny <span class="token operator">+</span> ix2<span class="token punctuation">;</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>ix<span class="token operator">+</span>blockDim<span class="token punctuation">.</span>x <span class="token operator">&lt;</span> nx <span class="token operator">&amp;&amp;</span> iy <span class="token operator">&lt;</span> ny<span class="token punctuation">)</span>
 <span class="token punctuation">{</span>
 <span class="token comment">// load two rows from global memory to shared memory</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> row_idx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>y <span class="token operator">*</span> <span class="token punctuation">(</span>blockDim<span class="token punctuation">.</span>x <span class="token operator">*</span> <span class="token number">2</span> <span class="token operator">+</span> IPAD<span class="token punctuation">)</span> <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 tile<span class="token punctuation">[</span>row_idx<span class="token punctuation">]</span> <span class="token operator">=</span> in<span class="token punctuation">[</span>ti<span class="token punctuation">]</span><span class="token punctuation">;</span>
 tile<span class="token punctuation">[</span>row_idx<span class="token operator">+</span>BDIMX<span class="token punctuation">]</span> <span class="token operator">=</span> in<span class="token punctuation">[</span>ti<span class="token operator">+</span>BDIMX<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token comment">// thread synchronization</span>
 <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// store two rows to global memory from two columns of shared memory</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">int</span> col_idx <span class="token operator">=</span> icol<span class="token operator">*</span><span class="token punctuation">(</span>blockDim<span class="token punctuation">.</span>x<span class="token operator">*</span><span class="token number">2</span><span class="token operator">+</span>IPAD<span class="token punctuation">)</span> <span class="token operator">+</span> irow<span class="token punctuation">;</span>
 out<span class="token punctuation">[</span>to<span class="token punctuation">]</span> <span class="token operator">=</span> tile<span class="token punctuation">[</span>col_idx<span class="token punctuation">]</span><span class="token punctuation">;</span>
 out<span class="token punctuation">[</span>to<span class="token operator">+</span>ny<span class="token operator">*</span>BDIMX<span class="token punctuation">]</span> <span class="token operator">=</span> tile<span class="token punctuation">[</span>col_idx<span class="token operator">+</span>BDIMX<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><ul><li><p>在这个内核中，添加列填充的一维共享内存数组tile被静态声明：<br><code>__shared__ float tile[BDIMY * (BDIMX * 2 + IPAD)];</code></p></li><li><p>对于一个给定的线程，输入矩阵的坐标和用于存储输入矩阵的全局内存数组的索引计<br> 算如下：<br><code>ix = blockIdx.x * blockDim.x * 2 + threadIdx.x;</code><br><code>iy = blockIdx.y * blockDim.y + threadIdx.y;</code><br><code>ti = iy * nx + ix;</code></p></li><li><p>如图5-17所示，一个32×16的线程块配置与一个展开大小为（32＋32）×16的数据块一<br> 起使用。<br><img src="`+G+'" alt="figure5-17" loading="lazy"></p></li><li><p>共享内存转置块中的新线程索引计算如下：<br><code>bidx = threadIdx.y * blockDim.x + threadIdx.x;</code><br><code>irow = bidx / blockDim.y;</code><br><code>icol = bidx % blockDim.y;</code></p></li><li><p>由于共享内存数组tile是一维的，所以必须将二维线程索引转换为一维共享内存索<br> 引，以访问填充的一维共享内存：<br><code>row_idx = threadIdx.y * (blockDim.x * 2 + IPAD) + threadIdx.x;</code><br><code>col_idx = icol * (blockDim.x * 2 + IPAD) + irow;</code></p></li><li><p>因为填充的内存不是用来存储数据的，所以计算索引时必须跳过填充列。</p></li><li><p>最后，转置矩阵中输出矩阵的坐标和被用来存储计算结果的全局内存中的相应索引计<br> 算如下：<br><code>ix2 = blockIdx.y * blockDim.y * 2 + icol;</code><br><code>iy2 = blockIdx.x * blockDim.x * 2 + irow;</code><br><code>to = iy2 * ny + ix2;</code></p></li><li><p>使用上面计算出的全局和共享内存的索引，每个线程读取全局内存一行中的两个数据<br> 元素，并将它们写入共享内存的一行中，代码如下所示：<br><code>tile[row_idx] = in[ti];</code><br><code>tile[row_idx + BDIMX] = in[ti + BDIMX];</code></p></li><li><p>同步之后，每个线程从共享内存的一列中读取两个数据元素，并将它们写入到全局内<br> 存的一行中。请注意，由于共享内存数组tile有添加填充，所以这些沿着同一列的共享内<br> 存请求不会导致存储体冲突。<br><code>out[to] = tile[col_idx];</code><br><code>out[to + ny * BDIMX] = tile[col_idx + BDIMX];</code></p></li><li><p>对这个核函数进行一个微小的扩展可以提供更多的灵活性，可以将共享内存数组tile<br> 的声明替换成下面这一行，以允许动态共享内存的分配。正如在以前的例子中观察到的，<br> 预计会有微小的性能下降。<br><code>extern __shared__ float tile[];</code></p></li><li><p>从表5-5中显示的结果可以看出在Tesla K40和Tesla M2090上，展开的两块提供了显著<br> 的性能改善。<br><img src="'+T+`" alt="table5-5" loading="lazy"></p></li><li><p>通过展开的两块，更多的内存请求将同时处于运行状态并且读/写的吞吐量会提高。<br> 这可以通过以下的nvprof指标来检查：<br><code>dram_read_throughput: Device Memory Read Throughput</code><br><code>dram_write_throughput: Device Memory Write Throughput</code></p></li><li><p>在Tesla K40上使用nvprof的结果总结如下。展开内核的吞吐量提高近1.5倍</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>Kernel<span class="token operator">:</span> <span class="token function">transposeSmemUnrollPad</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">)</span>
 <span class="token number">1</span> dram_read_throughput <span class="token number">94.135</span>GB<span class="token operator">/</span>s 
 <span class="token number">1</span> dram_write_throughput <span class="token number">94.128</span>GB<span class="token operator">/</span>s 
Kernel<span class="token operator">:</span> <span class="token function">transposeSmemUnrollPadDyn</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">)</span>
Coalescing Global Memory Accesses ❘ <span class="token number">249</span>
 <span class="token number">1</span> dram_read_throughput <span class="token number">94.112</span>GB<span class="token operator">/</span>s 
 <span class="token number">1</span> dram_write_throughput <span class="token number">94.110</span>GB<span class="token operator">/</span>s 
Kernel<span class="token operator">:</span> <span class="token function">transposeSmemPad</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">)</span>
 <span class="token number">1</span> dram_read_throughput <span class="token number">62.087</span>GB<span class="token operator">/</span>s 
 <span class="token number">1</span> dram_write_throughput <span class="token number">62.071</span>GB<span class="token operator">/</span>s 
Kernel<span class="token operator">:</span> <span class="token function">transposeSmem</span> <span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">)</span>
 <span class="token number">1</span> dram_read_throughput <span class="token number">59.646</span>GB<span class="token operator">/</span>s
 <span class="token number">1</span> dram_write_throughput <span class="token number">59.636</span>GB<span class="token operator">/</span>s 
Kernel<span class="token operator">:</span> <span class="token function">naiveGmem</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">)</span>
 <span class="token number">1</span> dram_read_throughput <span class="token number">34.791</span>GB<span class="token operator">/</span>s 
 <span class="token number">1</span> dram_write_throughput <span class="token number">44.497</span>GB<span class="token operator">/</span>s 
Kernel<span class="token operator">:</span> <span class="token function">copyGmem</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">)</span>
 <span class="token number">1</span> dram_read_throughput <span class="token number">94.018</span>GB<span class="token operator">/</span>s 
 <span class="token number">1</span> dram_write_throughput <span class="token number">94.011</span>GB<span class="token operator">/</span>s
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_5-4-5-增大并行性" tabindex="-1"><a class="header-anchor" href="#_5-4-5-增大并行性" aria-hidden="true">#</a> 5.4.5 增大并行性</h3><ul><li><p>一个简单而有效的优化技术是调整线程块的维度，以找出最佳的执行配置。表5-6总<br> 结了在Tesla K40上各种线程块配置的测试结果。块大小为16×16时展示出了最好的性能，<br> 因为它有更多的并发线程块，从而有最好的设备并行性。<br><img src="`+P+'" alt="table5-6" loading="lazy"></p></li><li><p>表5-7总结了在Tesla K40中从transposeSmemUnrollPadDyn函数上获得全局内存吞吐量<br> 和共享内存存储体冲突的nvprof结果。虽然线程块配置为32×16时最大程度地减少了存储<br> 体冲突，但线程块配置为16×16时最大程度地增加了全局内存吞吐量。由此，可以得出结<br> 论，与共享内存吞吐量相比，这个内核受到全局内存吞吐量的约束更多。<br><img src="'+q+'" alt="table5-7" loading="lazy"></p></li></ul><h2 id="_5-5-常量内存" tabindex="-1"><a class="header-anchor" href="#_5-5-常量内存" aria-hidden="true">#</a> 5.5 常量内存</h2><ul><li><p>常量内存是一种专用的内存，它用于只读数据和统一访问线程束中线程的数据。常量<br> 内存对内核代码而言是只读的，但它对主机而言既是可读又是可写的。</p></li><li><p>常量内存位于设备的DRAM上（和全局内存一样），并且有一个专用的片上缓存。和<br> 一级缓存和共享内存一样，从每个SM的常量缓存中读取的延迟，比直接从常量内存中读<br> 取的低得多。每个SM常量内存缓存大小的限制为64KB。</p></li><li><p>到目前为止相较于在本书中学习的任何其他类型的内存而言，常量内存有一个不同的<br> 最优访问模式。在常量内存中，如果线程束中的所有线程都访问相同的位置，那么这个访<br> 问模式就是最优的。如果线程束中的线程访问不同的地址，则访问就需要串行。因此，一<br> 个常量内存读取的成本与线程束中线程读取唯一地址的数量呈线性关系。</p></li><li><p>在全局作用域中必须用以下修饰符声明常量变量：<code>__constant__</code></p></li><li><p>常量内存变量的生存期与应用程序的生存期相同，其对网格内的所有线程都是可访问<br> 的，并且通过运行时函数对主机可访问。当使用CUDA独立编译能力时，常量内存变量跨<br> 多个源文件是可见的（在第10章有更多关于独立编译的细节内容）。因为设备只能读取常<br> 量内存，所以常量内存中的值必须使用以下运行时函数进行初始化：<br><code>cudaError_t cudaMemcpyToSymbol(const void *symbol, const void * src, size_t count, size_t offset, cudaMemcpyKind kind)</code></p></li><li><p>cudaMemcpyToSymbol函数将src指向的数据复制到设备上由symbol指定的常量内存<br> 中。枚举变量kind指定了传输方向，默认情况下，kind是cudaMemcpyHostToDevice。</p></li></ul><h3 id="_5-5-1-使用常量内存实现一维模板" tabindex="-1"><a class="header-anchor" href="#_5-5-1-使用常量内存实现一维模板" aria-hidden="true">#</a> 5.5.1 使用常量内存实现一维模板</h3><ul><li><p>在数值分析中，模板计算在几何点集合上应用函数，并用输出更新单一点的值。模板<br> 是求解许多偏微分方程算法的基础。在一维中，在位置x周围的九点模板会给这些位置上<br> 的值应用一些函数：<code>{x―4h，x―3h，x―2h，x―h，x，x＋h，x＋2h，x＋3h，x＋4h}</code><br><img src="'+z+'" alt="figure5-18" loading="lazy"></p></li><li><p>一个九点模板的例子是实变量函数f在点x上一阶导数的第八阶中心差分公式。理解这<br> 个公式的应用并不重要，只要简单地了解到它会将上述的九点作为输入并产生单一输出。<br> 在本节中该公式将被作为一个示例模板。<br><code>f&#39; (x) ≈ c0 (f(x + 4h) − f(x − 4h) ) + c1 (f(x + 3h) − f(x − 3h))-</code><br><code>c2 (f(x + 2h) − f(x − 2h) ) + c3 (f(x + h) − f(x − h))</code></p></li><li><p>在一维数组中对该公式的应用是对一个数据进行并行操作，该操作能很好地映射到<br> CUDA。它可以为每个线程分配位置x，并计算出f&#39;（x）。可以从Wrox.com下载constantStencil.cu文件，查看这个例子的代码。</p></li><li><p>现在，在模板计算中哪里可以应用常量内存？在上述模板公式的例子下，系数c0、<br> c1、c2和c3在所有线程中都是相同的并且不会被修改。这使它们成为常量内存最优的候<br> 选，因为它们是只读的，并将呈现一个广播式的访问模式：线程束中的每个线程同时引用<br> 相同的常量内存地址。</p></li><li><p>下面的内核实现了基于上述公式的一维模板计算。由于每个线程需要9个点来计算一<br> 个点，所以要使用共享内存来缓存数据，从而减少对全局内存的冗余访问。<br><code>__shared__ float smem[BDIM + 2 * RADIUS];</code></p></li><li><p>RADIUS定义了点x两侧点的数量，这些点被用于计算x点的值。在这个例子中，为了<br> 形成一个九点模板，RADIUS被定义为4：x两侧各有4个点加上位置x的值。如图5-19所<br> 示，在每个块的左、右边界上各需要一个RADIUS个元素的光环。<br><img src="'+X+`" alt="figure5-19" loading="lazy"></p></li><li><p>访问全局内存的索引可使用以下语句来进行计算：<code>int idx = blockIdx.x * blockDim.x + threadIdx.x;</code></p></li><li><p>访问共享内存的每个线程的索引可使用以下语句来进行计算：<code>int sidx = threadIdx.x + RADIUS;</code></p></li><li><p>从全局内存中读取数据到共享内存中时，前四个线程负责从左侧和右侧的光环中读取<br> 数据到共享内存中，如下所示：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">if</span> <span class="token punctuation">(</span>threadIdx<span class="token punctuation">.</span>x <span class="token operator">&lt;</span> RADIUS<span class="token punctuation">)</span> <span class="token punctuation">{</span> 
 smem<span class="token punctuation">[</span>sidx <span class="token operator">-</span> RADIUS<span class="token punctuation">]</span> <span class="token operator">=</span> in<span class="token punctuation">[</span>idx <span class="token operator">-</span> RADIUS<span class="token punctuation">]</span><span class="token punctuation">;</span> 
 smem<span class="token punctuation">[</span>sidx <span class="token operator">+</span> BDIM<span class="token punctuation">]</span> <span class="token operator">=</span> in<span class="token punctuation">[</span>idx <span class="token operator">+</span> BDIM<span class="token punctuation">]</span><span class="token punctuation">;</span> 
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>该模板计算是直接的。注意coef数组是存储上述系数的常量内存数组。<br> 此外，#pragma unroll的作用是提示CUDA编译器，表明这个循环将被自动展开。</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">unroll</span></span>
<span class="token keyword">for</span><span class="token punctuation">(</span> <span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span> i <span class="token operator">&lt;=</span> RADIUS<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 tmp <span class="token operator">+=</span> coef<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token punctuation">(</span>smem<span class="token punctuation">[</span>sidx<span class="token operator">+</span>i<span class="token punctuation">]</span> – smem<span class="token punctuation">[</span>sidx<span class="token operator">-</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>因为有限差分系数被存储在常量内存中，并且这是由主机线程准备的，所以在核函数<br> 中访问它们就像访问数组一样简单。完整的核函数如下：</li></ul><details class="hint-container details"><summary>Click me to view the code!</summary><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">stencil_1d</span><span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span>in<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>out<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token comment">// shared memory</span>
 __shared__ <span class="token keyword">float</span> smem<span class="token punctuation">[</span>BDIM <span class="token operator">+</span> <span class="token number">2</span><span class="token operator">*</span>RADIUS<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token comment">// index to global memory</span>
 <span class="token keyword">int</span> idx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
 <span class="token comment">// index to shared memory for stencil calculatioin</span>
 <span class="token keyword">int</span> sidx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> RADIUS<span class="token punctuation">;</span>
 <span class="token comment">// Read data from global memory into shared memory </span>
 smem<span class="token punctuation">[</span>sidx<span class="token punctuation">]</span> <span class="token operator">=</span> in<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token comment">// read halo part to shared memory</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>threadIdx<span class="token punctuation">.</span>x <span class="token operator">&lt;</span> RADIUS<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 smem<span class="token punctuation">[</span>sidx <span class="token operator">-</span> RADIUS<span class="token punctuation">]</span> <span class="token operator">=</span> in<span class="token punctuation">[</span>idx <span class="token operator">-</span> RADIUS<span class="token punctuation">]</span><span class="token punctuation">;</span>
 smem<span class="token punctuation">[</span>sidx <span class="token operator">+</span> BDIM<span class="token punctuation">]</span> <span class="token operator">=</span> in<span class="token punctuation">[</span>idx <span class="token operator">+</span> BDIM<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 <span class="token comment">// Synchronize (ensure all the data is available) </span>
 <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// Apply the stencil </span>
 <span class="token keyword">float</span> tmp <span class="token operator">=</span> <span class="token number">0.0f</span><span class="token punctuation">;</span>
 <span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">unroll</span></span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span> i <span class="token operator">&lt;=</span> RADIUS<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 tmp <span class="token operator">+=</span> coef<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token punctuation">(</span>smem<span class="token punctuation">[</span>sidx<span class="token operator">+</span>i<span class="token punctuation">]</span> <span class="token operator">-</span> smem<span class="token punctuation">[</span>sidx<span class="token operator">-</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 <span class="token comment">// Store the result </span>
 out<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> tmp<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><ul><li><p>在常量内存中声明coef数组，代码如下所示：<code>__constant__ float coef[RADIUS + 1];</code></p></li><li><p>然后使用cudaMemcpyToSymbol的CUDA API调用从主机端初始化的常量内存：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">void</span> <span class="token function">setup_coef_constant</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token keyword">const</span> <span class="token keyword">float</span> h_coef<span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>a0<span class="token punctuation">,</span> a1<span class="token punctuation">,</span> a2<span class="token punctuation">,</span> a3<span class="token punctuation">,</span> a4<span class="token punctuation">}</span><span class="token punctuation">;</span> 
 <span class="token function">cudaMemcpyToSymbol</span><span class="token punctuation">(</span>coef<span class="token punctuation">,</span> h_coef<span class="token punctuation">,</span> <span class="token punctuation">(</span>RADIUS <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> 
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_5-5-2-与只读缓存的比较" tabindex="-1"><a class="header-anchor" href="#_5-5-2-与只读缓存的比较" aria-hidden="true">#</a> 5.5.2 与只读缓存的比较</h3><ul><li><p>Kepler GPU添加了一个功能，即使用GPU纹理流水线作为只读缓存，用于存储全局内<br> 存中的数据。因为这是一个独立的只读缓存，它带有从标准全局内存读取的独立内存带<br> 宽，所以使用此功能可以为带宽限制内核提供性能优势。</p></li><li><p>每个Kepler SM都有48KB的只读缓存。一般来说，只读缓存在分散读取方面比一级缓<br> 存更好，当线程束中的线程都读取相同地址时，不应使用只读缓存。只读缓存的粒度为32<br> 个字节。</p></li><li><p>当通过只读缓存访问全局内存时，需要向编译器指出在内核的持续时间里数据是只读<br> 的。有两种方法可以实现这一点：<br> ·使用内部函数__ldg<br> ·全局内存的限定指针</p></li><li><p>内部函数__ldg用于代替标准指针解引用，并且强制加载通过只读数据缓存，如下面<br> 的代码片段所示：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">kernel</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span> output<span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span> input<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
 output<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token function">__ldg</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>input<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>也可以限定指针为const__restrict__，以表明它们应该通过只读缓存被访问:</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">void</span> <span class="token function">kernel</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span> output<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">float</span><span class="token operator">*</span> __restrict__ input<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
 output<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">+=</span> input<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>在只读缓存机制需要更多显式控制的情况下，或者在代码非常复杂以至于编译器无法<br> 检测到只读缓存的使用是否是安全的情况下，内部函数__ldg是一个更好的选择。</p></li><li><p>只读缓存是独立的，而且区别于常量缓存。通过常量缓存加载的数据必须是相对较小<br> 的，而且访问必须一致以获得良好的性能（一个线程束内的所有线程在任何给定时间内应<br> 该都访问相同的位置），而通过只读缓存加载的数据可以是比较大的，而且能够在一个非<br> 统一的模式下进行访问。</p></li><li><p>下面的内核是根据以前的模板内核修改而来的。它使用只读缓存来存储之前存储在常<br> 量内存中的系数。比较一下这两个内核，会发现它们唯一的区别就是函数声明。</p></li></ul><details class="hint-container details"><summary>Click me to view the code!</summary><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">stencil_1d_read_only</span> <span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span> in<span class="token punctuation">,</span>
 <span class="token keyword">float</span><span class="token operator">*</span> out<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">float</span> <span class="token operator">*</span>__restrict__ dcoef<span class="token punctuation">)</span> <span class="token punctuation">{</span> 
 <span class="token comment">// shared memory</span>
 __shared__ <span class="token keyword">float</span> smem<span class="token punctuation">[</span>BDIM <span class="token operator">+</span> <span class="token number">2</span><span class="token operator">*</span>RADIUS<span class="token punctuation">]</span><span class="token punctuation">;</span> 
 <span class="token comment">// index to global memory</span>
 <span class="token keyword">int</span> idx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x<span class="token punctuation">;</span> 
 <span class="token comment">// index to shared memory for stencil calculatioin</span>
 <span class="token keyword">int</span> sidx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> RADIUS<span class="token punctuation">;</span> 
 <span class="token comment">// Read data from global memory into shared memory </span>
 smem<span class="token punctuation">[</span>sidx<span class="token punctuation">]</span> <span class="token operator">=</span> in<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">;</span> 
 <span class="token comment">// read halo part to shared memory</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>threadIdx<span class="token punctuation">.</span>x <span class="token operator">&lt;</span> RADIUS<span class="token punctuation">)</span> <span class="token punctuation">{</span> 
 smem<span class="token punctuation">[</span>sidx <span class="token operator">-</span> RADIUS<span class="token punctuation">]</span> <span class="token operator">=</span> in<span class="token punctuation">[</span>idx <span class="token operator">-</span> RADIUS<span class="token punctuation">]</span><span class="token punctuation">;</span> 
 smem<span class="token punctuation">[</span>sidx <span class="token operator">+</span> BDIM<span class="token punctuation">]</span> <span class="token operator">=</span> in<span class="token punctuation">[</span>idx <span class="token operator">+</span> BDIM<span class="token punctuation">]</span><span class="token punctuation">;</span> 
 <span class="token punctuation">}</span> 
 <span class="token comment">// Synchronize (ensure all the data is available) </span>
 <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> 
 <span class="token comment">// Apply the stencil </span>
 <span class="token keyword">float</span> tmp <span class="token operator">=</span> <span class="token number">0.0f</span><span class="token punctuation">;</span>
 <span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">unroll</span></span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">;</span> i<span class="token operator">&lt;=</span>RADIUS<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 tmp <span class="token operator">+=</span> dcoef<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">*</span><span class="token punctuation">(</span>smem<span class="token punctuation">[</span>sidx<span class="token operator">+</span>i<span class="token punctuation">]</span><span class="token operator">-</span>smem<span class="token punctuation">[</span>sidx<span class="token operator">-</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 <span class="token comment">// Store the result </span>
 out<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> tmp<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><ul><li>因为该系数最初是存储在全局内存中并且读入缓存中的，调用内核之前必须分配和初<br> 始化全局内存以便在设备上存储系数，代码如下所示：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">const</span> <span class="token keyword">float</span> h_coef<span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>a0<span class="token punctuation">,</span> a1<span class="token punctuation">,</span> a2<span class="token punctuation">,</span> a3<span class="token punctuation">,</span> a4<span class="token punctuation">}</span><span class="token punctuation">;</span>
<span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>d_coef<span class="token punctuation">,</span> <span class="token punctuation">(</span>RADIUS <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>d_coef<span class="token punctuation">,</span> h_coef<span class="token punctuation">,</span> <span class="token punctuation">(</span>RADIUS <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>从Wrox.com上可以下载包含这个代码的constantReadOnly.cu文件。在Tesla K40上，使<br> 用nvprof测试得出的以下结果表明，对此应用程序使用只读内存时其性能实际上会降低。<br> 这是由于coef数组使用了广播访问模式，相比于只读缓存，该模式更适合于常量内存：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>
Tesla K40c array size<span class="token operator">:</span> <span class="token number">16777216</span> <span class="token punctuation">(</span>grid<span class="token punctuation">,</span> block<span class="token punctuation">)</span> <span class="token number">524288</span><span class="token punctuation">,</span><span class="token number">32</span> 
 <span class="token number">3.4517</span>ms <span class="token function">stencil_1d</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">)</span>
 <span class="token number">3.6816</span>ms <span class="token function">stencil_1d_read_only</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token keyword">const</span> <span class="token operator">*</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="常量缓存与只读缓存" tabindex="-1"><a class="header-anchor" href="#常量缓存与只读缓存" aria-hidden="true">#</a> 常量缓存与只读缓存</h4><p>·在设备上常量缓存和只读缓存都是只读的。<br> ·每个SM资源都有限：常量缓存是64 KB，而只读缓存是48 KB。<br> ·常量缓存在统一读取中可以更好地执行（统一读取是线程束中的每一个线程都访问相同的地址）。<br> ·只读缓存更适合于分散读取。</p><h2 id="_5-6-线程束洗牌指令" tabindex="-1"><a class="header-anchor" href="#_5-6-线程束洗牌指令" aria-hidden="true">#</a> 5.6 线程束洗牌指令</h2><ul><li><p>在本章中，已经介绍了如何使用共享内存执行线程块中线程间低延迟数据的交换。从<br> 用Kepler系列的GPU（计算能力为3.0或更高）开始，洗牌指令（shuffle instruction）作为一<br> 种机制被加入其中，只要两个线程在相同的线程束中，那么就允许这两个线程直接读取另<br> 一个线程的寄存器。</p></li><li><p>洗牌指令使得线程束中的线程彼此之间可以直接交换数据，而不是通过共享内存或全<br> 局内存来进行的。洗牌指令比共享内存有更低的延迟，并且该指令在执行数据交换时不消<br> 耗额外的内存。因此，洗牌指令为应用程序快速交换线程束中线程间的数据提供了一个有<br> 吸引力的方法。</p></li><li><p>因为洗牌指令在线程束中的线程之间被执行，所以首先介绍一下束内线程（lane）的<br> 概念。简单来说，一个束内线程指的是线程束内的单一线程。线程束中的每个束内线程是<br> [0，31]范围内束内线程索引（lane index）的唯一标识。线程束中的每个线程都有一个唯<br> 一的束内线程索引，并且同一线程块中的多个线程可以有相同的束内线程索引（就像同一<br> 网格中的多个线程可以有相同的threadIdx.x值一样）。然而，束内线程索引没有内置变<br> 量，因为线程索引有内置变量。在一维线程块中，对于一个给定线程的束内线程索引和线<br> 程束索引可以按以下公式进行计算：<br><code>laneID = threadIdx.x % 32</code><br><code>warpID = threadIdx.x / 32</code></p></li><li><p>例如，线程块中的线程1和线程33都有束内线程ID 1，但它们有不同的线程束ID。对<br> 于二维线程块，可以将二维线程坐标转换为一维线程索引，并应用前面的公式来确定束内<br> 线程和线程束的索引。</p></li></ul><h3 id="_5-6-1-线程束洗牌指令的不同形式" tabindex="-1"><a class="header-anchor" href="#_5-6-1-线程束洗牌指令的不同形式" aria-hidden="true">#</a> 5.6.1 线程束洗牌指令的不同形式</h3><ul><li><p>有两组洗牌指令：一组用于整型变量，另一组用于浮点型变量。每组有4种形式的洗<br> 牌指令。在线程束内交换整型变量，其基本函数标记如下：<br><code>int __shfl(int var, int srcLane, int width=warpSize);</code></p></li><li><p>内部指令__shfl返回值是var，var通过由srcLane确定的同一线程束中的线程传递给<br> __shfl。srcLane的含义变化取决于宽度值（详情如下）。这个函数能使线程束中的每个线<br> 程都可以直接从一个特定的线程中获取某个值。线程束内所有活跃的线程都同时产生此操<br> 作，这将导致每个线程中有4字节数据的移动。</p></li><li><p>变量width可被设置为2～32之间2任何的指数（包括2和32），这是可选择的。当设置<br> 为默认的warpSize（即32）时，洗牌指令跨整个线程束来执行，并且srcLane指定源线程的<br> 束内线程索引。然而，设置width允许将线程束细分为段，使每段包含有width个线程，并<br> 且在每个段上执行独立的洗牌操作。对于不是32的其他width值，线程的束内线程ID和其<br> 在洗牌操作中的ID不一定相同。在这种情况下，一维线程块中的线程洗牌ID可以按以下公<br> 式进行计算：<code>shuffleID = threadIdx.x % width;</code></p></li><li><p>例如，如果shfl被线程束中的每个线程通过以下参数调用：<code>int y = shfl(x, 3, 16);</code></p></li><li><p>那么线程0～15将从线程3接收x的值，线程16～31将从线程19接收x的值（在线程束的<br> 前16个线程中其偏移量为3）。为了简单起见，srcLane将被称为在本节的其余部分提到过<br> 的束内线程索引。</p></li><li><p>当传递给shfl的束内线程索引与线程束中所有线程的值相同时，指令从特定的束内线<br> 程到线程束中所有线程都执行线程束广播操作，如图5-20所示。<br><img src="`+E+'" alt="figure5-20" loading="lazy"></p></li><li><p>洗牌操作的另一种形式是从与调用线程相关的线程中复制数据：<br><code>int __shfl_up(int var, unsigned int delta, int width=warpSize)</code></p></li><li><p>__shfl_up通过减去调用的束内线程索引delta来计算源束内线程索引。返回由源线程所<br> 持有的值。因此，这一指令通过束内线程delta将var右移到线程束中。__shfl_up周围没有<br> 线程束，所以线程束中最低的线程delta将保持不变，如图5-21所示。<br><img src="'+Y+'" alt="figure5-21" loading="lazy"></p></li><li><p>相反，洗牌指令的第三种形式是从相对于调用线程而言具有高索引值的线程中复制：<br><code>int __shfl_down(int var, unsigned int delta, int width=warpSize)</code></p></li><li><p>__shfl_down通过给调用的束内线程索引增加delta来计算源束内线程索引。返回由源<br> 线程持有的值。因此，该指令通过束内线程delta将var的值左移到线程束中。使用<br> __shfl_down时周围没有线程束，所以线程束中最大的束内线程delta将保持不变，如图5-22所示。<br><img src="'+N+'" alt="figure5-22" loading="lazy"></p></li><li><p>洗牌指令的最后一种形式是根据调用束内线程索引自身的按位异或来传输束内线程中<br> 的数据：<code>int __shfl_xor(int var, int laneMask, int width=warpSize)</code></p></li><li><p>通过使用laneMask执行调用束内线程索引的按位异或，内部指令可计算源束内线程索<br> 引。返回由源线程持有的值。该指令适合于蝴蝶寻址模式（a butterfly addressing<br> pattern），如图5-23所示。<br><img src="'+F+`" alt="figure5-23" loading="lazy"></p></li><li><p>在本节讨论的所有洗牌函数还支持单精度浮点值。浮点洗牌函数采用浮点型的var参<br> 数，并返回一个浮点数。否则，浮点洗牌函数就与整型洗牌函数相同了。</p></li></ul><h3 id="_5-6-2-线程束内的共享数据" tabindex="-1"><a class="header-anchor" href="#_5-6-2-线程束内的共享数据" aria-hidden="true">#</a> 5.6.2 线程束内的共享数据</h3><ul><li>在本节中，会介绍几个有关线程束洗牌指令的例子，并说明线程束洗牌指令的优点。<br> 洗牌指令将被应用到以下3种整数变量类型中：<br> ·标量变量<br> ·数组<br> ·向量型变量</li></ul><h4 id="_5-6-2-1-跨线程束值的广播" tabindex="-1"><a class="header-anchor" href="#_5-6-2-1-跨线程束值的广播" aria-hidden="true">#</a> 5.6.2.1 跨线程束值的广播</h4><ul><li>下面的内核实现了线程束级的广播操作。每个线程都有一个寄存器变量value。源束<br> 内线程由变量srcLane指定，它等同于跨所有线程。每个线程都直接从源线程复制数据。</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">test_shfl_broadcast</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token operator">*</span>d_out<span class="token punctuation">,</span> <span class="token keyword">int</span> <span class="token operator">*</span>d_in<span class="token punctuation">,</span> <span class="token keyword">int</span> <span class="token keyword">const</span> srcLane<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token keyword">int</span> value <span class="token operator">=</span> d_in<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">;</span>
 value <span class="token operator">=</span> <span class="token function">__shfl</span><span class="token punctuation">(</span>value<span class="token punctuation">,</span> srcLane<span class="token punctuation">,</span> BDIMX<span class="token punctuation">)</span><span class="token punctuation">;</span> 
 d_out<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span> <span class="token operator">=</span> value<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>为了简单起见，使用有16个线程的一维线程块：<code>#define BDIMX 16</code></p></li><li><p>调用内核的方法如下。通过第三个参数test_shfl_broadcast将源束内线程设置为每个线<br> 程束内的第三个线程。全局内存的两片被传递到内核：输入数据和输出数据。<br><code>test_shfl_broadcast&lt;&lt;&lt;1, BDIMX&gt;&gt;&gt;(d_outData, d_inData, 2);</code></p></li><li><p>从Wrox.com上可以下载simpleShfl.cu文件中此示例的代码。线程束中每个线程的初始<br> 值是根据自己的线程索引来设置的。调用__shfl后，第三个线程（在束内线程2中且值为<br> 2）的数值将被广播到其他所有线程中。在Tesla K40上，CUDA 6.0版本下的结果如下：<br> initialData: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15<br> shfl bcast : 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2</p></li></ul><h4 id="_5-6-2-2-线程束内上移" tabindex="-1"><a class="header-anchor" href="#_5-6-2-2-线程束内上移" aria-hidden="true">#</a> 5.6.2.2 线程束内上移</h4><ul><li>下面的内核实现了洗牌上移的操作。线程束中每个线程的源束内线程都是独一无二<br> 的，并由它自身的线程索引减去delta来确定。</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">test_shfl_up</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token operator">*</span>d_out<span class="token punctuation">,</span> <span class="token keyword">int</span> <span class="token operator">*</span>d_in<span class="token punctuation">,</span> <span class="token keyword">unsigned</span> <span class="token keyword">int</span> <span class="token keyword">const</span> delta<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token keyword">int</span> value <span class="token operator">=</span> d_in<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">;</span>
 value <span class="token operator">=</span> <span class="token function">__shfl_up</span><span class="token punctuation">(</span>value<span class="token punctuation">,</span> delta<span class="token punctuation">,</span> BDIMX<span class="token punctuation">)</span><span class="token punctuation">;</span> 
 d_out<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span> <span class="token operator">=</span> value<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>此核函数也在上述的simpleShfl.cu文件中。通过指定delta为2可以调用核函数：<br><code>test_shfl_up&lt;&lt;&lt;1, BDIMX&gt;&gt;&gt;(d_outData, d_inData, 2);</code></p></li><li><p>其结果是，每个线程的值向右移动两个束内线程，结果如下所示。最左边的两个束内<br> 线程值保持不变。<br> initialData: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15<br> shfl up : 0 1 0 1 2 3 4 5 6 7 8 9 10 11 12 13</p></li></ul><h4 id="_5-6-2-3-线程束内下移" tabindex="-1"><a class="header-anchor" href="#_5-6-2-3-线程束内下移" aria-hidden="true">#</a> 5.6.2.3 线程束内下移</h4><ul><li>下面的内核实现了下移操作。线程束中每个线程的源束内线程都是独一无二的，并由<br> 它自身的线程索引加上delta来确定。</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">test_shfl_down</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token operator">*</span>d_out<span class="token punctuation">,</span> <span class="token keyword">int</span> <span class="token operator">*</span>d_in<span class="token punctuation">,</span> <span class="token keyword">unsigned</span> <span class="token keyword">int</span> <span class="token keyword">const</span> delta<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token keyword">int</span> value <span class="token operator">=</span> d_in<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">;</span>
 value <span class="token operator">=</span> <span class="token function">__shfl_down</span><span class="token punctuation">(</span>value<span class="token punctuation">,</span> delta<span class="token punctuation">,</span> BDIMX<span class="token punctuation">)</span><span class="token punctuation">;</span> 
 d_out<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span> <span class="token operator">=</span> value<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>此核函数也在上述的simpleShfl.cu文件中。通过指定delta为2可以调用核函数：<br><code>test_shfl_down&lt;&lt;&lt;1, BDIMX&gt;&gt;&gt;(d_outData, d_inData, 2);</code></p></li><li><p>每个线程的值向左移动两个束内线程，结果如下所示。最右边的两个束内线程值保持不变。<br> initialData: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15<br> shfl down : 2 3 4 5 6 7 8 9 10 11 12 13 14 15 14 15</p></li></ul><h4 id="_5-6-2-4-线程束内环绕移动" tabindex="-1"><a class="header-anchor" href="#_5-6-2-4-线程束内环绕移动" aria-hidden="true">#</a> 5.6.2.4 线程束内环绕移动</h4><ul><li>下面的核函数实现了跨线程束的环绕移动操作。每个线程的源束内线程是不同的，并<br> 由它自身的束内线程索引加上偏移量来确定。偏移量可为正数也可为负数。</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">test_shfl_wrap</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token operator">*</span>d_out<span class="token punctuation">,</span> <span class="token keyword">int</span> <span class="token operator">*</span>d_in<span class="token punctuation">,</span> <span class="token keyword">int</span> <span class="token keyword">const</span> offset<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token keyword">int</span> value <span class="token operator">=</span> d_in<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">;</span>
 value <span class="token operator">=</span> <span class="token function">__shfl</span><span class="token punctuation">(</span>value<span class="token punctuation">,</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> offset<span class="token punctuation">,</span> BDIMX<span class="token punctuation">)</span><span class="token punctuation">;</span> 
 d_out<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span> <span class="token operator">=</span> value<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>通过指定一个正偏移量来调用内核，代码如下：<br><code>test_shfl_wrap&lt;&lt;&lt;1,BDIMX&gt;&gt;&gt;(d_outData, d_inData, 2);</code></p></li><li><p>这个内核实现了环绕式左移操作，如下所示。不同于由test_shfl_down产生的结果，最<br> 右边的两个束内线程的值也变化了。<br> initialData : 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15<br> shfl wrap left : 2 3 4 5 6 7 8 9 10 11 12 13 14 15 0 1</p></li><li><p>通过指定一个负偏移量来调用内核，代码如下：<br><code>test_shfl_wrap &lt;&lt;&lt; 1, block &gt;&gt;&gt;(d_outData, d_inData, -2);</code></p></li><li><p>这个内核实现了环绕式右移操作，如下所示。此测试类似于test_shfl_up函数，不同的<br> 是这里最左边的两个束内线程也发生了改变。<br> initialData : 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15<br> shfl wrap right: 14 15 0 1 2 3 4 5 6 7 8 9 10 11 12 13</p></li></ul><h4 id="_5-6-2-5-跨线程束的蝴蝶交换" tabindex="-1"><a class="header-anchor" href="#_5-6-2-5-跨线程束的蝴蝶交换" aria-hidden="true">#</a> 5.6.2.5 跨线程束的蝴蝶交换</h4><ul><li>下面的内核实现了两个线程之间的蝴蝶寻址模式，这是通过调用线程和线程掩码确定的。</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">test_shfl_xor</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token operator">*</span>d_out<span class="token punctuation">,</span> <span class="token keyword">int</span> <span class="token operator">*</span>d_in<span class="token punctuation">,</span> <span class="token keyword">int</span> <span class="token keyword">const</span> mask<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token keyword">int</span> value <span class="token operator">=</span> d_in<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">;</span>
 value <span class="token operator">=</span> <span class="token function">__shfl_xor</span> <span class="token punctuation">(</span>value<span class="token punctuation">,</span> mask<span class="token punctuation">,</span> BDIMX<span class="token punctuation">)</span><span class="token punctuation">;</span> 
 d_out<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span> <span class="token operator">=</span> value<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>调用掩码值为1的内核将导致相邻的线程交换它们的值。<br><code>test_shfl_xor&lt;&lt;&lt;1, BDIMX&gt;&gt;&gt;(d_outData, d_inData, 1);</code></p></li><li><p>这个内核启动的输出如下：<br> initialData: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15<br> shfl xor : 1 0 3 2 5 4 7 6 9 8 11 10 13 12 15 14</p></li></ul><h4 id="_5-6-2-6-跨线程束交换数组值" tabindex="-1"><a class="header-anchor" href="#_5-6-2-6-跨线程束交换数组值" aria-hidden="true">#</a> 5.6.2.6 跨线程束交换数组值</h4><ul><li><p>考虑内核中使用寄存器数组的情况，在这种情况下，我们若想要在线程束的线程间交<br> 换数据的某些部分，则可以使用洗牌指令交换线程束中线程间的数组元素。</p></li><li><p>在下面的内核中，每个线程都有一个寄存器数组value，其大小是SEGM。每个线程从<br> 全局内存d_in中读取数据块到value中，使用由掩码确定的相邻线程交换该块，然后将接收<br> 到的数据写回到全局内存数组d_out中。</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">test_shfl_xor_array</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token operator">*</span>d_out<span class="token punctuation">,</span> <span class="token keyword">int</span> <span class="token operator">*</span>d_in<span class="token punctuation">,</span> <span class="token keyword">int</span> <span class="token keyword">const</span> mask<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token keyword">int</span> idx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> SEGM<span class="token punctuation">;</span>
 <span class="token keyword">int</span> value<span class="token punctuation">[</span>SEGM<span class="token punctuation">]</span><span class="token punctuation">;</span>
 
 <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> SEGM<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> value<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> d_in<span class="token punctuation">[</span>idx <span class="token operator">+</span> i<span class="token punctuation">]</span><span class="token punctuation">;</span>
 
 value<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">__shfl_xor</span> <span class="token punctuation">(</span>value<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> mask<span class="token punctuation">,</span> BDIMX<span class="token punctuation">)</span><span class="token punctuation">;</span> 
 value<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">__shfl_xor</span> <span class="token punctuation">(</span>value<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> mask<span class="token punctuation">,</span> BDIMX<span class="token punctuation">)</span><span class="token punctuation">;</span> 
 value<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">__shfl_xor</span> <span class="token punctuation">(</span>value<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> mask<span class="token punctuation">,</span> BDIMX<span class="token punctuation">)</span><span class="token punctuation">;</span> 
 value<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">__shfl_xor</span> <span class="token punctuation">(</span>value<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> mask<span class="token punctuation">,</span> BDIMX<span class="token punctuation">)</span><span class="token punctuation">;</span> 
 
 <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>i <span class="token operator">&lt;</span> SEGM<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> d_out<span class="token punctuation">[</span>idx <span class="token operator">+</span> i<span class="token punctuation">]</span> <span class="token operator">=</span> value<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>数组大小由下面的宏设置为4。<code>#define SEGM 4</code></p></li><li><p>因为每个线程有4个元素，所以线程块被缩小到原来大小的1/4。调用核函数如下所示：<br><code>test_shfl_xor_int4&lt;&lt;&lt;1, BDIMX / SEGM&gt;&gt;&gt;(d_outData, d_inData, 1);</code></p></li><li><p>因为掩码被设置为1，所以相邻的线程交换其数组值，如下所示：<br> initialData: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15<br> shfl array : 4 5 6 7 0 1 2 3 12 13 14 15 8 9 10 11</p></li></ul><h4 id="_5-6-2-7-跨线程束使用数组索引交换数值" tabindex="-1"><a class="header-anchor" href="#_5-6-2-7-跨线程束使用数组索引交换数值" aria-hidden="true">#</a> 5.6.2.7 跨线程束使用数组索引交换数值</h4><ul><li><p>在之前的内核中，通过洗牌操作交换的数组元素在每个线程的本地数组中有相同的偏<br> 移量。如果想在两个线程各自的数组中以不同的偏移量交换它们之间的元素，需要有基于<br> 洗牌指令的交换函数。</p></li><li><p>下面的函数交换了两个线程之间的一对值。布尔变量pred被用于识别第一个调用的线<br> 程，它是交换数据的一对线程。要交换的数据元素是由第一个线程的firstIdx和第二个线程<br> 的secondIdx偏移标识的。第一个调用线程通过交换firstIdx和secondIdx中的元素开始，但此<br> 操作仅限于本地数组。然后在两线程间的secondIdx位置执行蝴蝶交换。最后，第一个线程<br> 交换接收自secondIdx返回到firstIdx的元素。</p></li></ul>`,98),gn={class:"hint-container details"},fn=n("summary",null,"Click me to view the code!",-1),wn=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s(`__inline__ __device__ 
`),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"swap"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("value"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"int"),s(" laneIdx"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"int"),s(" mask"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"int"),s(" firstIdx"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"int"),s(" secondIdx"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token keyword"},"bool"),s(" pred "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},"("),s("laneIdx "),n("span",{class:"token operator"},"/"),s(" mask "),n("span",{class:"token operator"},"+"),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"=="),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("pred"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" tmp "),n("span",{class:"token operator"},"="),s(" value"),n("span",{class:"token punctuation"},"["),s("firstIdx"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 value`),n("span",{class:"token punctuation"},"["),s("firstIdx"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" value"),n("span",{class:"token punctuation"},"["),s("secondIdx"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(` 
 value`),n("span",{class:"token punctuation"},"["),s("secondIdx"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token operator"},"="),s(" tmp"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
 value`),n("span",{class:"token punctuation"},"["),s("secondIdx"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"__shfl_xor"),n("span",{class:"token punctuation"},"("),s("value"),n("span",{class:"token punctuation"},"["),s("secondIdx"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},","),s(" mask"),n("span",{class:"token punctuation"},","),s(" BDIMX"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(` 
 
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("pred"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" tmp "),n("span",{class:"token operator"},"="),s(" value"),n("span",{class:"token punctuation"},"["),s("firstIdx"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 value`),n("span",{class:"token punctuation"},"["),s("firstIdx"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" value"),n("span",{class:"token punctuation"},"["),s("secondIdx"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(` 
 value`),n("span",{class:"token punctuation"},"["),s("secondIdx"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token operator"},"="),s(" tmp"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token punctuation"},"}"),s(`
`),n("span",{class:"token punctuation"},"}"),s(`



`),n("span",{class:"token comment"},"//下面的内核基于上述的交换函数，交换两个线程间不同偏移的两个元素。"),s(`
__global__ 
`),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"test_shfl_swap"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("d_out"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("d_in"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token keyword"},"const"),s(" mask"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"int"),s(" firstIdx"),n("span",{class:"token punctuation"},","),s(` 
 `),n("span",{class:"token keyword"},"int"),s(" secondIdx"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" idx "),n("span",{class:"token operator"},"="),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"*"),s(" SEGM"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" value"),n("span",{class:"token punctuation"},"["),s("SEGM"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 
 `),n("span",{class:"token keyword"},"for"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" i "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(" i "),n("span",{class:"token operator"},"<"),s(" SEGM"),n("span",{class:"token punctuation"},";"),s(" i"),n("span",{class:"token operator"},"++"),n("span",{class:"token punctuation"},")"),s(" value"),n("span",{class:"token punctuation"},"["),s("i"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" d_in"),n("span",{class:"token punctuation"},"["),s("idx "),n("span",{class:"token operator"},"+"),s(" i"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token function"},"swap"),n("span",{class:"token punctuation"},"("),s("value"),n("span",{class:"token punctuation"},","),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},","),s(" mask"),n("span",{class:"token punctuation"},","),s(" firstIdx"),n("span",{class:"token punctuation"},","),s(" secondIdx"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 
 `),n("span",{class:"token keyword"},"for"),s(),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(" i "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(" i "),n("span",{class:"token operator"},"<"),s(" SEGM"),n("span",{class:"token punctuation"},";"),s(" i"),n("span",{class:"token operator"},"++"),n("span",{class:"token punctuation"},")"),s(" d_out"),n("span",{class:"token punctuation"},"["),s("idx "),n("span",{class:"token operator"},"+"),s(" i"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" value"),n("span",{class:"token punctuation"},"["),s("i"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
`),n("span",{class:"token punctuation"},"}"),s(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),In=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[n("span",{class:"token comment"},"//通过指定掩码为1、第一个索引为0、第二个索引为3调用内核："),s(`
test_shfl_swap`),n("span",{class:"token operator"},"<<"),n("span",{class:"token operator"},"<"),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},","),s(" block "),n("span",{class:"token operator"},"/"),s(" SEGM "),n("span",{class:"token operator"},">>"),n("span",{class:"token operator"},">"),n("span",{class:"token punctuation"},"("),s("d_outData"),n("span",{class:"token punctuation"},","),s(" d_inData"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"1"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token number"},"3"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`

`),n("span",{class:"token comment"},"//这两个函数都包含在simpleShfl.cu文件中。结果如下所示，对于每对线程而言，第一"),s(`
`),n("span",{class:"token comment"},"//个调用线程数组中的第一个元素与第二个调用线程数组中的第四个元素可以进行交换。"),s(`
initial `),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"0"),s(),n("span",{class:"token number"},"1"),s(),n("span",{class:"token number"},"2"),s(),n("span",{class:"token number"},"3"),s(),n("span",{class:"token number"},"4"),s(),n("span",{class:"token number"},"5"),s(),n("span",{class:"token number"},"6"),s(),n("span",{class:"token number"},"7"),s(),n("span",{class:"token number"},"8"),s(),n("span",{class:"token number"},"9"),s(),n("span",{class:"token number"},"10"),s(),n("span",{class:"token number"},"11"),s(),n("span",{class:"token number"},"12"),s(),n("span",{class:"token number"},"13"),s(),n("span",{class:"token number"},"14"),s(),n("span",{class:"token number"},"15"),s(`
shfl swap `),n("span",{class:"token operator"},":"),s(),n("span",{class:"token number"},"7"),s(),n("span",{class:"token number"},"1"),s(),n("span",{class:"token number"},"2"),s(),n("span",{class:"token number"},"3"),s(),n("span",{class:"token number"},"4"),s(),n("span",{class:"token number"},"5"),s(),n("span",{class:"token number"},"6"),s(),n("span",{class:"token number"},"0"),s(),n("span",{class:"token number"},"15"),s(),n("span",{class:"token number"},"9"),s(),n("span",{class:"token number"},"10"),s(),n("span",{class:"token number"},"11"),s(),n("span",{class:"token number"},"12"),s(),n("span",{class:"token number"},"13"),s(),n("span",{class:"token number"},"14"),s(),n("span",{class:"token number"},"8"),s(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),Dn=c(`<h3 id="_5-6-3-使用线程束洗牌指令的并行归约" tabindex="-1"><a class="header-anchor" href="#_5-6-3-使用线程束洗牌指令的并行归约" aria-hidden="true">#</a> 5.6.3 使用线程束洗牌指令的并行归约</h3><ul><li><p>在前面的5.3.1节中，已经介绍了如何使用共享内存来优化并行归约算法。在本节中，<br> 将介绍如何使用线程束洗牌指令来解决同样的问题。</p></li><li><p>基本思路非常简单，它包括3个层面的归约：<br> ·线程束级归约<br> ·线程块级归约<br> ·网格级归约</p></li><li><p>一个线程块中可能有几个线程束。对于线程束级归约来说，每个线程束执行自己的归<br> 约。每个线程不使用共享内存，而是使用寄存器存储一个从全局内存中读取的数据元素：<br><code>int mySum = g_idata[idx];</code></p></li><li><p>线程束级归约作为一个内联函数实现，如下所示：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__inline__ __device__ <span class="token keyword">int</span> <span class="token function">warpReduce</span><span class="token punctuation">(</span><span class="token keyword">int</span> mySum<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 mySum <span class="token operator">+=</span> <span class="token function">__shfl_xor</span><span class="token punctuation">(</span>mySum<span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 mySum <span class="token operator">+=</span> <span class="token function">__shfl_xor</span><span class="token punctuation">(</span>mySum<span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 mySum <span class="token operator">+=</span> <span class="token function">__shfl_xor</span><span class="token punctuation">(</span>mySum<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 mySum <span class="token operator">+=</span> <span class="token function">__shfl_xor</span><span class="token punctuation">(</span>mySum<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 mySum <span class="token operator">+=</span> <span class="token function">__shfl_xor</span><span class="token punctuation">(</span>mySum<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token keyword">return</span> mySum<span class="token punctuation">;</span> 
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>在这个函数返回之后，每个线程束的总和保存到基于线程索引和线程束大小的共享内<br> 存中，如下所示：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">int</span> laneIdx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">%</span> warpSize<span class="token punctuation">;</span>
<span class="token keyword">int</span> warpIdx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">/</span> warpSize<span class="token punctuation">;</span> 
mySum <span class="token operator">=</span> <span class="token function">warpReduce</span><span class="token punctuation">(</span>mySum<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span>laneIdx <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> smem<span class="token punctuation">[</span>warpIdx<span class="token punctuation">]</span> <span class="token operator">=</span> mySum<span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>对于线程块级归约，先同步块，然后使用相同的线程束归约函数将每个线程束的总和<br> 进行相加。之后，由线程块产生的最终输出由块中的第一个线程保存到全局内存中，如下<br> 所示：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> 
mySum <span class="token operator">=</span> <span class="token punctuation">(</span>threadIdx<span class="token punctuation">.</span>x <span class="token operator">&lt;</span> SMEMDIM<span class="token punctuation">)</span> <span class="token operator">?</span> smem<span class="token punctuation">[</span>laneIdx<span class="token punctuation">]</span> <span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span>warpIdx <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> mySum <span class="token operator">=</span> <span class="token function">warpReduce</span><span class="token punctuation">(</span>mySum<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span>threadIdx<span class="token punctuation">.</span>x <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> g_odata<span class="token punctuation">[</span>blockIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span> <span class="token operator">=</span> mySum<span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>对于网格级归约，g_odata被复制回到执行最终归约的主机中。下面是完整的reduceShfl核函数：</li></ul>`,8),Sn={class:"hint-container details"},Rn=n("summary",null,"Click me to view the code!",-1),Mn=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[s("__global__ "),n("span",{class:"token keyword"},"void"),s(),n("span",{class:"token function"},"reduceShfl"),n("span",{class:"token punctuation"},"("),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("g_idata"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"int"),s(),n("span",{class:"token operator"},"*"),s("g_odata"),n("span",{class:"token punctuation"},","),s(),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" n"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token punctuation"},"{"),s(`
 `),n("span",{class:"token comment"},"// shared memory for each warp sum"),s(`
 __shared__ `),n("span",{class:"token keyword"},"int"),s(" smem"),n("span",{class:"token punctuation"},"["),s("SMEMDIM"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// boundary check "),s(`
 `),n("span",{class:"token keyword"},"unsigned"),s(),n("span",{class:"token keyword"},"int"),s(" idx "),n("span",{class:"token operator"},"="),s(" blockIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token operator"},"*"),s("blockDim"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"+"),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("idx "),n("span",{class:"token operator"},">="),s(" n"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token keyword"},"return"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// read from global memory"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" mySum "),n("span",{class:"token operator"},"="),s(" g_idata"),n("span",{class:"token punctuation"},"["),s("idx"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token punctuation"},";"),s(`
 
 `),n("span",{class:"token comment"},"// calculate lane index and warp index"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" laneIdx "),n("span",{class:"token operator"},"="),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"%"),s(" warpSize"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"int"),s(" warpIdx "),n("span",{class:"token operator"},"="),s(" threadIdx"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"/"),s(" warpSize"),n("span",{class:"token punctuation"},";"),s(` 
 `),n("span",{class:"token comment"},"// block-wide warp reduce "),s(`
 mySum `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"warpReduce"),n("span",{class:"token punctuation"},"("),s("mySum"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 
 `),n("span",{class:"token comment"},"// save warp sum to shared memory"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("laneIdx"),n("span",{class:"token operator"},"=="),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s(" smem"),n("span",{class:"token punctuation"},"["),s("warpIdx"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" mySum"),n("span",{class:"token punctuation"},";"),s(`
 
 `),n("span",{class:"token comment"},"// block synchronization"),s(`
 `),n("span",{class:"token function"},"__syncthreads"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(` 
 
 `),n("span",{class:"token comment"},"// last warp reduce"),s(`
 mySum `),n("span",{class:"token operator"},"="),s(),n("span",{class:"token punctuation"},"("),s("threadIdx"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"<"),s(" SMEMDIM"),n("span",{class:"token punctuation"},")"),s(),n("span",{class:"token operator"},"?"),s(" smem"),n("span",{class:"token punctuation"},"["),s("laneIdx"),n("span",{class:"token punctuation"},"]"),n("span",{class:"token operator"},":"),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("warpIdx"),n("span",{class:"token operator"},"=="),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s(" mySum "),n("span",{class:"token operator"},"="),s(),n("span",{class:"token function"},"warpReduce"),s(),n("span",{class:"token punctuation"},"("),s("mySum"),n("span",{class:"token punctuation"},")"),n("span",{class:"token punctuation"},";"),s(`
 `),n("span",{class:"token comment"},"// write result for this block to global mem"),s(`
 `),n("span",{class:"token keyword"},"if"),s(),n("span",{class:"token punctuation"},"("),s("threadIdx"),n("span",{class:"token punctuation"},"."),s("x "),n("span",{class:"token operator"},"=="),s(),n("span",{class:"token number"},"0"),n("span",{class:"token punctuation"},")"),s(" g_odata"),n("span",{class:"token punctuation"},"["),s("blockIdx"),n("span",{class:"token punctuation"},"."),s("x"),n("span",{class:"token punctuation"},"]"),s(),n("span",{class:"token operator"},"="),s(" mySum"),n("span",{class:"token punctuation"},";"),s(`
`),n("span",{class:"token punctuation"},"}"),s(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),Cn=n("div",{class:"language-cpp line-numbers-mode","data-ext":"cpp"},[n("pre",{class:"language-cpp"},[n("code",null,[n("span",{class:"token comment"},"//可从Wrox.com上下载reduceIntegerShfl.cu文件。在Tesla K40上使用CUDA 6.0的结果如"),s(`
`),n("span",{class:"token comment"},"//下。使用洗牌指令实现线程束级并行归约获得了1.42倍的加速。"),s(`
`),n("span",{class:"token function"},"Time"),n("span",{class:"token punctuation"},"("),n("span",{class:"token operator"},"%"),n("span",{class:"token punctuation"},")"),s(` Time Calls Avg Min Max Name
 `),n("span",{class:"token number"},"24.95"),n("span",{class:"token operator"},"%"),s(),n("span",{class:"token number"},"4.0000u"),s("s "),n("span",{class:"token number"},"1"),s(),n("span",{class:"token number"},"4.0000u"),s("s "),n("span",{class:"token number"},"4.0000u"),s("s "),n("span",{class:"token number"},"4.0000u"),s("s "),n("span",{class:"token function"},"reduceSmem"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),s(`
 `),n("span",{class:"token number"},"17.76"),n("span",{class:"token operator"},"%"),s(),n("span",{class:"token number"},"2.8480u"),s("s "),n("span",{class:"token number"},"1"),s(),n("span",{class:"token number"},"2.8480u"),s("s "),n("span",{class:"token number"},"2.8480u"),s("s "),n("span",{class:"token number"},"2.8480u"),s("s "),n("span",{class:"token function"},"reduceShfl"),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),s(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),Bn=c('<h2 id="_5-7-总结" tabindex="-1"><a class="header-anchor" href="#_5-7-总结" aria-hidden="true">#</a> 5.7 总结</h2><ul><li><p>为了获得最大的应用性能，需要有一个能显式管理的内存层次结构。在C语言中，没<br> 有直接控制数据移动的方式。在本章中，介绍了不同CUDA内存层次结构类型，如共享内<br> 存、常量内存和只读缓存。介绍了当从共享内存中引入或删除数据时如何显式控制以显著<br> 提高其性能。还介绍了常量内存和只读缓存的行为，以及如何最有效地使用它们。</p></li><li><p>共享内存可以被声明为一维或二维数组，它能为每个程序提供一个简单的逻辑视图。<br> 物理上，共享内存是一维的，并能通过32个存储体进行访问。避免存储体冲突是在共享内<br> 存应用优化过程中一个重要的因素。共享内存被分配在所有常驻线程块中，因此，它是一<br> 个关键资源，可能会限制内核占用率。</p></li><li><p>在内核中使用共享内存有两个主要原因：一个是用于缓存片上数据并且减少全局内存<br> 访问量；另一个是传输共享内存中数据的安排方式，避免非合并的全局内存访问。</p></li><li><p>常量内存对只读数据进行了优化，这些数据每次都将数据广播到许多线程中。常量内<br> 存也使用自己的SM缓存，防止常量内存的读操作通过一级缓存干扰全局内存的访问。因<br> 此，对合适的数据使用常量内存，不仅可优化特定项目的访问，还可能提高整体全局内存<br> 吞吐量。</p></li><li><p>只读纹理缓存提供了常量内存的替代方案，该方案优化了数据的分散读取。只读缓存<br> 访问全局内存中的数据，但它使用一个独立的内存访问流水线和独立的缓存，以使SM可<br> 以访问数据。因此，只读缓存共享了常量内存的许多好处，同时对不同的访问模式也进行<br> 了优化。</p></li><li><p>洗牌指令是线程束级的内部功能，能使线程束中的线程彼此之间快速直接地共享数<br> 据。洗牌指令具有比共享内存更低的延迟，并且不需要分配额外的资源。使用洗牌指令可<br> 以减少内核中线程束同步优化的数目。然而，在许多情况下，洗牌指令不是共享内存的替<br> 代品，因为共享内存在整个线程块中都可见。</p></li><li><p>本章对一些有特殊用途的内存类型进行了深度了解。虽然这些内存类型比全局内存使<br> 用得少，但是适当地使用它们可以提高带宽利用率，降低整体的内存延迟。如果你正在研<br> 究优化的因素，那么牢记共享内存、常量内存、只读缓存和洗牌指令都是非常重要的。</p></li></ul><h2 id="_5-8-习题" tabindex="-1"><a class="header-anchor" href="#_5-8-习题" aria-hidden="true">#</a> 5.8 习题</h2><ul><li><p>1.假设你有一个<code>维度为[32][32]的共享内存块</code>，对于一个4字节访问模式的Kepler设<br> 备，给该内存共享块填充一列，然后画出数据元素和存储体之间映射关系的示意图。</p></li><li><p>2.参考checkSmemSquare.cu文件中的setRowReadCol函数，构造一个新的核函数<br> setColReadRow，该函数执行列写入和行读取操作。用nvprof测试内存事务并观察输出。</p></li><li><p>3.参考checkSmemSquare.cu文件中的setRowReadColDyn函数，构造一个新的核函数<br> setColRead-RowDyn，该函数动态地声明共享内存，然后执行列写入和行读取操作。用<br> nvprof测试内存事务并观察输出。</p></li><li><p>4.参考checkSmemSquare.cu文件中的setRowReadColPad函数，构造一个新的核函数<br> setColRead-RowPad，该函数填充一列，然后执行列写入和行读取操作。用nvprof测试内存<br> 事务并观察输出。</p></li><li><p>5.假设checkSmemSquare.cu文件中的方形共享内存数组大小为16×16，而不是32×32，<br> 那么在Fermi和Kepler设备上，共享内存事务的数量将会如何变化？尝试画出每种情况下<br> 共享内存安排的图形。</p></li><li><p>6.参考checkSmemRectangle.cu文件中的setRowReadCol函数，构造一个新的核函数<br> setColRead-Row，该函数执行列写入和行读取操作。用nvprof测试内存事务并观察输出。</p></li><li><p>7.参考checkSmemRectangle.cu文件中的setRowReadColPad函数，构造一个新的核函数<br> setColRead-RowPad，该函数执行列写入和行读取。用nvprof测试内存事务并观察输出。</p></li><li><p>8.参考reduceInteger.cu文件，测试大小分别为64.128、512和1024的块，通过nvprof计<br> 算核函数的运行时间，确定最佳的执行配置。</p></li><li><p>9.参考stencil_1d_read_only函数，用全局内存写一个核函数以存储有限差分的系数。<br> 通过nvprof比较3个核函数：使用常量缓存的核函数，使用只读缓存的核函数和使用带有<br> 一级缓存的全局内存的核函数。</p></li><li><p>10.参考simpleShfl.cu文件中的test_shfl_up函数，用一个负delta来调用它，结果如下：<br><code>test_shfl_up&lt;&lt;&lt;1, BDIMX&gt;&gt;&gt;(d_outData, d_inData, -2);</code>检查输出的结果和原因。</p></li><li><p>11.参考simpleShfl.cu文件中的test_shfl_wrap函数，构造一个新的可产生下列结果的核函数：<br> Initial: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15<br> Result : 2 4 6 8 10 12 14 16 18 20 22 24 26 28 14 16</p></li><li><p>12.参考simpleShfl.cu文件中的test_shfl_xor函数，构造一个新的可产生下列结果的核函数：<br> Initial: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15<br> Result : 1 1 5 5 9 9 13 13 17 17 21 21 25 25 29 29</p></li><li><p>13.参考simpleShfl.cu文件中的test_shfl_xor_array函数，构造一个新的仅能执行下列一<br> 个操作的核函数：<code> value[3] = __shfl_xor (value[0], mask, BDIMX);</code><br> 检查输出的结果和产生该结果的原因。</p></li><li><p>14.参考simpleShfl.cu文件中的test_shfl_wrap函数，构造一个新的核函数，可在一个环<br> 绕式的线程束方法中移动双精度变量。</p></li><li><p>15.参考reduceIntegerShfl.cu文件中的内联函数warpReduce，写一个使用__shfl_down指<br> 令的等效函数</p></li></ul>',4);function An(Kn,Un){const t=i("router-link"),l=i("CodeTabs");return r(),k("div",null,[$,W,d(" more "),n("nav",V,[n("ul",null,[n("li",null,[e(t,{to:"#简单介绍主要是基础"},{default:a(()=>[s("简单介绍主要是基础")]),_:1})]),n("li",null,[e(t,{to:"#第5章-共享内存和常量内存"},{default:a(()=>[s("第5章 共享内存和常量内存")]),_:1})]),n("li",null,[e(t,{to:"#_5-1-cuda共享内存概述"},{default:a(()=>[s("5.1 CUDA共享内存概述")]),_:1}),n("ul",null,[n("li",null,[e(t,{to:"#_5-1-1-共享内存"},{default:a(()=>[s("5.1.1 共享内存")]),_:1})]),n("li",null,[e(t,{to:"#_5-1-2-共享内存分配"},{default:a(()=>[s("5.1.2 共享内存分配")]),_:1})]),n("li",null,[e(t,{to:"#_5-1-3-共享内存存储体和访问模式"},{default:a(()=>[s("5.1.3 共享内存存储体和访问模式")]),_:1})]),n("li",null,[e(t,{to:"#_5-1-4-配置共享内存量"},{default:a(()=>[s("5.1.4 配置共享内存量")]),_:1})]),n("li",null,[e(t,{to:"#_5-1-5-同步"},{default:a(()=>[s("5.1.5 同步")]),_:1})])])]),n("li",null,[e(t,{to:"#_5-2-共享内存的数据布局"},{default:a(()=>[s("5.2 共享内存的数据布局")]),_:1}),n("ul",null,[n("li",null,[e(t,{to:"#_5-2-1-方形共享内存"},{default:a(()=>[s("5.2.1 方形共享内存")]),_:1})]),n("li",null,[e(t,{to:"#_5-2-2-矩形共享内存"},{default:a(()=>[s("5.2.2 矩形共享内存")]),_:1})])])]),n("li",null,[e(t,{to:"#_5-3-减少全局内存访问"},{default:a(()=>[s("5.3 减少全局内存访问")]),_:1}),n("ul",null,[n("li",null,[e(t,{to:"#_5-3-1-使用共享内存的并行归约"},{default:a(()=>[s("5.3.1 使用共享内存的并行归约")]),_:1})]),n("li",null,[e(t,{to:"#_5-3-2-使用展开的并行归约"},{default:a(()=>[s("5.3.2 使用展开的并行归约")]),_:1})]),n("li",null,[e(t,{to:"#_5-3-3-使用动态共享内存的并行归约"},{default:a(()=>[s("5.3.3 使用动态共享内存的并行归约")]),_:1})]),n("li",null,[e(t,{to:"#_5-3-4-有效带宽"},{default:a(()=>[s("5.3.4 有效带宽")]),_:1})])])]),n("li",null,[e(t,{to:"#_5-4-合并的全局内存访问"},{default:a(()=>[s("5.4 合并的全局内存访问")]),_:1}),n("ul",null,[n("li",null,[e(t,{to:"#_5-4-1-基准转置内核"},{default:a(()=>[s("5.4.1 基准转置内核")]),_:1})]),n("li",null,[e(t,{to:"#_5-4-2-使用共享内存的矩阵转置"},{default:a(()=>[s("5.4.2 使用共享内存的矩阵转置")]),_:1})]),n("li",null,[e(t,{to:"#_5-4-3-使用填充共享内存的矩阵转置"},{default:a(()=>[s("5.4.3 使用填充共享内存的矩阵转置")]),_:1})]),n("li",null,[e(t,{to:"#_5-4-4-使用展开的矩阵转置"},{default:a(()=>[s("5.4.4 使用展开的矩阵转置")]),_:1})]),n("li",null,[e(t,{to:"#_5-4-5-增大并行性"},{default:a(()=>[s("5.4.5 增大并行性")]),_:1})])])]),n("li",null,[e(t,{to:"#_5-5-常量内存"},{default:a(()=>[s("5.5 常量内存")]),_:1}),n("ul",null,[n("li",null,[e(t,{to:"#_5-5-1-使用常量内存实现一维模板"},{default:a(()=>[s("5.5.1 使用常量内存实现一维模板")]),_:1})]),n("li",null,[e(t,{to:"#_5-5-2-与只读缓存的比较"},{default:a(()=>[s("5.5.2 与只读缓存的比较")]),_:1})])])]),n("li",null,[e(t,{to:"#_5-6-线程束洗牌指令"},{default:a(()=>[s("5.6 线程束洗牌指令")]),_:1}),n("ul",null,[n("li",null,[e(t,{to:"#_5-6-1-线程束洗牌指令的不同形式"},{default:a(()=>[s("5.6.1 线程束洗牌指令的不同形式")]),_:1})]),n("li",null,[e(t,{to:"#_5-6-2-线程束内的共享数据"},{default:a(()=>[s("5.6.2 线程束内的共享数据")]),_:1})]),n("li",null,[e(t,{to:"#_5-6-3-使用线程束洗牌指令的并行归约"},{default:a(()=>[s("5.6.3 使用线程束洗牌指令的并行归约")]),_:1})])])]),n("li",null,[e(t,{to:"#_5-7-总结"},{default:a(()=>[s("5.7 总结")]),_:1})]),n("li",null,[e(t,{to:"#_5-8-习题"},{default:a(()=>[s("5.8 习题")]),_:1})])])]),O,n("details",H,[j,e(l,{id:"1003",data:[{id:"源代码"},{id:"编译运行"}],"tab-id":"shell"},{title0:a(({value:p,isActive:o})=>[s("源代码")]),title1:a(({value:p,isActive:o})=>[s("编译运行")]),tab0:a(({value:p,isActive:o})=>[J]),tab1:a(({value:p,isActive:o})=>[Q]),_:1})]),Z,n("details",nn,[sn,e(l,{id:"1072",data:[{id:"demo1"},{id:"demo2"}],"tab-id":"shell"},{title0:a(({value:p,isActive:o})=>[s("demo1")]),title1:a(({value:p,isActive:o})=>[s("demo2")]),tab0:a(({value:p,isActive:o})=>[an]),tab1:a(({value:p,isActive:o})=>[en]),_:1})]),tn,n("details",pn,[on,e(l,{id:"1112",data:[{id:"demo1"},{id:"demo2"}],"tab-id":"shell"},{title0:a(({value:p,isActive:o})=>[s("demo1")]),title1:a(({value:p,isActive:o})=>[s("demo2")]),tab0:a(({value:p,isActive:o})=>[cn]),tab1:a(({value:p,isActive:o})=>[ln]),_:1})]),un,n("details",rn,[kn,e(l,{id:"1171",data:[{id:"demo1"},{id:"demo2"}],"tab-id":"shell"},{title0:a(({value:p,isActive:o})=>[s("demo1")]),title1:a(({value:p,isActive:o})=>[s("demo2")]),tab0:a(({value:p,isActive:o})=>[dn]),tab1:a(({value:p,isActive:o})=>[mn]),_:1})]),bn,n("details",vn,[_n,e(l,{id:"1243",data:[{id:"demo1"},{id:"demo2"}],"tab-id":"shell"},{title0:a(({value:p,isActive:o})=>[s("demo1")]),title1:a(({value:p,isActive:o})=>[s("demo2")]),tab0:a(({value:p,isActive:o})=>[hn]),tab1:a(({value:p,isActive:o})=>[yn]),_:1})]),xn,n("details",gn,[fn,e(l,{id:"2117",data:[{id:"demo1"},{id:"demo2"}],"tab-id":"shell"},{title0:a(({value:p,isActive:o})=>[s("demo1")]),title1:a(({value:p,isActive:o})=>[s("demo2")]),tab0:a(({value:p,isActive:o})=>[wn]),tab1:a(({value:p,isActive:o})=>[In]),_:1})]),Dn,n("details",Sn,[Rn,e(l,{id:"2176",data:[{id:"demo1"},{id:"demo2"}],"tab-id":"shell"},{title0:a(({value:p,isActive:o})=>[s("demo1")]),title1:a(({value:p,isActive:o})=>[s("demo2")]),tab0:a(({value:p,isActive:o})=>[Mn]),tab1:a(({value:p,isActive:o})=>[Cn]),_:1})]),Bn])}const Pn=u(L,[["render",An],["__file","E-第五章.html.vue"]]);export{Pn as default};
