import{_ as l}from"./plugin-vue_export-helper-c27b6911.js";import{r as o,o as i,c as u,d as r,a as n,e as s,w as e,b as a,f as t}from"./app-2a2d189a.js";const d="/assets/figure8-1-33c4d106.png",k="/assets/table8-1-c44467bc.png",b="/assets/table8-2-4ccfd092.png",v="/assets/figure8-2-a28941b8.png",m="/assets/figure8-3-2c5694d1.png",A="/assets/figure8-4-5a3c0e32.png",_="/assets/figure8-5-e09ed9e1.png",h="/assets/figure8-6-0f16a201.png",f="/assets/figure8-7-fa48b17b.png",g="/assets/table8-3-644a7aeb.png",C="/assets/table8-4-25aee3f3.png",y="/assets/figure8-8-e0eef180.png",S="/assets/figure8-9-93caaeca.png",w="/assets/figure8-10-89311bc5.png",D="/assets/figure8-11-d2917341.png",P="/assets/figure8-12-7faa3fcf.png",R="/assets/figure8-13-bdb8b2e2.png",U="/assets/figure8-14-fd765f7e.png",x="/assets/table8-5-e788ecf0.png",N="/assets/table8-6-5fb5e7ed.png",F="/assets/table8-7-d42c3fd1.png",G="/assets/table8-8-ea39730a.png",O="/assets/table8-9-5eecb8ea.png",L="/assets/table8-10-785cbd83.png",I={},M=n("h1",{id:"h-第八章",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#h-第八章","aria-hidden":"true"},"#"),a(" H-第八章")],-1),T=n("p",null,"H-第八章",-1),B={class:"table-of-contents"},E=t('<h2 id="简单介绍主要是基础" tabindex="-1"><a class="header-anchor" href="#简单介绍主要是基础" aria-hidden="true">#</a> 简单介绍主要是基础</h2><div class="hint-container info"><p class="hint-container-title">说明</p><p>主要是各种搜索找的学习；</p><p>主题：CUDA核心GPU编程</p><p>前置条件：</p><ul><li>应具备C++编程知识</li><li>需理解内存管理，如malloc和free</li><li>理解STL及其模板机制</li><li>需配置NVIDIA显卡，型号需为900系列或更高</li><li>所用扩展要求版本为11或更新</li><li>编译器版本不低于11</li><li>CMake版本需在3.18以上</li></ul></div><h2 id="第8章-gpu加速库和openacc" tabindex="-1"><a class="header-anchor" href="#第8章-gpu加速库和openacc" aria-hidden="true">#</a> 第8章 GPU加速库和OpenACC</h2><ul><li><p>本章内容：<br> ·利用CUDA库（GPU加速库）探索并行编程的新高度<br> ·了解多种CUDA库共享的通用工作流<br> ·尝试在线性代数、傅里叶变换和随机数中使用CUDA库<br> ·CUDA 6.0中新的库特性<br> ·使用OpenACC指令在GPU上进行应用程序加速</p></li><li><p>通过对本书的学习，你已经掌握了CUDA C的一些特性。在今后编写新的应用程序、<br> 自定义应用程序或进行应用程序移植时，这些学习经验能使你充分利用GPU在大吞吐量应<br> 用中的计算优势。在多数情况下，用CUDA构建应用程序的最大障碍是开发时间，因此，<br> 在创建或移植应用程序时，必须最大限度地提高开发效率。</p></li><li><p>CUDA提供了一系列的库来提高CUDA开发人员的开发效率。NVIDIA和其他机构提供<br> 了特定领域内的CUDA库，它们可以作为编写复杂的应用程序的构建模块。这些库被<br> CUDA编程方面的专家所优化，同时，他们设计具有标准化数据格式的高水平API来提供<br> 应用程序接口。CUDA库在CUDA运行时之上，为主机应用程序和第三方库提供一个简<br> 单、熟悉且有针对性的接口（如图8-1所示）。<br><img src="'+d+'" alt="figure8-1" loading="lazy"></p></li><li><p>另一个在CUDA上提供抽象层的工具是OpenACC。OpenACC使用编译指令注释来自于<br> 主机端和加速设备端用于减荷的代码和数据区域。编译器通过自动生成任意必要的内存拷<br> 贝、内核启动以及其他CUDA API调用，来对这些在设备上执行的代码进行编译。你会觉<br> 得OpenACC很熟悉，这是因为它的工作方式与第6章中提到的OpenMP类似。OpenACC可<br> 以与CUDA库和手写的CUDA内核相结合，它允许程序员实现自己编写的内核代码，但会<br> 分离出很多普通的CUDA编程任务。</p></li><li><p>接下来的部分和示例将使你对CUDA有更深入的理解，以帮助你了解这些工具的使用<br> 以及如何将它们整合到你的应用程序中。你将从以下CUDA库的学习开始探寻更多有关<br> OpenACC的细节。<br> ·cuSPARSE提供了一系列针对稀疏矩阵的基本线性代数子程式<br> ·cuBLAS提供了1、2、3级标准基础线性代数子程序（BLAS）库中所有函数的CUDA接口<br> ·cuFFT提供了一系列函数帮助开发者进行快速傅里叶变换（FFT）及其逆变<br> ·cuRAND提供了使用GPU快速生成随机数的不同方法</p></li></ul><h2 id="_8-1-cuda库概述" tabindex="-1"><a class="header-anchor" href="#_8-1-cuda库概述" aria-hidden="true">#</a> 8.1 CUDA库概述</h2><ul><li><p>CUDA库和系统库或用户自定义库没有什么不同，它们是一组在头文件中说明其原型<br> 的函数定义的集合。CUDA库的特殊性在于，其中实现的所有计算均使用了GPU加速，而<br> 不是CPU。</p></li><li><p>使用CUDA库与创建手写CUDA C程序和使用主机现有的库相比有很多优势。CUDA库<br> 为很多应用程序在可用性和性能之间提供了最佳平衡。许多CUDA库中的API与相同作用<br> 域中的标准库API基本相同。因此，你可以以基于主机的方式来使用CUDA库，这样能减<br> 少编程工作量，同时还能实现明显的加速。将复杂的算法从CPU移植到GPU中所需的时间<br> 可以从几个月或几周减少到几天甚至几小时。</p></li><li><p>CUDA库在性能方面已经超过了主机库，而且有时也超过了手写的CUDA实现。<br> CUDA库的开发人员对GPU体系架构的研究都有很深的造诣，CUDA库使你能够利用他们<br> 的专业知识迅速加速应用程序的开发。</p></li><li><p>对CUDA库的使用也降低了软件开发人员的维护成本，通过重用现有的比较成熟的实<br> 现工具，在CUDA中对这些复杂算法的测试和管理也变得简单了。这些库是由NVIDIA及<br> 其合作伙伴严格测试和管理的，这就减轻了领域内专家和新接触CUDA的程序员的工作<br> 量。</p></li><li><p>不过，将CUDA库添加到现有的应用程序中一般还需要几个步骤，而且与标准主机库<br> 相比，性能提升还有进一步优化的可能。需要声明的是，NVIDIA开发者社区（NVIDIA<br> Developer Zone）免费提供优秀的在线参考指南。本章的重点不在于每个独立函数的使<br> 用，而在于其高级的使用方法以及应用程序的优化。本节中的示例使用了基于特定库进行<br> 案例分析的CUDA库。</p></li></ul><h3 id="_8-1-1-cuda库支持的作用域" tabindex="-1"><a class="header-anchor" href="#_8-1-1-cuda库支持的作用域" aria-hidden="true">#</a> 8.1.1 CUDA库支持的作用域</h3>',7),z={href:"http://developer.nvidia.com",target:"_blank",rel:"noopener noreferrer"},V=n("br",null,null,-1),W=n("br",null,null,-1),X=n("br",null,null,-1),H=n("img",{src:k,alt:"table8-1",loading:"lazy"},null,-1),K=n("li",null,[n("p",null,[a("如果你的应用程序符合这些作用域中的任何一个，那么强烈建议你去探索NVIDIA开"),n("br"),a(" 发者社区提供的关于这些库的在线文档。")])],-1),Y=t('<h3 id="_8-1-2-通用的cuda库工作流" tabindex="-1"><a class="header-anchor" href="#_8-1-2-通用的cuda库工作流" aria-hidden="true">#</a> 8.1.2 通用的CUDA库工作流</h3><ul><li><p>当在主机端程序中调用CUDA库函数时，很多函数有通用的概念、特性及使用步骤。<br> NVIDIA函数库的通用工作流如下所示：<br> 1.在库操作中创建一个特定的库句柄来管理上下文信息。<br> 2.为库函数的输入输出分配设备内存。<br> 3.如果输入格式不是函数库支持的格式则需要进行转换。<br> 4.将输入以支持的格式填入预先分配的设备内存中。<br> 5.配置要执行的库运算。<br> 6.执行一个将计算部分交付给GPU的库函数调用。<br> 7.取回设备内存中的计算结果，它可能是库设定的格式。<br> 8.如有必要，则将取回的数据转换成应用程序的原始格式。<br> 9.释放CUDA资源。<br> 10.继续完成应用程序的其他工作。</p></li><li><p>并非每个库都遵循这一工作流，有些库可能会跳过某些步骤。你对每一步工作背后内<br> 容的认识是很重要的，因为这有助于你进行性能优化或简化调试过程。本章后面涉及的每<br> 个函数库基本上都遵循这个工作流。下面对该工作流的每一步进行详细说明，其中包含一<br> 些新概念和新词汇。</p></li></ul><h4 id="_8-1-2-1-第1步-创建一个函数库句柄" tabindex="-1"><a class="header-anchor" href="#_8-1-2-1-第1步-创建一个函数库句柄" aria-hidden="true">#</a> 8.1.2.1 第1步：创建一个函数库句柄</h4><ul><li>许多CUDA库都有句柄这个概念，它包含了该库的一些上下文信息，如使用的数据结<br> 构格式、用于计算的设备端的使用等。对于使用句柄的库，在库调用前要做的就是为句柄<br> 分配内存及初始化。一般情况下，可以把句柄视作一个存放在主机上、包含每个库函数可<br> 能访问的信息且对程序员不透明的对象。例如，你可能希望所有的库操作都在一个特定的<br> CUDA流中运行。尽管不同函数库使用不同的函数名，许多函数库都有一个使所有操作在<br> 特定流中运行的函数（例如，cuSPARSE中的cusparseSetStream，cuBLAS中的<br> cublasSetStream以及cuFFT中的cufftSetStream）。这个流信息就保存在库句柄中，这个句柄<br> 提供了一种存储库信息的方法，程序员则负责管理句柄的并发访问。</li></ul><h4 id="_8-1-2-2-第2步-分配设备内存" tabindex="-1"><a class="header-anchor" href="#_8-1-2-2-第2步-分配设备内存" aria-hidden="true">#</a> 8.1.2.2 第2步：分配设备内存</h4><ul><li>本节所介绍的函数库，都是由程序员或函数库自己调用cudaMalloc为其分配设备内存<br> 的。只有在使用多GPU编程库时，才需要使用API来分配设备内存</li></ul><h4 id="_8-1-2-3-第3步-将输入数据转换为函数库支持的格式" tabindex="-1"><a class="header-anchor" href="#_8-1-2-3-第3步-将输入数据转换为函数库支持的格式" aria-hidden="true">#</a> 8.1.2.3 第3步：将输入数据转换为函数库支持的格式</h4><ul><li>如果CUDA库不支持应用程序的数据格式，那么就需要进行格式转换。例如，如果应<br> 用程序按行优先顺序存储二维数组，但CUDA库只接受按列优先顺序存储的数组，那么你<br> 就需要进行格式转换了。为了取得最优性能，应尽可能地与CUDA库的数据格式一致从而<br> 避免数据转换。</li></ul><h4 id="_8-1-2-4-第4步-将输入数据传送到设备内存中" tabindex="-1"><a class="header-anchor" href="#_8-1-2-4-第4步-将输入数据传送到设备内存中" aria-hidden="true">#</a> 8.1.2.4 第4步：将输入数据传送到设备内存中</h4><ul><li>有了第2步分配的全局内存和第3步格式化后的数据，第4步的任务就是将数据传送到<br> 设备内存中，以供CUDA设备上的库函数使用。这类似于cudaMemcpy的作用，尽管多数情<br> 况下使用的是库特有的函数。例如，在使用基于cuBLAS的应用程序中把一个向量从主机<br> 传输到设备，用的就是cublasSetVector。当然其内部还是调用cudaMemcpy（或其他等价函<br> 数）来将输入数据传输到设备内存中的。</li></ul><h4 id="_8-1-2-5-第5步-配置函数库" tabindex="-1"><a class="header-anchor" href="#_8-1-2-5-第5步-配置函数库" aria-hidden="true">#</a> 8.1.2.5 第5步：配置函数库</h4><ul><li>通常，被调用的库函数必须明确自己所用的数据格式、维度或其他配置参数。在第5<br> 步，需要你来管理这个配置过程。在某些情况下，这些配置只是一些传递给计算函数库的<br> 参数。在其他情况下，就需要手动配置之前所说的库句柄了。还有个别情况，你需要管理<br> 一些分离的数据对象。</li></ul><h4 id="_8-1-2-6-第6步-执行" tabindex="-1"><a class="header-anchor" href="#_8-1-2-6-第6步-执行" aria-hidden="true">#</a> 8.1.2.6 第6步：执行</h4><ul><li>执行阶段其实是函数库调用中最简单的一步！前面的5个步骤已经配置好了所需的库<br> 函数，并且获得了高度优化的CUDA库函数性能。</li></ul><h4 id="_8-1-2-7-第7步-取回设备内存中的结果" tabindex="-1"><a class="header-anchor" href="#_8-1-2-7-第7步-取回设备内存中的结果" aria-hidden="true">#</a> 8.1.2.7 第7步：取回设备内存中的结果</h4><ul><li>在这一步中，将输出数据按预定义的格式从设备内存中传回至主机内存（数据格式按<br> 第5步配置的或由函数库规定的），可以理解为它是第4步的反过程。</li></ul><h4 id="_8-1-2-8-第8步-将数据转换回原始格式" tabindex="-1"><a class="header-anchor" href="#_8-1-2-8-第8步-将数据转换回原始格式" aria-hidden="true">#</a> 8.1.2.8 第8步：将数据转换回原始格式</h4><ul><li>如果应用程序的原始数据格式和CUDA库支持的格式不同，那么就需要将其转换回应<br> 用程序所用的格式，这是第3步的反过程。</li></ul><h4 id="_8-1-2-9-第9步-释放cuda资源" tabindex="-1"><a class="header-anchor" href="#_8-1-2-9-第9步-释放cuda资源" aria-hidden="true">#</a> 8.1.2.9 第9步：释放CUDA资源</h4><ul><li>如果被工作流分配的资源不再使用就要释放掉，以便在以后的计算中使用。注意，分<br> 配和释放资源会有一些开销，因此最好多次调用CUDA库来重用设备内存、函数库句柄和<br> CUDA流等资源。</li></ul><h4 id="_8-1-2-10-第10步-继续应用程序的其他部分" tabindex="-1"><a class="header-anchor" href="#_8-1-2-10-第10步-继续应用程序的其他部分" aria-hidden="true">#</a> 8.1.2.10 第10步：继续应用程序的其他部分</h4><ul><li><p>在第7步取回输出的数据并（可选地）在第8步转换成应用程序的原始数据格式后，便<br> 可以继续其他操作了，就好像在GPU上还没有执行计算操作一样。</p></li><li><p>以上这些复杂的介绍或许会让你觉得使用CUDA库是一件高开销低效率的事。后面几<br> 节会说明事实并非如此。很多情况下，整个工作流只需要几行代码。以上如此详细的介绍<br> 是为了帮助你加深对函数库的理解。</p></li><li><p>在下一节中，你将会对一些最常用的CUDA库进行更深入的学习。接下来将介绍每个<br> 函数库的相关概念，并通过一个例子来理解其工作流。</p></li></ul><h2 id="_8-2-cusparse库" tabindex="-1"><a class="header-anchor" href="#_8-2-cusparse库" aria-hidden="true">#</a> 8.2 cuSPARSE库</h2><ul><li><p>cuSPARSE是一个线性代数库，内含很多通用的稀疏线性代数函数。这些函数支持一<br> 系列稠密和稀疏的数据格式。</p></li><li><p>表8-2列举了cuSPARSE支持的线性代数运算。想要对下列函数有更详细的了解，请参<br> 阅在线的cuSPARSE用户指南。cuSPARSE将函数进行了分类，第一类函数只能在稠密向量<br> 和稀疏向量中进行操作，第二类函数可以在稀疏矩阵和稠密向量中进行操作，第三类函数<br> 可以在稀疏矩阵和稠密矩阵中进行操作。</p></li><li><p>注：在每个稀疏线性代数操作的描述中，小写黑斜体字母表示向量，大写黑斜体字母<br> 表示矩阵，白斜体小写字母表示标量。</p></li><li><p>在下一节，你将学习到cuSPARSE所支持的数据格式以及数据格式的转换。<br><img src="'+b+'" alt="table8-2" loading="lazy"></p></li></ul><h3 id="_8-2-1-cusparse数据存储格式" tabindex="-1"><a class="header-anchor" href="#_8-2-1-cusparse数据存储格式" aria-hidden="true">#</a> 8.2.1 cuSPARSE数据存储格式</h3><ul><li>稠密矩阵中基本都是非零元素，矩阵中的每个值都是存储在一个多维数组中的。相<br> 反，稀疏矩阵和稀疏向量中基本都是零元素，因此在存储时可以只保存非零元素的值及其<br> 坐标。稀疏矩阵的存储方式有很多，目前cuSPARSE支持的有8种，本节简要介绍其中3种<br> 存储方式。</li></ul><h4 id="_8-2-1-1-稠密存储方式" tabindex="-1"><a class="header-anchor" href="#_8-2-1-1-稠密存储方式" aria-hidden="true">#</a> 8.2.1.1 稠密存储方式</h4><ul><li>稠密矩阵格式是一种常见的存储方式，这种方式把矩阵中的每个元素都存储起来，不<br> 管它是否为零。由于这些矩阵是存储在内存中的，而内存本身是一维的，因此稠密矩阵中<br> 的每个元素必须变平且映射到连续的一维内存地址中。图8-2所示为二维矩阵M到一维存<br> 储格式T的映射。<br><img src="'+v+'" alt="figure8-2" loading="lazy"></li></ul><h4 id="_8-2-1-2-坐标存储方式" tabindex="-1"><a class="header-anchor" href="#_8-2-1-2-坐标存储方式" aria-hidden="true">#</a> 8.2.1.2 坐标存储方式</h4><ul><li><p>坐标稀疏矩阵格式（COO）存储了稀疏矩阵中每个非零元素的行坐标、列坐标及其<br> 元素值。因此当通过给定的行列坐标对存储在COO格式中的稀疏矩阵进行检索的时候，<br> 如果没有匹配值，那么这个位置的值为零。</p></li><li><p>坐标矩阵存储格式与稠密矩阵存储格式所占用的空间大小取决于矩阵的稀疏程度、元<br> 素的大小以及存储坐标类型的大小。例如，一个存储32位浮点型数据的稀疏矩阵，其坐标<br> 索引使用32位整型表示，只有当矩阵中的非零元素不到1/3时，才会节约存储空间。这是<br> 因为在这样的存储格式下，存储一个非零元素占用的空间是稠密格式下的3倍。图8-3所示<br> 为二维矩阵M到表示其坐标索引T的映射。<br><img src="'+m+'" alt="figure8-3" loading="lazy"></p></li></ul><h4 id="_8-2-1-3-压缩稀疏行方式-csr" tabindex="-1"><a class="header-anchor" href="#_8-2-1-3-压缩稀疏行方式-csr" aria-hidden="true">#</a> 8.2.1.3 压缩稀疏行方式（CSR）</h4><ul><li><p>压缩稀疏行方式（CSR）与COO类似。唯一不同的是对于非零元素行索引的存储。在<br> COO中，每个非零元素对应一个表示其值行索引的整数，而不是为每个值显式地存储行<br> 索引。而CSR则为同一行的所有元素值存储一个偏移量。</p></li><li><p>例如，假设稀疏矩阵M的非零元素存储在数组V中，而这些元素的列索引则存储在数<br> 组C中，如图8-4所示。相比COO，CSR没有存储行索引。<br><img src="'+A+'" alt="figure8-4" loading="lazy"></p></li><li><p>因为同一行的所有元素在V中都是被相邻的存储，因此要想找到某一行的值只需要数<br> 组V中的一个偏移量和长度值。例如，如果你只想知道M中第三行的非零元素有哪些，我<br> 们可以使用偏移量2和长度2在V中进行检索，如图8-5所示。这就是CSR中行索引的存储方<br> 式。<br><img src="'+_+'" alt="figure8-5" loading="lazy"></p></li><li><p>在列数组C中利用相同的偏移量和长度值可以确定所存储元素的列索引，因此该方法<br> 完全可以确定某个元素在原始的稀疏矩阵M中的位置。当存储一个较大的矩阵且每行元素<br> 都较多时，每行都使用一个偏移量和长度值进行存储比存储每个值的行索引要有效得多。</p></li><li><p>那么，每行数据的偏移量和长度该如何存储呢？最简单的方法是创建长度为nRows的<br> 数组RO和RL，RO用来储存每一行的偏移量，RL用来存储每一行的长度。但如果一个矩<br> 阵有很多行，就需要有两个较大的数组。因此，我们可以使用一个长度为nRows＋1的简<br> 单数组R，数组V和C中第i行的偏移量就存储在数组R的i索引中。第i行的长度可以通过比<br> 较i和i＋1行的偏移量来判定。而<code>数组R[i＋1]</code>中实质上存储的是所有行中所有非零值的总<br> 数。<code>R[nRows]</code>是矩阵M中非零值的总数，综上所得的数组R如图8-6所示。<br><img src="'+h+'" alt="figure8-6" loading="lazy"></p></li><li><p>由图8-6可知，在数组V和C中可以获得矩阵M中第0行的值和列索引，其长度为1―0＝<br> 1，对于矩阵M的第1行和第2行元素可以应用同样的方法得到其值和列索引。M中非零值<br> 的总数也可以由R的最后一个元素获得。</p></li><li><p>因此，CSR比COO更节省存储空间。CSR的完整示意如图8-7所示。<br><img src="'+f+`" alt="figure8-7" loading="lazy"></p></li><li><p>可以把CSR格式的稀疏矩阵传到GPU中，然后直接在cuSPARSE函数中使用。首先，<br> 假设你已经通过下列代码在主机上定义了一个CSR格式的稀疏矩阵：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">float</span> <span class="token operator">*</span>h_csrVals<span class="token punctuation">;</span>
<span class="token keyword">int</span> <span class="token operator">*</span>h_csrCols<span class="token punctuation">;</span>
<span class="token keyword">int</span> <span class="token operator">*</span>h_csrRows<span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>h_csrVals用来存储稀疏矩阵的非零值个数，h_csrCols用来存储每个值的列索引，<br> h_csrRows用来存储h_csrVals和h_csrCols中的行偏移。接下来为每个数组分配设备内存，<br> 然后传给GPU：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">float</span> <span class="token operator">*</span>d_csrVals<span class="token punctuation">;</span>
<span class="token keyword">int</span> <span class="token operator">*</span>d_csrCols<span class="token punctuation">;</span>
<span class="token keyword">int</span> <span class="token operator">*</span>d_csrRows<span class="token punctuation">;</span>
<span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>d_csrVals<span class="token punctuation">,</span> n_vals <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>d_csrCols<span class="token punctuation">,</span> n_vals <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>d_csrRows<span class="token punctuation">,</span> <span class="token punctuation">(</span>n_rows <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>d_csrVals<span class="token punctuation">,</span> h_csrVals<span class="token punctuation">,</span> n_vals <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>d_csrCols<span class="token punctuation">,</span> h_csrCols<span class="token punctuation">,</span> n_vals <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>d_csrRows<span class="token punctuation">,</span> h_csrRows<span class="token punctuation">,</span> <span class="token punctuation">(</span>n_rows <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_8-2-1-4-cusparse存储格式小结" tabindex="-1"><a class="header-anchor" href="#_8-2-1-4-cusparse存储格式小结" aria-hidden="true">#</a> 8.2.1.4 cuSPARSE存储格式小结</h4><ul><li>在cuSPARSE中支持本节描述的所有存储格式，并且每种存储格式因所处理数据集的<br> 特点而表现出不同的优缺点。cuSPARSE用户指南的第三部分中有cuSPARSE数据格式的完<br> 整说明。表8-3列出了cuSPARSE当前支持的数据格式及各自的最佳使用情况。<br><img src="`+g+'" alt="table8-3" loading="lazy"></li></ul><h3 id="_8-2-2-用cusparse进行格式转换" tabindex="-1"><a class="header-anchor" href="#_8-2-2-用cusparse进行格式转换" aria-hidden="true">#</a> 8.2.2 用cuSPARSE进行格式转换</h3><ul><li><p>在函数库的工作流中有两个阶段，先将应用程序的原始数据格式转换成函数库支持的<br> 数据格式，然后再进行这个过程的逆过程。当用cuSPARSE支持的格式转换应用程序的原<br> 始数据格式的开销很高时，这两个步骤与之相关。例如，许多传统的应用程序可能只使用<br> 稠密矩阵存储格式，然而，在cuSPARSE中执行矩阵与向量或矩阵与矩阵之间的操作时就<br> 要求用CSR，BSR，BSRX或HYB等存储格式。</p></li><li><p>cuSPARSE数据格式转换所带来的开销，包括计算开销和存储空间的开销。因此，为<br> 了发挥cuSPARSE在稀疏矩阵存储上的优势，你应尽量避免进行这种数据格式转换。</p></li><li><p>cuSPARSE里有很多用于格式转换的函数，表8-4列出了其中几个。最上面一行是输入<br> 数据（源数据）格式，最左边那一列是输出数据（目标数据）格式。空的单元格表明不支<br> 持两种数据格式的转换，你可以通过多次转换来实现未显示支持的转换。例如，dense2bsr<br> 的转换没有被支持，但我们可以用dense2csr和csr2bsr来进行间接转换。<br><img src="'+C+`" alt="table8-4" loading="lazy"></p></li></ul><h3 id="_8-2-3-cusparse功能示例" tabindex="-1"><a class="header-anchor" href="#_8-2-3-cusparse功能示例" aria-hidden="true">#</a> 8.2.3 cuSPARSE功能示例</h3><ul><li>本节代码涉及矩阵向量乘法、格式转换等cuSPARSE特性。你可以在Wrox.com中下载<br> cusparse.cu的示例代码，代码核心如下所示：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token comment">// Create the cuSPARSE handle</span>
 <span class="token function">cusparseCreate</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>handle<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// Allocate device memory for vectors and the dense form of the matrix A</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
 <span class="token comment">// Construct a descriptor of the matrix A</span>
 <span class="token function">cusparseCreateMatDescr</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>descr<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token function">cusparseSetMatType</span><span class="token punctuation">(</span>descr<span class="token punctuation">,</span> CUSPARSE_MATRIX_TYPE_GENERAL<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token function">cusparseSetMatIndexBase</span><span class="token punctuation">(</span>descr<span class="token punctuation">,</span> CUSPARSE_INDEX_BASE_ZERO<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// Transfer the input vectors and dense matrix A to the device</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
 <span class="token comment">// Compute the number of non-zero elements in A</span>
 <span class="token function">cusparseSnnz</span><span class="token punctuation">(</span>handle<span class="token punctuation">,</span> CUSPARSE_DIRECTION_ROW<span class="token punctuation">,</span> M<span class="token punctuation">,</span> N<span class="token punctuation">,</span> descr<span class="token punctuation">,</span> dA<span class="token punctuation">,</span>
 M<span class="token punctuation">,</span> dNnzPerRow<span class="token punctuation">,</span> <span class="token operator">&amp;</span>totalNnz<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// Allocate device memory to store the sparse CSR representation of A</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
 <span class="token comment">// Convert A from a dense formatting to a CSR formatting, using the GPU</span>
 <span class="token function">cusparseSdense2csr</span><span class="token punctuation">(</span>handle<span class="token punctuation">,</span> M<span class="token punctuation">,</span> N<span class="token punctuation">,</span> descr<span class="token punctuation">,</span> dA<span class="token punctuation">,</span> M<span class="token punctuation">,</span> dNnzPerRow<span class="token punctuation">,</span>
 dCsrValA<span class="token punctuation">,</span> dCsrRowPtrA<span class="token punctuation">,</span> dCsrColIndA<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// Perform matrix-vector multiplication with the CSR-formatted matrix A</span>
 <span class="token function">cusparseScsrmv</span><span class="token punctuation">(</span>handle<span class="token punctuation">,</span> CUSPARSE_OPERATION_NON_TRANSPOSE<span class="token punctuation">,</span>
 M<span class="token punctuation">,</span> N<span class="token punctuation">,</span> totalNnz<span class="token punctuation">,</span> <span class="token operator">&amp;</span>alpha<span class="token punctuation">,</span> descr<span class="token punctuation">,</span> dCsrValA<span class="token punctuation">,</span> dCsrRowPtrA<span class="token punctuation">,</span>
 dCsrColIndA<span class="token punctuation">,</span> dX<span class="token punctuation">,</span> <span class="token operator">&amp;</span>beta<span class="token punctuation">,</span> dY<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// Copy the result vector back to the host</span>
 <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>Y<span class="token punctuation">,</span> dY<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span> <span class="token operator">*</span> M<span class="token punctuation">,</span> cudaMemcpyDeviceToHost<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>cusparse.cu只是一个传统应用程序的小例子，它使用的是稠密矩阵数据格式，使用<br> cuSPARSE和CSR稀疏矩阵格式可以进行移植。它的工作流与前文所述的通用工作流非常<br> 类似：<br> 1.使用cusparseCreate创建一个cuSPARSE库句柄。<br> 2.使用cudaMalloc可以分配设备内存，它用于存储稠密和CSR格式的输入矩阵和向<br> 量。<br> 3.用cusparseCreateMatDescr和cusparseSetMat*来配置矩阵的某一属性，然后用<br> cudaMemcpy将所有输入数据传到预先分配好的设备内存中。格式转换子程式cusparse-<br> Sdense2csr用于生成CSR格式的稠密输入数据，并由cusparseSnnz统计稠密矩阵中各列和各<br> 行非零元素的数目。<br> 4.在CSR稀疏矩阵和输入向量上调用cusparseScsrmv来执行矩阵向量乘法。<br> 5.cudaMemcpy用于从设备内存的向量y上取回最终的计算结果，由于计算结果是以稠<br> 密向量格式存储和处理的，因此不需要进行格式转换。<br> 6.使用cudaFree，cusparseDestroyMatDescr和cusparseDestroy释放CUDA和cuSPARSE资<br> 源。</p></li><li><p>本例使用了以下命令：<code>$ nvcc -lcusparse cusparse.cu –o cusparse</code></p></li></ul><h3 id="_8-2-4-cusparse发展中的重要主题" tabindex="-1"><a class="header-anchor" href="#_8-2-4-cusparse发展中的重要主题" aria-hidden="true">#</a> 8.2.4 cuSPARSE发展中的重要主题</h3><ul><li><p>尽管可以说cuSPARSE是CUDA库中以最快和最简单的方式执行高性能线性代数的函<br> 数库，但如果你要探索cuSPARSE更多的高级功能，那么你需要谨记cuSPARSE使用的一些<br> 关键点。</p></li><li><p>你可能会遇到的第一个挑战就是需要保证正确的矩阵和向量数据格式。cuSPARSE本<br> 身是不能检测到错误或不恰当的数据输入格式的（例如，将一个CSR格式的矩阵传递给一<br> 个只接受COO格式输入的函数）。如果出错，最好的诊断信息可能来自于cuSPARSE内的<br> 段错误，或应用程序上的验证错误。</p></li><li><p>对于cuSPARSE的数据格式转换函数来说，在矩阵和向量数据规模较小时，手动验证<br> 其数据格式是可行的。通过格式转换的逆过程得到原数据格式的数据，可以使自动验证数<br> 据集成为可能，并比较两次转换后的数据与原数据是否相同。</p></li><li><p>为了对计算函数验证输入数据格式，建议你与具有相同功能的主机端实现进行对比。</p></li><li><p>另一个挑战是cuSPARSE默认的异步行为。对于许多CUDA函数来说这并没有什么特<br> 别的，但对于传统的有返回值的主机端阻塞式数学库来说，计算结果会出乎预料。如果你<br> 使用cudaMemcpy将cuSPARSE的结果从设备传到主机，那么应用程序将会自动阻塞，等待<br> 来自设备的结果（类似cusparse.cu中的情况）。然而，如果配置要求cuSPARSE使用CUDA<br> 流和cudaMemcpyAsync，那么在访问cuSPARSE调用结果之前必须确保任务同步性的正确。</p></li><li><p>最后一点比较新奇的是标量参数的转换，它总是以引用的方式传递的。如下所示，在<br> cusparse.cu内，传递的是浮点数值beta的地址而不是数值：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">float</span> beta <span class="token operator">=</span> <span class="token number">4.0f</span><span class="token punctuation">;</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token comment">// Perform matrix-vector multiplication with the CSR-formatted matrix A</span>
<span class="token function">cusparseScsrmv</span><span class="token punctuation">(</span>handle<span class="token punctuation">,</span> CUSPARSE_OPERATION_NON_TRANSPOSE<span class="token punctuation">,</span>
 M<span class="token punctuation">,</span> N<span class="token punctuation">,</span> totalNnz<span class="token punctuation">,</span> <span class="token operator">&amp;</span>alpha<span class="token punctuation">,</span> descr<span class="token punctuation">,</span> dCsrValA<span class="token punctuation">,</span> dCsrRowPtrA<span class="token punctuation">,</span>
 dCsrColIndA<span class="token punctuation">,</span> dX<span class="token punctuation">,</span> <span class="token operator">&amp;</span>beta<span class="token punctuation">,</span> dY<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>如果你不小心传递了beta而不是&amp;beta，那么你的应用程序会在主机端产生来自于cuSPARSE库的报错（SEGFAULT），不注意的话会很难调试。</p></li><li><p>此外，标量输出参数可以作为主机或设备指针进行传递。对于返回的标量结果，用<br> cu-sparseSetPointerMode函数来决定是否使用指针来获取计算结果。</p></li></ul><h3 id="_8-2-5-cusparse小结" tabindex="-1"><a class="header-anchor" href="#_8-2-5-cusparse小结" aria-hidden="true">#</a> 8.2.5 cuSPARSE小结</h3><ul><li>本节简要介绍了cuSPARSE库的使用，它在稀疏线性代数操作中充分利用了GPU计算<br> 吞吐量的优势。你已经学习了cuSPARSE支持的数据格式、cuSPARSE支持的一些操作以及<br> 原始的数据格式与cuSPARSE支持的数据格式之间的转换方法。在下一节中，你将学习一<br> 个类似于CUDA的库函数：cuBLAS。</li></ul><h2 id="_8-3-cublas库" tabindex="-1"><a class="header-anchor" href="#_8-3-cublas库" aria-hidden="true">#</a> 8.3 cuBLAS库</h2><ul><li><p>cuBLAS是一个线性代数子程式。与cuSPARSE不同的是，cuBLAS是一个传统线性代<br> 数库的接口，即基本线性代数子程序库（BLAS）。</p></li><li><p>与BLAS类似，基于cuBLAS子程序操作的数据类型，对这些子程序进行了分类。第一<br> 类包含仅有向量参与的操作，如向量加法。第二类包含矩阵与向量之间的操作，如矩阵-<br> 向量乘法。第三类包含矩阵与矩阵之间的操作，如矩阵乘法。与cuSPARSE不同，cuBLAS<br> 不支持多种稀疏数据格式，它仅支持并善于优化稠密向量和稠密矩阵的操作。</p></li><li><p>由于最初的BLAS库是用FORTRAN语言编写的，因此它使用的是以列优先的数组存储<br> 和以1为基准的索引。列优先是指多维矩阵在一维地址空间中的存储方式。8.2.1节是对稠<br> 密矩阵进行以行优先的压缩。在列优先的压缩格式中，在处理下一列之前会先遍历该列中<br> 的所有元素并将其存储在连续的地址空间中。因此，同一列的元素在内存中的位置是相邻<br> 的，而同一行中的元素是不相邻的。这与行优先的cuBLAS的C/C++语义有很大差别，也<br> 就是说同一行中元素的存储位置是彼此相邻的。图8-2所示的是将一个二维矩阵压缩成一<br> 个行优先的一维数组的结果。图8-8是同样的过程，但是按列优先的顺序排列的。<br><img src="`+y+`" alt="figure8-8" loading="lazy"></p></li><li><p>换句话说，给定一个要被压缩成一维数组的二维矩阵的M行N列，可以使用以下公式<br> 计算元素的目的位置（m，n）：<br> 行优先：f（m，n）＝m×N＋n<br> 列优先：f（m，n）＝n×M＋m</p></li><li><p>出于兼容性的考虑，cuBLAS库也选择使用列优先的存储方式。所以对于习惯了<br> C/C++中行优先的数组布局的程序员来说，这是一个令人苦恼的问题。</p></li><li><p>另一方面，以1为基准的索引意味着数组中第一个元素的引用是1而不是0，这在C语<br> 言和其他程序中常遇到。也就是说，一个N元数组中最后一个元素的引用是N而不是<br> N―1。</p></li><li><p>然而，cuBLAS库不能决定C/C++编程语言的构建，所以它必须使用从零开始的索<br> 引。这时FORTRAN BLAS库适用的列优先的规则就会出现一种混乱的情况，而以1为基准<br> 的索引规则就不会。</p></li><li><p>cuBLAS库有两个API。cuBLAS Legascy API是cuBLAS最原始的一个实现，现在已经不<br> 用了。现在的cuBLAS API（CUDA 4.0以后可用）用于所有应用程序的开发工作。在大多<br> 数情况下，它们之间的差别是很小的，但要注意的是，差别虽然小但仍然存在。本章中所<br> 有的示例代码都来自当前所用的cuBLAS API。</p></li><li><p>在本节中，你会发现cuBLAS的工作流与cuSPARSE的通用工作流有很多相似之处。需<br> 要管理句柄、流和标量参数，在完成本节示例的学习后，你应该对通用工作流很熟悉了。</p></li></ul><h3 id="_8-3-1-管理cublas数据" tabindex="-1"><a class="header-anchor" href="#_8-3-1-管理cublas数据" aria-hidden="true">#</a> 8.3.1 管理cuBLAS数据</h3><ul><li><p>与cuSPARSE相比，cuBLAS中的数据格式和类型的注意事项相对少很多。所有操作都<br> 是在稠密cuBLAS向量或矩阵上完成的。使用cudaMalloc分配连续的设备内存给这些向量<br> 和矩阵，但是使用自定义的cuBLAS函数，如cublasSetVector/cublasGetVector和cublasSetMatrix/cublasGetMatrix，<br> 在主机和设备之间传输数据。尽管你可以将这些特殊函数看作<br> 是cudaMemcpy周围的封装器，但它们可以更好地传输连续和不连续的数据。以下是对<br> cublasSetMatrix函数的一次调用：<br><code>cublasStatus_t cublasSetMatrix(int rows, int cols, int elementSize, const void *A, int lda, void *B, int ldb);</code></p></li><li><p>前四个参数不需要特别说明：它们定义了要传输矩阵的维度，矩阵中每个元素的大<br> 小，以及主机内存中列优先的源矩阵A的内存位置。第六个参数B定义了设备内存中目标<br> 矩阵的位置。第五个和第七个参数的用途不太清楚。lda和ldb指定源矩阵A和目标矩阵B的<br> 主维度。所谓主维度就是矩阵各自的总行数。如果主机内存中只有一个矩阵的子矩阵被传<br> 送到GPU中的话，这个方法就很有用。也就是说，如果传输的是存储在A和B中的整个矩<br> 阵，那么lda和ldb应该相等，且等于M。如果传输的是子矩阵，lda和ldb的值应该是全矩阵<br> 的行长度。lda和ldb应该总是大于或等于行数。</p></li><li><p>如果给定一个主机端列优先的稠密二维矩阵A，其元素是单精度浮点类型，矩阵大小<br> 为M×N，则使用cublasSetMatrix来传输矩阵：<br><code>cublasSetMatrix(M, N, sizeof(float), A, M, dA, M);</code></p></li><li><p>你还可以使用cublasSetVector来将矩阵A中的单个列传给设备端的向量dV：<br><code>cublasStatus_t cublasSetVector(int n, int elemSize, const void *x, int incx, void *y, int incy)</code></p></li><li><p>x是主机端的源位置，y是设备端的目标位置，n是要传输的元素数量，elemSize是以字<br> 节为单位的每个元素的大小，incx/incy是传输元素之间的地址间隔。使用下列命令将长度<br> 为M行优先的矩阵A的某一列传给向量dV：<code>cublasSetVector(M, sizeof(float), A, 1, dV, 1);</code></p></li><li><p>你也可以使用cublasSetVector将矩阵A中的某一行传给设备上的向量dV：<code>cublasSetVector(N, sizeof(float), A, M, dV, 1);</code></p></li><li><p>这个函数可以跳过M个元素将A中的N个元素复制给向量dV。由于矩阵A是一个列优<br> 先的矩阵，这个命令可以将矩阵A的第一行复制到设备端，下面是第i行的实况：<br><code>cublasSetVector(N, sizeof(float), A + i, M, dV, 1);</code></p></li><li><p>这是一个比cuSPARSE展示的简单得多的数据模型。除非应用程序对稀疏的数据结构<br> 需求较大，否则利用cuBLAS在提升性能的同时，也能提高开发效率</p></li></ul><h3 id="_8-3-2-cublas功能示例" tabindex="-1"><a class="header-anchor" href="#_8-3-2-cublas功能示例" aria-hidden="true">#</a> 8.3.2 cuBLAS功能示例</h3><ul><li>这里演示的cuBLAS示例重点在于说明cuBLAS的统一性和易用性。GPU比优化的主机<br> 端BLAS库的计算速度要快15倍以上，用cuBLAS进行开发的工作量仅略微大于传统的<br> BLAS的实现。</li></ul><h4 id="_8-3-2-1-一个简单的cublas示例" tabindex="-1"><a class="header-anchor" href="#_8-3-2-1-一个简单的cublas示例" aria-hidden="true">#</a> 8.3.2.1 一个简单的cuBLAS示例</h4><ul><li>这个例子是要在GPU上执行矩阵向量乘法的运算，一个cuBLAS二级操作。你可以从<br> Wrox.com中下载cublas.cu示例代码或使用下面的代码片段：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token comment">// Create the cuBLAS handle</span>
 <span class="token function">cublasCreate</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>handle<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// Allocate device memory</span>
 <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>dA<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span> <span class="token operator">*</span> M <span class="token operator">*</span> N<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>dX<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span> <span class="token operator">*</span> N<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>dY<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span> <span class="token operator">*</span> M<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// Transfer inputs to the device</span>
 <span class="token function">cublasSetVector</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">,</span> X<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> dX<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token function">cublasSetVector</span><span class="token punctuation">(</span>M<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Y<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> dY<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token function">cublasSetMatrix</span><span class="token punctuation">(</span>M<span class="token punctuation">,</span> N<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">,</span> A<span class="token punctuation">,</span> M<span class="token punctuation">,</span> dA<span class="token punctuation">,</span> M<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// Execute the matrix-vector multiplication</span>
 <span class="token function">cublasSgemv</span><span class="token punctuation">(</span>handle<span class="token punctuation">,</span> CUBLAS_OP_N<span class="token punctuation">,</span> M<span class="token punctuation">,</span> N<span class="token punctuation">,</span> <span class="token operator">&amp;</span>alpha<span class="token punctuation">,</span> dA<span class="token punctuation">,</span> M<span class="token punctuation">,</span> dX<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span>
 <span class="token operator">&amp;</span>beta<span class="token punctuation">,</span> dY<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// Retrieve the output vector from the device</span>
 <span class="token function">cublasGetVector</span><span class="token punctuation">(</span>M<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dY<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Y<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>使用cuBLAS库比较简单。cublas.cu示例演示了一个与前面cuSPARSE示例相比简单得<br> 多的通用库工作流的子流程。它包含以下步骤：<br> 1.用cublasCreateHandle创建一个cuBLAS句柄。<br> 2.使用cudaMalloc可以分配用于输入输出的设备内存。<br> 3.使用cublasSetVector和cublasSetMatrix向分配好的设备内存填充输入数据。<br> 4.调用cublasSgemv库来让GPU执行矩阵向量乘法操作。<br> 5.使用cublasGetVector从设备内存中取回结果。<br> 6.使用cudaFree和cublasDestroy来释放CUDA和cuBLAS资源。</p></li><li><p>这个示例使用以下命令进行创建：<code> nvcc -lcublas cublas.cu</code></p></li><li><p>使用cuBLAS库比使用cuSPARSE库要容易得多，这主要是因为cuBLAS与传统的BLAS<br> 库高度兼容。</p></li></ul><h4 id="_8-3-2-2-blas库的程序移植" tabindex="-1"><a class="header-anchor" href="#_8-3-2-2-blas库的程序移植" aria-hidden="true">#</a> 8.3.2.2 BLAS库的程序移植</h4><ul><li><p>将BLAS库中C语言实现的传统应用程序移植到cuBLAS也是很简单的。移植过程主要<br> 包括4个步骤：</p></li><li><p>1.为任何输入输出向量或矩阵的应用程序添加设备内存分配调用（cudaMalloc）和设<br> 备内存释放调用（cudaFree）。</p></li><li><p>2.在主机和设备之间添加传输输入输出向量或矩阵状态的方法（如cublasSetVector，<br> cublasSetMatrix，cublasGetVector，cublasGetMatrix）。</p></li><li><p>3.将实际对BLAS库的调用转换为调用相应的cuBLAS库。这可能需要对传入的参数进<br> 行细微的改变。前面的示例用的是以下cuBLAS函数：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>cublasStatus_t <span class="token function">cublasSgemv</span><span class="token punctuation">(</span>cublasHandle_t handle<span class="token punctuation">,</span> cublasOperation_t trans<span class="token punctuation">,</span> 
 <span class="token keyword">int</span> m<span class="token punctuation">,</span> <span class="token keyword">int</span> n<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">float</span> <span class="token operator">*</span>alpha<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">float</span> <span class="token operator">*</span>A<span class="token punctuation">,</span> <span class="token keyword">int</span> lda<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">float</span> <span class="token operator">*</span>x<span class="token punctuation">,</span> <span class="token keyword">int</span>
 incx<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">float</span> <span class="token operator">*</span>beta<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>y<span class="token punctuation">,</span> <span class="token keyword">int</span> incy<span class="token punctuation">)</span><span class="token punctuation">;</span>
等价的BLAS命令是：
<span class="token keyword">void</span> <span class="token function">cblas_sgemv</span><span class="token punctuation">(</span><span class="token keyword">const</span> CBLAS_ORDER order<span class="token punctuation">,</span> <span class="token keyword">const</span> CBLAS_TRANSPOSE TransA<span class="token punctuation">,</span>
 <span class="token keyword">const</span> MKL_INT M<span class="token punctuation">,</span> <span class="token keyword">const</span> MKL_INT N<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">float</span> alpha<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">float</span> <span class="token operator">*</span>A<span class="token punctuation">,</span>
 <span class="token keyword">const</span> MKL_INT lda<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">float</span> <span class="token operator">*</span>X<span class="token punctuation">,</span> <span class="token keyword">const</span> MKL_INT incX<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">float</span> beta<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>Y<span class="token punctuation">,</span> 
 <span class="token keyword">const</span> MKL_INT incY<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>两个命令有许多参数是相同或相似的（trans、M、N、alpha、A、lda、X、incx、<br> beta、Y、incy），BLAS包含的是有序参数（使输入可以是行优先也可以使列优先），同<br> 时，cuBLAS添加了cuBLAS句柄。还要注意，BLAS中的alpha和beta参数并不像cuBLAS中<br> 那样以引用的形式进行传递。这些都是细微的差别，这并不是移植BLAS应用程序到<br> cuBLAS中的主要障碍。</p></li><li><p>4.最后，你也可以在程序移植成功后优化新的cuBLAS程序，这个步骤可能包括：<br> a.对于每次的cuBLAS调用，复用内存分配空间，而不是重复进行内存分配和释放。<br> b.对于向量和矩阵，除去设备到主机之间拷贝的冗余数据，这些冗余数据就是下一次<br> cuBLAS调用时复用的输入数据。<br> c.使用cublasSetStream添加基于流的执行，以实现异步传输。想了解更多关于流是怎<br> 样辅助提高性能的，参见第6章。</p></li></ul><h3 id="_8-3-3-cublas发展中的重要主题" tabindex="-1"><a class="header-anchor" href="#_8-3-3-cublas发展中的重要主题" aria-hidden="true">#</a> 8.3.3 cuBLAS发展中的重要主题</h3><ul><li><p>与cuSPARSE相比，如果你用过传统的BLAS库，那么cuBLAS对你来说就非常熟悉<br> 了。因此，对程序执行过程的理解对你来说也就容易很多了。这种简单也就意味着，与<br> cuSPARSE相比，可能出现的潜在问题通常更容易分开来解决。</p></li><li><p>如果你常用的是行优先的编程语言，用cuBLAS进行开发则可能需要多关注细节。使<br> 用最熟悉的编程模式会比较容易，例如，使用行优先的索引来压缩一个数组。为了方便起<br> 见，你可以定义宏去自动实现以0为基准的行优先索引到列优先索引的转换：<br><code>#define R2C(r, c, nrows) ((c) * (nrows) + (r))</code></p></li><li><p>但是，即使使用这样的宏，你也需要更多考虑循环次序问题。许多C/C++程序员倾向<br> 于使用以下命令：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> r <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> r <span class="token operator">&lt;</span> nrows<span class="token punctuation">;</span> r<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> c <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> c <span class="token operator">&lt;</span> ncols<span class="token punctuation">;</span> c<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 A<span class="token punctuation">[</span><span class="token function">R2C</span><span class="token punctuation">(</span>r<span class="token punctuation">,</span> c<span class="token punctuation">,</span> nrows<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
 <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>虽然这段代码是正确的，但不是最优的，因为它没有线性扫描数组A中的内存位置。<br> 例如，如果数组A从内存为0的位置开始，这个循环完成的前三个引用将位于0，nrows，<br> 和2×nrows这3个位置上。鉴于nrows可能非常大，所以以很大间隔分隔开的内存访问可能<br> 会导致很差的缓存局部性。因此，当使用列优先的数组时，必须将循环倒置：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> c <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> c <span class="token operator">&lt;</span> ncols<span class="token punctuation">;</span> c<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> r <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> r <span class="token operator">&lt;</span> nrows<span class="token punctuation">;</span> r<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 A<span class="token punctuation">[</span><span class="token function">R2C</span><span class="token punctuation">(</span>r<span class="token punctuation">,</span> c<span class="token punctuation">,</span> nrows<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
 <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>这样做时要小心，因为可能会无意中导致分配空间的右侧有较差的缓存局部性。<br> cuBLAS最吸引人的地方是从传统的BLAS库转变后的易用性。在这种情况下，唯一的<br> 主要变化是设备内存管理和CUDA调用转移的增加。</li></ul><h3 id="_8-3-4-cublas小结" tabindex="-1"><a class="header-anchor" href="#_8-3-4-cublas小结" aria-hidden="true">#</a> 8.3.4 cuBLAS小结</h3><ul><li>本节介绍了简单易用的cuBLAS库，重点介绍了传统的BLAS库。下一节重点介绍目前<br> 在科学计算和信号处理中最实用的算法：快速傅里叶变换。</li></ul><h2 id="_8-4-cufft库" tabindex="-1"><a class="header-anchor" href="#_8-4-cufft库" aria-hidden="true">#</a> 8.4 cuFFT库</h2><ul><li>cuFFT库提供了一个优化的且基于CUDA实现的快速傅里叶变换（FFT）。FFT在信号<br> 处理中可以将信号从时域转换到频域，逆FFT过程则相反。换句话说，一个FFT以规则的<br> 时间间隔接收信号中的序列样本并作为输入。然后使用这些样本生成一组叠加的分量频<br> 率，按频率抽取作为输入样本的信号。如图8-9所示，两个信号叠加形成信号cos（x）＋<br> cos（2x），并通过FFT将两个信号的分量转为频率1.0和2.0。FFT其他的详细内容超出了<br> 本书范围。<br><img src="`+S+`" alt="figure8-9" loading="lazy"></li></ul><h3 id="_8-4-1-使用cufft-api" tabindex="-1"><a class="header-anchor" href="#_8-4-1-使用cufft-api" aria-hidden="true">#</a> 8.4.1 使用cuFFT API</h3><ul><li><p>cuFFT通常指两个独立的库：核心高性能的cuFFT库和可移植的cuFFTW库。cuFFT库<br> 是在CUDA中能提供自身API的FFT实现。另一方面，cuFFTW与标准的FFTW（快速傅里<br> 叶变换的标准C语言程序集）主机端FFT库有相同的API。和cuBLAS与传统的BLAS库共享<br> 大部分API的情况类似，cuFFTW则是用来最大限度地提高使用FFTW现有代码的可移植<br> 性。FFTW库的很多函数在cuFFTW中同样适用。此外，cuFFTW库假设所有要传输的输入<br> 数据都存储在主机内存中，并为用户处理所有的内存分配（cudaMalloc）和内存拷贝<br> （cudaMemcpy）。虽然这可能对性能有所影响，但它大大加快了程序移植的过程。至于<br> cuFFTW和cuFFT支持的操作，请参阅cuFFT用户指南。</p></li><li><p>cuFFT库的配置是用FFT plan完成的，即cuFFT是用来指代它的操作术语。一个plan定<br> 义了一个要进行的单一变换操作。cuFFT使用plan来获取内存分配、内存转移，以及内核<br> 启动来执行变换请求。不同的plan创建函数可以用来生成增大复杂性和维数的plan：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>cufftResult <span class="token function">cufftPlan1d</span><span class="token punctuation">(</span>cufftHandle <span class="token operator">*</span>plan<span class="token punctuation">,</span> <span class="token keyword">int</span> nx<span class="token punctuation">,</span> cufftType type<span class="token punctuation">,</span> <span class="token keyword">int</span> batch<span class="token punctuation">)</span><span class="token punctuation">;</span>
cufftResult <span class="token function">cufftPlan2d</span><span class="token punctuation">(</span>cufftHandle <span class="token operator">*</span>plan<span class="token punctuation">,</span> <span class="token keyword">int</span> nx<span class="token punctuation">,</span> <span class="token keyword">int</span> ny<span class="token punctuation">,</span> cufftType type<span class="token punctuation">)</span><span class="token punctuation">;</span>
cufftResult <span class="token function">cufftPlan3d</span><span class="token punctuation">(</span>cufftHandle <span class="token operator">*</span>plan<span class="token punctuation">,</span> <span class="token keyword">int</span> nx<span class="token punctuation">,</span> <span class="token keyword">int</span> ny<span class="token punctuation">,</span> <span class="token keyword">int</span> nz<span class="token punctuation">,</span> cufftType type<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>cuFFT还支持多种输入和输出数据类型，包括以下几种：<br> ·复数到复数<br> ·实数到复数<br> ·复数到实数</p></li><li><p>对于许多实际的应用程序，最实用的是实数到复数这种类型，它允许你从实际系统输<br> 入实际的测量结果到cuFFT中。</p></li><li><p>一旦配置好一个cuFFT plan，使用cufftExec*函数来对它进行调用执行（例如，cufft-<br> ExecC2C）。一般来说，无论该变换是一种正向FFT（时域到频域）还是逆向FFT（频域<br> 到时域），函数调用都可以将plan、输入数据的存储位置、输出数据的存放位置作为输<br> 入。</p></li></ul><h3 id="_8-4-2-cufft功能示例" tabindex="-1"><a class="header-anchor" href="#_8-4-2-cufft功能示例" aria-hidden="true">#</a> 8.4.2 cuFFT功能示例</h3><ul><li>本节介绍一个使用cuFFT API执行一维FFT变换的简单例子，其中，输入输出都是复<br> 数类型。你可以在Wrox.com中下载cufft.cu示例代码，也可以直接学习以下代码段。</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token comment">// Setup the cuFFT plan</span>
 <span class="token function">cufftPlan1d</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>plan<span class="token punctuation">,</span> N<span class="token punctuation">,</span> CUFFT_C2C<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// Allocate device memory</span>
 <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>dComplexSamples<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span>cufftComplex<span class="token punctuation">)</span> <span class="token operator">*</span> N<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// Transfer inputs into device memory</span>
 <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>dComplexSamples<span class="token punctuation">,</span> complexSamples<span class="token punctuation">,</span>
 <span class="token keyword">sizeof</span><span class="token punctuation">(</span>cufftComplex<span class="token punctuation">)</span> <span class="token operator">*</span> N<span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// Execute a complex-to-complex 1D FFT</span>
 <span class="token function">cufftExecC2C</span><span class="token punctuation">(</span>plan<span class="token punctuation">,</span> dComplexSamples<span class="token punctuation">,</span> dComplexSamples<span class="token punctuation">,</span>
 CUFFT_FORWARD<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// Retrieve the results into host memory</span>
 <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>complexFreq<span class="token punctuation">,</span> dComplexSamples<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span>cufftComplex<span class="token punctuation">)</span> <span class="token operator">*</span> N<span class="token punctuation">,</span>
 cudaMemcpyDeviceToHost<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>一个cuFFT应用程序的工作流的不同取决于变换的复杂性。一个cuFFT应用程序的工<br> 作流一般应包括：<br> 1.创建并配置一个cuFFT plan。<br> 2.用cudamalloc函数分配设备内存来存储输入样本和输出频率。注意，所分配的内存<br> 必须支持对应执行的变换类型（例如，复数到复数、实数到复数、复数到实数）。你可以<br> 使用相同的设备内存对输入和输出直接进行变换。<br> 3.用cudaMemcpy把输入信号样本传给设备内存。<br> 4.使用cufftExec*函数执行plan。<br> 5.用cudaMemcpy取回设备内存中的结果。<br> 6.用cudaFree和cufftDestroy释放CUDA和cuFFT资源。</p></li><li><p>使用下面的命令构建示例：<code>$ nvcc -lcufft cufft.cu –o cufft</code></p></li><li><p>cufft.cu提供的示例从函数cos（x）中生成一个输入样本序列，将其转换为复数后传给<br> GPU，在将结果拷贝回主机端之前执行复数到复数的一维plan。值得注意的是，对于输入<br> 和输出参数，因为可以将相同的内存位置dComplexSamples传给cufftExecC2C，所以这是一<br> 个就地FFT运算。可以预先分配一个独立的输出缓冲区，并用来存储输出结果。</p></li></ul><h3 id="_8-4-3-cufft小结" tabindex="-1"><a class="header-anchor" href="#_8-4-3-cufft小结" aria-hidden="true">#</a> 8.4.3 cuFFT小结</h3><ul><li>本节简要介绍了cuFFT库对使用FFT的应用程序加速的能力。在下一节中，你将了解<br> 用于生成随机数的CUDA库，该函数库有两个API：一个用于在主机中创建随机数，另一<br> 个用于在设备端直接创建随机数。</li></ul><h2 id="_8-5-curand库" tabindex="-1"><a class="header-anchor" href="#_8-5-curand库" aria-hidden="true">#</a> 8.5 cuRAND库</h2><ul><li><p>随机数的生成在应用科学、密码学和金融应用领域中都有很广泛的用途。一个随机数<br> 生成器（RNG）是一个没有任何参数的函数f，但是在每次调用时都能返回随机值序列的<br> 下一个值。你可以把它看作一个指针，该指针可以遍历随机数构成的数组，如图8-10所示。<br><img src="`+w+`" alt="figure8-10" loading="lazy"></p></li><li><p>cuRAND库用在基于CUDA库的拟随机数和伪随机数的生成。下一节讲述了随机数生<br> 成的一些背景、cuRAND的配置以及使用cuRAND的两个例子。</p></li></ul><h3 id="_8-5-1-拟随机数或伪随机数的选择" tabindex="-1"><a class="header-anchor" href="#_8-5-1-拟随机数或伪随机数的选择" aria-hidden="true">#</a> 8.5.1 拟随机数或伪随机数的选择</h3><ul><li><p>对于以计算机为基础的随机数生成的学习，需要明白的是没有真正的随机数生成。因<br> 为计算机是一个有序系统（以保证函数正常运行），所以从根本上来说就没有能描绘随机<br> 序列的概念，也就不能生成真正的随机数。某些硬件解决方案可以生成被认为是真正的随<br> 机数，但是许多库用来生成随机数的RNG算法也都有很好的算法结构和定义，它能让用<br> 户有了生成真正随机数的错觉。然而，不能说这是一个不好的特性，虽然它在某些情况下<br> 还是有用的。</p></li><li><p>例如，RNG是从一个种子数据开始生成随机数的，这个种子是生成随机数序列的初<br> 始值。你可以把它当作是图8-10所示的最开始的第一个值，其他所有值都是在它的基础上<br> 生成的。你可以每次都给一个定义好的RNG算法提供相同的初始值，而每次都会得到相<br> 同的随机数序列，这对于测试应用程序很有用，可以重复使用相同的随机序列。</p></li><li><p>RNG可以分为两大类：伪随机数生成器和拟随机数生成器。两者各有各的用途并且<br> 都被cuRAND所支持。</p></li><li><p>一个伪随机数生成器（PRNG）使用RNG算法生成随机数序列。在这个序列中，每个<br> 值都是有效范围内的任意值，并且都是RNG所用的数据存储类型。例如，当从一个整数<br> 类型的PRNG中取回一个值时，返回值为1的概率P（1）和返回值是2的概率P（2）或是3<br> 的概率P（3）以及所有的P（INT_MAX）都相等。这对于PRNG中返回的每一个值都成<br> 立。这就意味着，不能仅仅因为上一个取回值是2就认为下一个取值是2的概率就会变小。<br> 换句话说，对一个伪随机数序列，每次采样都是独立统计事件，对以后抽样的样本观察值<br> 并不会有影响。</p></li><li><p>但是，这在拟随机数生成器（QRNG）中是不成立的。一个QRNG会尽量均匀地填充<br> 输出类型的范围。因此，如果QRNG采样的前一个值为2，那么下一个值是2的概率P（2）<br> 实际上会减小。一个QRNG的序列采样不是独立统计的。</p></li><li><p>PRNG和QRNG在不同的应用程序中发挥着不同的作用。当需要真正的随机时，PRNG<br> 是更好的选择。对于一个使用密码生成的应用程序，PRNG是一个比QRNG更好的选择，<br> 因为若使用PRNG的话，已经生成的密码信息对同一序列内其他密码的生成概率没有影<br> 响。</p></li><li><p>另一方面，QRNG在探索不为人知的空间时是很有用的。QRNG能保证多维空间有更<br> 均匀的采样，也有可能发现采用固定采样间隔所没有发现的一些性质。例如，采用蒙特卡<br> 罗方法的某些应用程序就得益于QRNG的使用。</p></li></ul><h3 id="_8-5-2-curand库概述" tabindex="-1"><a class="header-anchor" href="#_8-5-2-curand库概述" aria-hidden="true">#</a> 8.5.2 cuRAND库概述</h3><ul><li>cuRAND库可以用于伪随机序列和拟随机序列的采样。它既有一个主机端API又有一<br> 个设备端API，这在本书所讨论的CUDA库中是独有的。这意味着它可以直接被主机端调<br> 用，也可以直接被内核代码调用。cuRAND库的许多概念对于这两种API来说是共享的，<br> 但当使用设备端API时增加了一些选项。</li></ul><h4 id="_8-5-2-1-概念介绍" tabindex="-1"><a class="header-anchor" href="#_8-5-2-1-概念介绍" aria-hidden="true">#</a> 8.5.2.1 概念介绍</h4><ul><li><p>主机和设备cuRAND API的配置项有4个：用于生成随机序列的RNG算法，返回值遵循<br> 的一个分布，初始种子数值和随机数序列开始采样的一个偏移量。由于设备端API指定每<br> 个参数都要依照规范进行设置，如果用户没有给定初始值，那么主机端API会自动将其设<br> 置为默认值。</p></li><li><p>主机和设备端API也都有其他CUDA库里的句柄概念。在主机端API中，句柄即所谓的<br> 随机数生成器。你可以用curandCreateGenerator构造一个随机数生成器，随机数生成器是<br> 使用一系列通用方法来配置的，如curandSetStream或curandSetGeneratorOffset。只需有一个<br> 生成器来访问主机端API。而在设备端API中，句柄则是指cuRAND的状态。设备状态有很<br> 多种类型，每一种对应设备端API支持不同的RNG。然而，状态对象的作用仍然是维护<br> GPU上单线程cuRAND上下文的配置和状态。因此，通常需要分配很多的设备状态对象，<br> 每一个对应于不同的GPU线程。</p></li><li><p>在cuRAND主机和设备端API中第一个配置项是RNG算法。在主机端API中，使用如下<br> 配置：<code>curandStatus_t curandCreateGenerator(curandGenerator_t *generator, curandRngType_t rng_type);</code></p></li><li><p>在设备端API中，这是通过调用一个特定的RNG初始化函数来配置的，该函数包含<br> RNG特定的状态对象，该对象在设备端API中被当成一个cuRAND生成器：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__device__ <span class="token keyword">void</span> <span class="token function">curand_init</span><span class="token punctuation">(</span><span class="token keyword">unsigned</span> <span class="token keyword">long</span> <span class="token keyword">long</span> seed<span class="token punctuation">,</span> 
 <span class="token keyword">unsigned</span> <span class="token keyword">long</span> <span class="token keyword">long</span> subsequence<span class="token punctuation">,</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">long</span> <span class="token keyword">long</span> offset<span class="token punctuation">,</span>
 curandStateXORWOW_t <span class="token operator">*</span>state<span class="token punctuation">)</span><span class="token punctuation">;</span>
__device__ <span class="token keyword">void</span> <span class="token function">curand_init</span><span class="token punctuation">(</span><span class="token keyword">unsigned</span> <span class="token keyword">long</span> <span class="token keyword">long</span> seed<span class="token punctuation">,</span> 
 <span class="token keyword">unsigned</span> <span class="token keyword">long</span> <span class="token keyword">long</span> subsequence<span class="token punctuation">,</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">long</span> <span class="token keyword">long</span> offset<span class="token punctuation">,</span>
 curandStateMRG32k3a_t <span class="token operator">*</span>state<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>选择不同的RNG算法会影响随机数生成技术，并可能影响生成序列的随机性和算法<br> 性能，主机端和设备端都支持多种随机数生成算法。例如，可以用以下命令在设备端初始<br> 化RNG，使用的是XORWOW RNG算法：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">kernel</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 curandStateXORWOW_t rand_state<span class="token punctuation">;</span>
 <span class="token function">curand_init</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span>rand_state<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>然后，使用rand_state作为生成随机数的句柄。</p></li><li><p>接下来，不同分布方式的选择会影响到由RNG生成的随机数在一定取值范围内的分<br> 布（注意，即使是浮点类型的值也是在一个离散的有限范围内的）。一个RNG算法和所<br> 采用的分布方式之间的关系可能不太明显。RNG算法可以被看成是一个能产生二进制位<br> 的随机序列的黑盒。这些二进制位对RNG算法来说并没有实际意义。在RNG之上添加一<br> 个指向cuRAND的特定返回类型，然后用这些二进制位来生成一个能表示所选择分布的特<br> 征数值。主机和设备端API都支持正态分布、均匀分布、对数正态分布和泊松分布。</p></li><li><p>当通过调用特定的分布函数来生成随机数时，所需的分布也就确定了。在主机端API<br> 中若使用均匀分布需要使用curandGenerateUniform：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>curandGenerator_t rand_state<span class="token punctuation">;</span>
<span class="token keyword">int</span> d_rand_length <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span>
<span class="token keyword">float</span> <span class="token operator">*</span>d_rand<span class="token punctuation">;</span>
<span class="token function">curandCreateGenerator</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>rand_state<span class="token punctuation">,</span> CURAND_RNG_PSEUDO_DEFAULT<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>d_rand<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span> <span class="token operator">*</span> d_rand_length<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>在设备端，按照如下方式使用curand_uniform来代替：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">kernel</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 curandStateXORWOW_t rand_state<span class="token punctuation">;</span>
 <span class="token function">curand_init</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span>rand_state<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token keyword">float</span> f <span class="token operator">=</span> <span class="token function">curand_uniform</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>rand_state<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>cuRAND中第三个配置项是种子值。种子的概念出现在PRNG和QRNG中，但在两者中<br> 用法不同。为cuRAND PRNG选择作为种子的值是64位的，由人随机指定，为PRNG接下<br> 来生成随机序列打下基础。不同种子会产生不同的随机序列。主机端API允许使用<br> curandSetPseudoRandomGeneratorSeed为PRNG选取种子：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>curandGenerator_t rand_state<span class="token punctuation">;</span>
<span class="token function">curandCreateGenerator</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>rand_state<span class="token punctuation">,</span> CURAND_RNG_PSEUDO_DEFAULT<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">curandSetPseudoRandomGeneratorSeed</span><span class="token punctuation">(</span>rand_state<span class="token punctuation">,</span> <span class="token number">9872349ULL</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>如果没有特殊情况，那么会使用默认的种子值；另一方面，对于每个线程的PRNG，<br> 设备端API都要设置好确定的种子值。如下调用curand_init来选取种子，第一个参数为创建<br> RNG指定的起始种子：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__device__ <span class="token keyword">void</span> <span class="token function">curand_init</span><span class="token punctuation">(</span><span class="token keyword">unsigned</span> <span class="token keyword">long</span> <span class="token keyword">long</span> seed<span class="token punctuation">,</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">long</span> <span class="token keyword">long</span> subsequence<span class="token punctuation">,</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">long</span> <span class="token keyword">long</span> offset<span class="token punctuation">,</span>
 curandStateXORWOW_t <span class="token operator">*</span>state<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>唯一被主机和设备端API支持的QRNG是基于Sobol拟随机序列的（该讨论超出了本书<br> 范围）。一个Sobol序列以方向向量作为种子。回忆前文，一个拟随机数生成器的优点是<br> 每个采样都不是一个独立的统计事件，一个QRNG会特意在取值范围内均匀地取数。你可<br> 以把这些方向向量看成是探索n维空间的起始方向，随机数据位就是从这个n维空间产生<br> 的。因此，所谓的种子，就是人为指定的初始的随机性，即便有时名字不同，但意义是一<br> 样的。在cuRAND主机端API中，只有用于QRNG的维数可以使用<br> curandSetQuasiRandomGeneratorDimensions来设置：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>curandGenerator_t rand_state<span class="token punctuation">;</span>
<span class="token function">curandCreateGenerator</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>rand_state<span class="token punctuation">,</span> CURAND_RNG_QUASI_SOBOL32<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">curandSetQuasiRandomGeneratorDimensions</span><span class="token punctuation">(</span>rand_state<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>而设备端API允许指定种子的方向向量：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">kernel</span><span class="token punctuation">(</span>curandDirectionVectors32_t <span class="token operator">*</span>direction_vector<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 curandStateSobol32_t rand_state<span class="token punctuation">;</span>
 <span class="token function">curand_init</span><span class="token punctuation">(</span><span class="token operator">*</span>direction_vector<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span>rand_state<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">}</span>
curandDirectionVectors32_t <span class="token operator">*</span>h_vectors<span class="token punctuation">;</span>
<span class="token function">curandGetDirectionVectors32</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>h_vectors<span class="token punctuation">,</span> CURAND_DIRECTION_VECTORS_32_JOEKUO6<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>d_vectors<span class="token punctuation">,</span> h_vectors<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span>curandDirectionVectors32_t<span class="token punctuation">)</span><span class="token punctuation">,</span>
 cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>
kernel<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span>blocks<span class="token punctuation">,</span> threads<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>d_vectors<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>最后，cuRAND中第四个配置项是随机数序列在起始点的偏移量。也就是说，由不同<br> 的种子起始生成的随机数序列也不同。这个偏移量允许你跳转到当前序列的第i个随机值<br> 上。在主机端API中，可以使用curandSetGeneratorOffset来进行设置：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>curandGenerator_t rand_state<span class="token punctuation">;</span>
<span class="token function">curandCreateGenerator</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>rand_state<span class="token punctuation">,</span> CURAND_RNG_PSEUDO_DEFAULT<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">curandSetGeneratorOffset</span><span class="token punctuation">(</span>rand_state<span class="token punctuation">,</span> <span class="token number">0ULL</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>在cuRAND设备端API中，偏移量为curand_init函数的一个参数（与种子类似）：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__device__ <span class="token keyword">void</span> <span class="token function">curand_init</span><span class="token punctuation">(</span><span class="token keyword">unsigned</span> <span class="token keyword">long</span> <span class="token keyword">long</span> seed<span class="token punctuation">,</span>
 <span class="token keyword">unsigned</span> <span class="token keyword">long</span> <span class="token keyword">long</span> subsequence<span class="token punctuation">,</span>
<span class="token keyword">unsigned</span> <span class="token keyword">long</span> <span class="token keyword">long</span> offset<span class="token punctuation">,</span>
 curandStateXORWOW_t <span class="token operator">*</span>state<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_8-5-2-2-主机和设备端api对比" tabindex="-1"><a class="header-anchor" href="#_8-5-2-2-主机和设备端api对比" aria-hidden="true">#</a> 8.5.2.2 主机和设备端API对比</h4><ul><li><p>对一个特定应用程序来说，需要对是否使用主机或设备的cuRand API做出决定。两个<br> API提供了相似的功能：相同的RNG，相同的分布，以及相同的可配置性（参数不同）。<br> 但是，对这些功能进行访问的方法却大有不同。本节根据应用程序的需求，对选择过程提<br> 供了指南。</p></li><li><p>如果你唯一的目标是在主机端应用中生成高效、高质量的随机数，那么主机端API是<br> 最好的选择。CUDA方面的专家已经着手编写相关程序，并达到了此应用目的的最优性<br> 能，这远比你自己编写内核程序来调用设备端API要好用得多（接下来的8.5.3节中将举例<br> 说明）。如果考虑到之后GPU内核的消耗，由于使用主机端API在GPU上预生成随机数，<br> 因此这并没有什么优势。按提供者与使用者对随机性进行的划分可能会导致代码可读性下<br> 降，也可能会因cuRAND主机函数库和内核启动开销的升高而导致性能变差，同时会要求<br> 在内核执行之前，就要知道必要的随机数数目。</p></li><li><p>如果你想要对随机数生成有更多的控制权，如果你正使用一组由手写CUDA内核生成<br> 的随机数，特别是内核中所需要的随机数是动态变化的，那么设备端API是正确的选择。<br> 只需要编写少量程序来初始化和管理设备端RNG的状态，就可以在CUDA程序进行内部操<br> 作时获得更大的灵活性。</p></li></ul><h3 id="_8-5-3-curand介绍" tabindex="-1"><a class="header-anchor" href="#_8-5-3-curand介绍" aria-hidden="true">#</a> 8.5.3 cuRAND介绍</h3><ul><li>本节介绍了两个cuRAND API的例子。第一个是使用主机和设备端cuRAND API来替换<br> 系统自带的rand函数。第二个是使用主机和设备端cuRAND API和系统自带的rand调用来创<br> 建一个CUDA内核随机数。</li></ul><h4 id="_8-5-3-1-替换rand" tabindex="-1"><a class="header-anchor" href="#_8-5-3-1-替换rand" aria-hidden="true">#</a> 8.5.3.1 替换rand（）</h4><ul><li><p>你可以从Wrox.com中下载replace-rand.cu进行学习，此程序通过使用主机和设备端<br> cuRAND API的调用来为之后的主机耗能生成随机数。这个例子会在一次函数库调用中产<br> 生大量的随机数，然后在主机请求新的随机数时循环对它们进行访问。只有当现有的随机<br> 数都用过了，才回到cuRAND函数库调用产生更多的随机数。</p></li><li><p>使用主机端API的工作流在本章中是最简单的，其步骤如下：<br> 1.使用curandCreateGenerator创建一个由所需RNG配置的cuRAND生成器。对这样的生<br> 成器进行配置是可行的（例如，使用curandSetStream），但对于主机端API则是可选择<br> 的。<br> 2.使用cudaMalloc为cuRNAD预分配设备内存，使其用来存储输出的随机数。<br> 3.通过执行一个cuRAND库调用来生成随机数，例如，curandGenerateUniform。<br> 4.如果主机端一定要有能耗的话，则使用cudaMemcpy从设备内存中取回生成的随机数。</p></li><li><p>以下代码段是使用cuRAND主机端API的工作流：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token comment">/*
 * An implementation of rand() that uses the cuRAND host API.
 */</span>
<span class="token keyword">float</span> <span class="token function">cuda_host_rand</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>dRand <span class="token operator">==</span> <span class="token constant">NULL</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token comment">/*
 * If the cuRAND state hasn’t been initialized yet, construct a cuRAND
 * host generator and pre-allocate memory to store the generated random
 * values in.
 */</span>
 <span class="token function">curandCreateGenerator</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>randGen<span class="token punctuation">,</span>
 CURAND_RNG_PSEUDO_DEFAULT<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>dRand<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span> <span class="token operator">*</span> dRand_length<span class="token punctuation">)</span><span class="token punctuation">;</span>
 hRand <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span><span class="token punctuation">)</span><span class="token function">malloc</span><span class="token punctuation">(</span><span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span> <span class="token operator">*</span> dRand_length<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>dRand_used <span class="token operator">==</span> dRand_length<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token comment">/*
 * If all pre-generated random numbers have been consumed, regenerate a
 * new batch using curandGenerateUniform.
 */</span>
 <span class="token function">curandGenerateUniform</span><span class="token punctuation">(</span>randGen<span class="token punctuation">,</span> dRand<span class="token punctuation">,</span> dRand_length<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>hRand<span class="token punctuation">,</span> dRand<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span> <span class="token operator">*</span> dRand_length<span class="token punctuation">,</span>
 cudaMemcpyDeviceToHost<span class="token punctuation">)</span><span class="token punctuation">;</span>
 dRand_used <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 <span class="token comment">// Return the next pre-generated random number</span>
 <span class="token keyword">return</span> hRand<span class="token punctuation">[</span>dRand_used<span class="token operator">++</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>对设备端API的处理稍微有些复杂，有如下几步：<br> 1.在设备内存中为每个线程预分配一套cuRAND状态对象来管理其RNG（随机数生成<br> 器）的状态。<br> 2.如果cuRAND产生的随机值被规定为复制到主机或必须存储至后期的内核，那么来<br> 存储它们的预分配设备内存可选。<br> 3.在设备内存中使用CUDA内核调用初始化所有cuRAND状态对象的状态。<br> 4.执行一个CUDA内核，该内核调用一个cuRAND设备端函数（如curand_uniform），<br> 然后使用预分配的cuRAND状态对象生成随机数。这一步和上一步可以合并成到一个核函<br> 数中，但需要注意的是，在获取之后要用随机数时，不用重新初始化配状态对象。<br> 5.如果在第2步预分配了用于取回随机数的设备内存，那么就要将随机数传回主机<br> 端。</p></li><li><p>下面是关于cuRAND设备端API的工作流代码段：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token comment">/*
 * An implementation of rand() that uses the cuRAND device API.
 */</span>
<span class="token keyword">float</span> <span class="token function">cuda_device_rand</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>dRand <span class="token operator">==</span> <span class="token constant">NULL</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token comment">/*
c08.indd 08/19/2014 Page 355
356 ❘ CHAPTER 8 GPU-ACCELERATED CUDA LIBRARIES AND OPENACC
 * If the cuRAND state hasn’t been initialized yet, pre-allocate memory
 * to store the generated random values in as well as the cuRAND device
 * state objects.
 */</span>
 <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>dRand<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span> <span class="token operator">*</span> dRand_length<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>states<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span>curandState<span class="token punctuation">)</span> <span class="token operator">*</span>
 threads_per_block <span class="token operator">*</span> blocks_per_grid<span class="token punctuation">)</span><span class="token punctuation">;</span>
 hRand <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span><span class="token punctuation">)</span><span class="token function">malloc</span><span class="token punctuation">(</span><span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span> <span class="token operator">*</span> dRand_length<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// Initialize states on the device</span>
 initialize_state<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span>blocks_per_grid<span class="token punctuation">,</span> threads_per_block<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>states<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>dRand_used <span class="token operator">==</span> dRand_length<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token comment">/*
 * If all pre-generated random numbers have been consumed, regenerate a
 * new batch.
 */</span>
 refill_randoms<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span>blocks_per_grid<span class="token punctuation">,</span> threads_per_block<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>dRand<span class="token punctuation">,</span>
 dRand_length<span class="token punctuation">,</span> states<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>hRand<span class="token punctuation">,</span> dRand<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span> <span class="token operator">*</span> dRand_length<span class="token punctuation">,</span>
 cudaMemcpyDeviceToHost<span class="token punctuation">)</span><span class="token punctuation">;</span>
 dRand_used <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 <span class="token comment">// Return the next pre-generated random number</span>
 <span class="token keyword">return</span> hRand<span class="token punctuation">[</span>dRand_used<span class="token operator">++</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>这个示例可以使用如下指令进行创建：<code>$ nvcc -lcurand replace-rand.cu –o replace-rand</code></p></li><li><p>所有这些工作流在replace-rand.cu示例中都是可用的。在replace-rand.cu中有3个不同的<br> 函数，用这3个函数来取回一个单一的、随机的、在0.0f和1.0f之间的单精度浮点值。<br> host_rand函数只是借助于rand系统调用获取一个随机数。cuda_host_rand采用cuRAND的主<br> 机端API预生成一个大批量的随机数，然后在连续调用cuda_host_rand过程中对这些随机数<br> 进行遍历。它会记下预生成的随机数的数量和已使用的随机数的数量，然后根据这些统计<br> 数量来确定什么时候产生新的批处理。cuda_device_rand使用cuRAND设备端API，通过在<br> 设备上预分配一系列cuRAND状态对象来执行同样的操作，使用这些对象来生成大批量的<br> 随机数，并且采用与cuda_host_rand相同的方式来管理数据。</p></li><li><p>在这个例子中，在使用rand函数提供的cuRAND实现时需要注意的一个方面是突发性<br> 处理造成的抖动性。大多数对cuda_host_rand和cuda_device_rand的调用是很快的，并且只<br> 由一个数组引用和一个累加计数器组成。每次调用都需要使用GPU重新生成大批量的随机<br> 数，这很耗费时间。在某些应用程序中，这种不均匀及不可预测性是受排斥的。为此，在<br> Wrox.com的replace-rand-streams.cu中提供了一个修改后的代码，当主机应用程序正在运行<br> 时，将cuRAND API CUDA绑定到CUDA流上，在GPU上异步执行随机数生成代码。考虑到<br> 主机应用程序有足够多的任务，以重叠GPU上随机数的生成任务，这使得在最后一批随机<br> 数用完之前，一组新的随机数就已经生成了。</p></li></ul><h4 id="_8-5-3-2-为cuda内核生成随机数" tabindex="-1"><a class="header-anchor" href="#_8-5-3-2-为cuda内核生成随机数" aria-hidden="true">#</a> 8.5.3.2 为CUDA内核生成随机数</h4><ul><li><p>你可以在Wrox.com中的rand-kernel.cu中下载示例代码来进行学习。与上一节的<br> replace-rand.cu和replace-rand-stream.cu的例子相比，本例利用cuRAND主机和设备端API来<br> 生成供CUDA内核使用的随机数。</p></li><li><p>use_host_api在调用一个使用这些随机数的CUDA内核之前，使用cuRAND主机端API<br> 预生成N个随机数。注意，这需要来自主机程序和cuRAND的多个内核调用，以及专门分<br> 配来存储所生成的随机数的设备内存。下面代码段的意义是，使用curand-GenerateUniform<br> 生成随机数并传给dRand，将这些值传给host_api_kernel，然后将host_api_kernel的最终输<br> 出从设备端（dOut）传到主机端（hOut）：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token comment">// Generate N random values from a uniform distribution</span>
<span class="token function">curandGenerateUniform</span><span class="token punctuation">(</span>randGen<span class="token punctuation">,</span> dRand<span class="token punctuation">,</span> N<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// Consume the values generated by curandGenerateUniform</span>
host_api_kernel<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span>blocks_per_grid<span class="token punctuation">,</span> threads_per_block<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>dRand<span class="token punctuation">,</span> dOut<span class="token punctuation">,</span> N<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// Retrieve outputs</span>
<span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>hOut<span class="token punctuation">,</span> dOut<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span> <span class="token operator">*</span> N<span class="token punctuation">,</span>
 cudaMemcpyDeviceToHost<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>use_device_api函数使用cuRAND设备端API在GPU上按需生成随机数。注意，只需要<br> 一个包括所有cuRAND初始化和执行的单一的内核调用，无需分配用于存储这些随机值的<br> CUDA设备内存。CUDA内核能直接使用生成的任意随机数。下面代码段的意义是，内核<br> device_api_kernel在预分配的cuRAND设备生成器上的执行，以及将内核的最终输出从设备<br> 传到主机。</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token comment">// Execute a kernel that generates and consumes its own random numbers</span>
device_api_kernel<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span>blocks_per_grid<span class="token punctuation">,</span> threads_per_block<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>states<span class="token punctuation">,</span> dOut<span class="token punctuation">,</span> N<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// Retrieve the results</span>
<span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>hOut<span class="token punctuation">,</span> dOut<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span> <span class="token operator">*</span> N<span class="token punctuation">,</span>
 cudaMemcpyDeviceToHost<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>使用以下命令构建这个示例：<code> nvcc -lcurand rand-kernel.cu –o rand-kernel</code></li></ul><h3 id="_8-5-4-curand发展中的重要主题" tabindex="-1"><a class="header-anchor" href="#_8-5-4-curand发展中的重要主题" aria-hidden="true">#</a> 8.5.4 cuRAND发展中的重要主题</h3><ul><li><p>cuRAND是一个使用起来简单而灵活的API。基于cuRAND的对象中最重要的部分就是<br> 了解随机性的要求。</p></li><li><p>例如，不同的随机数生成器或不同的分布选择对应用程序的性能、正确性和结果会有<br> 很大的影响。特别是对像蒙特卡罗模拟这样依赖于随机数的应用程序。还有一点比较重要<br> 的是，要确保你已经正确配置了cuRAND环境以生成期望的随机数类型。即便给出了高度<br> 依赖随机性的应用程序的范围，也不知道选择哪个应用程序是正确的。请咨询你身边友好<br> 的计算机学者。</p></li></ul><h2 id="_8-6-cuda6-0中函数库的介绍" tabindex="-1"><a class="header-anchor" href="#_8-6-cuda6-0中函数库的介绍" aria-hidden="true">#</a> 8.6 CUDA6.0中函数库的介绍</h2><ul><li>CUDA 6.0新增了两个特性：Drop-In库和Multi-GPU库。</li></ul><h3 id="_8-6-1-drop-in库" tabindex="-1"><a class="header-anchor" href="#_8-6-1-drop-in库" aria-hidden="true">#</a> 8.6.1 Drop-In库</h3><ul><li><p>Drop-In库可以使某些GPU加速库无缝地替换已有的CPU库。只要GPU加速库与原主机<br> 库使用相同的API，就可以直接把一个应用程序链接到一个Drop-In库中。Drop-In库的设计<br> 目的是提高传统应用程序的可移植性。事实上，有了Drop-In库，甚至不需要重新编译应<br> 用程序代码。</p></li><li><p>在已有的应用程序中，目前只支持两个CUDA库。NVBLAS是cuBLAS库的一个子函数<br> 库，它可以替换任意的三层BLAS函数。cyFFTW可以替换FFTW库的调用。</p></li><li><p>有两种方法可以强制应用程序用一个Drop-In库来替换BLAS或FFTW。第一种是可以<br> 重新编译应用程序以链接到CUDA库而不是标准库。举例来说，如果有一个使用BLAS库<br> 的应用程序，该应用程序是由源文件app.c创建的，通常使用以下编译命令：<br><code>$ gcc app.c –lblas –o app</code></p></li><li><p>如果你想用与cuBLAS等价的函数库来替换应用程序中所有的BLAS 3调用，那么需要<br> 重建应用程序来使用cuBLAS库，如下所示:<code>$ gcc app.c –lnvblas –o app</code></p></li><li><p>第二种是强制在主机库之前加载CUDA库，这种方法是在Linux环境下使用CUDA<br> Drop-In的。它可以通过使用LD_PRELOAD环境变量来实现，它引导操作系统在检查默认<br> 设置之前查找指定库的函数定义。这是在你运行完应用程序的命令之后，接着使用env<br> shell实现的。例如，如果前面示例中的应用程序没有使用命令行参数，而且你也不想重新<br> 编译此程序，那么就可以使用等价的CUDA命令替换BLAS 3例程来执行此程序，命令行如<br> 下所示：<code>$ env LD_PRELOAD=libnvlas.so ./app</code></p></li><li><p>你可以从Wrox.com中下载drop-in.c进行学习，也可以直接学习下面的代码段。这个应<br> 用程序使用了sgemm BLAS例程并且完全用C语言进行编写。以下是核心代码：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token comment">// Generate inputs</span>
 <span class="token function">srand</span><span class="token punctuation">(</span><span class="token number">9384</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token function">generate_random_dense_matrix</span><span class="token punctuation">(</span>M<span class="token punctuation">,</span> N<span class="token punctuation">,</span> <span class="token operator">&amp;</span>A<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token function">generate_random_dense_matrix</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> M<span class="token punctuation">,</span> <span class="token operator">&amp;</span>B<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token function">generate_random_dense_matrix</span><span class="token punctuation">(</span>M<span class="token punctuation">,</span> N<span class="token punctuation">,</span> <span class="token operator">&amp;</span>C<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token function">sgemm_</span><span class="token punctuation">(</span>“N”<span class="token punctuation">,</span> “N”<span class="token punctuation">,</span> <span class="token operator">&amp;</span>M<span class="token punctuation">,</span> <span class="token operator">&amp;</span>M<span class="token punctuation">,</span> <span class="token operator">&amp;</span>N<span class="token punctuation">,</span> <span class="token operator">&amp;</span>alpha<span class="token punctuation">,</span> A<span class="token punctuation">,</span> <span class="token operator">&amp;</span>M<span class="token punctuation">,</span> B<span class="token punctuation">,</span> <span class="token operator">&amp;</span>N<span class="token punctuation">,</span> <span class="token operator">&amp;</span>beta<span class="token punctuation">,</span> C<span class="token punctuation">,</span> <span class="token operator">&amp;</span>M<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>通过以下编译指令可以在主机上运行drop-in.c，前提是已经安装了C BLAS库并设置好<br> 了库路径。<code>$ gcc drop-in.c –lblas –lm –o drop-in</code></p></li><li><p>如果要在GPU上运行sgemn调用，只需使用如下命令重新进行编译：<code>$ gcc drop-in.c –lnvblas –o drop-in</code></p></li><li><p>或使用如下编译：<code>$ env LD_PRELOAD=libnvlas.so ./drop-in</code></p></li><li><p>Drop-In库帮助解决了函数移植的障碍，利用高性能的CUDA库进一步提高了工作效<br> 率。通过简单地重新连接或添加一个环境设置，你可以用大规模并行GPU加速来有效地加<br> 强现有应用程序的执行。</p></li></ul><h3 id="_8-6-2-多gpu库" tabindex="-1"><a class="header-anchor" href="#_8-6-2-多gpu库" aria-hidden="true">#</a> 8.6.2 多GPU库</h3><ul><li><p>为了证明使用多个GPU能提高性能一些应用程序充分利用了并行。第9章对如何使用<br> 原有的CUDA API来验证多GPU加速功能有更多的介绍。对由CUDA执行的多GPU使用的讨<br> 论是很有必要的，因为它不要求程序员对其有深刻的理解，并且能获得性能提升和更好的<br> 硬件利用率。</p></li><li><p>多GPU库（也被称为XT库接口）是在CUDA 6.0中被引入的。它们能使单一的函数库<br> 调用在多个GPU上自动地执行。由于在多个GPU上执行需要在设备上划分任务，与GPU全<br> 局内存相比，一个多GPU库可以对更大规模的数据集进行操作。因此，即使你的系统只有<br> 一个GPU，也可以通过交换GPU内外的数据分区，来对超出可用全局内存大小的输入数据<br> 进行操作。</p></li><li><p>在CUDA 6.0中，cuFFT中的一些函数和所有的Level 3 cuBLAS函数都支持多GPU上的<br> 程序执行。在性能优化上，cuBLAS Level 3多GPU库调用利用内核计算自动覆盖了内存传<br> 输。</p></li><li><p>使用多GPU库需要进行一些额外的工作。你可以从Wrox.com中下载cufft-multi.cu进行<br> 学习，或者直接学习下面的代码段。cufft-multi.cu运行的例子与cufft.cu相同，但使用<br> cuFFTXT API把所有任务分派给了系统中所有的GPU。</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">int</span> nGPUs <span class="token operator">=</span> <span class="token function">getAllGpus</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>gpus<span class="token punctuation">)</span><span class="token punctuation">;</span>
 nGPUs <span class="token operator">=</span> nGPUs <span class="token operator">&gt;</span> <span class="token number">2</span> <span class="token operator">?</span> <span class="token number">2</span> <span class="token operator">:</span> nGPUs<span class="token punctuation">;</span>
 workSize <span class="token operator">=</span> <span class="token punctuation">(</span>size_t <span class="token operator">*</span><span class="token punctuation">)</span><span class="token function">malloc</span><span class="token punctuation">(</span><span class="token keyword">sizeof</span><span class="token punctuation">(</span>size_t<span class="token punctuation">)</span> <span class="token operator">*</span> nGPUs<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// Setup the cuFFT Multi-GPU plan</span>
 <span class="token function">cufftCreate</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>plan<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token function">cufftXtSetGPUs</span><span class="token punctuation">(</span>plan<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> gpus<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token function">cufftMakePlan1d</span><span class="token punctuation">(</span>plan<span class="token punctuation">,</span> N<span class="token punctuation">,</span> CUFFT_C2C<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> workSize<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// Generate inputs</span>
 <span class="token function">generate_fake_samples</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> <span class="token operator">&amp;</span>samples<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token function">real_to_complex</span><span class="token punctuation">(</span>samples<span class="token punctuation">,</span> <span class="token operator">&amp;</span>complexSamples<span class="token punctuation">,</span> N<span class="token punctuation">)</span><span class="token punctuation">;</span>
 cufftComplex <span class="token operator">*</span>complexFreq <span class="token operator">=</span> <span class="token punctuation">(</span>cufftComplex <span class="token operator">*</span><span class="token punctuation">)</span><span class="token function">malloc</span><span class="token punctuation">(</span>
 <span class="token keyword">sizeof</span><span class="token punctuation">(</span>cufftComplex<span class="token punctuation">)</span> <span class="token operator">*</span> N<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// Allocate memory across multiple GPUs and transfer the inputs into it</span>
 <span class="token function">cufftXtMalloc</span><span class="token punctuation">(</span>plan<span class="token punctuation">,</span> <span class="token operator">&amp;</span>dComplexSamples<span class="token punctuation">,</span> CUFFT_XT_FORMAT_INPLACE<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token function">cufftXtMemcpy</span><span class="token punctuation">(</span>plan<span class="token punctuation">,</span> dComplexSamples<span class="token punctuation">,</span> complexSamples<span class="token punctuation">,</span>
 CUFFT_COPY_HOST_TO_DEVICE<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// Execute a complex-to-complex 1D FFT across multiple GPUs</span>
 <span class="token function">cufftXtExecDescriptorC2C</span><span class="token punctuation">(</span>plan<span class="token punctuation">,</span> dComplexSamples<span class="token punctuation">,</span> dComplexSamples<span class="token punctuation">,</span>
 CUFFT_FORWARD<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token comment">// Retrieve the results from multiple GPUs into host memory</span>
 <span class="token function">cufftXtMemcpy</span><span class="token punctuation">(</span>plan<span class="token punctuation">,</span> complexSamples<span class="token punctuation">,</span> dComplexSamples<span class="token punctuation">,</span>
 CUFFT_COPY_DEVICE_TO_HOST<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>cufft.cu和cufft-multi.cu之间的主要区别是：<br> ·需要列出当前系统中所有的GPU（使用getAllGpus函数），并配置cuFFT plan来使用<br> 这些GPU（cufftXtSetGPU）。<br> ·使用cufftXtMalloc而不是cudaMalloc在多个GPU上分配设备内存，并将其与相同的<br> CUFFT plan进行关联。需要注意的是，分配信息结果存储在一个cudaLibXtDesc对象中而<br> 没有将其传给一个指针。<br> ·使用cufftXtMemcpy而不是cudaMemcpy实现主机内存与多个GPU之间的数据传输。注<br> 意，cufftXtMemcpy支持主机端数组和cudaLibXtDesc对象之间的数据拷贝，并支持两个<br> cudaLibXtDesc对象之间的数据拷贝。cufftXtMemcpy与cudaMemcpy类似，需要指定数据传<br> 输方向，如CUFFT_COPY_HOST_TO_DEVICE、CUFFT_COPY_DEVICE_TO_HOST或<br> CUFFT_COPY_DEVICE_TO_DEVICE。使用cuFF-TXTT的多GPU执行的任何设备位置必须<br> 表示为cudaLibXtDesc对象。<br> ·使用cufftExecDescriptor<em>库调用而不是cufftExec</em>来执行实际的FFT变换。</p></li><li><p>使用如下命令进行编译：<code>$ nvcc -lcufft cufft-multi.cu –o cufft-multi</code></p></li><li><p>cuFFTXT库使用FFT函数之前的知识来分配GPU之间的数据，这样做没有破坏FFT结<br> 果的有效性（并且在多GPU上对cuBLAS有类似的操作）.</p></li><li><p>在程序移植过程中，添加多GPU支持需要特别注意。如果你的应用程序有很好的并行<br> 性，那么使用多GPU CUDA XT接口比自定义多GPU实现更简单。cuBLAS和cuFFT库的XT<br> 接口是CUDA库的一个强大的附加功能。</p></li></ul><h2 id="_8-7-cuda函数库的性能研究" tabindex="-1"><a class="header-anchor" href="#_8-7-cuda函数库的性能研究" aria-hidden="true">#</a> 8.7 CUDA函数库的性能研究</h2><ul><li>通常情况下，考虑到性能方面的表现，我们会选择在CUDA中运行应用程序。因此，<br> 如果在GPU执行上所得到的性能加速结果不尽人意，那么CUDA库的使用对我们来说就是<br> 没有意义的。本节包含了CUDA库与标准库性能对比的文献。记住，对于所有性能测试，<br> 你的试验结果可能会因为编译器、硬件或其他环境的不同而不同。</li></ul><h3 id="_8-7-1-cusparse与mkl的比较" tabindex="-1"><a class="header-anchor" href="#_8-7-1-cusparse与mkl的比较" aria-hidden="true">#</a> 8.7.1 cuSPARSE与MKL的比较</h3><ul><li><p>可以说，数学核心库（MKL）是稀疏线性代数性能的黄金准则。MKL使用向量指令<br> 在多核CPU上手动优化的执行密集和稀疏线性代数。目前有大量对各种计算内核中的MKL<br> 和cuSPARSE进行比较的文献资料。</p></li><li><p>随着CUDA 5.0版本的发布，NVIDIA在多个计算内核和多个数据集上对cuSPARSE和<br> MKL进行了全面的性能比较。通过在18个不同的数据集上执行稀疏矩阵-稠密向量乘法，<br> 研究人员发现，与MKL相比，cuSPARSE的性能有1.1～3.1倍的提升。稀疏矩阵-稠密向量<br> 乘法能获取相对更好的性能优势，约有3～12倍的性能提升。最后，当比较cuSPARSE和<br> MKL之间的三对角解法时，取得了高达17倍的加速结果，这一结果取决于数据集的大小<br> 和原始数据的类型（见图8-11）。</p></li><li><p>对于发布的CUDA 6.0版本而言，NVIDIA对CUDA库进行了类似的性能比较。结果表<br> 明，在计算速度和性能上，稀疏矩阵-稠密向量乘法是三对角解法、不完全LU和Cholesky<br> 预调节器的1.8～5.4倍，总体上有了很大提升。</p></li><li><p>显然，cuSPARSE库是高度可用的，它保留了预期的GPU硬件性能优势并进行了改进<br><img src="`+D+'" alt="figure8-11" loading="lazy"></p></li></ul><h3 id="_8-7-2-cublas与mkl-blas的比较" tabindex="-1"><a class="header-anchor" href="#_8-7-2-cublas与mkl-blas的比较" aria-hidden="true">#</a> 8.7.2 cuBLAS与MKL BLAS的比较</h3><ul><li><p>由于MKL还包括BLAS例程的手动优化版本，这对于cuBLAS来说也是一个可以比较的<br> 地方。与cuSPARSE类似，在与MKL的比较中，对cuBLAS已经进行高度关注。</p></li><li><p>在CUDA 5.0的性能报告中，是在整个BLAS Level 3程序范围内对cuBLAS进行评估<br> 的。相对于MKL的加速结果，大约从2.7倍到8.7倍不等（如图8-12所示）。对ZGEMM的性<br> 能表现进行的深入研究，说明在512×512到4096×4096大小的矩阵范围内，cuBLAS比MKL<br> 有显著的性能优势（大于5倍的加速比）。<br><img src="'+P+'" alt="figure8-12" loading="lazy"></p></li><li><p>在CUDA 6.0性能报告中，NVIDIA指出了最新的MKLBLAS加速了6～17倍。对<br> ZGEMM来说，与MKL相比，cuBLAS也有类似的性能改进。随着多GPU cuBLAS-XT库的<br> 引进，NVIDIA在多个GPU上展示了cuBLAS的可扩展性（如图8-13所示）。<br><img src="'+R+'" alt="figure8-13" loading="lazy"></p></li></ul><h3 id="_8-7-3-cufft与fftw及mkl的比较" tabindex="-1"><a class="header-anchor" href="#_8-7-3-cufft与fftw及mkl的比较" aria-hidden="true">#</a> 8.7.3 cuFFT与FFTW及MKL的比较</h3><ul><li><p>FFTW库在多核CPU上拥有性能优异的一维和多维FFT，宣称其性能“通常优于其他公<br> 开的FFT软件，甚至可以与供应商调试的代码相抗衡”。很明显，FFTW的主要目标是性能<br> 优化，因此，对cuFFT来说它是一个很好的比较对象。MKL库也支持FFT。</p></li><li><p>NVIDIA的CUDA 5.0报告显示，FFT的性能表现取决于数据规模，范围从低至30<br> GFLOPS到高达250 GFLOPS。在单核系统报告中，FFTW的性能估计大约从1 GFLOPS到<br> 5.5 GFLOPS。由以上结果推断得出，20个CPU核心等价于一个GPU运行cuFFT。如果在相<br> 同数据大小的情况下，比较cuFFT最佳性能大约为250 GFLOPS和FFTW的最佳性能大约为<br> 5 GFLOPS，那么cuFFT的结果更优：50个CPU核心等价于一个GPU的计算性能。</p></li><li><p>NVIDIA报告指出，使用CUDA 6.0，在一维单精度复杂FFT上达到700 GFLOPS的性能<br> 加速是可能的，双精度则可超过250 GFLOPS。报告还强调，在大范围的数据集上也能保<br> 持性能优势（如图8-14所示）。<br><img src="'+U+`" alt="figure8-14" loading="lazy"></p></li></ul><h3 id="_8-7-4-cuda库性能小结" tabindex="-1"><a class="header-anchor" href="#_8-7-4-cuda库性能小结" aria-hidden="true">#</a> 8.7.4 CUDA库性能小结</h3><ul><li>在本节中，通过对cuSPARSE、cuBLAS和cuFFT的性能评估进行学习，表明CUDA库<br> 的性能并不能衡量其可用性。通过直接学习CUDA专家提出的复杂计算算法的CUDA实<br> 现，可以提高工作效率和应用程序的性能。</li></ul><h2 id="_8-8-openacc的使用" tabindex="-1"><a class="header-anchor" href="#_8-8-openacc的使用" aria-hidden="true">#</a> 8.8 OpenACC的使用</h2><ul><li><p>OpenACC是CUDA的一个补充编程模型，使用基于编译器指令的API，具有高性能、<br> 可编程性和跨平台可移植性。本节将会介绍OpenACC的概念和方法，重点介绍CUDA和<br> OpenACC之间的关系。</p></li><li><p>OpenACC的线程模型与CUDA的线程模型类似，但添加了一个并行的维度。OpenACC可以分为gang、worker和vector 3个并行层次。<br> 在上层，gang类似于CUDA线程块。一个gang可包含一个或多个执行的线程，在每个gang内部每个gang都包含一个或多个<br> worker。在CUDA中，一个worker类似于线程中的一个线程束。每个worker都有一个向量<br> 宽度，由一个或多个同时执行相同指令的向量元素组成。每个向量元素都类似于一个<br> CUDA线程，因为它是一个单一的执行流。OpenACC和CUDA线程模型之间的主要区别在<br> 于，OpenACC在编程模型中直接指出了worker的概念（即线程束），而在CUDA中并没有<br> 明确建立线程束。</p></li><li><p>OpenACC平台模型与CUDA类似，但它使用不同的术语和略有不同的抽象概念。<br> OpenACC的目标是建立一个具有单线程的主机程序平台，在该主机程序中，将内核交付<br> 给多处理单元（PU），在此平台上，每个PU一次只运行一个gang。每个PU可以同时执行<br> 多个独立的并发执行线程（worker）。每个执行线程可以执行具有一定向量宽度的向量运<br> 算。在OpenACC中，gang并行使用多个PU。每个gang里的多线程并行即为worker并行。每<br> 个worker里的并行以及一个跨向量操作的并行被称为向量并行。当在GPU上使用OpenACC<br> 时，一个PU就类似于一个SM。</p></li><li><p>根据任务是否通过gang、worker、vector并行执行，OpenACC执行被分成几种模式。<br> 现在，假设在一个OpenACC程序的并行计算区域中，创建了G个gang，其中每个gang包含<br> W个worker，每个worker的向量宽度为V。那么，总共有G×W×V个执行线程处理这个并行<br> 区域。</p></li><li><p>当开始执行并行区域时，gang以gang冗余模式执行，这有利于在并行执行开始前对<br> gang的状态进行初始化。在gang冗余模式中，每个gang的worker中只有一个活跃vector元<br> 素，其他worker和vector元素是闲置的，因此只有G个活跃的执行线程。此外，每个gang都<br> 执行相同的运算，所以在这个阶段没有通过gang并行任务。在CUDA中，gang冗余并行将<br> 作为执行相同计算的线程块里的一个线程来实现：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">kernel</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>threadIdx<span class="token punctuation">.</span>x <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token function">foo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>在OpenACC并行区域的某些地方，应用程序可能通过gang转换为并行执行。在这种情<br> 况下，程序以gang分裂模式执行。在gang分裂模式下，每个gang中仍然只有一个活跃的<br> vector元素和一个活动的worker，但每个活跃的vector元素执行不同的并行区域。因此，该<br> 计算区域的任务被分散到各个gang中。在CUDA中，gang分裂模式将作为一个线程来实<br> 现，在这个线程里每个线程块处理分离的数据点。对于向量加法，在gang分裂模式下执行<br> 的CUDA内核如下所示：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">kernel</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token operator">*</span>in1<span class="token punctuation">,</span> <span class="token keyword">int</span> <span class="token operator">*</span>in2<span class="token punctuation">,</span> <span class="token keyword">int</span> <span class="token operator">*</span>out<span class="token punctuation">,</span> <span class="token keyword">int</span> N<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>threadIdx<span class="token punctuation">.</span>x <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token keyword">int</span> i<span class="token punctuation">;</span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> i <span class="token operator">+=</span> gridDim<span class="token punctuation">.</span>x<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 out<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> in1<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> in2<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>那么对于worker并行和vector并行呢？当在一个gang中只有一个活跃的worker时，程序<br> 处于单一worker模式。当worker中只有一个活跃的vector元素时，程序处于单一vector模<br> 式。因此，gang冗余模式和gang分裂模式也可以被称为单一worker模式和单一vector模式。</p></li><li><p>在worker分裂模式下，并行区域的工作被划分到多个gang和多个worker中。使用所有<br> gang里的所有worker可以提供G×W路并行。在CUDA中，worker分裂模式通过每个线程束<br> 中的第一个线程来实现：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>__global__ <span class="token keyword">void</span> <span class="token function">kernel</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token operator">*</span>in1<span class="token punctuation">,</span> <span class="token keyword">int</span> <span class="token operator">*</span>in2<span class="token punctuation">,</span> <span class="token keyword">int</span> <span class="token operator">*</span>out<span class="token punctuation">,</span> <span class="token keyword">int</span> N<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token keyword">if</span> <span class="token punctuation">(</span>threadIdx<span class="token punctuation">.</span>x <span class="token operator">%</span> warpSize <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token keyword">int</span> warpId <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">/</span> warpSize<span class="token punctuation">;</span>
 <span class="token keyword">int</span> warpsPerBlock <span class="token operator">=</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">/</span> warpSize<span class="token punctuation">;</span>
 <span class="token keyword">int</span> i<span class="token punctuation">;</span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> warpsPerBlock <span class="token operator">+</span> warpId<span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span>
 i <span class="token operator">+=</span> gridDim<span class="token punctuation">.</span>x <span class="token operator">*</span> warpsPerBlock<span class="token punctuation">)</span> <span class="token punctuation">{</span>
 out<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> in1<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> in2<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>在vector分裂模式下，工作任务在gang、worker和vector通道上进行划分，同时提供<br> G×W×V路并行。这个模式与编写的CUDA内核模式最为相似。这些不同的OpenACC模<br> 式，使得一个应用程序的并行性可在代码的并行区域内进行动态调整。</p></li><li><p>当使用OpenACC时，由程序员用编译器指令指定并行代码区域，或是并行运行。编<br> 译器指令还可以指定使用何种类型的并行处理。编译器指令是一行源代码，用C/C++编<br> 写，开头为#pragma。OpenACC指令使用acc关键字作为唯一标识，这意味着所有OpenACC<br> 指令都是以#pragma acc开头的。</p></li><li><p>尽管编译器指令是程序源代码的一部分，但它们对编译器生成的可执行文件的影响是<br> 不一定的。如果编译器无法识别或不支持#pragma的这种类型，那么在编译时就会忽略<br> #pragma的存在。另外，在运行本节中的任何示例代码时，都需要启用使能OpenACC的编<br> 译器。目前，PGI、Cray和CAPS编译器都支持OpenACC指令。本章中的例子使用的是PGI<br> 编译器，但实际上要求的是所有源代码在所有编译器上都可以运行。查看你的编译文件，<br> 然后添加需要的标志以支持OpenACC。</p></li><li><p>使能OpenACC编译器能对程序的OpenACC指令做出解释，也能对源代码进行自动分<br> 析以自动生成加速器源代码。因此，只需添加几行指令代码，就可以在GPU上自动执行应<br> 用程序了。如下是OpenACC向量加法的实现：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc kernels</span></span>
<span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 C<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> A<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> B<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>#pragma acc内核指令标志着下列顺序代码块在OpenACC加速器上符合执行的条件<br> （如GPU）。如果构建源代码的编译器是支持OpenACC的，那么它会分析循环过程，决定<br> 在gang、worker和vector通道上并行执行的策略，然后自动生成内存拷贝、内核启动及在<br> GPU上并行执行循环部分必需的内核代码。与此相反，在CUDA中的手动编码（没有<br> CUDA统一内存）则要求：1）把循环体转换成CUDA__global__kernel，2）用cudaMalloc<br> 分配内存，3）用cudaMemcpy将数据拷贝到设备端，4）启动内核，5）将数据拷贝回主机<br> 端。有了OpenACC，所有这些都可以由#pragma来完成。</p></li><li><p>除了编译器指令，OpenACC也提供了一系列库函数。与OpenACC的编译器指令相<br> 比，这些函数可以实现与其相同的、互补的或独有的功能。</p></li><li><p>本节的剩余部分将学习OpenACC的指令及其应用。你将从探索计算指令是如何将串<br> 行的C代码自动转换为并行执行开始，然后探究数据指令是如何让你管理主机和设备之间<br> 的数据传输的。紧接着是对OpenACC运行时API的简要讨论，这部分将通过一个使用<br> OpenACC的示例来介绍。</p></li></ul><h3 id="_8-8-1-openacc计算指令的使用" tabindex="-1"><a class="header-anchor" href="#_8-8-1-openacc计算指令的使用" aria-hidden="true">#</a> 8.8.1 OpenACC计算指令的使用</h3><ul><li>在OpenACC中，用计算编译程序指令来通知编译器是如何让一个代码块并行执行<br> 的。有两个相关的计算指令：#pragma acc kernels和#pragma acc parallel。</li></ul><h4 id="_8-8-1-1-内核指令的使用" tabindex="-1"><a class="header-anchor" href="#_8-8-1-1-内核指令的使用" aria-hidden="true">#</a> 8.8.1.1 内核指令的使用</h4><ul><li><p>#pragma acc kernels采取了一种比#pragma acc parallel更自动化且编译器可驱动的方<br> 法。当在一个代码块中应用内核指令时，编译器会自动分析这个代码块中可并行的循环。<br> 当找到可并行的区域后，编译器可以在每个并行循环中使用任意配置的gang、worker和<br> vector宽度来对并行执行进行调度。也就是说，编译器会自动决定何时使用gang冗余模<br> 式、gang分裂模式、worker分裂模式等。在CUDA中，编译器会搜寻代码块，在CUDA内<br> 核中，这些代码块是由并行循环所执行的内核指令所修饰的。在内核块中不能并行的其他<br> 代码仍要执行，只是不以并行方式执行。</p></li><li><p>可以将从Wrox.com下载的simple-kernels.c中的代码作为简单的示例。以下代码段是核<br> 心代码：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc kernels</span></span>
<span class="token punctuation">{</span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 C<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> A<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> B<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 D<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> C<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">*</span> A<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>这个内核块包含两个可以并行的循环。如果你有一个PGI编译器，那么就可以用以下<br> 命令进行编译：<code>$ pgcc –acc simple-kernels.c –o simple-kernels</code></p></li><li><p>为PGI编译器添加-acc标志使其支持OpenACC，允许其在所提供的代码中识别任何带<br> 有#pragma acc的指令。同时强烈建议你在PGI编译器中添加-Minfo=accel标志，以弄清楚自<br> 动并行化是如何实现的。在simple-kernels.c中使用-Minfo=accel可得到以下输出：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>$ pgcc –acc –Minfo<span class="token operator">=</span>accel simple<span class="token operator">-</span>kernels<span class="token punctuation">.</span>c –o simple<span class="token operator">-</span>kernels
main<span class="token operator">:</span>
 <span class="token number">34</span><span class="token punctuation">,</span> Generating <span class="token function">present_or_copyout</span><span class="token punctuation">(</span>C<span class="token punctuation">[</span><span class="token operator">:</span><span class="token number">1024</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
 Generating <span class="token function">present_or_copyin</span><span class="token punctuation">(</span>A<span class="token punctuation">[</span><span class="token operator">:</span><span class="token number">1024</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
 Generating <span class="token function">present_or_copyin</span><span class="token punctuation">(</span>B<span class="token punctuation">[</span><span class="token operator">:</span><span class="token number">1024</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
 Generating <span class="token function">present_or_copyout</span><span class="token punctuation">(</span>D<span class="token punctuation">[</span><span class="token operator">:</span><span class="token number">1024</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
 Generating Tesla code
 <span class="token number">36</span><span class="token punctuation">,</span> Loop is parallelizable
 Accelerator kernel generated
 <span class="token number">36</span><span class="token punctuation">,</span> #pragma acc loop gang<span class="token punctuation">,</span> <span class="token function">vector</span><span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span> <span class="token comment">/* blockIdx.x threadIdx.x */</span>
 <span class="token number">39</span><span class="token punctuation">,</span> Loop is parallelizable
 Accelerator kernel generated
 <span class="token number">39</span><span class="token punctuation">,</span> #pragma acc loop gang<span class="token punctuation">,</span> <span class="token function">vector</span><span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span> <span class="token comment">/* blockIdx.x threadIdx.x */</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>现在，忽略那些有present_or_copyout和present_or_copyin的语句。这些语句在8.8.2节<br> 中会有所提及。使用36和39标记的行是源代码中每个循环开始的地方。在这两种情况下，<br> OpenACC能自动找到可并行化的循环。它还为每个循环所用的并行化策略输出相关信息：<br><code>#pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */</code></p></li><li><p>信息表明，在一个有128个元素的向量宽度下，这两个循环都通过gang和vector完全并<br> 行化了。在CUDA中，这就对应一个128个线程的线程块，需要尽可能多的块启动来并行<br> 执行循环迭代。</p></li><li><p>内核指令后面也可能会加一些有修饰其行为的选项，例如：<code>#pragma acc kernels if(cond)</code></p></li><li><p>如果cond是false，那么应禁止代码块在OpenACC加速器上执行。如果在GPU上并行执<br> 行没有任何意义，在这种情况下，你若想阻止执行，那么上述指令就非常有用了，类似如<br> 下命令：<code>#pragma acc kernels if(N &lt; 128).</code></p></li><li><p>在OpenACC中，对所有计算来说，在内核指令结束时有一个默认的等待命令。但<br> 是，如果使用async子句那么执行就不会被阻塞：<code>#pragma acc kernels async(id)</code></p></li><li><p>async子句接受一个可选的整型参数。这个整数给内核块指定的唯一ID，允许相同的<br> 整数ID在之后被用于测试或等待这个内核块的实现。如果没有给出这个ID，那么内核块仍<br> 异步执行，但是不会等待那个内核块执行完毕。例如，如果用如下命令创建一个内核块：<br><code>#pragma acc kernels async(3)</code></p></li><li><p>然后应用程序可以使用如下等待指令，等待完成与内核指令相关的计算：<code>#pragma acc wait(3)</code></p></li><li><p>或者通过调用库函数acc_async_wait：<code>acc_async_wait(3);</code></p></li><li><p>你还可以使用一个空的等待指令来等待所有异步任务的完成：<code>#pragma acc wait</code></p></li><li><p>或使用库函数acc_async_wait_all：<code>acc_async_wait_all();</code></p></li><li><p>在CUDA中，使用整数ID的异步指令和函数，类似于使用cudaEvent_t来识别等待执行<br> 任务中的一个点。然后，对异步任务使用一个等待指令或阻塞函数，类似于使用cudaEventSynchronize函数阻塞某个事件。<br> 如果没有整数ID，等待行为类似于cudaDeviceSynchronize调用。</p></li><li><p>你也可以在内核指令中添加一个wait子句，确保内核区域的执行在下列情形之前未启<br> 动：1）之前所有异步任务均已完成，2）与所提供的整数ID相关的任务都已经完成。将内<br> 核区域中的异步和wait子句结合起来，可以链接到异步加速区域：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc kernels <span class="token function">async</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></span></span>
<span class="token punctuation">{</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">}</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc kernels <span class="token function">wait</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token function">async</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span></span></span>
<span class="token punctuation">{</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">}</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc kernels <span class="token function">wait</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token function">async</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span></span></span>
<span class="token punctuation">{</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">}</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc <span class="token function">wait</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span></span></span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>此外，OpenACC还支持检查异步计算是否是在没有阻塞的情况下完成的。这只能用<br> 库函数来实现。acc_async_test（int）检查所给出的ID内核是否已经执行完毕，而<br> acc_async_test_all检测所有的异步命令是否都已经完成。如果所有的异步命令已经完成，<br> 就返回一个非零值；否则，返回零。</p></li><li><p>注意可以将多个子句进行组合。例如，下面的#pragma指令将一个内核区域标记为异<br> 步的，但只有在N＞128的加速器上才能执行。对于这个例子，if子句应用于内核指令，但<br> 不是内核指令的异步性。<code>#pragma acc kernels if(N &gt; 128) async</code></p></li></ul><h4 id="_8-8-1-2-并行指令的使用" tabindex="-1"><a class="header-anchor" href="#_8-8-1-2-并行指令的使用" aria-hidden="true">#</a> 8.8.1.2 并行指令的使用</h4><ul><li><p>内核指令及其相关的子句对应用程序的加速来说是一个很强大的工具，使用它们可以<br> 让你对应用程序的实际执行有较少的控制。OpenACC编译器会自动分析代码并选择一个<br> 合适的并行策略，这只需要你进行很少的参与。为了解决这个问题，OpenACC添加了另<br> 一个类似于内核的指令，但这个指令提供了更多的执行控制：#pragma acc并行指令。内核<br> 指令允许编译器将标记代码分组到尽可能多的加速器内核中，该内核中包含编译器认为所<br> 有必要的并行部分。在使用一个并行指令时，所有的gang和worker都在并行区域的开始位<br> 置启动，在末尾处停止执行。尽管编译器可以基于你的指令在多种执行模式之间进行转<br> 换，但它不能调整在并行区域中间位置的并行维度。与CUDA中一样，这使你可以完全掌<br> 控并行性的创建。</p></li><li><p>异步并行指令支持那些解释一部分内核指令的子句，如if子句、async子句和wait子<br> 句。此外，并行指令还支持以下子句：使用num_gangs（int）设置gang的数量，用<br> num_workers（int）设置worker的数量，以及用vector_length（int）设置每个worker的向量<br> 宽度。你应该熟悉在CUDA中配置线程块的数量和每个块中线程的数量，这里只不过多了<br> 一个维度。并行指令还支持reduction子句。一旦一个并行区域执行结束，reduction子句就<br> 会自动将每个gang的输出结合起来，处理成一个单一值进行输出，一旦并行指定完成就可<br> 以获得这个值。reduciton子句需要一个运算和一个变量列表来实现，它们之间用冒号隔<br> 开：<code>#pragma acc parallel reduction(op:var1,var2,...)</code></p></li><li><p>在并行区域的每个gang中每个变量都有一个变量副本var1，var2…，将其初始化为一<br> 个默认的、运算指定的初始值。当并行区域执行结束时，每个gang中的副本都执行运算<br> op，并将运算结果作为最终结果进行输出。例如，如果你想通过gang对变量result求和，可<br> 以使用以下命令：<code>#pragma acc parallel reduction(+:result)</code></p></li><li><p>OpenACC支持各种简化运算符，包括+、*、max、min、&amp;、|、^、&amp;&amp;以及||。</p></li><li><p>在CUDA中，reduction子句将通过在__shared__内存中存储一个标量来完成实现，从每<br> 个线程块不断更新它的值，并且在内核结束时使用原子操作将每个线程块写入的值进行结<br> 合。这比使用reduction子句需要更多的编程工作，但却使之更可控、更具有可自定义性<br> （例如，通过启用自定义原子操作）。</p></li><li><p>并行指令中也可以使用private和firstprivate子句。private和firstprivate子句运用变量列<br> 表。当使用private时，会为每个gang创建一个private型复制变量。只有该gang可以使用该<br> 变量的拷贝，因此该值的改变对其他gang或主机应用程序是不可见的。例如，下面的代码<br> 段：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">int</span> a<span class="token punctuation">;</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc parallel <span class="token keyword">private</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span></span></span>
<span class="token punctuation">{</span>
 a <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>并行区域中的每个gang将a的复制变量设为不同的值。这些值对其他gang或主机应用<br> 程序是不可见的。从概念上讲，你可以认为它类似于CUDA中的__shared__内存变量。</p></li><li><p>firstprivate子句与private子句功能相同，但是要将每个gang中的private型变量的值初始<br> 化为主机上该变量的当前值。代码段如下：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">int</span> a <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">;</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc parallel <span class="token function">firstprivate</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span></span></span>
<span class="token punctuation">{</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>并行区域中的每个gang会以a的值被设置为5的复制变量开始。对于每个gang来说，对a<br> 的任何更改都是private型。</li></ul><h4 id="_8-8-1-3-循环指令的使用" tabindex="-1"><a class="header-anchor" href="#_8-8-1-3-循环指令的使用" aria-hidden="true">#</a> 8.8.1.3 循环指令的使用</h4><ul><li>并行指令的挑战是，需要你为要加速的编译器明确标注并行性。并行区域总是以gang<br> 冗余模式开始的。执行并行模式之间的转换（如gang分裂模式或work分裂模式）需要对有<br> 更高并行期望水平的编译器有明确的指示。这是通过使用#pragma acc循环指令标记并行循<br> 环来完成的，你可以直接对该循环所使用的执行模式进行操作。例如，你可以用之前使用<br> 的并行指令和循环指令实现较早的simple-kerhcls示例，目的是将包含的循环标记为可并行<br> 的（如下所示）：本示例的完整代码可以在Wrox.com中的simple-parallel.c中找到。</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc parallel</span></span>
 <span class="token punctuation">{</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc loop</span></span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 C<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> A<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> B<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc loop</span></span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 D<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> C<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">*</span> A<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 <span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>由于在这个例子中没有为循环指令添加子句，所以编译器可以自由使用它认为最优的<br> 任何循环调度。程序员也可以通过对循环指令添加gang、worker或vector子句显式地控制<br> 每一级的并行性。当在循环指令中添加了以上列出的一个或多个子句时，这个循环在各自<br> 的维度上就可以并行执行了。例如，考虑以下代码段：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc parallel</span></span>
<span class="token punctuation">{</span>
 <span class="token keyword">int</span> b <span class="token operator">=</span> a <span class="token operator">+</span> c<span class="token punctuation">;</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc loop gang</span></span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
 <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>这里，并行区域以gang冗余模式开始。当遇到循环指令时，由于gang子句的存在，执<br> 行会切换至gang分裂模式。</p></li><li><p>然而，循环指令不是仅在一个并行区域内有效。它也可以与内核指令相结合，为编译<br> 器标记并行循环，目的是将其变成加速器内核。然而，其子句的意义因上下文的不同而有<br> 所差别。表8-5列出了可应用于循环指令的子句，以及依赖于它们在并行内部或内核区域<br> 使用时含义的变化。<br><img src="`+x+`" alt="table8-5" loading="lazy"></p></li><li><p>你也可以把并行或内核循环指令结合到一个pragma中：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc parallel loop</span></span>
<span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">}</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc kernels loop</span></span>
<span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">}</span>

这些只是扩展并行指令和内核指令的语法修改，后面紧跟着一个循环指令：
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc parallel</span></span>
<span class="token punctuation">{</span>
 <span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc loop</span></span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
 <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc kernels</span></span>
<span class="token punctuation">{</span>
 <span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc loop</span></span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
 <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_8-8-1-4-openacc计算指令小结" tabindex="-1"><a class="header-anchor" href="#_8-8-1-4-openacc计算指令小结" aria-hidden="true">#</a> 8.8.1.4 OpenACC计算指令小结</h4><ul><li><p>本节涵盖了一系列可用于在加速器中并行化代码计算区域的OpenACC子句和指令。<br> kernels指令是自动执行的，允许编译器自动将一段代码转为并行执行且不需要人为参与，<br> 但parallel指令则需要更多的人为参与来决定如何将一段代码并行化。在这两种情况下，<br> 循环指令可用于告诉编译器如何将循环体并行化。</p></li><li><p>本节给出了在OpenACC中为了将计算映射给加速器提供的综合性相关说明，但你可<br> 能注意到，本节并没有指明主机应用程序及其加速器之间是如何通信的。parallel指令和<br> kernels指令可以自动完成两者之间所有的转换工作。那么在OpenACC中，是如何使用data<br> 指令和附加子句来优化主机和加速器之间的通信的呢？下一节将围绕这个话题展开讨论。</p></li></ul><h3 id="_8-8-2-openacc数据指令的使用" tabindex="-1"><a class="header-anchor" href="#_8-8-2-openacc数据指令的使用" aria-hidden="true">#</a> 8.8.2 OpenACC数据指令的使用</h3><ul><li>在编写OpenACC程序时，你可能对数据转移问题毫不关心。但是，这样做会让<br> OpenACC进行了很多不必要的通信从而使性能显著下降。本节将介绍#pragma acc data指令<br> 是如何显式地在主机和OpenACC加速器之间进行通信的。你还将了解到可用于并行指令<br> 和内核指令的相关数据子句。</li></ul><h4 id="_8-8-2-1-数据指令的使用" tabindex="-1"><a class="header-anchor" href="#_8-8-2-1-数据指令的使用" aria-hidden="true">#</a> 8.8.2.1 数据指令的使用</h4><ul><li><p>在OpenACC中，#pragma acc data被显式地用于在主机应用程序和加速器之间传输数<br> 据，类似于CUDA中的cudaMemcpy。与kernels和parallel指令类似，数据被应用到代码的某<br> 个区域。它定义了在该区域边界处必须进行的数据传输工作。例如，可以把一个变量标记<br> 为copyin，也就是说，可以将这个变量在该区域的起始位置传送给加速器，但最后不能传<br> 出。相反地，copyout是在数据区的末端将该变量传回主机端，但不能在该数据区域的起<br> 始位置将其传给加速器。</p></li><li><p>你可以从Wrox.com中下载simple-data.c进行学习。simple-data.c是simple-parallel.c的扩<br> 展。核心代码如下：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc data <span class="token function">copyin</span><span class="token punctuation">(</span>A<span class="token punctuation">[</span><span class="token number">0</span><span class="token operator">:</span>N<span class="token punctuation">]</span><span class="token punctuation">,</span> B<span class="token punctuation">[</span><span class="token number">0</span><span class="token operator">:</span>N<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token function">copyout</span><span class="token punctuation">(</span>C<span class="token punctuation">[</span><span class="token number">0</span><span class="token operator">:</span>N<span class="token punctuation">]</span><span class="token punctuation">,</span> D<span class="token punctuation">[</span><span class="token number">0</span><span class="token operator">:</span>N<span class="token punctuation">]</span><span class="token punctuation">)</span></span></span>
 <span class="token punctuation">{</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc parallel</span></span>
 <span class="token punctuation">{</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc loop</span></span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 C<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> A<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> B<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc loop</span></span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 D<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> C<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">*</span> A<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 <span class="token punctuation">}</span>
 <span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>所添加的#pragma acc data指令通知编译器：只有A和B应该拷贝到设备端，只有C和D<br> 应该拷贝回来。该段代码还指明了传输数组的范围，在这种情况下，传输的应该是整个数<br> 组。在某些情况下，编译器能够推断出要复制的数组大小，这能略微简化代码：<br><code>#pragma acc data copyin(A, B) copyout(C, D)</code></p></li><li><p>以上修改的结果是，与没有使用数据指令的传输过程相比，要传输的字节数减少了一<br> 半。</p></li><li><p>除了数据指令，在执行过程中也可以用#pragma acc enter data和#pragma acc exit data来<br> 标记任意节点传入和传出加速器的数组。当编译器遇到enter data指令时，它会指明哪些数<br> 据应该复制到设备端。这些数据将继续留在设备端，直到编译器遇到将其传回的exit data<br> 指令或者程序终止执行。当与async子句和wait子句相结合时，enter data指令和exit data指<br> 令能够发挥最大的作用。注意，data指令不支持async子句和wait子句。</p></li><li><p>当把async子句应用到enter data和exit data指令中时，它会创建将数据传入或传出加速<br> 器的异步传输任务，类似于cudaMemcpyAsync。正如在CUDA中异步拷贝是很有用的一<br> 样，作为一种重叠计算和通信的方法，在OpenACC中它也是很有用的。当把wait子句应用<br> 到enter data和exit data指令中时，它的作用与在kernels指令或parallel指令中一样：通信指<br> 令要等待其他异步任务结束后再执行。需要注意的是通信指令（即enter data和exit data指<br> 令）可以使用async和wait子句来交互异步计算任务（即kernels指令和parallel指令），反之<br> 亦然。参考下面的代码段：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">int</span> <span class="token operator">*</span>A <span class="token operator">=</span> <span class="token function">init_data</span><span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">int</span> <span class="token operator">*</span>B <span class="token operator">=</span> <span class="token function">init_more_data</span><span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">do_some_heavy_work</span><span class="token punctuation">(</span>C<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc data <span class="token function">copyin</span><span class="token punctuation">(</span>B<span class="token punctuation">[</span><span class="token number">0</span><span class="token operator">:</span>N<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token function">copyout</span><span class="token punctuation">(</span>A<span class="token punctuation">[</span><span class="token number">0</span><span class="token operator">:</span>N<span class="token punctuation">]</span><span class="token punctuation">)</span></span></span>
<span class="token punctuation">{</span>
 <span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc kernels</span></span>
 <span class="token punctuation">{</span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 A<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">do_work</span><span class="token punctuation">(</span>B<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
 <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token function">do_lots_more_work</span><span class="token punctuation">(</span>D<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>这里，data指令将B传送到设备端，然后将A传输回来。但是，由于data指令使用的是<br> 同步传输，所以这个应用程序必须停止并且等待要传送的潜在的大数组。如果用async子<br> 句代替enter data和exit data指令，那么do_some_heavy_work和do_lots_more_work中的通信<br> 开销可以被隐藏：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">int</span> <span class="token operator">*</span>A <span class="token operator">=</span> <span class="token function">init_data</span><span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">int</span> <span class="token operator">*</span>B <span class="token operator">=</span> <span class="token function">init_more_data</span><span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// copy B to the accelerator asynchronously, with ID 0</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc enter data <span class="token function">copyin</span><span class="token punctuation">(</span>B<span class="token punctuation">[</span><span class="token number">0</span><span class="token operator">:</span>N<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token function">async</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></span></span>
<span class="token comment">// do work on the host</span>
<span class="token function">do_some_heavy_work</span><span class="token punctuation">(</span>C<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// execute this block of code asynchronously on the accelerator.</span>
<span class="token comment">// use wait(0) to ensure that it waits for the transfer of B to complete first.</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc kernels <span class="token function">async</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token function">wait</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></span></span>
<span class="token punctuation">{</span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 A<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">do_work</span><span class="token punctuation">(</span>B<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token comment">// copy A back to the host after the kernels region finishes</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc exit data <span class="token function">copyout</span><span class="token punctuation">(</span>A<span class="token punctuation">[</span><span class="token number">0</span><span class="token operator">:</span>N<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token function">async</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token function">wait</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span></span></span>
<span class="token comment">// do work on the host</span>
<span class="token function">do_lots_more_work</span><span class="token punctuation">(</span>D<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// wait for the transfer of A to finish</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression"><span class="token function">wait</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span></span></span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>这里，enter data指令用于将B异步传输到设备端，与do_some_heavy_work的作用相<br> 同。然后，内核指令使用wait子句来确保B的异步拷贝已经完成，并启动一个异步计算任<br> 务。随后，exit data指令用来将A异步地传回，与do_lots_more_work的作用相同，但要先<br> 等待内核区域执行结束。最后，必须使用一个wait指令确保A已经传送回主机端。</p></li><li><p>与kernels指令和parallel指令类似，data指令支持和共享多种子句。表8-6列出了data指<br> 令所支持的子句以及支持这些子句的指令。<br><img src="`+N+`" alt="table8-6" loading="lazy"></p></li></ul><h4 id="_8-8-2-2-为内核指令和并行指令添加data子句" tabindex="-1"><a class="header-anchor" href="#_8-8-2-2-为内核指令和并行指令添加data子句" aria-hidden="true">#</a> 8.8.2.2 为内核指令和并行指令添加data子句</h4><ul><li><p>通常情况下，由于输入和输出数据都是在计算区域之前或之后进行传输的，所以数据<br> 指令与计算指令紧密相关。尽管可以对每个任务使用独立的指令，但OpenACC还是支持<br> 使用计算指令上的data子句来简化代码。</p></li><li><p>例如，考虑前面提到的simple-data.c中的核心逻辑：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc data <span class="token function">copyin</span><span class="token punctuation">(</span>A<span class="token punctuation">[</span><span class="token number">0</span><span class="token operator">:</span>N<span class="token punctuation">]</span><span class="token punctuation">,</span> B<span class="token punctuation">[</span><span class="token number">0</span><span class="token operator">:</span>N<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token function">copyout</span><span class="token punctuation">(</span>C<span class="token punctuation">[</span><span class="token number">0</span><span class="token operator">:</span>N<span class="token punctuation">]</span><span class="token punctuation">,</span> D<span class="token punctuation">[</span><span class="token number">0</span><span class="token operator">:</span>N<span class="token punctuation">]</span><span class="token punctuation">)</span></span></span>
 <span class="token punctuation">{</span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc parallel</span></span>
 <span class="token punctuation">{</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
 <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>可以为并行指令添加一个data子句而不是保留两个分离的编译器指令：</li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc parallel <span class="token function">copyin</span><span class="token punctuation">(</span>A<span class="token punctuation">[</span><span class="token number">0</span><span class="token operator">:</span>N<span class="token punctuation">]</span><span class="token punctuation">,</span> B<span class="token punctuation">[</span><span class="token number">0</span><span class="token operator">:</span>N<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token function">copyout</span><span class="token punctuation">(</span>C<span class="token punctuation">[</span><span class="token number">0</span><span class="token operator">:</span>N<span class="token punctuation">]</span><span class="token punctuation">,</span> D<span class="token punctuation">[</span><span class="token number">0</span><span class="token operator">:</span>N<span class="token punctuation">]</span><span class="token punctuation">)</span></span></span>
<span class="token punctuation">{</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>这种改变简化了源代码，并且更容易看到的是，并行区域和数据传输是相关联的。</p></li><li><p>内核指令和并行指令都支持表8-6中列举的copy，copy in，copy out，create，present，<br> present_or_copy，present_or_copyin，present_or_copyout，present_or_create和deviceptr子句。</p></li></ul><h3 id="_8-8-3-openacc运行时api" tabindex="-1"><a class="header-anchor" href="#_8-8-3-openacc运行时api" aria-hidden="true">#</a> 8.8.3 OpenACC运行时API</h3><ul><li><p>除了编译器指令，OpenACC也提供了一个函数库。在介绍async和wait子句时已经有<br> 所提及：函数acc_async_wait、acc_async_wait_all、acc_async_test和acc_async_test_all都是<br> OpenACC运行时API的一部分。使用OpenACC运行时API中的函数要求添加头文件<br> openacc.h。</p></li><li><p>许多用OpenACC编写的程序完全可以不使用OpenACC运行时API，因为在许多情况<br> 下，编译器指令就可以提供其所需要的功能。不过，仍然有一些由运行时API提供的操作<br> 是OpenACC编译器指令不能提供的。</p></li><li><p>OpenACC运行时API函数可分成4个方面：设备管理、异步控制、运行时初始化和内<br> 存管理。本节不会对运行时API的所有函数都进行介绍，而是着重介绍一些比较有用的函<br> 数。</p></li><li><p>设备管理函数允许你显式控制使用哪个加速器或加速器类型来执行OpenACC计算区<br> 域。许多设备管理函数使用acc_device_t类型，这是一个枚举类型，它代表了由OpenACC<br> 实现所支持的不同设备类型。最低限度，所有的OpenACC实现必须支持acc_device_none、<br> acc_device_default、acc_device_host和acc_device_not_host类型，当然也可以支持其他类<br> 型，例如，PGI 14.4支持以下设备类型：</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token keyword">typedef</span> <span class="token keyword">enum</span> <span class="token punctuation">{</span>
 acc_device_none <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span>
 acc_device_default <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>
 acc_device_host <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>
 acc_device_not_host <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span>
 acc_device_nvidia <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">,</span>
 acc_device_radeon <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span>
 acc_device_xeonphi <span class="token operator">=</span> <span class="token number">6</span><span class="token punctuation">,</span>
 acc_device_pgi_opencl <span class="token operator">=</span> <span class="token number">7</span><span class="token punctuation">,</span>
 acc_device_nvidia_opencl <span class="token operator">=</span> <span class="token number">8</span><span class="token punctuation">,</span>
 acc_device_opencl <span class="token operator">=</span> <span class="token number">9</span>
<span class="token punctuation">}</span> acc_device_t<span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>表8-7列出了一些设备管理函数<br><img src="`+F+'" alt="table8-7" loading="lazy"></p></li><li><p>异步控制函数允许你检查或等待异步操作的执行状态。异步操作包括使用并行指令和<br> 内核指令创建的异步计算和使用OpenACC数据指令创建的异步通信。表8-8中给出了一些<br> 异步控制函数。<br><img src="'+G+'" alt="table8-8" loading="lazy"></p></li><li><p>运行时初始化函数用来初始化或管理OpenACC的内部状态。表8-9中给出了一些运行<br> 时初始化函数。如果acc_init没有被OpenACC的应用程序显式调用，那么运行时初始化自<br> 动作为应用程序的第一个OpenACC操作来执行。<br><img src="'+O+'" alt="table8-9" loading="lazy"></p></li><li><p>内存管理函数用于管理加速器内存分配以及在主机和加速器之间的数据传输。因此，<br> 在许多情况下，它们的功能与OpenACC的数据指令和子句相同。表8-10中给出了一些内存<br> 管理函数。<br><img src="'+L+'" alt="table8-10" loading="lazy"></p></li></ul><h3 id="_8-8-4-openacc和cuda库的结合" tabindex="-1"><a class="header-anchor" href="#_8-8-4-openacc和cuda库的结合" aria-hidden="true">#</a> 8.8.4 OpenACC和CUDA库的结合</h3>',204),Q=n("br",null,null,-1),$=n("br",null,null,-1),q=n("br",null,null,-1),Z={href:"http://xn--Wrox-z25f52b20sy1wjb2855bled51k0xc.xn--comcuda-openacc-nj3xra68621a.cu",target:"_blank",rel:"noopener noreferrer"},j=n("br",null,null,-1),J=t(`<p>1.使用cudaMalloc为矩阵分配设备内存，使用curandCreateGenerator和cublasCreate为<br> cuRAND和CUBLAS库创建句柄。<br> 2.cuRAND库中的curandGenerateUniform函数产生的随机数据对设备内存中的输入矩阵<br> 进行填充。<br> 3.使用OpenACC指令，在GPU上并行执行两个矩阵间的乘法。<br> 4.cublasSasum用于计算输出矩阵中所有元素的总和。<br> 5.使用cudaFree释放设备内存。</p><ul><li><p>用PGI OpenACC编译器对cuda-openacc.cu进行编译，命令如下：<br><code>$ pgcpp -acc cuda-openacc.cu -o cuda-openacc -Minfo=accel \\ -L\${CUDA_HOME}/lib64 -lcurand -lcublas –lcudart</code></p></li><li><p>注意，这里的C++编译器pgcpp与CUDA库是兼容的。保留-acc参数以支持OpenACC，-Minfo=accel用来表示在OpenACC并行计算区域内的诊断信息。此外，将CUDA库<br> 的路径应添加到编译器的库路径中，以便编译器可以找到cuRAND，cuBLAS和CUDA运行<br> 时函数的定义。此命令的输出如下所示</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code>main<span class="token operator">:</span>
 <span class="token number">70</span><span class="token punctuation">,</span> Accelerator kernel generated
 <span class="token number">70</span><span class="token punctuation">,</span> #pragma acc loop gang <span class="token comment">/* blockIdx.x */</span>
 <span class="token number">72</span><span class="token punctuation">,</span> #pragma acc loop <span class="token function">vector</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">worker</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span> <span class="token comment">/* threadIdx.x threadIdx.
 70, Generating Tesla code
 72, Loop is parallelizable
 74, Loop is parallelizable
</span></code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p>需要注意的是内核是在70和72行的循环上产生的，包括使用gang并行的外层循环和使<br> 用worker及vector并行的内部循环。</p></li><li><p>在学习完CUDA库和OpenACC的全部章节后，大部分代码对你来说应该都很熟悉了，<br> 只有两点可能还比较陌生。</p></li><li><p>第一点，deviceptr子句是在并行指令中使用的。deviceptr允许一个应用程序显式地分<br> 配和管理自己的设备内存，然后直接将其传递给OpenACC计算区域。在这种情况下，在<br> 用cuRAND填充数据之前，cuda-openacc应用程序会用cudaMalloc显式地分配自己的设备内<br> 存。然后，使用deviceptr给OpenACC内核提供相同设备内存的直接访问权，而不必在使用<br> copyin之前将其传回主机。deviceptr是允许OpenACC和其他GPU编程框架相结合的一个关<br> 键组成部分。</p></li><li><p>第二点，示例cuda-openacc.cu中也使用了cublasSetPointerMode来衡量cuBLAS函数是否<br> 使用主机或设备的指针来返回标量结果。在这种情况下，cublasSasum返回一个标量结果<br> 作为它的最后一个参数。最初，在设备端对输出矩阵的行进行求和时，cublasSetPointerMode用来将模式设置为CUBLAS_POINTER_MODE_DEVICE。<br> 当执行最终的跨行求和时，模式切换为CUBLAS_POINTER_MODE_HOST，返回地址为主机应用程序地址空间<br> 中的一个变量。你可能还记得一个关于这个函数的cuSPARSE版本的简要介绍，<br> cusparseSetPointerMode，在8.2.4节中有所介绍.</p></li></ul><h3 id="_8-8-5-openacc小结" tabindex="-1"><a class="header-anchor" href="#_8-8-5-openacc小结" aria-hidden="true">#</a> 8.8.5 OpenACC小结</h3><ul><li><p>本节介绍了OpenACC的执行和编程模型。OpenACC是一个灵活的、易于使用的、高<br> 性能的编程模型，它在许多方面对CUDA和CUDA库进行了补充。与CUDA库相比，<br> OpenACC的使用更加灵活，允许你使用C语言编写自己的计算函数。与CUDA相比，<br> OpenACC的使用更为方便，在通信和计算方面比CUDA C需要更少的人为参与。</p></li><li><p>但是，OpenACC也有一些缺点。一个忽略数据移动的简单的OpenACC实现往往会由<br> 于不必要的内存拷贝而使性能降低。在默认情况下OpenACC对优化策略是保守的。即便<br> 使用async，copyin和copyout子句，OpenACC的性能表现往往落后于手动编码的CUDA程<br> 序。此外，在许多领域中，OpenACC在性能和可用性上根本无法与CUDA库相抗衡。</p></li><li><p>虽然有这些缺点，但OpenACC的性能、可用性和可定制性间的平衡使之成为非常有<br> 吸引力的编程模型，是对有高性能GPU应用程序快速开发的CUDA程序的补充。</p></li></ul><h2 id="_8-9-总结" tabindex="-1"><a class="header-anchor" href="#_8-9-总结" aria-hidden="true">#</a> 8.9 总结</h2><ul><li><p>通过本章的学习，你可以利用cuSPARSE，cuBLAS，cuFFT，cuRAND和OpenACC来<br> 加速应用程序开发过程。</p></li><li><p>CUDA库在简单性、易用性、可移植性及性能方面有很好的表现。它们是由领域内的<br> 专家根据他们的经验专门设计的。不需要大量自定义的应用程序可以将这些库及其组件函<br> 数作为GPU加速应用程序的基本构件来使用。</p></li><li><p>更重要的是，专注于通用工作流、抽象概念及库之间共享的移植过程使你能在本章之<br> 外继续学习，去探索更多更先进的理念以及全新的CUDA库。本章中介绍的库是根据其应<br> 用范围有选择进行介绍的，因此只能对CUDA库进行简略的介绍。</p></li><li><p>另一方面，与CUDA库相比，OpenACC给了编程人员更多对GPU的控制权，同时省去<br> 了许多GPU编程中普通的任务。在OpenACC中，由CUDA API支持的许多相同操作可以用<br> 引导自动并行的编译器指令来执行。事实上，本书中大部分与性能相关的课程同时适用于<br> CUDA和OpenACC。此外，你可以用一个更直观的形式（类似于串行的主机端代码）编写<br> 自定义的GPU内核。OpenACC相比于CUDA降低了复杂程度并相比于CUDA库提高了灵活<br> 性。</p></li><li><p>总体来说，本章主要从一个更抽象的硬件视角介绍了CUDA之上的框架，使你能够使<br> 用更少的代码，获得更好的性能。如果你的应用程序在CUDA库所覆盖的范围内执行，那<br> 么在CUDA专家编写的核函数及兼容的API的帮助下，能有效简化你的开发工作并能获得<br> 更好的性能。通过减少手动编写的代码使其自动执行内存管理、任务分配及并行化处理，<br> OpenACC加速了CUDA内核的发展进程。</p></li></ul><h2 id="_8-10-习题" tabindex="-1"><a class="header-anchor" href="#_8-10-习题" aria-hidden="true">#</a> 8.10 习题</h2><ul><li><p>1.下列cuBLAS工作流中缺少了哪一步：<br> （1）按列优先的顺序从数据文件中读取输入数据。<br> （2）用cudaMalloc分配设备内存。<br> （3）用cublasCreate配置一个cuBLAS句柄。<br> （4）用cublasSgemm执行矩阵和矩阵间的乘法。<br> （5）用cudaGetMatrix取回结果。</p></li><li><p>2.写一个函数，输入一个行为M列为N的稠密矩阵A，并使用cuSPARSE的格式转换函<br> 数将其转换为COO格式。假设这不是一个较大矩阵的子矩阵，你的函数原型应该是：<br><code>void dense2coo(float *M, int M, int N, float **values, int **row_indices, int **col_indices);</code></p></li><li><p>3.在cusparse.cu中使用随机矩阵生成函数generate_random_dense_matrix随机生成两个稠<br> 密矩阵，并使用cuSPARSE执行矩阵和矩阵间的乘法。</p></li><li><p>4.修改第3题的代码，以实现在双精度浮点数值上进行操作。需要注意的是，这些修<br> 改需要对数据初始化、存储和使用cuSPARSE函数。使用nvprof来检测和解释性能差异。</p></li><li><p>5.使用cublas.cu中的generate_random_dense_matrix函数。首先，对外循环重排以遍历行<br> 和列（与现在正在操作的步骤的相反），无须修改用于引用数组A的索引，使用第7章<br> nbody.cu示例中的第二个函数去比较修改前后的generate_random_dense_matrix的执行时间。<br> 如果没有显著差异，尝试增加M或N的值。你有什么发现？是什么原因导致这种性能差<br> 异？接下来，修改引用数组A的索引，以使数组按行优先顺序进行排列，重新对性能进行<br> 测试。又有什么变化？原因是什么？</p></li><li><p>6.使用一个cuBLAS Level 3函数和cublas.cu中的generate_random_dense_matrix函数，执<br> 行矩阵和矩阵间的乘法。</p></li><li><p>7.在第6题编写的代码中添加CUDA流，你只能使用异步函数在主机和设备之间传输数<br> 据（例如，cublasSetMatrixAsync、cublasGetMatrixAsync）。回想一下可知，cuBLAS中所<br> 有的可执行函数默认都是异步的。</p></li><li><p>8.cuFFT支持正向和反向的FFT。在本章的cufft.cu例子中，cufftExecC2C接收<br> CUFFT_FORWARD作为其最后一个参数，以表明需要一个正向FFT。为了在其后添加一个<br> 反向操作，你需要向该示例程序中添加什么？当这样操作后，输出会发生什么样的变化？<br> 这些新的输出与原来的样本设计是如何建立联系的？记住，FFT往往需要标准化，FFT会<br> 保留信号中的频率信息，但不会保留振幅信息。</p></li><li><p>9.伪随机和拟随机生成的随机数序列之间有什么区别？</p></li><li><p>10.考虑一个你过去用过的使用随机数的应用程序，使用伪随机数生成器或拟随机数<br> 生成器的应用程序其行为会有何不同？</p></li><li><p>11.考虑一个在多GPU上执行的大规模矩阵加法运算，尽管你没有看见过多设备执行<br> 的CUDA API，你是如何理解多个独立的地址空间对类似于内存分配或数据传输等任务的<br> 影响的？你会如何对在多个GPU上执行向量加法中的任务进行分配呢？你对多GPU库的实<br> 现有什么见解？通过结合cudaMalloc和cudaMemcpy，并为这些CUDA操作指定一个目标设<br> 备，你会怎么设计像cufftXtMalloc和cufftXtMemcpy一样的函数？</p></li><li><p>12.给出以下OpenACC术语的定义：gang冗余模式，gang分裂模式，单一worker模式，<br> worker分裂模式。</p></li><li><p>13.比较OpenACC中的并行指令和内核编译器指令，尤其要对可编程性及性能进行讨论。</p></li><li><p>14.OpenACC中的循环编译器指令是如何使用的？在下面的例子中使用该指令，使其<br> 在执行循环体时能达到最大的并行性。</p></li></ul><div class="language-cpp line-numbers-mode" data-ext="cpp"><pre class="language-cpp"><code><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">pragma</span> <span class="token expression">acc parallel</span></span>
<span class="token punctuation">{</span>
 <span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
 <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,11);function nn(an,sn){const p=o("router-link"),c=o("ExternalLinkIcon");return i(),u("div",null,[M,T,r(" more "),n("nav",B,[n("ul",null,[n("li",null,[s(p,{to:"#简单介绍主要是基础"},{default:e(()=>[a("简单介绍主要是基础")]),_:1})]),n("li",null,[s(p,{to:"#第8章-gpu加速库和openacc"},{default:e(()=>[a("第8章 GPU加速库和OpenACC")]),_:1})]),n("li",null,[s(p,{to:"#_8-1-cuda库概述"},{default:e(()=>[a("8.1 CUDA库概述")]),_:1}),n("ul",null,[n("li",null,[s(p,{to:"#_8-1-1-cuda库支持的作用域"},{default:e(()=>[a("8.1.1 CUDA库支持的作用域")]),_:1})]),n("li",null,[s(p,{to:"#_8-1-2-通用的cuda库工作流"},{default:e(()=>[a("8.1.2 通用的CUDA库工作流")]),_:1})])])]),n("li",null,[s(p,{to:"#_8-2-cusparse库"},{default:e(()=>[a("8.2 cuSPARSE库")]),_:1}),n("ul",null,[n("li",null,[s(p,{to:"#_8-2-1-cusparse数据存储格式"},{default:e(()=>[a("8.2.1 cuSPARSE数据存储格式")]),_:1})]),n("li",null,[s(p,{to:"#_8-2-2-用cusparse进行格式转换"},{default:e(()=>[a("8.2.2 用cuSPARSE进行格式转换")]),_:1})]),n("li",null,[s(p,{to:"#_8-2-3-cusparse功能示例"},{default:e(()=>[a("8.2.3 cuSPARSE功能示例")]),_:1})]),n("li",null,[s(p,{to:"#_8-2-4-cusparse发展中的重要主题"},{default:e(()=>[a("8.2.4 cuSPARSE发展中的重要主题")]),_:1})]),n("li",null,[s(p,{to:"#_8-2-5-cusparse小结"},{default:e(()=>[a("8.2.5 cuSPARSE小结")]),_:1})])])]),n("li",null,[s(p,{to:"#_8-3-cublas库"},{default:e(()=>[a("8.3 cuBLAS库")]),_:1}),n("ul",null,[n("li",null,[s(p,{to:"#_8-3-1-管理cublas数据"},{default:e(()=>[a("8.3.1 管理cuBLAS数据")]),_:1})]),n("li",null,[s(p,{to:"#_8-3-2-cublas功能示例"},{default:e(()=>[a("8.3.2 cuBLAS功能示例")]),_:1})]),n("li",null,[s(p,{to:"#_8-3-3-cublas发展中的重要主题"},{default:e(()=>[a("8.3.3 cuBLAS发展中的重要主题")]),_:1})]),n("li",null,[s(p,{to:"#_8-3-4-cublas小结"},{default:e(()=>[a("8.3.4 cuBLAS小结")]),_:1})])])]),n("li",null,[s(p,{to:"#_8-4-cufft库"},{default:e(()=>[a("8.4 cuFFT库")]),_:1}),n("ul",null,[n("li",null,[s(p,{to:"#_8-4-1-使用cufft-api"},{default:e(()=>[a("8.4.1 使用cuFFT API")]),_:1})]),n("li",null,[s(p,{to:"#_8-4-2-cufft功能示例"},{default:e(()=>[a("8.4.2 cuFFT功能示例")]),_:1})]),n("li",null,[s(p,{to:"#_8-4-3-cufft小结"},{default:e(()=>[a("8.4.3 cuFFT小结")]),_:1})])])]),n("li",null,[s(p,{to:"#_8-5-curand库"},{default:e(()=>[a("8.5 cuRAND库")]),_:1}),n("ul",null,[n("li",null,[s(p,{to:"#_8-5-1-拟随机数或伪随机数的选择"},{default:e(()=>[a("8.5.1 拟随机数或伪随机数的选择")]),_:1})]),n("li",null,[s(p,{to:"#_8-5-2-curand库概述"},{default:e(()=>[a("8.5.2 cuRAND库概述")]),_:1})]),n("li",null,[s(p,{to:"#_8-5-3-curand介绍"},{default:e(()=>[a("8.5.3 cuRAND介绍")]),_:1})]),n("li",null,[s(p,{to:"#_8-5-4-curand发展中的重要主题"},{default:e(()=>[a("8.5.4 cuRAND发展中的重要主题")]),_:1})])])]),n("li",null,[s(p,{to:"#_8-6-cuda6-0中函数库的介绍"},{default:e(()=>[a("8.6 CUDA6.0中函数库的介绍")]),_:1}),n("ul",null,[n("li",null,[s(p,{to:"#_8-6-1-drop-in库"},{default:e(()=>[a("8.6.1 Drop-In库")]),_:1})]),n("li",null,[s(p,{to:"#_8-6-2-多gpu库"},{default:e(()=>[a("8.6.2 多GPU库")]),_:1})])])]),n("li",null,[s(p,{to:"#_8-7-cuda函数库的性能研究"},{default:e(()=>[a("8.7 CUDA函数库的性能研究")]),_:1}),n("ul",null,[n("li",null,[s(p,{to:"#_8-7-1-cusparse与mkl的比较"},{default:e(()=>[a("8.7.1 cuSPARSE与MKL的比较")]),_:1})]),n("li",null,[s(p,{to:"#_8-7-2-cublas与mkl-blas的比较"},{default:e(()=>[a("8.7.2 cuBLAS与MKL BLAS的比较")]),_:1})]),n("li",null,[s(p,{to:"#_8-7-3-cufft与fftw及mkl的比较"},{default:e(()=>[a("8.7.3 cuFFT与FFTW及MKL的比较")]),_:1})]),n("li",null,[s(p,{to:"#_8-7-4-cuda库性能小结"},{default:e(()=>[a("8.7.4 CUDA库性能小结")]),_:1})])])]),n("li",null,[s(p,{to:"#_8-8-openacc的使用"},{default:e(()=>[a("8.8 OpenACC的使用")]),_:1}),n("ul",null,[n("li",null,[s(p,{to:"#_8-8-1-openacc计算指令的使用"},{default:e(()=>[a("8.8.1 OpenACC计算指令的使用")]),_:1})]),n("li",null,[s(p,{to:"#_8-8-2-openacc数据指令的使用"},{default:e(()=>[a("8.8.2 OpenACC数据指令的使用")]),_:1})]),n("li",null,[s(p,{to:"#_8-8-3-openacc运行时api"},{default:e(()=>[a("8.8.3 OpenACC运行时API")]),_:1})]),n("li",null,[s(p,{to:"#_8-8-4-openacc和cuda库的结合"},{default:e(()=>[a("8.8.4 OpenACC和CUDA库的结合")]),_:1})]),n("li",null,[s(p,{to:"#_8-8-5-openacc小结"},{default:e(()=>[a("8.8.5 OpenACC小结")]),_:1})])])]),n("li",null,[s(p,{to:"#_8-9-总结"},{default:e(()=>[a("8.9 总结")]),_:1})]),n("li",null,[s(p,{to:"#_8-10-习题"},{default:e(()=>[a("8.10 习题")]),_:1})])])]),E,n("ul",null,[n("li",null,[n("p",null,[a("在本书的写作期间，NVIDIA开发者社区（"),n("a",z,[a("developer.nvidia.com"),s(c)]),a("）收录了19个可供下载"),V,a(" 的GPU加速库文档。想要获取最新的列表，请前往NVIDIA开发者社区。表8-1列举了当前"),W,a(" 所有的GPU加速库以及它们的作用域。"),X,H])]),K]),Y,n("ul",null,[n("li",null,[a("尽管CUDA和OpenACC是相互独立的编程模型，但它们仍可在同一应用程序中使用。"),Q,a(" 这样就需要更改应用程序的编译方式，同时必须使用deviceptr子句来实现CUDA和"),$,a(" OpenACC之间的数据共享。本节所示的应用程序，在一个源文件中同时使用了CUDA库和"),q,a(" OpenACC。"),n("a",Z,[a("示例的应用程序可从Wrox.com上下载cuda-openacc.cu"),s(c)]),a("，cuda-openacc.cu可以分"),j,a(" 成以下几步：")])]),J])}const tn=l(I,[["render",nn],["__file","H-第八章.html.vue"]]);export{tn as default};
